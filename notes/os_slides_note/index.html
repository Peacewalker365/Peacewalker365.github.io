<!DOCTYPE html>
<html lang="en">
  <head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">

  <meta name="generator" content="Hugo 0.90.1" />
  <link rel="canonical" href="https://Peacewalker365.github.io/notes/os_slides_note/">

  
    
    <meta name="description" content="Memory Sharing  can we share memory between processors?  some page table entries need to be mapped to the same physical frames One can read, other can write?: yes, control bits can be diff Does the shared mem must be the same VA in the two processes?: no How can we know a shared mem can be reclaimed?: have a counter like a ref bit    Copy on Write  UNIX fork with copy on write  copy the parent page table entries to the child, and turn on a special bit called copy-on-write bit on both parent and child’s PTEs Notice this is a OS bit (unused bit modified by the OS), hardware don’t know what it is!">
  

  <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
  <link rel="manifest" href="/site.webmanifest">
  <link rel="mask-icon" href="/safari-pinned-tab.svg" color="#000000">
  <meta name="msapplication-TileColor" content="#ffffff">
  <meta name="theme-color" content="#ffffff">

  <link rel="stylesheet" type="text/css" href="/css/paper.css">

  
  
  <link rel="stylesheet" type="text/css" href="/css/custom.css">

  
  
  <title>Virtual Memory and Concurrency Note 2 | myStack</title>
</head>
  <body>
    <div class="container paper">
      <nav class="border split-nav">
  <div class="nav-brand">
    <h3><a href="/">myStack</a></h3>
  </div>
  <div class="collapsible">
    <input id="collapsible1" type="checkbox" name="collapsible1">
    <button>
    <label for="collapsible1">
        <div class="bar1"></div>
        <div class="bar2"></div>
        <div class="bar3"></div>
      </label>
    </button>
    <div class="collapsible-body">
      <ul class="inline">
      
        <li><a href="/blogs/">Blog</a></li>
      
        <li><a href="/notes/">Note</a></li>
      
        <li><a href="/tags/">Tags</a></li>
      
        <li><a href="/about/">About</a></li>
      
        <li><a href="https://github.com/Peacewalker365">Github</a></li>
      
      </ul>
    </div>
  </div>
</nav>
      <main>
        

<h1>Virtual Memory and Concurrency Note 2</h1>
<h4 id="memory-sharing">Memory Sharing</h4>
<ul>
<li>can we share memory between processors?
<ul>
<li>some page table entries need to be mapped to the same physical frames</li>
<li>One can read, other can write?: yes, control bits can be diff</li>
<li>Does the shared mem must be the same VA in the two processes?: no</li>
<li>How can we know a shared mem can be reclaimed?: have a counter like a ref bit</li>
</ul>
</li>
</ul>
<h4 id="copy-on-write">Copy on Write</h4>
<ul>
<li>UNIX fork with copy on write
<ol>
<li>copy the parent page table entries to the child, and turn on a special bit called copy-on-write bit on both parent and child&rsquo;s PTEs
Notice this is a OS bit (unused bit modified by the OS), hardware don&rsquo;t know what it is!</li>
<li>read is fine, but if anyone want to write&hellip; We need the help from the hardware
which means we need to turn on the read-only bit on hardware.
When a write happens on either process, exception happens due to read-only bit. Kernel handler will find out the exception is due to copy on write.</li>
<li>Kernel then allocate a new physical frame, and copy the content from the current shared frame to the new frame.
The offending PTE(whichever need to write) will point to this new frame.
So now the shared mem is not shared.</li>
<li>Clear copy-on-write bit on the offending PTE, decrease the ref bit for that shared frame, and if the is no body else sharing that shared mem(ref bit is 0), then also clear the other PTE&rsquo;s copy-on-write bit.
We here also need a reverse pointer pointing to the PTE who points to the shared mem.
if ref bit is now 0, then follow reverse pointer to clear copy-on-write and read-only bit on the last process.
copy-on-write can be implement in the software level since hardware don&rsquo;t care.</li>
</ol>
</li>
</ul>
<h5 id="notice-that-both-hardware-and-software-know-pte-but-only-kernel-knows-the-copy-on-write">Notice that both hardware and software know PTE, but only kernel knows the Copy-on-write</h5>
<h4 id="fill-on-demand">Fill On Demand</h4>
<ul>
<li>Can I start running a program before its code is in physical memory?</li>
</ul>
<h4 id="design-a-page-fault-handler">Design a page fault handler</h4>
<ol>
<li>OS must book-keeping whereabouts of all the physical frames on persistent storage</li>
</ol>
<ul>
<li>
<p>What info shall the kernel maintain?</p>
<ul>
<li>For every swapped out VPN of a process, the disk location of the page content</li>
</ul>
</li>
<li>
<p>when does such book-keeping info need to be create?</p>
<ul>
<li>the first time a virtual page is swapped out from a process</li>
<li>Subsequent swap out of the page amy result in change of the mapping, depending on OS policy</li>
</ul>
</li>
<li>
<p>What needs to happen during the page fault handler?
allocate a free physical frame to copy the page data to</p>
<ul>
<li>how to locate the page data on the persistent storage?
<ul>
<li>use the book-keeping info stored.</li>
</ul>
</li>
<li>what kernel data needs to be updated?
<ul>
<li>PTE entry for the virtual page</li>
<li>can also update the TLB</li>
</ul>
</li>
</ul>
</li>
<li>
<p>what other actions need to take place?</p>
<ul>
<li>load the page content from persistent storage into mem</li>
<li>while waiting for disk I/O to complete, schedule a diff process to run, mark the offending process as &ldquo;blocked&rdquo;.</li>
</ul>
</li>
</ul>
<ol start="2">
<li>
<p>How does the OS know which physical frame this offending PTE used to point?
This question is wrong!
You should not go to find that physical frame, it might have been used by another process. We should copy the disk data to a new physical frame. Or you might overwrite the data being used by other processor.</p>
</li>
<li>
<p>Transfer the data stored on the persistent storage into mem.</p>
</li>
</ol>
<h2 id="lecture-16-concurrency-ii">Lecture 16: Concurrency II</h2>
<p>Synchronization: Mutual Exclusive + Ordering</p>
<p>By the definition of thread, its access to shared memory space is unfettered.</p>
<p>And its scheduling is completely unpredictable.</p>
<p>So, from this angle, all threads race to access data! ==&gt; very bad design</p>
<p>Defs:
<strong>Race condition</strong>
<strong>Mutual exclusion</strong>
<strong>Lock</strong>
<strong>Critical section</strong></p>
<h3 id="locks">Locks</h3>
<p>Lock::acquire
Lock::release</p>
<p>Milk problem:</p>
<ol>
<li>Liveness: Someone buys if needed</li>
<li>Safety: At most one person buys</li>
<li>Fairness: Everyone has fair chances to get the lock</li>
</ol>
<p>1 &amp; 2 are the most important, 3 is good to have.</p>
<p>If you only have a single processor, we should disable the interrupt, or we may have a dead lock.</p>
<h3 id="only-in-lecture">ONLY IN LECTURE</h3>
<p>Once you acquire the lock, you can assume that it&rsquo;s in persistant state.</p>
<pre tabindex="0"><code>// Basic programming pattern for Critical section
Lock::acquire
  Manipulation of shared data
Lock::release
</code></pre><ol>
<li>One lock per shared data</li>
<li>To be effective, all threads must apply locking on the data</li>
</ol>
<p>The difference between Concurrency access in OS v.s. program:
OS does not trust others.
The program can behave like designed, there is no enforcement.</p>
<p>So Synchronization is kinda weird for the OS since it&rsquo;s more of a cooperation rather than enforcement.
The lock does not really lock it, it just signal others that the data is occupied by me, do not come.</p>
<p>When you have some threads, you&rsquo;ll never know when they will be executed.</p>
<p>Implementing Threads:</p>
<ol>
<li>
<p>kernel Threads: to the kernel, a kernel thread and a single threaded user processor looks quite similar.</p>
</li>
<li>
<p>multithreads processes using kernel threads</p>
</li>
<li>
<p>User-level threads</p>
</li>
</ol>
<p>We are going to focus on the first possibility.</p>
<p>Thread data structure:
TCB and stack
TCB &ndash;&gt; stack info, saved registers, thread meta data
shared state are shared among all threads: code global vars, heap</p>
<p>Thread Context Switch</p>
<ol>
<li>Voluntary
yield and join</li>
<li>Involuntary
Interrupt or exception
Some other thread is higher priority</li>
<li>How does it happen?
return to a new place</li>
</ol>
<p>The key trick:</p>
<pre tabindex="0"><code>void thread_switch(oldThreadTCB, newTheadTCB){
    pushad;
    oldThreadTCB-&gt;sp = %esp;
    %esp = newThreadTCB-&gt;sp;
    popad;
    return;
  }
</code></pre><h4 id="how-to-implement-thread_yield">How to implement thread_yield()?</h4>
<p>in the thread_yield(), there is thread_switch()</p>
<p>in the yield() after the swith(), the it&rsquo;s resumed to the old TCB NOT THE chosen TCB.</p>
<p>And the eableInterrupt() is not re-eable the one at the beginning of the yield(), but that in another thread.</p>
<p>the yield() is very fast so that do not worry about the length of the time of interrupt.(for single core)</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-c++" data-lang="c++"><span style="color:#66d9ef">void</span> <span style="color:#a6e22e">thread_yield</span>(){
  TCB <span style="color:#f92672">*</span>previous_runningTCB, <span style="color:#f92672">*</span>chosenTCB, <span style="color:#f92672">*</span>finishedTCB;
  
  <span style="color:#75715e">//Prevent an interrupt from stopping us in the middle of a switch
</span><span style="color:#75715e"></span>  disableInterrupts();
  
  <span style="color:#75715e">// choose another TCB from the ready list
</span><span style="color:#75715e"></span>  chosenTCB <span style="color:#f92672">=</span> readyList.getNextThread();
  
  <span style="color:#66d9ef">if</span> (chosenTCB <span style="color:#f92672">==</span> NULL){
    <span style="color:#75715e">//Nothing, go back to the original thread
</span><span style="color:#75715e"></span>  }
  <span style="color:#66d9ef">else</span>{
    runningThread<span style="color:#f92672">-&gt;</span>state <span style="color:#f92672">=</span> ready;
    readyList.add(runningThread);
    previous_runningTCB <span style="color:#f92672">=</span> runningThread;
    runningThread <span style="color:#f92672">=</span> chosenTCB;
    thread_switch(<span style="color:#f92672">*</span>previous_runningTCB, chosenTCB);
    runningThread<span style="color:#f92672">-&gt;</span>state <span style="color:#f92672">=</span> running;
  }
  
  <span style="color:#66d9ef">while</span>((finishedTCB <span style="color:#f92672">=</span> finishedList<span style="color:#f92672">-&gt;</span>getNextThread()) <span style="color:#f92672">!=</span> NULL){
    <span style="color:#66d9ef">delete</span> finishedTCB<span style="color:#f92672">-&gt;</span>stack;
    <span style="color:#66d9ef">delete</span> finishedTCB;
  }
  enableInterrupts();
}
</code></pre></div><h5 id="why-disable-the-interrupt">why disable the interrupt?</h5>
<p>to protect the shared data: ready list!</p>
<p>If this is not kernel code, we have to use other tricks like locks.</p>
<h4 id="never-acquire-a-lock-in-interrupt-handler">Never acquire a lock in interrupt handler!!!</h4>
<p>because if the interrupt handler tries to acquire a lock that being held by others, DEAD LOK!!</p>
<p>In this case, one CPU core own their own ready list. Or there still may be a race condition on the ready list since the disableInterrupt() only works on the current CPU. The downside is that if a thread is ready but other cores are not doing anything.</p>
<h2 id="lecture-18">Lecture 18</h2>
<p>EXAM: what does this line do? Is there anything wrong? yield() switch() join() &hellip; we should be able to implement those.</p>
<p>All these funtions have nothing special that make them can be only done in kernel, you can implement similar things in user mode with proper coding.</p>
<h4 id="thread_create">Thread_create()</h4>
<p>need a wrapper, to call the create() and exit once created, since we might not use it immediately after creating it.</p>
<ul>
<li>allocate TCB</li>
<li>allocate stack</li>
<li>build stack frame for base of stack (stub)</li>
<li>put thread on ready list</li>
<li>will run sometime later (maybe right away)</li>
</ul>
<pre tabindex="0"><code>thread_create(thread_t thread, void (*func)(int), int arg){
    TCB* tcb = new TCB();
    thread-&gt;tcb = tcb;
    tcb-&gt;stack_size = INIT_STACK_SIZE;
    tcb-&gt;stack = new Stack(INIT_STACK_SIZE);
    // now the TCB and stack are allocated

    tcb-&gt;sp = stack + INIT_STACK_SIZE;
    tcb-&gt;pc = stub;
    // init the register to let the program run at the stub
    
    *(tcb-&gt;sp--) = stub;
    *(tcb-&gt;sp) = func;
    tcb-&gt;sp -= SizeOfPopad;

    tcb-&gt;state = READY;
    readyList.add(tcb); // put tcb on ready readyList
    
  }


  stub(func, args){
      (*func)(args);
      thread_exit();
    }

</code></pre><p>Notice here the tcb&rsquo;s member vars: tcb, stack_size, stack, sp, pc, state&hellip;</p>
<p>the create() function  pretend it&rsquo;s resuming from another thread, so that every function is in a unified format, which means they can all use thread_swith(). When it gets resumed, it needs certain words int the stack to fufill the popad instructions in thread_switch(). Thus, we need a fake funcion like stub() to create that stack space.</p>
<p>The popad will add those random vals into the stack but it doesn&rsquo;t matter since a new thread should not trust any un-init vals.</p>
<h4 id="subtlety">Subtlety</h4>
<ul>
<li>thread_create() puts new thread on ready list</li>
<li>When it first runs, some thread needs to call thread_switch()
<ul>
<li>save old thread state to stack</li>
<li>pop the new thread state from stack into the registers</li>
</ul>
</li>
<li>Set up new thread&rsquo;s stack as if it has saved its state in thread_switch()
<ul>
<li>return to the sub at the base address of the stack to run the func</li>
</ul>
</li>
</ul>
<h3 id="involuntary">Involuntary</h3>
<ol>
<li>timer or I/O interrput
lernel can decide that some other thread should run</li>
<li>once you are in the kernel, the process are seen as threads.</li>
<li>notice that user process has the kernel stack and the user stack, but the kernel thread only has the kernel stack</li>
<li>we can use switch() as context switch</li>
<li>simple version
End of interrupt handler calls thread_switch()
when resumed, return from handler resumes kernel thread or uer process.
Thus, processor context is saved/restored twice.(once by thread switch, and once by interrupt handler)</li>
</ol>
<p>![After an interrupt at x86](img/After an interrupt at x86.png)</p>
<p>It seems that we need to do sth like in the yield(), call the scheduler to run to give us a chosen pcb and call swith(), in the switch() we use iret after popad.</p>
<p>However, think about this. Since you are already in an interrupt, we have states saved in the trap frame, on top of that we also do pushad in the swith(), which is redundant.</p>
<p>Resuming a thread from the switch() which is also interrupted let the resumed thread start at the interrupt handler, which will next do the popad again followed by an iret.</p>
<h4 id="faster-threadprocess-switch">Faster Thread/Process Switch</h4>
<ul>
<li>Essentially tail call elimination &lt;== if the context switch is cause by interrupt
<ul>
<li>interrupt handler will saved all the states</li>
<li>decide to run a new thread</li>
<li>throw away current state of interrupt handler
<ul>
<li>you DO NOT really call thread_switch() and create a new frame for it, which would save the registers and return address. Instead it become a jump.</li>
<li>reuse the thread&rsquo;s saved state when entering the interrupt handler</li>
</ul>
</li>
</ul>
</li>
<li>Set saved stack pointer to trap frame (on x86, including the saved registers and six vals)</li>
<li>On resume, pops trap frame to restore interrupt thread</li>
<li>This requires thread_switch() use the same format stack frame as trap frame. On x86, this also means thread_switch() will use iret, instead of ret instruction. Now both voluntary and involuntary context switch are all looks like resume from an interrupt so that they are uniform.</li>
</ul>
<h4 id="can-we-support-user-level-threads-without-the-help-of-kernel">Can we support user level threads without the help of kernel?</h4>
<h5 id="reason-kernel-only-has-one-way-of-scheduling-which-is-less-flexible-for-the-need-from-app-to-app">reason: kernel only has one way of scheduling, which is less flexible for the need from app to app.</h5>
<p>In this case, the kernel may not know the existence of the user threads since the thread context swith is not down throught kernel.</p>
<ol>
<li>What if there is an I/O request and the kernel block the whole processor?</li>
<li>How do we preempt other threads when kernel does not kick in (one way to do is to use yield() everywhere to let threads balance the workload but this is unpractical)?</li>
</ol>
<h2 id="lecture-19">Lecture 19</h2>
<p>We can use <strong>signal</strong>. Like in the terminal &lt;ctr + c&gt; is s signal to do a <strong>up call</strong>, and kernel will ask the user processor to do something. And then we can write our own signal handler.</p>
<p>For example, kernel has timer interrupt, so kernel can decide to send a signal to a process who need it periodically.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-c" data-lang="c"><span style="color:#75715e">/*
</span><span style="color:#75715e">
</span><span style="color:#75715e">An upcall is a mechanism that allows the kernel to execute a function
</span><span style="color:#75715e">in userspace, and potentially be returned information as a result.
</span><span style="color:#75715e">
</span><span style="color:#75715e">An upcall is like a signal, except that the kernel may use it at any
</span><span style="color:#75715e">time, for any purpose, including in an interrupt handler.
</span><span style="color:#75715e">
</span><span style="color:#75715e">This means that an upcall can potentially destroy the behaviour of the
</span><span style="color:#75715e">kernel. If an interrupt handler decides to ask a user space function
</span><span style="color:#75715e">for some information, and the function page faults or does blocking
</span><span style="color:#75715e">IO, your kernel is quite likely trashed.
</span><span style="color:#75715e">
</span><span style="color:#75715e">So, upcalls aren&#39;t there for everyday software development. But for
</span><span style="color:#75715e">specific purposes, they can be extremely useful. 
</span><span style="color:#75715e">
</span><span style="color:#75715e">*/</span>
</code></pre></div><h4 id="green-threadearly-java">Green thread(early JAVA)</h4>
<ul>
<li>user level lib, within a process</li>
<li>lub does thread context swtich</li>
<li>preemption via upcall/UNIX signal on timer interrupt</li>
<li>use multiple processes for multi-core parallelism
<ul>
<li>shared mem region mapped into each process</li>
</ul>
</li>
</ul>
<p>Since the process can change the user level stack for the threads</p>
<p>Say if we have a multi-core CPU, this does not work. Because when you want to let a core to take care of a thread, it needs kernel to kick in. However, the green thread does everthing at user level.</p>
<p>The solution is to use shared mem region mapped into each process.</p>
<h4 id="more-modern-way">More modern way</h4>
<ul>
<li>Scheduler activations
<ul>
<li>kernel allocates processors to user-level thread lib (after the specific core take over, the scheduling will be done in that core, which are decided by the user level processors in that core, and we have the following 2 bullet points)</li>
<li>thread lib implements context switch</li>
<li>thread lib decides what thread to run next</li>
</ul>
</li>
<li>upcall whenever kernel needs a user level scheduling decision (if there is I/O interrupt, kernel will ask the process to do sth or it will be blocked)
<ul>
<li>process assigned a new processor</li>
<li>processor removed from process</li>
<li>sys call blocks in kernel</li>
</ul>
</li>
</ul>
<h3 id="spinlock-issue">Spinlock issue</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-c" data-lang="c">Spinlock<span style="color:#f92672">::</span>acquire() {
  <span style="color:#66d9ef">while</span> (testAndSet(<span style="color:#f92672">&amp;</span>lockValue) <span style="color:#f92672">==</span> BUSY){
    
  }
}

Spinlock<span style="color:#f92672">::</span>release() {
lockValue <span style="color:#f92672">=</span> FREE
}
<span style="color:#75715e">// downside: a waste of cpu resources
</span><span style="color:#75715e">// fairness issues: generally cannot assure fairness
</span></code></pre></div><h4 id="how-to-solve-it">How to solve it?</h4>
<p>we may try to make the spinlock less aggressive. for perfomance</p>
<p>and we should have a wait queue? for fairness</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-c" data-lang="c"><span style="color:#75715e">// There might be multiple threads trying to acquire the lock and put themselves into the wait list. So there will be race conditions(since you will have the pointers to move and change).
</span><span style="color:#75715e">// Thus, they have to be synchronized ==&gt; they have to be protected by another lock -- a spinlock
</span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-c++" data-lang="c++"><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">Lock</span> {
	<span style="color:#66d9ef">private</span><span style="color:#f92672">:</span>
  	SpinLock spinLock; <span style="color:#75715e">// ==&gt; to protext the lock data structure
</span><span style="color:#75715e"></span>		<span style="color:#66d9ef">int</span> value <span style="color:#f92672">=</span> FREE;
  	Queue waiting;
  <span style="color:#66d9ef">public</span><span style="color:#f92672">:</span>
  	<span style="color:#66d9ef">void</span> acquire();
  	<span style="color:#66d9ef">void</span> <span style="color:#a6e22e">release</span>();
}


Lock<span style="color:#f92672">::</span>acquire() {
  spinLock.acquire();
  <span style="color:#66d9ef">if</span> (value <span style="color:#f92672">==</span> BUSY) {
    waiting.add(myTCB);
    scheduler<span style="color:#f92672">-&gt;</span>suspend(<span style="color:#f92672">&amp;</span>spinLock);
  }<span style="color:#66d9ef">else</span> {
    value <span style="color:#f92672">=</span> BUSY;
    spinLock.release();
  }
}

Lock<span style="color:#f92672">::</span>release() {
  spinLock.aquire();
  <span style="color:#66d9ef">if</span> (<span style="color:#f92672">!</span>waiting.empty()) {
    next <span style="color:#f92672">=</span> waiting.remove();
    scheduler<span style="color:#f92672">-&gt;</span>makeReady(next);
  }<span style="color:#66d9ef">else</span> {
    value <span style="color:#f92672">=</span> FREE;
  }
  spinLock.release();
}
</code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-c++" data-lang="c++">Sched<span style="color:#f92672">::</span>suspend(SpinLock <span style="color:#f92672">*</span>spinLock) {
  TCB<span style="color:#f92672">*</span> next;
  
  disableInterrupts(); <span style="color:#75715e">// we need to disable interrupt to ensure the data consistancy?
</span><span style="color:#75715e"></span>  schedSpinLock.acquire(); <span style="color:#75715e">// we need a seperate spin lock to protect the ready list
</span><span style="color:#75715e"></span>  spinLock<span style="color:#f92672">-&gt;</span>release();
  runningThread<span style="color:#f92672">-&gt;</span>state <span style="color:#f92672">=</span> WAITING;
  next <span style="color:#f92672">=</span> readyList.remove();
  runningThread <span style="color:#f92672">=</span> next;
  thread_switch(myTCB, next);
  runningThread<span style="color:#f92672">-&gt;</span> RUNNING;
  schedSpinLock<span style="color:#f92672">-&gt;</span>release();
  enableInterrupts();
}


</code></pre></div><p>Notice that the suspend() can resume the thread stopped by yield().</p>
<h4 id="why-we-want-interrupt">why we want interrupt</h4>
<p>if the interrupt handler need to modify the ready list, then it will acquire the spin lock that may be held by others. DEAD LOCK!</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-c++" data-lang="c++">Sched<span style="color:#f92672">::</span>makeReady(TCB<span style="color:#f92672">*</span> <span style="color:#66d9ef">thread</span>) {
  disableInterrupt();
  schedSpinLock.acquire();
  readyList.add(<span style="color:#66d9ef">thread</span>);
  <span style="color:#66d9ef">thread</span><span style="color:#f92672">-&gt;</span>state <span style="color:#f92672">=</span> READY;
  schedSpinLock.release();
  enableInterrupts();
}
</code></pre></div><p><strong>IMPORTANT:</strong></p>
<ul>
<li>in Lock::acquire(), can we release the spinLock right after the waiting.add()?
<ul>
<li>Because other threads may do sth before we change the readyList.</li>
<li>maybe makeReady the thread that we are about to suspend.</li>
<li>You won&rsquo;t have a dead lock.</li>
<li>But I&rsquo;m about to put myself to waitList having a state of WAITING after someone put me in the readyList.
<ul>
<li>The problem here is that every thread in ready list should have a state of ready, it&rsquo;s about the data consistency.</li>
<li>It&rsquo;s not a bug though</li>
</ul>
</li>
<li>We really need to acqurie the lock in a order so that we don&rsquo;t generate a gap between and may produce flaws.</li>
</ul>
</li>
</ul>
<h2 id="lecture-20-ordering-condition-variable">Lecture 20 Ordering, Condition Variable</h2>
<p><strong>IMPORTANT</strong>, <strong>EXAM</strong>:</p>
<ul>
<li>
<p>why should we release the lock in suspend() rather than in the acquire() after waiting.add()</p>
<ul>
<li>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-c++" data-lang="c++"><span style="color:#75715e">// If we release the spinLock right after the waiting.add(), we will fail to keep the consistency. Other thread may get in and put that thread we just added in to the waiting list in the ready list.
</span><span style="color:#75715e">// And since the state update and switch() does not get to run, the vals of the TCB get put in the ready list is stale.
</span><span style="color:#75715e">// So when get resumed, it kind of walking back the time. Since the pointer to the code section may still point to somewhere it has executed in the past.
</span></code></pre></div></li>
<li>
<p>Exam may ask where the lastest timing we can put the release()</p>
</li>
</ul>
</li>
</ul>
<h3 id="ordering">Ordering</h3>
<p>we can do thread_join() for every thread</p>
<p>thread_join() is like a waiting list to synchronize all threads</p>
<h4 id="shared-bounded-buffer">Shared Bounded Buffer</h4>
<ul>
<li>A bounded buffer is shared among multiple threads for message exchange</li>
<li>producer threads put items into the buffer (sending the message)</li>
<li>consumerj thread get items from the buffer (receiving a message)</li>
<li><strong>Requirement: each message is received by only one thread.</strong></li>
</ul>
<h5 id="implementation">implementation</h5>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-c++" data-lang="c++"><span style="color:#75715e">// Consumer
</span><span style="color:#75715e"></span><span style="color:#66d9ef">while</span>(<span style="color:#f92672">!</span>(item<span style="color:#f92672">=</span>tryget())) {
  
}
use(item);

<span style="color:#75715e">// producer
</span><span style="color:#75715e"></span><span style="color:#66d9ef">while</span>(<span style="color:#f92672">!</span>tryput(item) {
}
      
tryget() {
  item <span style="color:#f92672">=</span> NULL;
  lock.acquire();
  <span style="color:#66d9ef">if</span> (front <span style="color:#f92672">&lt;</span> tail) {
    item <span style="color:#f92672">=</span> buf(front <span style="color:#f92672">%</span> MAX);
    front<span style="color:#f92672">++</span>;
    notify threads waiting on <span style="color:#a6e22e">condition</span> (tail <span style="color:#f92672">-</span> front) <span style="color:#f92672">&lt;</span> MAX
  } <span style="color:#66d9ef">else</span> {
		go to sleep on condition front <span style="color:#f92672">&lt;</span> tail
    put <span style="color:#66d9ef">thread</span> on waiting list and release the lock
    lock.acquire
  }
  lock.release();
  <span style="color:#66d9ef">return</span> item;
}
      
tryput(item) {
  success <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>;
  lock.acquire();
  <span style="color:#66d9ef">if</span> (tail <span style="color:#f92672">-</span> front <span style="color:#f92672">!=</span> <span style="color:#ae81ff">0</span>) {
    buf(tail <span style="color:#f92672">%</span> MAX) <span style="color:#f92672">=</span> item;
    tail<span style="color:#f92672">++</span>;
    success <span style="color:#f92672">=</span> <span style="color:#ae81ff">1</span>;
    notify threads waiting on condition front <span style="color:#f92672">&lt;</span> tail
  } <span style="color:#66d9ef">else</span> {
    go to sleep on <span style="color:#a6e22e">condition</span> (tail <span style="color:#f92672">-</span> front) <span style="color:#f92672">&lt;</span> MAX
    put <span style="color:#66d9ef">thread</span> on waiting list and release the lock
    lock.acquire
  }
  lock.release();
  <span style="color:#66d9ef">return</span> success;
}
      
<span style="color:#75715e">// need to have separate waiting queues for differnent conditions of interest
</span></code></pre></div><p>Should we assume the condition is right after being waken up.</p>
<p>NO!! Since other threads may take over in between right after the thread was woken up.</p>
<p>How to fix this?</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-c++" data-lang="c++">tryget() {
  item <span style="color:#f92672">=</span> NULL;
  lock.acquire();
  <span style="color:#66d9ef">while</span> (<span style="color:#f92672">!</span>(front <span style="color:#f92672">&lt;</span> tail) {
    go to sleep on condition front <span style="color:#f92672">&lt;</span> tail
    put <span style="color:#66d9ef">thread</span> on waiting list and release the lock <span style="color:#75715e">// context switch (suspend or yield)
</span><span style="color:#75715e"></span>    lock.acquire
  }
  item <span style="color:#f92672">=</span> buf(front <span style="color:#f92672">%</span> MAX);
  front<span style="color:#f92672">++</span>;
  notify threads waiting on <span style="color:#a6e22e">condition</span> (tail <span style="color:#f92672">-</span> front) <span style="color:#f92672">&lt;</span> MAX
  lock.release();
  <span style="color:#66d9ef">return</span> item;
}
      
tryput(item) {
  success <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>;
  lock.acquire();
  <span style="color:#66d9ef">while</span> (<span style="color:#f92672">!</span>((tail <span style="color:#f92672">-</span> front) <span style="color:#f92672">&lt;</span> MAX)) {
    go to sleep on <span style="color:#a6e22e">condition</span> (tail <span style="color:#f92672">-</span> front) <span style="color:#f92672">&lt;</span> MAX
    put <span style="color:#66d9ef">thread</span> on waiting list and release the lock <span style="color:#75715e">// context switch (suspend or yield)
</span><span style="color:#75715e"></span>    lock.acquire
  } 
  buf(tail <span style="color:#f92672">%</span> MAX) <span style="color:#f92672">=</span> item;
  tail<span style="color:#f92672">++</span>;
  success <span style="color:#f92672">=</span> <span style="color:#ae81ff">1</span>;
  notify threads waiting on condition front <span style="color:#f92672">&lt;</span> tail
  lock.release();
  <span style="color:#66d9ef">return</span> success;
}
</code></pre></div><h3 id="condition-variables">Condition Variables</h3>
<ul>
<li>Indicates a condition that needs to be satisfied for a thread to proceed.</li>
<li>if condition is not satisfied, a thread can be put on a wait queue associated with the condition variable.
<ul>
<li>Must <strong>call wait()</strong> inside a critical section, <strong>while holding the lock</strong></li>
<li>wait() <strong>atomically</strong> releases the lock and put the thread on the wait queue.</li>
<li>when woken, <strong>reacquires the lock before returning from wait()</strong></li>
</ul>
</li>
<li>A thread can wake thread(s) waiting on a condition variable
<ul>
<li>signal</li>
<li>broadcast</li>
</ul>
</li>
</ul>
<h3 id="cv-design-pattern">CV Design Pattern</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-c++" data-lang="c++">methodThatWaits() {
  lock.acquire();
  <span style="color:#75715e">// R/W shared state
</span><span style="color:#75715e"></span>  
  <span style="color:#66d9ef">while</span> (<span style="color:#f92672">!</span>testSharedState()) {
    cv.wait(<span style="color:#f92672">&amp;</span>lock);
  }
  
  <span style="color:#75715e">// R/W shared state
</span><span style="color:#75715e"></span>  lock.release();
}

methodThatSignals() {
  lock.acquire();
  <span style="color:#75715e">// R/W shared state
</span><span style="color:#75715e"></span>  
  <span style="color:#75715e">// if testSharedState is no true
</span><span style="color:#75715e"></span>  cv.signal();
  
  <span style="color:#75715e">// R/W shared state
</span><span style="color:#75715e"></span>  lock.release();
}
</code></pre></div><h3 id="shared-bounded-buffer-1">Shared Bounded Buffer</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-c++" data-lang="c++">get() {
  lock.acquire();
  <span style="color:#66d9ef">while</span>(front <span style="color:#f92672">==</span> tail) {
    empty.wait(<span style="color:#f92672">&amp;</span>lock);
  }
  item <span style="color:#f92672">=</span> buf[front <span style="color:#f92672">%</span> MAX];
  front<span style="color:#f92672">++</span>;
  full.signal();
  lock.release();
  <span style="color:#66d9ef">return</span> item;
}

put(item) {
  lock.acquire();
  <span style="color:#66d9ef">while</span> ((tail <span style="color:#f92672">-</span> front) <span style="color:#f92672">==</span> MAX) {
    full.wait(<span style="color:#f92672">&amp;</span>lock);
  }
  buf[tail <span style="color:#f92672">%</span> MAX] <span style="color:#f92672">=</span> item;
  tail<span style="color:#f92672">++</span>;
  empty.signal();
  lock.release<span style="color:#f92672">*</span>();
}

<span style="color:#75715e">// Initially: front = tail = 0; MAX is buffer capacity
</span><span style="color:#75715e">// empty/full are condition variables
</span></code></pre></div><p>pre/post CV</p>
<h3 id="key-pionts-for-cv">Key Pionts for CV</h3>
<ul>
<li>
<p>ALWAYS hold lock when calling wait, signal, broadcast</p>
<ul>
<li>Condition variable is sync FOR shared state</li>
<li>ALWAYS hold lock when accessing shared state</li>
</ul>
</li>
<li>
<p>CV is memoryless</p>
<ul>
<li>if signal when no one is waiting, no op</li>
<li>if wait before signal, waiter wakes up</li>
</ul>
</li>
<li>
<p>Wait atomically releases lock and put the thread into waiting list</p>
<ul>
<li>why?
<ul>
<li>we might lost the signal, since before putting the thread into the waiting list, the signal might be emitted.</li>
</ul>
</li>
</ul>
</li>
<li>
<p>When a thread is woken up from wait, it may not run immediately (this is why we need to put it in a loop)</p>
<ul>
<li>signal/broadcast put thread on ready list</li>
</ul>
</li>
<li>
<p>Wait MUST be in a loop</p>
<ul>
<li>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-c++" data-lang="c++"><span style="color:#66d9ef">while</span>(needToWait()) {
  condition.Wait(<span style="color:#f92672">&amp;</span>lock);
}
</code></pre></div></li>
</ul>
</li>
<li>
<p>simplified implementation</p>
<ul>
<li>of condition vars and locks</li>
<li>of code that uses condition vars and locks</li>
</ul>
</li>
</ul>
<h3 id="cv-implementation">CV implementation</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-c++" data-lang="c++"><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">CV</span> {
  <span style="color:#66d9ef">private</span><span style="color:#f92672">:</span>
  Queue waiting;
  <span style="color:#66d9ef">public</span><span style="color:#f92672">:</span>
  <span style="color:#66d9ef">void</span> wait(lock.isHeld());
  <span style="color:#66d9ef">void</span> <span style="color:#a6e22e">signal</span>();
  <span style="color:#66d9ef">void</span> <span style="color:#a6e22e">broadcast</span>();
}
</code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-c++" data-lang="c++"><span style="color:#66d9ef">void</span> CV<span style="color:#f92672">::</span>wait(Lock <span style="color:#f92672">*</span>lock) {
  assert(lock.isHeld());
  waiting.add(myTCB);
  scheduler.suspend(<span style="color:#f92672">&amp;</span>lock);
  lock<span style="color:#f92672">-&gt;</span>acquire();
}


<span style="color:#66d9ef">void</span> CV<span style="color:#f92672">::</span>signal() {
  <span style="color:#66d9ef">if</span> (waiting.notEmpty()) {
    <span style="color:#66d9ef">thread</span> <span style="color:#f92672">=</span> waiting.remove();
    scheduler.makeReady(<span style="color:#66d9ef">thread</span>);
  }
}

<span style="color:#66d9ef">void</span> CV<span style="color:#f92672">::</span>broadcast() {
  <span style="color:#66d9ef">while</span> (waiting.notEmpty()) {
    <span style="color:#66d9ef">thread</span> <span style="color:#f92672">=</span> waiting.remove();
    scheduler.makeReady(<span style="color:#66d9ef">thread</span>);
  }
}
</code></pre></div><h2 id="lecture-21-semaphore">Lecture 21 Semaphore</h2>
<p>(Dijkstra again)</p>
<p><strong>One execution sequence waits for another</strong></p>
<p>purpose 1: mutual exclusion</p>
<p>purpose 2: ordering (we use CV)</p>
<table>
<thead>
<tr>
<th></th>
<th>Block oneself</th>
<th>Unblock others</th>
</tr>
</thead>
<tbody>
<tr>
<td>Mutual Exclusion</td>
<td>Lock.acquire()</td>
<td>Lock.release()</td>
</tr>
<tr>
<td>Ordering</td>
<td>Cond.wait()</td>
<td>Cond.signal()</td>
</tr>
</tbody>
</table>
<h3 id="semaphore-concept">Semaphore Concept</h3>
<ul>
<li>Semaphore has a non-negative integer value
<ul>
<li>P() <strong>atomically</strong> waits for value to become &gt; 0,. then decrements</li>
<li>V() <strong>atomically</strong> increments value (waking up waiter if needed)</li>
<li>Operations are <strong>atomic</strong>
<ul>
<li>e.g., if value is 1, two P&rsquo;s will result in value 0 and one waiter</li>
</ul>
</li>
</ul>
</li>
</ul>
<table>
<thead>
<tr>
<th></th>
<th>Block oneself</th>
<th>Unblock others</th>
</tr>
</thead>
<tbody>
<tr>
<td>Mutual Exclusion</td>
<td>Sem.P()</td>
<td>Sem.V()</td>
</tr>
<tr>
<td>Ordering</td>
<td>Sem.P()</td>
<td>Sem.V()</td>
</tr>
</tbody>
</table>
<p>Prob: it may hard to understand the code since this is too elegant</p>
<h4 id="init-val">Init val!</h4>
<p>Sem.init(N) sets an initial value of the semaphore</p>
<p>The init val determines the behavior of the semaphore in subsequent use</p>
<h4 id="using-sem-for-mutual-exclusion">Using Sem for Mutual Exclusion</h4>
<p>Sem.init(1)</p>
<p>![Sem for Mutual Exclusion](img/Sem for Mutual Exclusion.png)</p>
<p>EXAM: how to implement sth in Semaphore!</p>
<p>The atomic means the whole things have to be atomic. From sem operations to wake up funciont and increment/decrement are all atomic!</p>
<p>When we use with a init of 1, we call it binary sem, since it works like a lock.</p>
<h4 id="using-sem-for-ordering">Using Sem for Ordering</h4>
<p>![Sem for Ordering](img/Sem for Ordering.png)</p>
<h5 id="why-you-cant-do-sem_mutexp-first">why you can&rsquo;t do sem_mutex.P() first?</h5>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-c++" data-lang="c++"><span style="color:#75715e">// Becase if you do a sem_full.P(), you can potentially get blocked.
</span><span style="color:#75715e">// You can only be woken up by another thread using V().
</span><span style="color:#75715e">// However, you are holding the sem_mutex.P() so that nobody can get in
</span><span style="color:#75715e">// DEAD LOCK!
</span></code></pre></div><p>empty is init with 0 and full is init with MAX.
Since the put() will work first and get() will wait first.</p>
<p>Notice:
For singals, they can emit singals and nobody is waiting.
But for V(), if no one is waiting, then we will change the val!
Which is not acceptable.
V() will increment the val by 1.
Signal is memoryless, but V() is not.</p>
<p>Thus,semaphore is harder to implement.</p>
<p>Also, for signal, when you wake up, you have to check the condition since
it can be false by then. However, semaphore is differnent.</p>
<h5 id="sem-for-cv">Sem for CV?</h5>
<h3 id="bottom-like-regarding-semaphore">Bottom Like regarding Semaphore</h3>
<ul>
<li>an elegant and uniform solution for Synchronization</li>
<li>Require careful design, in particular mapping the semaphore&rsquo;s initial value to
problem domain</li>
<li>can be confusing, especially since it can be used for two very differnent purposes</li>
<li>Recommendation for general programming: stick with lock and CV</li>
</ul>
<h3 id="concurrency-bugs">Concurrency Bugs</h3>
<p>(safty: race condition   progress: dead lock or starvation)</p>
<ul>
<li>did not apply Synchronization</li>
<li>deadlock or starvation</li>
</ul>
<h4 id="the-dining-philosopher-problem">The Dining Philosopher Problem</h4>
<h4 id="principled-synchronization">Principled Synchronization</h4>
<ul>
<li>identfy objs or data structures that can be accessed by multiple threads Concurrency
<ul>
<li>in OS kernel, everything</li>
</ul>
</li>
<li>Add locks to objs/module
<ul>
<li>grab lock on start to every method/procedure</li>
<li>Release lock on finish</li>
</ul>
</li>
<li>If need to wait
<ul>
<li>while (needToWait()){condition.Wait(lock);}</li>
<li>do not assume when you wake up the condition has become true</li>
</ul>
</li>
<li>if do sth that might wake someone up
<ul>
<li>signal or broadcast</li>
</ul>
</li>
<li>always leave shared state vars in a consistent state
<ul>
<li>when lock is released, or when entering waiting</li>
</ul>
</li>
<li>if need to acquire multiple locks, use the same order across all threads</li>
</ul>

  

      </main>
      
  
  <script>
  window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
  ga('create', 'UA-123456789-1', 'auto');
  ga('send', 'pageview');
  </script>
  <script async src='https://www.google-analytics.com/analytics.js'></script>
  

  </div>
  </body>
</html>