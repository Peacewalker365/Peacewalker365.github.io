<!DOCTYPE html>
<html lang="en">
  <head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">

  <meta name="generator" content="Hugo 0.90.1" />
  <link rel="canonical" href="https://Peacewalker365.github.io/notes/os_reading_note/">

  
    
    <meta name="description" content="OS_notes_for book_reading Virtual Memory Paging Segmentation leads to fragmentation so that we need the new idea of paging.
Pages are memory chunks with fixed size, we can view physical memory as an array of fixed-sized slots called page frames.
Paging gives us flexibility so that we donâ€™t need to whether the way a process uses to address space will cause external fragmentation.
Paging also gives us the simplicity of free-space management that paging affords.">
  

  <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
  <link rel="manifest" href="/site.webmanifest">
  <link rel="mask-icon" href="/safari-pinned-tab.svg" color="#000000">
  <meta name="msapplication-TileColor" content="#ffffff">
  <meta name="theme-color" content="#ffffff">

  <link rel="stylesheet" type="text/css" href="/css/paper.css">

  
  
  <link rel="stylesheet" type="text/css" href="/css/custom.css">

  
  
  <title>Virtual Memory and Concurrency Note | myStack</title>
</head>
  <body>
    <div class="container paper">
      <nav class="border split-nav">
  <div class="nav-brand">
    <h3><a href="/">myStack</a></h3>
  </div>
  <div class="collapsible">
    <input id="collapsible1" type="checkbox" name="collapsible1">
    <button>
    <label for="collapsible1">
        <div class="bar1"></div>
        <div class="bar2"></div>
        <div class="bar3"></div>
      </label>
    </button>
    <div class="collapsible-body">
      <ul class="inline">
      
        <li><a href="/blogs/">Blog</a></li>
      
        <li><a href="/notes/">Note</a></li>
      
        <li><a href="/tags/">Tags</a></li>
      
        <li><a href="/about/">About</a></li>
      
        <li><a href="https://github.com/Peacewalker365">Github</a></li>
      
      </ul>
    </div>
  </div>
</nav>
      <main>
        

<h1>Virtual Memory and Concurrency Note</h1>
<h1 id="os_notes_for-book_reading">OS_notes_for book_reading</h1>
<h2 id="virtual-memory">Virtual Memory</h2>
<h3 id="paging">Paging</h3>
<p>Segmentation leads to fragmentation so that we need the new idea of paging.</p>
<p>Pages are memory chunks with fixed size, we can view physical memory as an array of fixed-sized slots called page frames.</p>
<p>Paging gives us <strong>flexibility</strong> so that we don&rsquo;t need to whether the way a process uses to address space will cause external fragmentation.</p>
<p>Paging also gives us the <strong>simplicity</strong> of free-space management that paging affords.</p>
<p>The OS keeps a <strong>free list</strong> of all free pages.</p>
<h3 id="page-table">Page Table</h3>
<p>The major role of page table is to store <strong>address translations</strong> for each of the virtual pages of the address space, thus letting us know where in physical memory each page resides.</p>
<p>It&rsquo;s important to know that page table is a <strong>per-process</strong> data structure. An exception of this is the <strong>inverted page table</strong>.</p>
<h4 id="notice">Notice</h4>
<p>Notice that two same virtual addresses in different processes may lead to a same physical frame.</p>
<h4 id="translation">Translation</h4>
<p>VA &ndash;&gt; VPN(Virtual Address Number) + offset</p>
<p>For example, the page size is 16 bytes in a 64-byte address space.
Then we need 4 pages, the virtual page number will be indicated by the first 2-bit.</p>
<p>VPN &ndash;&gt; PFN(Physical Frame Number)
Physical Address = VFN + offset</p>
<h4 id="where-are-page-tables-stored">Where are page tables stored?</h4>
<p>Page tables can get terribly large, much larger than the small segment table or base/bounds pair.
For example, for a typical 32-bit address space, with 4KB pages. This VA splits into 20-bit VPN and 12-bit offset. 20 bits implies 2^20 translations that the OS would have to manage for each process.
Assuming we need 4 bytes per PTE to hold the PFN + control bits, then we need an immense 4MB of memory for each page table. And this is only for one process.</p>
<h4 id="whats-in-the-page-table">What&rsquo;s in the page table?</h4>
<p>The simplest one is the <strong>linear page table</strong>, which is just an array.
The OS indexes the array by the virtual page number, and looks up the page-table entry at that VPN to find the desired PFN.</p>
<p>We also have control bits such as:</p>
<p><strong>Valid bit</strong> ==&gt; indicating whether the particular translation is valid. All unused space will be marked invalid.</p>
<p><strong>Protection bit</strong> ==&gt; indicating whether the page can be read, written, or executed.</p>
<p><strong>Present bit</strong> ==&gt; indicating whether this page is in physical memory or on disk.</p>
<p><strong>Dirty bit</strong> ==&gt; indicating whether the page has been modified</p>
<p><strong>Reference bit</strong>(accessed bit) ==&gt; track whether a page has been accessed, and this is useful to tell which page is popular so that we should keep in memory.</p>
<h4 id="problem-paging-is-so-slow">Problem: paging is so slow</h4>
<p>To fetch the desired data:</p>
<ol>
<li>fetch the proper page table entry from the process&rsquo;s page table.</li>
<li>Perform the translation.</li>
<li>Load the data from ther physical memory.</li>
</ol>
<p>To do so, the hardware must know where to find the page table of the current running process. Thus we need a <strong>page-table base register</strong> holding the location.</p>
<p>However, implementing paging without care will lead to a slower machine as well as memory waste.</p>
<h3 id="tlbs">TLBs</h3>
<h4 id="translation-lookaside-buffertlb">Translation-lookaside Buffer(TLB)</h4>
<p>A TLB is a part of memory-management unit(MMU), and is a hardware cache.</p>
<h4 id="tlb-basic-algorithm">TLB Basic Algorithm</h4>
<p>Extract the VPN from the VA and check if the TLB holds it.</p>
<p>If yes, then we have a <strong>TLB hit</strong>. We can now extract the PFN from the relevant TLB entry, concatenate that onto the offset from the original VA, and form the PA we want. If protection checks do not fail, then we can perform the operation correctly.</p>
<p>If no, then we have a <strong>TLB miss</strong>. Then we have to walk the page table, the memory, or even copy the data from disk. And then update the TLB.</p>
<p>Note that page fault can be triggered by both TLB hit and TLB miss.</p>
<p>The TLB hit rate will greatly affect the performance, so we need to find the sweet spot for the TLB size. Also, if the TLB size is too large, walk the TLB will consume more time. And also, if you want a fast cache, it has to be small. This is the physical limit.</p>
<p>TLB also improves the performance due to <strong>spatial locality</strong> even if it&rsquo;s the first time to visit that memory space.</p>
<h4 id="who-handle-the-tlb-miss">Who handle the TLB miss?</h4>
<p>Could be hardware or software.</p>
<p>Hardware: the hardware has to know where exactly the page tables are located in memory(<strong>page-table base register</strong>), as well as the format. On a miss, the hardware will walk through the page table, find the right PTE and extract the desired translation, update the TLB with the translation, and retry the instruction.</p>
<p>For example, the Intel x86 architecture uses a fixed multi-level page table, and the current table is pointed to by the CR3 register.</p>
<p>Software: More modern architecture such as RISC, has a software-managed TLB. On a TLB miss, the hardware will raise an exception to pause the current instruction stream. Then it traps into kernel mode and jumps to a trap handler dealing with TLB misses. The code will look up the page table and update the TLB and return from the trap. The hardware will retry the instruction.</p>
<p>Notice that the return-from-trap behaves differently from that in a system call. In the system call case, it should resume execution at the instruction after the trap into the OS. However, in this case, the hardware must resume execution at the instruction that cause the trap and retry it so that it will has a TLB hit this time. We need be aware of the OS need to save different PC in these two cases.</p>
<p>Also, when running the TLB miss-handling code, the OS need to be extra careful not to cause an infinite chain of TLB misses to occur. The solution would be to keep TLB miss handlers in physical memory that are unmapped and not subject to address translation. Or reserve some entries in the TLB for permanently-valid translations and use some of those permanent translation slots for the handler code itself, these wired translations always hit in the TLB.</p>
<h4 id="aside-tlb-valid-bit--page-table-valid-bit">Aside: TLB valid bit != page table valid bit</h4>
<p>TLB valid bit indicates whether a TLB entry has a valid translation in it.</p>
<p>The page table valid bit indicates the page has not been allocated by the process, and should not be accessed by a correctly working program.</p>
<p>The TLB valid bit is quite useful when performing a context switch too. By setting all TLB entries to invalid, the system can ensure that the about-to-run process does not accidentally use a virtual-to-physical translation from a previous process.</p>
<h4 id="important">IMPORTANT:</h4>
<p>The dirty bit in PTE indicates where the PTE is modified rather than whether the memory location is modified, which is indicated by the dirty bit of that memory location.</p>
<p>Based on this fact, we can know that the content of PTE in TLB does not need to be the same as the one in the page table since whether the memory is modified is indicated by the memory itself rather than the PTE.</p>
<p>In addition, TLB PTE doesn&rsquo;t need to be the as same as the one in the page table because the OS can keep just TLB updated rather than both. Think of about this, if we have the PTE in TLB, when we want to go to that PA, we always get a TLB hit and will never walk the page table.</p>
<p>The additional work would be to update the PTE in the page table when the PTE in the TLB is evicted.</p>
<h5 id="my-question-here-is-whether-the-same-tlb-is-shared-by-processes-or-even-cores">My QUESTION here is whether the same TLB is shared by processes or even cores?</h5>
<h4 id="whats-in-the-tlb">What&rsquo;s in the TLB?</h4>
<p>VPN | PFN | other bits</p>
<p>A typical TLB might have 32, 64, 128 entries and be <strong>fully associative</strong>, which means any given translation can be anywhere in the TLB, and that the hardware will search the entire TLB in parallel to find the desired translation.</p>
<h4 id="tlb-issue-context-switches">TLB Issue: Context Switches</h4>
<p>The virtual-to-physical translations are not meaningful for other processes.</p>
<p>*<strong>How do we manage TLB contents on a context switch?</strong></p>
<ol>
<li>Flush the TLB on context Switches. But the cost is that each time a process runs, it must incur TLB misses as it touches its data and code pages. The cost will be high, if the OS Switches between processes frequently.</li>
<li>Some hardware provide ASID(address space identifier) field in the TLB, which usually has fewer bits than PID. The ASID is used to distinguish/mark PTEs from different processes.</li>
</ol>
<h4 id="issue-replacement-policy">Issue: Replacement Policy</h4>
<p>We have to consider cache replacement. Specifically, when we are installing a new entry in the TLB, which one should we replace?</p>
<h5 id="how-to-design-tlb-replacement-policy">How to design TLB replacement policy?</h5>
<ol>
<li>LRU(least-recently-used)</li>
<li>Random policy &ndash;&gt; avoid corner-case behaviors + simplicity</li>
</ol>
<h4 id="a-real-tlb-entry">A Real TLB Entry</h4>
<p>![MISP TLB Entry.png](img/MISP TLB Entry.png)</p>
<p>G is the global bit indicating whether the page is global shared among processes. Thus if global bit is set, the ASID is ignored.</p>
<p>C is the coherence bits indicating how a page is cached by the hardware.</p>
<p>D is the dirty bit indicating whether the page has been written to. (notice that this is the Intel&rsquo;s way of implementation.)</p>
<p>V is the valid bit telling the hardware if the there is a valid translation present in the entry.</p>
<h5 id="ram-isnt-always-ram">RAM isn&rsquo;t always RAM</h5>
<p>If the number of pages you want to access exceeds the TLB coverage, it can lead to severe performance issue. <strong>Culler&rsquo;s Law</strong> TLB as the source of many performance problems.</p>
<p>TLB actually brings many problems. Check the book for details.</p>
<h3 id="smaller-tables">Smaller Tables</h3>
<h4 id="page-tables-are-too-big">Page tables are too big</h4>
<p>Linear page tables are pretty big. Assuming a 32-bit address space, with 4KB pages and a 4-byte page-table size. There are roughly one million virtual pages in it, which will occupy 4MB memory.</p>
<h4 id="simple-solution-bigger-pages">Simple Solution: Bigger Pages</h4>
<h5 id="side-note-many-archs-now-support-multiple-page-sizes">Side note: many archs now support multiple page sizes.</h5>
<p>Bigger pages may cause <strong>internal fragmentation</strong>.</p>
<h4 id="hybrid-approach-paging-and-segments">Hybrid Approach: Paging and Segments</h4>
<p>Most of the page table is unused, full of invalid entries.</p>
<p>Instead of havin a single page table for the entris, why not one per logical segment.</p>
<p>Base tells us the address of each segment. It holds the pysical address of the page table of that segment.</p>
<p>Bound tells us the size of each segment.</p>
<p>Thus the VA looks like:
Seg | VPN | Offset</p>
<p>The hardware use segment bit(SN) to determine which base and bound pair to use.</p>
<h4 id="idea-when-you-have-two-good-and-seemly-opposite-ideas-you-should-always-see-if-you-can-combine-them-into-hybrid-that-manage-to-achieve-the-best-of-both-worlds">IDEA: When you have two good and seemly opposite ideas, you should always see if you can combine them into hybrid that manage to achieve the best of both worlds.</h4>
<p>So if the code segment just have three entries, then the bound will be set to 3. This greatly reduces the waste of space for page tables.</p>
<p>However, the problem is that if we have a large but sparsely-used heap. This will cause the <strong>external fragmentation</strong> again.</p>
<h4 id="multi-level-page-tables">Multi-level Page Tables</h4>
<p>It turns the linear page table like a tree.
We use <strong>page directory</strong> to find the valid page tables.</p>
<p>![Multi-level Page Tables](img/Multi-level Page Tables.png)</p>
<p>The page directory, in a simple two-level table, contains of a number of <strong>PDE</strong>(page directory entry).</p>
<p>A PDE has a valid bit and a PFN, similar to PTE. However, the valid bit in PDE indcates whether at least one of the PTEs on the page pointed to by this PDE is valid. If the PDE is not valid, then the rest of the PDE is not defined. (The valid bit is the first bit in PDE)</p>
<h5 id="advantage">Advantage:</h5>
<ol>
<li>Better supports sparse address spaces.</li>
<li>If carefully constructed, each portion of the page table fits neatly within a page, so it&rsquo;s easier to manage memory to avoid internal fragmentation.</li>
</ol>
<h5 id="disadvantage">Disadvantage:</h5>
<p>If we have a TLB miss, two loads from memory will be required to get the right translation, one for the page directory and one for the PTE itself.</p>
<p>So there is a <strong>time-space trade-off</strong>. Smaller cache is faster but not for free. The TLB miss suffers from higher cost with this smaller table.</p>
<p><img src="img/PDE.png" alt="PDE"></p>
<p>![Page Directory and Page of PT](img/Page Directory and Page of PT.png)</p>
<h4 id="more-than-two-levels">More Than Two Levels</h4>
<p>![More than two levels](img/More than two levels.png)</p>
<h4 id="important-the-pdts-pa-will-be-stored-in-a-register-but-it-does-not-mean-that-the-addr-of-pdt-has-to-be-in-a-fixed-pa-it-just-has-to-be-memorized">IMPORTANT: The PDT&rsquo;s PA will be stored in a register, but it does not mean that the addr of PDT has to be in a fixed PA, it just has to be memorized.</h4>
<h4 id="inverted-page-tables">Inverted Page Tables</h4>
<p><strong>Inverted page tables</strong> are even more space saving.</p>
<p>We keep a single page table that has an entry for each physical page of the system. The entry tells use which prcess is using this page, and which virtual page of that process maps to this physical page.</p>
<h3 id="swapping-mechanisms">Swapping: Mechanisms</h3>
<h4 id="swap-space">Swap space</h4>
<p>Firstly, we need to reserve some space on the disk for moving pages back and forth.</p>
<p>Then the OS need to remember the disk address of a given page.</p>
<p>The size of the swap space is important since it determines the maximum number of memory pages that can be in use by a system in a ginven time.</p>
<p>![Physical Memory and Swap Space](img/Physical Memory and Swap Space.png)</p>
<h4 id="the-present-bit">The Present Bit</h4>
<p>The hardware first extract the VPN from the VA, the check the TLB for a match. If a miss, the hardware locates the PDT and corresponding page tables and look up the PTE, and the present bit on the PTE is 0, it means that the page is not in physical memory, which is commonly referred to as a <strong>page fault</strong>.</p>
<p>Nowadays not only swapping will trigger page fault but also illegal memory accesses and so on. It becomes a more general term for &ldquo;page missing&rdquo;.</p>
<h4 id="the-page-fault">The Page Fault</h4>
<p>Upon a page fault, the OS invokes <strong>page-fault handler</strong> to deal with the issue, no matter for a hardware or software managed TLBs.</p>
<p>When a page fault happens, the OS needs to swap the page into memory in order to service the page fault.</p>
<p>When the disk I/O completes, the OS will then update the page table to mark the page as present, update the PFN of the PTE, and retry the instruction.</p>
<p>Notice that this next attampt still may generate a TLB miss, which would the be serviced and update the TLB with the translation.(The other approach is to update the TLB when handling the page fault.)</p>
<p>Finally, a last attampt will get a TLB hit.</p>
<p>Note that while the I/O is in flight, the process will be blocked, and other processes will execute.</p>
<h5 id="how-will-the-os-know-where-to-find-the-desired-page">How will the OS know where to find the desired page?</h5>
<p>The OS could use the bits in the PTE normally used for data such as the PFN of the page for a disk address. When the OS receives a page fault for a page, it looks in the PTE to find the address, and issues the request to disk to fetch the page into memory.</p>
<h5 id="why-hardware-doesnt-handle-page-faults">Why hardware doesn&rsquo;t handle page faults?</h5>
<ol>
<li>Page fault to disk is slow, even if the OS takes a long time to handle it, there is not to much of a difference.</li>
<li>To deal with the page fault, the hardware need to know the swap space, the I/Os to disk, and a lot of other details.</li>
</ol>
<h4 id="what-if-memory-is-full">What if memory is full?</h4>
<p>The OS may lie to first page out one or more pages to make room for the new pages. The process of picking a page to kick out, or replace is known as the <strong>page-replacement policy</strong>.</p>
<h4 id="page-fault-control-flow">Page Fault Control Flow</h4>
<p>If the page was both present and valid, the TLB miss handler will just grab the PFN from the PTE into TLB and try again.</p>
<p>If the page was not present but valid, then the page fault handler will run.</p>
<p>If the page is not valid, in this case, no other bits matter. The hardware traps this invalid access, and the OS trap handler runs, likely terminating the offending process.</p>
<h4 id="when-replacement-really-occur">When Replacement Really occur</h4>
<p>PLACEHOLDER</p>
<h3 id="swapping-policies">Swapping Policies</h3>
<h4 id="cache-management">Cache management</h4>
<h4 id="the-optimal-replacement-policy">The Optimal Replacement Policy</h4>
<h4 id="fifo">FIFO</h4>
<h4 id="random">Random</h4>
<h4 id="lru">LRU</h4>
<h4 id="approximating-lru">Approximating LRU</h4>
<p>The key is the use bit and clock algorithm.</p>
<h4 id="thrashing">Thrashing</h4>
<h2 id="concurrency">Concurrency</h2>
<h3 id="intro">Intro</h3>
<p>Each thread is very much like a separate process, except for one difference: they share the same address space and thus can access the same data.</p>
<p>Context switch between threads are similar to that between processes. We save the PC, registers, state and so on in TCB. The difference is that the address space remains the same.</p>
<h4 id="why-thread">why thread?</h4>
<ol>
<li>Parallelism</li>
<li>To avoid blocking program progress due to slow I/O</li>
</ol>
<h4 id="thread-creation">Thread Creation</h4>
<p>After the threads are created, the OS scheduler decides who runs the next.</p>
<h4 id="why-it-gets-worse-shared-data">Why It Gets Worse: Shared Data</h4>
<h5 id="recall-the-concept-if-the-hazard">[recall the concept if the Hazard]</h5>
<ul>
<li>
<p>Data Hazards</p>
<ul>
<li>
<p>RAW</p>
<pre tabindex="0"><code>i1. R2 &lt;- R5 + R3
i2. R4 &lt;- R2 + R3
</code></pre></li>
<li>
<p>WAR</p>
<pre tabindex="0"><code>i1. R4 &lt;- R1 + R5
i2. R5 &lt;- R1 + R2
</code></pre></li>
<li>
<p>WAW</p>
<pre tabindex="0"><code>i1. R2 &lt;- R4 + R7
i2. R2 &lt;- R1 + R3
</code></pre></li>
</ul>
</li>
<li>
<p>Structural Hazards</p>
</li>
<li>
<p>Control Hazards</p>
</li>
</ul>
<p>// compile with -g will include symbol info in the program. Then `prompt &gt; objdump -d main will give you the assembly code neatly labeled.</p>
<p>// You may want to master debugger gdb, memory profilers valgrind or purify, and the compiler itself.</p>
<h4 id="core-problem-uncontrolled-scheduling">Core Problem: Uncontrolled Scheduling</h4>
<p>We may have a race condition, or so to speak, a data race.</p>
<p>An<strong>indeterminate</strong>programconsistsofoneormoreraceconditions; the output of the program varies from run to run, depending on which threads ran when. The outcome is thus not <strong>deterministic</strong>, something we usually expect from computer systems.</p>
<p>A critical section is a piece of code that accesses a shared variable (or more generally, a shared resource) and must not be concurrently executed by more than one thread.</p>
<p>What we really want for this code is what we call <strong>mutual exclusion</strong>. This property guarantees that if one thread is executing within the critical section, the others will be prevented from doing so.</p>
<h4 id="one-more-problem-waiting-for-another">One More Problem: Waiting For Another</h4>
<h3 id="interlude-thread-api">Interlude: Thread API</h3>
<h4 id="thread-creation-1">Thread Creation</h4>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-c" data-lang="c"><span style="color:#75715e">#include</span> <span style="color:#75715e">&lt;pthread.h&gt;</span><span style="color:#75715e">
</span><span style="color:#75715e"></span><span style="color:#66d9ef">int</span> <span style="color:#a6e22e">pthread_create</span>(pthread_t<span style="color:#f92672">*</span> <span style="color:#66d9ef">thread</span>, <span style="color:#66d9ef">const</span> pthread_attr_t <span style="color:#f92672">*</span> attr, <span style="color:#66d9ef">void</span><span style="color:#f92672">*</span> (<span style="color:#f92672">*</span>start_routine) (<span style="color:#66d9ef">void</span><span style="color:#f92672">*</span>), <span style="color:#66d9ef">void</span> <span style="color:#f92672">*</span>arg);

<span style="color:#75715e">/*
</span><span style="color:#75715e">
</span><span style="color:#75715e">The second argument, attr, is used to specify any attributes this thread might have. Some examples include setting the stack size or perhaps in- formation about the scheduling priority of the thread. An attribute is initialized with a separate call to pthread attr init(); see the man- ual page for details. However, in most cases, the defaults will be fine; in this case, we will simply pass the value NULL in.
</span><span style="color:#75715e">The third argument is the most complex, but is really just asking: which function should this thread start running in? In C, we call this a function pointer, and this one tells us the following is expected: a function name (start routine), which is passed a single argument of type void * (as indicated in the parentheses after start routine), and which returns a value of type void * (i.e., a void pointer).
</span><span style="color:#75715e">Finally, the fourth argument, arg, is exactly the argument to be passed to the function where the thread begins execution.
</span><span style="color:#75715e">*/</span>

<span style="color:#75715e">/*
</span><span style="color:#75715e">having a void pointer as an argument to the function start routine allows us to pass in any type of argument; having it as a return value allows the thread to return any type of result.
</span><span style="color:#75715e">*/</span>
</code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-c" data-lang="c"><span style="color:#75715e">#include</span> <span style="color:#75715e">&lt;stdio.h&gt;</span><span style="color:#75715e">
</span><span style="color:#75715e">#include</span> <span style="color:#75715e">&lt;pthread.h&gt;</span><span style="color:#75715e">
</span><span style="color:#75715e"></span>
<span style="color:#66d9ef">typedef</span> <span style="color:#66d9ef">struct</span> {
  <span style="color:#66d9ef">int</span> a;
  <span style="color:#66d9ef">int</span> b;
} myarg_t;

<span style="color:#66d9ef">void</span> <span style="color:#f92672">*</span><span style="color:#a6e22e">mythread</span>(<span style="color:#66d9ef">void</span> <span style="color:#f92672">*</span>arg) {
  myarg_t <span style="color:#f92672">*</span>args <span style="color:#f92672">=</span> (myarg_t<span style="color:#f92672">*</span>) arg;
  printf(<span style="color:#e6db74">&#34;%d %d</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#34;</span>, args<span style="color:#f92672">-&gt;</span>a, args<span style="color:#f92672">-&gt;</span>b);
  <span style="color:#66d9ef">return</span> NULL;
} 

<span style="color:#66d9ef">int</span> <span style="color:#a6e22e">main</span>(<span style="color:#66d9ef">int</span> argc, <span style="color:#66d9ef">char</span><span style="color:#f92672">*</span> argv[]){
  pthread_t p;
  myarg_t args <span style="color:#f92672">=</span> { <span style="color:#ae81ff">10</span>, <span style="color:#ae81ff">20</span> };
  <span style="color:#66d9ef">int</span> rc <span style="color:#f92672">=</span> pthread_create(<span style="color:#f92672">&amp;</span>p, NULL, mythread, <span style="color:#f92672">&amp;</span>args);
}
</code></pre></div><h4 id="thread-completion">Thread Completion</h4>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-c" data-lang="c"><span style="color:#75715e">// What if you want to wait for a thread to complete?
</span><span style="color:#75715e"></span><span style="color:#66d9ef">int</span> <span style="color:#a6e22e">pthread_join</span>(pthread_t <span style="color:#66d9ef">thread</span>, <span style="color:#66d9ef">void</span> <span style="color:#f92672">**</span>value_ptr);

<span style="color:#75715e">/*
</span><span style="color:#75715e">This routine takes two arguments. The first is of type pthread t, and is used to specify which thread to wait for. This variable is initialized by the thread creation routine (when you pass a pointer to it as an argument to pthread create()); if you keep it around, you can use it to wait for that thread to terminate.
</span><span style="color:#75715e">The second argument is a pointer to the return value you expect to get back. Because the routine can return anything, it is defined to return a pointer to void; because the pthread join() routine changes the value of the passed in argument, you need to pass in a pointer to that value, not just the value itself.
</span><span style="color:#75715e">*/</span>
</code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-c" data-lang="c"><span style="color:#66d9ef">typedef</span> <span style="color:#66d9ef">struct</span> { <span style="color:#66d9ef">int</span> a; <span style="color:#66d9ef">int</span> b; } myarg_t;
<span style="color:#66d9ef">typedef</span> <span style="color:#66d9ef">struct</span> { <span style="color:#66d9ef">int</span> x; <span style="color:#66d9ef">int</span> y; } myret_t;

<span style="color:#66d9ef">void</span> <span style="color:#f92672">*</span><span style="color:#a6e22e">mythread</span>(<span style="color:#66d9ef">void</span> <span style="color:#f92672">*</span>arg) {
  myret_t <span style="color:#f92672">*</span>rvals <span style="color:#f92672">=</span> Malloc(<span style="color:#66d9ef">sizeof</span>(myret_t));
	rvals<span style="color:#f92672">-&gt;</span>x <span style="color:#f92672">=</span> <span style="color:#ae81ff">1</span>;
	rvals<span style="color:#f92672">-&gt;</span>y <span style="color:#f92672">=</span> <span style="color:#ae81ff">2</span>;
	<span style="color:#66d9ef">return</span> (<span style="color:#66d9ef">void</span> <span style="color:#f92672">*</span>) rvals;
}

<span style="color:#66d9ef">int</span> <span style="color:#a6e22e">main</span>(<span style="color:#66d9ef">int</span> argc, <span style="color:#66d9ef">char</span> <span style="color:#f92672">*</span>argv[]) {
pthread_t p;
myret_t <span style="color:#f92672">*</span>rvals;
myarg_t args <span style="color:#f92672">=</span> { <span style="color:#ae81ff">10</span>, <span style="color:#ae81ff">20</span> };
Pthread_create(<span style="color:#f92672">&amp;</span>p, NULL, mythread, <span style="color:#f92672">&amp;</span>args);
Pthread_join(p, (<span style="color:#66d9ef">void</span> <span style="color:#f92672">**</span>) <span style="color:#f92672">&amp;</span>rvals);
printf(<span style="color:#e6db74">&#34;returned %d %d</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#34;</span>, rvals<span style="color:#f92672">-&gt;</span>x, rvals<span style="color:#f92672">-&gt;</span>y);
free(rvals);
<span style="color:#66d9ef">return</span> <span style="color:#ae81ff">0</span>;
}
</code></pre></div><ol>
<li>If we just create a thread with no args, we can pass <code>NULL</code> in as an arg.</li>
<li>Similarly, we can pass <code>NULL</code> into <code>pthread_join()</code> if we care nothing about the return value.</li>
<li>If we are just passing in a single value, then we don&rsquo;t need to package it up as a arg.</li>
<li>We should be extremely careful with how values are returned from a thread. Never return a pointer which refers to something allocated on the thread&rsquo;s call stack.</li>
<li>We have a <code>pthread_create()</code> followed by<code>pthread_join()</code>. We can use <strong>procedure call</strong> instead.</li>
</ol>
<h4 id="locks">Locks</h4>
<p>The routines should be easy to understand and use. When you have a region of code that is a <strong>critical section</strong>, and thus needs to be protected to ensure correct operation, locks are quite useful.</p>
<p><code>int pthread_mutex_lock(pthread_mutex_t *mutex)</code></p>
<p><code>int pthread_mutex_unlock(pthread_mutex_t *mutex)</code></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-c" data-lang="c">pthread_mutex_t lock <span style="color:#f92672">=</span> PTHREAD_MUTEX_INITIALIZER; <span style="color:#75715e">// we must do the init for locks
</span><span style="color:#75715e">// or we can do as
</span><span style="color:#75715e"></span><span style="color:#66d9ef">int</span> rc <span style="color:#f92672">=</span> pthread_mutex_init(<span style="color:#f92672">&amp;</span>lock, NULL);
assert(rc <span style="color:#f92672">==</span> <span style="color:#ae81ff">0</span>); <span style="color:#75715e">// always check success!
</span><span style="color:#75715e"></span>

pthread_mutex_lock(<span style="color:#f92672">&amp;</span>lock);
x <span style="color:#f92672">=</span> x <span style="color:#f92672">+</span> <span style="color:#ae81ff">1</span>; <span style="color:#75715e">// or whatever your critical section is
</span><span style="color:#75715e"></span>pthread_mutex_unlock(<span style="color:#f92672">&amp;</span>lock);
</code></pre></div><p>Also, <code>pthread mutex destroy() </code> should be called afterwards.</p>
<p>There is a problem in the code above, which is that we didn&rsquo;t check the errors. If it fails, it fails silently.</p>
<p>The lock and unlock routines are not the only routines within the</p>
<p>pthreads library to interact with locks. Two other routines of interest:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-c" data-lang="c"><span style="color:#66d9ef">int</span> <span style="color:#a6e22e">pthread_mutex_trylock</span>(pthread_mutex_t <span style="color:#f92672">*</span>mutex);
<span style="color:#66d9ef">int</span> <span style="color:#a6e22e">pthread_mutex_timedlock</span>(pthread_mutex_t <span style="color:#f92672">*</span>mutex, <span style="color:#66d9ef">struct</span> timespec <span style="color:#f92672">*</span>abs_timeout);
</code></pre></div><p>These two calls are used in lock acquisition. The trylock version returns failure if the lock is already held; the timedlock version of acquiring a lock returns after a timeout or after acquiring the lock, whichever happens first. Thus, the timedlock with a timeout of zero degenerates to the trylock case. Both of these versions should generally be avoided; however, there are a few cases where avoiding getting stuck (perhaps indefinitely) in a lock acquisition routine can be useful.</p>
<h4 id="condition-variables">Condition Variables</h4>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-c" data-lang="c"><span style="color:#66d9ef">int</span> <span style="color:#a6e22e">pthread_cond_wait</span>(pthread_cond_t <span style="color:#f92672">*</span>cond, pthread_mutex_t <span style="color:#f92672">*</span>mutex);
<span style="color:#66d9ef">int</span> <span style="color:#a6e22e">pthread_cond_signal</span>(pthread_cond_t <span style="color:#f92672">*</span>cond);

<span style="color:#75715e">/*
</span><span style="color:#75715e">The first routine, pthread cond wait(), puts the calling thread to sleep, and thus waits for some other thread to signal it, usually when something in the program has changed that the now-sleeping thread might care about.
</span><span style="color:#75715e">*/</span>
</code></pre></div><h4 id="compile-and-run">Compile and Run</h4>
<p>All of the code examples in this chapter are relatively easy to get up and running. To compile them, you must include the header pthread.h in your code. On the link line, you must also explicitly link with the pthreads library, by adding the -pthread flag.</p>
<p>For example, to compile a simple multi-threaded program, all you have to do is the following:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-powershell" data-lang="powershell">gcc -o main main.c -Wall -pthread
</code></pre></div><h4 id="summary">Summary</h4>
<ul>
<li>Keep it simple</li>
<li>Minimize thread interactions</li>
<li>Initialize locks and conditon variables</li>
<li>Check you return codes</li>
<li>Be careful with how you pass arguments to, and return values from, threads</li>
<li>Each thread has its own stack</li>
<li>Always use condition variables to signal beween threads</li>
<li>Use the manual pages</li>
</ul>
<h3 id="locks-1">Locks</h3>
<h4 id="the-basic-idea">The Basic Idea</h4>

  

      </main>
      
  
  <script>
  window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
  ga('create', 'UA-123456789-1', 'auto');
  ga('send', 'pageview');
  </script>
  <script async src='https://www.google-analytics.com/analytics.js'></script>
  

  </div>
  </body>
</html>