[{"categories":["Moment"],"content":"My first blog!","date":"2021-12-12","objectID":"/first-post/","series":["Casual"],"tags":["Blog"],"title":"First Post","uri":"/first-post/"},{"categories":["Moment"],"content":"Better late than never. ","date":"2021-12-12","objectID":"/first-post/:0:0","series":["Casual"],"tags":["Blog"],"title":"First Post","uri":"/first-post/#"},{"categories":["Note"],"content":"Design Patterns For OOL ","date":"2022-01-10","objectID":"/design-patterns-for-ool/:0:0","series":[],"tags":["Design Pattern"],"title":"Design Patterns","uri":"/design-patterns-for-ool/#design-patterns-for-ool"},{"categories":["Note"],"content":"Terms Association Aggregation implies a relationship where the child can exist independently of the parent. Example: Class (parent) and Student (child). Delete the Class and the Students still exist. Composition implies a relationship where the child cannot exist independent of the parent. Example: House (parent) and Room (child). Rooms don’t exist separate to a House. ","date":"2022-01-10","objectID":"/design-patterns-for-ool/:0:1","series":[],"tags":["Design Pattern"],"title":"Design Patterns","uri":"/design-patterns-for-ool/#terms"},{"categories":["Note"],"content":"SOLID Design Principles S: Single-responsibility principle O: Open-closed principle L: Liskov’s substitution principle I: Interface segregation principle D: Dependency inversion principle There are mainly 3 catagories for design patterns. Creational: Diff ways to create objs Structural: Relationships btw objs Behavioural: Interactions and comm. btw objs There are more undocumented design patterns existed. We can use design patterns to comm. with dev at a more abstract lvl. And make reusable, extensible, maintainable software. ","date":"2022-01-10","objectID":"/design-patterns-for-ool/:1:0","series":[],"tags":["Design Pattern"],"title":"Design Patterns","uri":"/design-patterns-for-ool/#solid-design-principles"},{"categories":["Note"],"content":"Strategy Pattern The strategy pattern defines a family of algorithms and encapsulate each one, and makes them interchangeable.Strategy let the algorithms very independently found the clients who use it. (If you want to change the algorithems, you don’t need to change the client.) https://www.youtube.com/watch?v=OMPfEXIlTVE\u0026t=1782s Null Object Pattern The key idea of strategy pattern: Compostion \u0026 Injection Inheritance is useful for sepecialization not for sharing codes! Name the concepts using spread sheet. Class data ??? ???? House data nothing? RandomHouse data shuffle EchoHouse data ?? duplicate nothing? is not a nothing, it is a algorithm. ??? is the order! Order is the role of this, and nothing? is the default order. So, we can do this: class House attr_reader :data def initialize(orderer: DefaultOrder.new) @data = orderer.order(DATA) end #... end class DefaultOrder def order(data) data end end class RandomOrder def order(data) data.shuffle end end Similarly, we can get this: Class data order format House data default default RandomHouse data shuffle default EchoHouse data default duplicate We can make the design neat and elegant by analysis. Just creating subclasses for every object having some unique behavior is not the solution. Now we realize the same goal with less code and zero duplication. We isolate the differences and name the concepts and define that role and APIs, then inject into the object. Make good use of the “Active Nothing” (do not search for the null everytime, let the object stand in for that since “Nothing is always something\"). Composition + Denpendency Injection For example, there are abstract class Dog with several methods. Then there are 2 subclasses sharing some methods that the super class does not have. Here we should use interface instead of inheritance. And then implement the interface differently and apply accordingly to each subclass of dog. When you use inheritance, though the subclass don’t have that much methods, the instance of the subclass can be large since all hidden methods from the super class are also there. Pro: Prevents the conditional statements. (switch, if, else…) The algorithms are loosely coupled with the context entity. They can be changed/replaced without changing the context entity. Very easy extendable. Con: Clients must know existence of different strategies and a client must understand how the Strategies differ It increases the number of objects in the application. ","date":"2022-01-10","objectID":"/design-patterns-for-ool/:2:0","series":[],"tags":["Design Pattern"],"title":"Design Patterns","uri":"/design-patterns-for-ool/#strategy-pattern"},{"categories":["Note"],"content":"Observer Pattern Push vs. Poll Think about that we now have a wether station and a client like a phone. Now we want to know if there are any updated news. One way to do this is through polling. The phone will simply query the data periodically. It consumes a lot of resources to keep asking for the changes. (There might be millions of clients need the data) The other way is to let the phone subscribe the weather station which will notify the phone whenever the data get updated. And this solvement leans to the concept of pushing. The clients are observers, and the weather station is the observerable. The weather station has the following methods: add(…) remove(…) notify() The client has the following methods: update() We should notice that in this case, the client may “has-a” weather station. And we know that usually this relationship only appear on the higher abstraction level rather than the implementation level. The reason is that we have to pass in the weather station object into the constructor of the client so that when the client call the update() method where no arguments are passed in, it know how to access the data from the weather station. In the notify, we iterate through the list of subscribers and call the update() method of it. There are a lot of vairiants of ob pattern. You can do it in push\u0026pull, poll\u0026push, and etc. Please google it if you forget. For the push\u0026poll, we need to pass in the type of the observable into the constructor of the observer so that the implemented instances can access the data of the corresponding observables without creating abstractions for every type of the observables. Check Christopher Okhravi’s youtube vids if you forget everything. Pro: Con: You might end up with complicated nested event-driven structure, a event send signal to a event that send a sigal back to the first event, and there could be more complex structure in the middle. ","date":"2022-01-10","objectID":"/design-patterns-for-ool/:3:0","series":[],"tags":["Design Pattern"],"title":"Design Patterns","uri":"/design-patterns-for-ool/#observer-pattern"},{"categories":["Note"],"content":"Decorator Pattern You have an object, we send a message like speak() to the object and expect a string returned. If we want to change the object’s behavior without change the code of the object itself, we can use a decorator to wrap it up, which is like an outer object. Now we send the message to the decorator and it sends the mesage to the object. Then the object send the string to the decorator, the decorator processes the result and send it to us. The decorator has a component and is a component. The decorators is the same type of its inside while the decorators are also the wrappers of the inside. We say the decorator is a its component because we want to treat it as it was the same thing. We say the decorator has a its component because you want to send the message downward and get them back. Each level of the decorators attach additional responsibilities to an object dynamically. Decorator pattern provides flexibility for the subclasses to extend functionalities. At runtime, you cannot create a object combine subclass A and B but you can use decorator X and Y to combine them. We have a abstract class Beverage, and we also have bunch of subclasses such as Decaf, Mocha, Steamed, Milk.., We cannot create a subclass for each of the combination since those would be too many and each of them just do some tiny work. Most importantly, they are unmanageable. Attempt: All these options can be treated as bools. And we can include those bools throught setters in the superclass. Probs: But this is extremely unexpressive, and when we have such conditionals we will put ourselves in a place that needs more conditionals! (conditional breed) And if we want to expand the options, we have to modify the superclass so that many other subclass will also get this functions inherited they’ll never use, which disobeys the SOLID principles. Return a boolean usually invoke a conditional statement else where in your code. Attempt: Now introducing =\u003e Decoraaaaators Abstract class Beverage has getDress() cost() class Decaf class Espresso Addon Decorator is a Beverage and has a Beverage. And it has getDress() And it has bunch of implementations like CaramelDeco, SoyDeco No matter how many decorators you want, just add it as an additional outer wrapper. Notice here the Addon Decorator has the getDress() function so that it acts like the Beverage, and the fact that it is the outer decorator make it has a Beverage inside. Please note that in this case the decorator pattern may not be the best implementation but this case illustrates the concepts very well. The value passing downward and upward is through recursion. For example, the cost() here. The decorator calls the cost() recursively so that when it reaches the base case, which is when it reaches the cost() of Decaf or Espresso, the value get returned from inside to outside. There might be multiple decorators but each of them just think it is wrapping up only one thing. abstract class Beverage{ public abstract int cost(); } abstract class AddonDecorator: Beverage{ public abstract int cost(); } class Espresso: Beverage{ public abstract int cost(){ return 1; } } class CaramelDeco: AddonDecorator{ Beverage beverage; int price = 2; public CaramelDeco(Beverage b) { this.beverage = b; } public int cost() { return this.beverage.cost() + this.price; } } Frankly, iteration pattern would be more properate to calculate the total cost, since the cost() in each decorator behaves the same. A better example would be buffterAlignmentDeco –\u003e …non-deco or deco… –\u003e bufferInputDeco –\u003e inputString This is better since: They are working on the same type: String Each decorator behaves differently ","date":"2022-01-10","objectID":"/design-patterns-for-ool/:4:0","series":[],"tags":["Design Pattern"],"title":"Design Patterns","uri":"/design-patterns-for-ool/#decorator-pattern"},{"categories":["Note"],"content":"Factory Pattern ","date":"2022-01-10","objectID":"/design-patterns-for-ool/:5:0","series":[],"tags":["Design Pattern"],"title":"Design Patterns","uri":"/design-patterns-for-ool/#factory-pattern"},{"categories":["Note"],"content":"Golang why golang c/c++ fast but have to carry historical burdens, slow compile java kinda same python, easy to use but slow. None of these are developed toward to the best performance in terms of concurrency Strong and staticaaly typed excellent comm. Key features simplicity fast compile times garbage collected compile to standaline binaries(all dependencies are in there) built-in concurrency package main // have to specify the package name import ( \"fmt\" ) func main() { fmt.Println(\"Hello, playground\") } ","date":"2022-01-10","objectID":"/golang/:0:0","series":[],"tags":["Golang"],"title":"Golang","uri":"/golang/#golang"},{"categories":["Note"],"content":"Set up the env if you don’t install it in the default route, you may want to set the GOROOT and GOPATH in the bash file. GOROOT is where you golang are installed. GOPATH is where your files and binaries are located. But you can set up 2 GOPATH, the first one is going to be used for go get to hold all files or 3rd party go libs, while both are searched for source code. So it helps us to set up the workspace. In a workspace, we have src for sourec code, we have bin for binaries, and pkg for intermediate binaries liked some 3rd party libs you want to integrated into your project. ","date":"2022-01-10","objectID":"/golang/:1:0","series":[],"tags":["Golang"],"title":"Golang","uri":"/golang/#set-up-the-env"},{"categories":["Note"],"content":"Complile go run src/github.com/PceWlkr/fisrtapp/Main.go go build github.com/PceWlkr/firstapp // use the package addr. it will look into it if there is a main.go ./firstapp go install github.com/PceWlkr/firstapp ./bin/firstapp Notice there might be some changes since the build and install are not working for me with the package path. ","date":"2022-01-10","objectID":"/golang/:2:0","series":[],"tags":["Golang"],"title":"Golang","uri":"/golang/#complile"},{"categories":["Note"],"content":"Complile go run src/github.com/PceWlkr/fisrtapp/Main.go go build github.com/PceWlkr/firstapp // use the package addr. it will look into it if there is a main.go ./firstapp go install github.com/PceWlkr/firstapp ./bin/firstapp Notice there might be some changes since the build and install are not working for me with the package path. ","date":"2022-01-10","objectID":"/golang/:2:0","series":[],"tags":["Golang"],"title":"Golang","uri":"/golang/#notice-there-might-be-some-changes-since-the-build-and-install-are-not-working-for-me-with-the-package-path"},{"categories":["Note"],"content":"Variables package main import( \"fmt\" ) var i int 42 // you have to use this syntax if you declare it on package level var I int 54 // upper case var declared at package level is exposed to the ouside of the package while lower case vars declared at package level stays in the package scope var ( str string = \"my name\" num int = 3 ) func main(){ var o int // sometime you don't want a init, and this is in the block scope o = 42 // or var j float32 = 27. // or k := 99 i := 1 // error: you cannot delcare the same var in the same scope for twice i = 1 // this is OK var i int = 22 // This is also OK, but the package level i is hidden now, we can only the local i here var p int = 0; // this will throw a error, you cannot just declare it without using in your code fmt.Println(i) fmt.Printf(\"%v, %T, %T\", j, j, k) // will print 27, float32, float64 } var i int = 42 var j float32 j = float32(i) var i int = 42 var j string j = string(i) // the j here will be * // since it will look up the unicode for 42 and it's * j = strconv.Itoa(i) // we need to use this to convert int to string you want ","date":"2022-01-10","objectID":"/golang/:3:0","series":[],"tags":["Golang"],"title":"Golang","uri":"/golang/#variables"},{"categories":["Note"],"content":"Spring5 IOC AOP ------------------------- ----------------------- |Data Access/Integration| | Web | | JDBC ORM | |WebSocket WebMVC | | OXM JMS | |Web WebFlux | | Transactions | | | ------------------------- ----------------------- AOP Aspects Instrument Messaging ----------------------------------------------------- | Core Container | | Beans Core Context Expression | ----------------------------------------------------- ","date":"2022-01-10","objectID":"/spring5/:0:0","series":[],"tags":["Spring5"],"title":"Spring5","uri":"/spring5/#spring5"},{"categories":["Note"],"content":"Installation Spring Download Spring Framework Unzip it libs –\u003e jars jar sources –\u003e source code javadoc –\u003e doc schema –\u003e configs For basic functions, we need: Beans Core Context Expression commons-logging (Not in Spring, google it) ","date":"2022-01-10","objectID":"/spring5/:1:0","series":[],"tags":["Spring5"],"title":"Spring5","uri":"/spring5/#installation"},{"categories":["Note"],"content":"Have a Taste: Create Objects ","date":"2022-01-10","objectID":"/spring5/:2:0","series":[],"tags":["Spring5"],"title":"Spring5","uri":"/spring5/#have-a-taste-create-objects"},{"categories":["Note"],"content":"xml public class User{ public void add(){ System.out.println(\"added...\"); } } Create a xml file, for axample, bean.xml \u003c?xml version=\"1.0\" encoding=\"UTF-8\"?\u003e \u003cbeans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd\"\u003e \u003c!--create User object--\u003e \u003cbean id=\"user\" class=\"com.pcewlkr.spring.basics.User\"\u003e\u003c/bean\u003e \u003c/beans\u003e Write a test to verify if it works @Test public void testCreatingObject(){ // load spring config ApplicationContext context = new ClassPathXmlApplicationContext(\"bean.xml\"); // get the obj User user = context.getBean(\"user\", User.class); System.out.println(user); } Output: com.pcewlkr.spring.basics.User@4816278d ","date":"2022-01-10","objectID":"/spring5/:2:1","series":[],"tags":["Spring5"],"title":"Spring5","uri":"/spring5/#xml"},{"categories":["Note"],"content":"IOC Container ","date":"2022-01-10","objectID":"/spring5/:3:0","series":[],"tags":["Spring5"],"title":"Spring5","uri":"/spring5/#ioc-container"},{"categories":["Note"],"content":"IOC –\u003e Low Level What is IOC? Inverse of Control. Usually, the creation of objects and the calling between them are managed by our codes, but now we hand those over Spring framework. Goal of IOC: low coupling IOC Explain xml parsing, factory mode, and reflection For example, if we have service class and dao class, then we need to create a factory class. First step is the xml config. \u003cbean id=\"dao\" class=\"com.me.UserDao\"/\u003e class UserFactory { public UserDao getDao() { Sting classValue = classAttributes // --\u003e xml parsing Class clazz = Class.forName(classValue); // --\u003e create objects using reflection return (UserDao) clazz.newInstance(); } } ","date":"2022-01-10","objectID":"/spring5/:3:1","series":[],"tags":["Spring5"],"title":"Spring5","uri":"/spring5/#ioc----low-level"},{"categories":["Note"],"content":"IOC Interface –\u003e BeanFactory IOC is based on IOC container, which is based on the object factory. Spring provides 2 implementations of IOC containers (2 interfaces): BeanFactory: Fundamental of IOC container, which usually is not directly used by devs. AplicationContext: Sub interface of BeanFactory, which provides more powerful functions and often used by devs in real life. ApplicationContext: implementation classes FileSystemXmlApplicationContext –\u003e use absolute path ClassPathXmlApplicationContext –\u003e use relative path ","date":"2022-01-10","objectID":"/spring5/:3:2","series":[],"tags":["Spring5"],"title":"Spring5","uri":"/spring5/#ioc-interface----beanfactory"},{"categories":["Note"],"content":"IOC Ops Bean Managment –\u003e XML Based What is Bean Managment? Spring Object Creation Spring Attribute Injection 2 ways of implementations of Bean Managment Based on xml config Based on annotations xml config based   Object Creation \u003cbean id=\"user\" class=\"com.me.spring.User\"/\u003e Add attributes in bean tags. e.g.: id, class. Attributes Injection –\u003e DI: Dependency Injection Setter Constructor with params p namespace Injection –\u003e Simplifies xml config \u003c!-- Setter --\u003e \u003cbean id=\"user\" class=\"com.me.spring.User\"\u003e \u003cproperty name=\"username\" value=\"peacewalker\"\u003e\u003c/property\u003e \u003cproperty name=\"age\" value=\"25\"\u003e\u003c/property\u003e \u003c/bean\u003e \u003c!-- Constructor with params --\u003e \u003cbean id=\"order\" class=\"com.me.spring.basics.Order\"\u003e \u003cconstructor-arg name=\"name\" value=\"Mr. Li\"\u003e\u003c/constructor-arg\u003e \u003cconstructor-arg name=\"address\" value=\"NYC\"\u003e\u003c/constructor-arg\u003e \u003c/bean\u003e At he beginning of Spring config xml, there are info about xml namespace. Add p namespace config. Config in bean tag \u003c!-- p namespace --\u003e \u003c?xml version=\"1.0\" encoding=\"UTF-8\"?\u003e \u003cbeans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:p=\"http://www.springframework.org/schema/p\" // here is the namespace p added xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd\"\u003e \u003cbean id=\"order\" class=\"com.me.spring.basics.Order\" p:name=\"Mr. Li\" p:address=\"NYC\"/\u003e \u003c/beans\u003e How to assign null and other special chars? Use escape chars use \u003cproperty name=\"address\"\u003e \u003cnull/\u003e \u003c/property\u003e \u003cproperty name=\"address\" value=\"\u0026lt;NYC\u0026gt;\"/\u003e \u003cproperty name=\"name\"\u003e \u003cvalue\u003e\u003c![CDATA[\u003cNYC\u003e]]\u003e\u003c/value\u003e \u003c/property\u003e Attribute Injection –\u003e Outer bean Create 2 classes: service and dao Invoke dao’s methods from service config in Spring config xml package com.me.spring.basics.dao; public interface UserDao { void update(); } package com.me.spring.basics.dao; public class UserDaoImpl implements UserDao{ @Override public void update(){ System.out.println(\"dao updated...\"); } } package com.me.spring.basics.service; import com.me.spring.basics.dao.UserDao; import com.me.spring.basics.dao.UserDaoImpl; public class UserService { private UserDao userDao; public void setUserDao(UserDao userDao) { this.userDao = userDao; } public void add(){ System.out.println(\"Service added...\"); // UserDao userDao = new UserDaoImpl(); // userDao.update(); } } \u003c?xml version=\"1.0\" encoding=\"UTF-8\"?\u003e \u003cbeans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd\"\u003e \u003cbean id=\"userService\" class=\"com.me.spring.basics.service.UserService\"\u003e \u003c!-- Inject the object using the attribute name in UserService class and the obj bean id --\u003e \u003cproperty name=\"userDao\" ref=\"userDaoToInject\"\u003e\u003c/property\u003e \u003c/bean\u003e \u003cbean id=\"userDaoToInject\" class=\"com.me.spring.basics.dao.UserDaoImpl\"\u003e\u003c/bean\u003e \u003c/beans\u003e @Test public void test03(){ ApplicationContext context = new ClassPathXmlApplicationContext(\"outerBeanInjection.xml\"); UserService userService = context.getBean(\"userService\", UserService.class); userService.add(); } Attribute Injection –\u003e Inner bean and inline assignment 1 to n 1 staff can belong to 1 department 1 department can have n staffs \u003c?xml version=\"1.0\" encoding=\"UTF-8\"?\u003e \u003cbeans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd\"\u003e \u003cbean id=\"staff\" class=\"com.me.spring.basics.bean.Staff\"\u003e \u003cproperty name=\"name\" value=\"Lucy\"\u003e\u003c/property\u003e \u003cproperty name=\"gender\" value=\"Female\"\u003e\u003c/property\u003e \u003cproperty name=\"dept\"\u003e \u003cbean id=\"dept\" class=\"com.me.spring.basics.bean.Dept\"\u003e \u003cproperty name=\"name\" value=\"Security Dept\"\u003e\u003c/property\u003e \u003c/bean\u003e \u003c/property\u003e \u003c/bean\u003e \u003c/beans\u003e Notice: Inner bean cannot be referenced outside. \u003c?xml ver","date":"2022-01-10","objectID":"/spring5/:3:3","series":[],"tags":["Spring5"],"title":"Spring5","uri":"/spring5/#ioc-ops-bean-managment----xml-based"},{"categories":["Note"],"content":"IOC Ops Bean Managment – XML Based What is Bean Managment? Spring Object Creation Spring Attribute Injection 2 ways of implementations of Bean Managment Based on xml config Based on annotations xml config based Object Creation Add attributes in bean tags. e.g.: id, class. Attributes Injection – DI: Dependency Injection Setter Constructor with params p namespace Injection – Simplifies xml config At he beginning of Spring config xml, there are info about xml namespace. Add p namespace config. Config in bean tag How to assign null and other special chars? Use escape chars use ]] Attribute Injection – Outer bean Create 2 classes: service and dao Invoke dao’s methods from service config in Spring config xml package com.me.spring.basics.dao; public interface UserDao { void update(); } package com.me.spring.basics.dao; public class UserDaoImpl implements UserDao{ @Override public void update(){ System.out.println(\"dao updated...\"); } } package com.me.spring.basics.service; import com.me.spring.basics.dao.UserDao; import com.me.spring.basics.dao.UserDaoImpl; public class UserService { private UserDao userDao; public void setUserDao(UserDao userDao) { this.userDao = userDao; } public void add(){ System.out.println(\"Service added...\"); // UserDao userDao = new UserDaoImpl(); // userDao.update(); } } @Test public void test03(){ ApplicationContext context = new ClassPathXmlApplicationContext(\"outerBeanInjection.xml\"); UserService userService = context.getBean(\"userService\", UserService.class); userService.add(); } Attribute Injection – Inner bean and inline assignment 1 to n 1 staff can belong to 1 department 1 department can have n staffs Notice: Inner bean cannot be referenced outside. ","date":"2022-01-10","objectID":"/spring5/:3:3","series":[],"tags":["Spring5"],"title":"Spring5","uri":"/spring5/#xml-config-based"},{"categories":["Note"],"content":"Bean and FactoryBean There are 2 kinds of bean: bean and FactoryBean. FactoryBean –\u003e The return type can be diff from the defined class in xml. package com.me.spring.basics.factoryBean; import com.me.spring.basics.collections.Course; import org.springframework.beans.factory.FactoryBean; public class MyBean implements FactoryBean\u003cCourse\u003e { private Course course; public Course getCourse() { return course; } public void setCourse(Course course) { this.course = course; } @Override public Course getObject() throws Exception { return course; } @Override public Class\u003c?\u003e getObjectType() { return Course.class; } @Override public boolean isSingleton() { return FactoryBean.super.isSingleton(); } } \u003c?xml version=\"1.0\" encoding=\"UTF-8\"?\u003e \u003cbeans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd\"\u003e \u003cbean id=\"course1\" class=\"com.me.spring.basics.collections.Course\"\u003e \u003cproperty name=\"name\" value=\"Java\"\u003e\u003c/property\u003e \u003c/bean\u003e \u003cbean id=\"myBean\" class=\"com.me.spring.basics.factoryBean.MyBean\"\u003e \u003cproperty name=\"course\" ref=\"course1\"\u003e\u003c/property\u003e \u003c/bean\u003e \u003c/beans\u003e @Test public void test06(){ ApplicationContext context = new ClassPathXmlApplicationContext(\"factoryBean.xml\"); Course myBean = context.getBean(\"myBean\", Course.class); System.out.println(myBean); } ","date":"2022-01-10","objectID":"/spring5/:3:4","series":[],"tags":["Spring5"],"title":"Spring5","uri":"/spring5/#bean-and-factorybean"},{"categories":["Note"],"content":"Bean’s Scope We can set whether a bean instance is a Singleton(单实例)or Prototype(多实例). By defalt, it’s Singleton. \u003cbean id=\"someID\" class=\"com.me.spring.SomeClass\" scope=\"Prototype\"/\u003e Singleton是单例类型，就是在创建起容器时就同时自动创建了一个bean的对象，不管你是否使用，他都存在了，每次获取到的对象都是同一个对象。注意，Singleton作用域是Spring中的缺省作用域。 Prototype是原型类型，它在我们创建容器的时候并没有实例化，而是当我们获取bean的时候才会去创建一个对象，而且我们每次获取到的对象都不是同一个对象。 五种作用域中，request、session和global session三种作用域仅在基于web的应用中使用（不必关心你所采用的是什么web应用框架），只能用在基于web的Spring ApplicationContext环境。 ","date":"2022-01-10","objectID":"/spring5/:3:5","series":[],"tags":["Spring5"],"title":"Spring5","uri":"/spring5/#beans-scope"},{"categories":["Note"],"content":"Bean’s Lifetime Create bean instance through non-param constructor Use setters to inject bean attributes and other beans BeanPostProcessor Interface –\u003e postProcessBeforeInitialization() Invoke bean’s init method –\u003e need to be configured BeanPostProcessor Interface –\u003e postProcessAfterInitialization() Running Once the container is closed, invoke the Destroy() method –\u003e need to be configured Bean实例生命周期的执行过程如下： Spring对bean进行实例化，默认bean是单例； Spring对bean进行依赖注入； 如果bean实现了BeanNameAware接口，Spring将bean的名称传给setBeanName()方法； 如果bean实现了BeanFactoryAware接口，Spring将调用setBeanFactory()方法，将BeanFactory实例传进来； 如果bean实现了ApplicationContextAware接口，它的setApplicationContext()方法将被调用，将应用上下文的引用传入到bean中； 如果bean实现了BeanPostProcessor接口，它的postProcessBeforeInitialization()方法将被调用； 如果bean中有方法添加了@PostConstruct注解，那么该方法将被调用； 如果bean实现了InitializingBean接口，spring将调用它的afterPropertiesSet()接口方法，类似的如果bean使用了init-method属性声明了初始化方法，该方法也会被调用； 如果在xml文件中通过\u003cbean\u003e标签的init-method元素指定了初始化方法，那么该方法将被调用； 如果bean实现了BeanPostProcessor接口，它的postProcessAfterInitialization()接口方法将被调用； 此时bean已经准备就绪，可以被应用程序使用了，他们将一直驻留在应用上下文中，直到该应用上下文被销毁； 如果bean中有方法添加了@PreDestroy注解，那么该方法将被调用； 若bean实现了DisposableBean接口，spring将调用它的distroy()接口方法。同样的，如果bean使用了destroy-method属性声明了销毁方法，则该方法被调用； 这里特别说明一下Aware接口，Spring的依赖注入最大亮点就是所有的Bean对Spring容器的存在是没有意识的。但是在实际项目中，我们有时不可避免的要用到Spring容器本身提供的资源，这时候要让 Bean主动意识到Spring容器的存在，才能调用Spring所提供的资源，这就是Spring的Aware接口，Aware接口是个标记接口，标记这一类接口是用来“感知”属性的，Aware的众多子接口则是表征了具体要“感知”什么属性。例如BeanNameAware接口用于“感知”自己的名称，ApplicationContextAware接口用于“感知”自己所处的上下文。其实Spring的Aware接口是Spring设计为框架内部使用的，在大多数情况下，我们不需要使用任何Aware接口，除非我们真的需要它们，实现了这些接口会使应用层代码耦合到Spring框架代码中。 package com.me.spring.basics.lifetime; public class Lifetime { private int time; private Lifetime lifetime; public void setTime(int time) { this.time = time; } public Lifetime(){ System.out.println(\"Create bean instance through Lifetime()\"); } public Lifetime(int time) { this.time = time; System.out.println(\"Setter DI\"); } public void initMethod(){ System.out.println(\"Execute init method\"); } public void destroyMethod(){ System.out.println(\"Destroy bean instance\"); } } package com.me.spring.basics.lifetime; import org.springframework.beans.BeansException; import org.springframework.beans.factory.config.BeanPostProcessor; public class LifetimePostProcessor implements BeanPostProcessor { @Override public Object postProcessBeforeInitialization(Object bean, String beanName) throws BeansException { System.out.println(\"Before init\"); return bean; } @Override public Object postProcessAfterInitialization(Object bean, String beanName) throws BeansException { System.out.println(\"After init\"); return bean; } } \u003c?xml version=\"1.0\" encoding=\"UTF-8\"?\u003e \u003cbeans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd\"\u003e \u003cbean id=\"lifetime\" class=\"com.me.spring.basics.lifetime.Lifetime\" scope=\"singleton\" init-method=\"initMethod\" destroy-method=\"destroyMethod\"\u003e\u003c/bean\u003e \u003c!-- All beans will be modified by this post processor! --\u003e \u003cbean id=\"postProcessor\" class=\"com.me.spring.basics.lifetime.LifetimePostProcessor\"\u003e\u003c/bean\u003e \u003c/beans\u003e @Test public void test07(){ ApplicationContext context = new ClassPathXmlApplicationContext(\"lifetime.xml\"); Lifetime lifetime = context.getBean(\"lifetime\", Lifetime.class); System.out.println(\"Using bean...\"); System.out.println(lifetime); ((ClassPathXmlApplicationContext)context).close(); } ","date":"2022-01-10","objectID":"/spring5/:3:6","series":[],"tags":["Spring5"],"title":"Spring5","uri":"/spring5/#beans-lifetime"},{"categories":["Note"],"content":"Autowire According to the attribute name or type, Spring will do the matching and injection package com.me.spring.basics.autowire; public class Emp { private Dept dept; @Override public String toString() { return \"Emp{\" + \"dept=\" + dept + '}'; } public void setDept(Dept dept) { this.dept = dept; } } package com.me.spring.basics.autowire; public class Dept { @Override public String toString() { return \"Dept{}\"; } } \u003c?xml version=\"1.0\" encoding=\"UTF-8\"?\u003e \u003cbeans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd\"\u003e \u003c!-- The injected bean's id must be same as the string after 'set' in the setter's method name in the current bean class --\u003e \u003cbean id=\"emp1\" class=\"com.me.spring.basics.autowire.Emp\" autowire=\"byName\"\u003e\u003c/bean\u003e \u003c!-- Find the type of the attributes in the current bean class, notice there will be error occur if there are more than one bean with same type we needed --\u003e \u003cbean id=\"emp2\" class=\"com.me.spring.basics.autowire.Emp\" autowire=\"byType\"\u003e\u003c/bean\u003e \u003cbean id=\"dept\" class=\"com.me.spring.basics.autowire.Dept\"\u003e\u003c/bean\u003e \u003c/beans\u003e ","date":"2022-01-10","objectID":"/spring5/:3:7","series":[],"tags":["Spring5"],"title":"Spring5","uri":"/spring5/#autowire"},{"categories":["Note"],"content":"IOC Bean –\u003e Outside Config File Directly Configure DB Info Configure Druid Conection Pool Refer outside config file to configure DB connection pool Create jdbc.properties prop.driverClass=com.mysql.jdbc.Driver prop.url=jdbc:mysql://localhost:3306/userDb prop.username=root prop.password=root Reference through context namespace in Spring config file \u003c?xml version=\"1.0\" encoding=\"UTF-8\"?\u003e \u003cbeans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:context=\"http://www.springframework.org/schema/context\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd\"\u003e \u003c!-- Directly configure data connection pool --\u003e \u003c!-- \u003cbean id=\"dataSource\" class=\"com.alibaba.druid.pool.DruidDataSource\"\u003e--\u003e \u003c!-- \u003cproperty name=\"driverClassName\" value=\"com.mysql.jdbc.Driver\"\u003e\u003c/property\u003e--\u003e \u003c!-- \u003cproperty name=\"url\" value=\"jdbc:mysql://localhost:3306/userDb\"\u003e\u003c/property\u003e--\u003e \u003c!-- \u003cproperty name=\"username\" value=\"root\"\u003e\u003c/property\u003e--\u003e \u003c!-- \u003cproperty name=\"password\" value=\"root\"\u003e\u003c/property\u003e--\u003e \u003c!-- \u003c/bean\u003e--\u003e \u003ccontext:property-placeholder location=\"classpath:jdbc.properties\"/\u003e \u003cbean id=\"dataSource\" class=\"com.alibaba.druid.pool.DruidDataSource\"\u003e \u003cproperty name=\"driverClassName\" value=\"${prop.driverClass}\"\u003e\u003c/property\u003e \u003cproperty name=\"url\" value=\"${prop.url}\"\u003e\u003c/property\u003e \u003cproperty name=\"username\" value=\"${prop.username}\"\u003e\u003c/property\u003e \u003cproperty name=\"password\" value=\"${prop.password}\"\u003e\u003c/property\u003e \u003c/bean\u003e \u003c/beans\u003e ","date":"2022-01-10","objectID":"/spring5/:3:8","series":[],"tags":["Spring5"],"title":"Spring5","uri":"/spring5/#ioc-bean----outside-config-file"},{"categories":["Note"],"content":"IOC Ops Bean Managment –\u003e Annotation Based @Component @Service @Controller @Repository How? Import aop jar Turn on component scan Create classes and add annotations Detailed config on component scan package com.me.spring.basics.annotations.service; import org.springframework.stereotype.Component; // you can omit the value, the default value is as same as the class name with a lowercase of the first letter @Component(value = \"userService\") // \u003cbean id = \"userService\" class=\"...\"/\u003e public class UserService { public void add(){ System.out.println(\"Service added...\"); } } \u003c?xml version=\"1.0\" encoding=\"UTF-8\"?\u003e \u003cbeans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:context=\"http://www.springframework.org/schema/context\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd\"\u003e \u003c!-- turn on component scan, to scan multiple packages, use `,` or use higher level path--\u003e \u003ccontext:component-scan base-package=\"com.me.spring.basics.annotations, com.me.spring.basics.test\"\u003e\u003c/context:component-scan\u003e \u003c!-- example 1--\u003e \u003ccontext:component-scan base-package=\"com.me.spring.basics\" use-default-filters=\"false\"\u003e \u003c!-- only scan Controller annotation--\u003e \u003ccontext:include-filter type=\"annotation\" expression=\"org.springframework.stereotype.Controller\"/\u003e \u003c/context:component-scan\u003e \u003c!-- example 2--\u003e \u003ccontext:component-scan base-package=\"com.me.spring.basics\"\u003e \u003c!-- Do not scan Controller annotation--\u003e \u003ccontext:exclude-filter type=\"annotation\" expression=\"org.springframework.stereotype.Controller\"/\u003e \u003c/context:component-scan\u003e \u003c/beans\u003e ","date":"2022-01-10","objectID":"/spring5/:3:9","series":[],"tags":["Spring5"],"title":"Spring5","uri":"/spring5/#ioc-ops-bean-managment----annotation-based"},{"categories":["Note"],"content":"Annotations for Atrributes Injection @Autowired –\u003e by type @Qualifier –\u003e by name @Resource –\u003e type or name @Value –\u003e primitives @Autowired add annotations on classes Injection package com.me.spring.basics.annotations.service; import com.me.spring.basics.annotations.dao.UserDao; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.stereotype.Service; // you can omit the value, the default value is as same as the class name with a lowercase of the first letter @Service // \u003cbean id = \"userService\" class=\"...\"/\u003e public class UserService { @Autowired // do not need setter since it's encapsulated private UserDao userDao; public void add(){ System.out.println(\"Service added...\"); userDao.add(); } } package com.me.spring.basics.annotations.dao; import org.springframework.stereotype.Repository; @Repository public class UserDaoImpl implements UserDao{ @Override public void add() { System.out.println(\"userDao.add() is called...\"); } } @Qualifier Must be used along with @Autowired @Autowired // do not need setter since it's encapsulated @Qualifier(value = \"userDaoImpl\") ... @Resource –\u003e not in Spring but javax.annotation.Resource @Resource –\u003e by type @Resource(name =\"userDaoImpl\") –\u003e by name @Value –\u003e for the primitives @Value(value = \"TheName\") private String name; ","date":"2022-01-10","objectID":"/spring5/:3:10","series":[],"tags":["Spring5"],"title":"Spring5","uri":"/spring5/#annotations-for-atrributes-injection"},{"categories":["Note"],"content":"Annotations for Atrributes Injection @Autowired – by type @Qualifier – by name @Resource – type or name @Value – primitives @Autowired add annotations on classes Injection package com.me.spring.basics.annotations.service; import com.me.spring.basics.annotations.dao.UserDao; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.stereotype.Service; // you can omit the value, the default value is as same as the class name with a lowercase of the first letter @Service // public class UserService { @Autowired // do not need setter since it's encapsulated private UserDao userDao; public void add(){ System.out.println(\"Service added...\"); userDao.add(); } } package com.me.spring.basics.annotations.dao; import org.springframework.stereotype.Repository; @Repository public class UserDaoImpl implements UserDao{ @Override public void add() { System.out.println(\"userDao.add() is called...\"); } } @Qualifier Must be used along with @Autowired @Autowired // do not need setter since it's encapsulated @Qualifier(value = \"userDaoImpl\") ... @Resource – not in Spring but javax.annotation.Resource @Resource – by type @Resource(name =\"userDaoImpl\") – by name @Value – for the primitives @Value(value = \"TheName\") private String name; ","date":"2022-01-10","objectID":"/spring5/:3:10","series":[],"tags":["Spring5"],"title":"Spring5","uri":"/spring5/#autowired"},{"categories":["Note"],"content":"Annotations for Atrributes Injection @Autowired – by type @Qualifier – by name @Resource – type or name @Value – primitives @Autowired add annotations on classes Injection package com.me.spring.basics.annotations.service; import com.me.spring.basics.annotations.dao.UserDao; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.stereotype.Service; // you can omit the value, the default value is as same as the class name with a lowercase of the first letter @Service // public class UserService { @Autowired // do not need setter since it's encapsulated private UserDao userDao; public void add(){ System.out.println(\"Service added...\"); userDao.add(); } } package com.me.spring.basics.annotations.dao; import org.springframework.stereotype.Repository; @Repository public class UserDaoImpl implements UserDao{ @Override public void add() { System.out.println(\"userDao.add() is called...\"); } } @Qualifier Must be used along with @Autowired @Autowired // do not need setter since it's encapsulated @Qualifier(value = \"userDaoImpl\") ... @Resource – not in Spring but javax.annotation.Resource @Resource – by type @Resource(name =\"userDaoImpl\") – by name @Value – for the primitives @Value(value = \"TheName\") private String name; ","date":"2022-01-10","objectID":"/spring5/:3:10","series":[],"tags":["Spring5"],"title":"Spring5","uri":"/spring5/#qualifier"},{"categories":["Note"],"content":"Annotations for Atrributes Injection @Autowired – by type @Qualifier – by name @Resource – type or name @Value – primitives @Autowired add annotations on classes Injection package com.me.spring.basics.annotations.service; import com.me.spring.basics.annotations.dao.UserDao; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.stereotype.Service; // you can omit the value, the default value is as same as the class name with a lowercase of the first letter @Service // public class UserService { @Autowired // do not need setter since it's encapsulated private UserDao userDao; public void add(){ System.out.println(\"Service added...\"); userDao.add(); } } package com.me.spring.basics.annotations.dao; import org.springframework.stereotype.Repository; @Repository public class UserDaoImpl implements UserDao{ @Override public void add() { System.out.println(\"userDao.add() is called...\"); } } @Qualifier Must be used along with @Autowired @Autowired // do not need setter since it's encapsulated @Qualifier(value = \"userDaoImpl\") ... @Resource – not in Spring but javax.annotation.Resource @Resource – by type @Resource(name =\"userDaoImpl\") – by name @Value – for the primitives @Value(value = \"TheName\") private String name; ","date":"2022-01-10","objectID":"/spring5/:3:10","series":[],"tags":["Spring5"],"title":"Spring5","uri":"/spring5/#resource----not-in-spring-but-javaxannotationresource"},{"categories":["Note"],"content":"Annotations for Atrributes Injection @Autowired – by type @Qualifier – by name @Resource – type or name @Value – primitives @Autowired add annotations on classes Injection package com.me.spring.basics.annotations.service; import com.me.spring.basics.annotations.dao.UserDao; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.stereotype.Service; // you can omit the value, the default value is as same as the class name with a lowercase of the first letter @Service // public class UserService { @Autowired // do not need setter since it's encapsulated private UserDao userDao; public void add(){ System.out.println(\"Service added...\"); userDao.add(); } } package com.me.spring.basics.annotations.dao; import org.springframework.stereotype.Repository; @Repository public class UserDaoImpl implements UserDao{ @Override public void add() { System.out.println(\"userDao.add() is called...\"); } } @Qualifier Must be used along with @Autowired @Autowired // do not need setter since it's encapsulated @Qualifier(value = \"userDaoImpl\") ... @Resource – not in Spring but javax.annotation.Resource @Resource – by type @Resource(name =\"userDaoImpl\") – by name @Value – for the primitives @Value(value = \"TheName\") private String name; ","date":"2022-01-10","objectID":"/spring5/:3:10","series":[],"tags":["Spring5"],"title":"Spring5","uri":"/spring5/#value----for-the-primitives"},{"categories":["Note"],"content":"Pure Annotation Dev Create a config class to substitute xml config Test case @Configuration @ComponentScan(basePackages = {\"com.me.spring.basics\"}) ApplicationContext context = new AnnotationConfigApplicationContext(SpringConfig.class); ","date":"2022-01-10","objectID":"/spring5/:3:11","series":[],"tags":["Spring5"],"title":"Spring5","uri":"/spring5/#pure-annotation-dev"},{"categories":["Note"],"content":"AOP Add funcitons without modify the original codes, whether make it in effect is determined by whether AOP scans it ","date":"2022-01-10","objectID":"/spring5/:4:0","series":[],"tags":["Spring5"],"title":"Spring5","uri":"/spring5/#aop"},{"categories":["Note"],"content":"At Low Level -\u003e Dynamic Proxy With an interface –\u003e JDK Dynamic Proxy –\u003e use interface impl as proxy Without an interface –\u003e CGLIB Dynamic Proxy –\u003e use subclass implementing Invocationhandler as proxy –\u003e less constrains but less efficiency ","date":"2022-01-10","objectID":"/spring5/:4:1","series":[],"tags":["Spring5"],"title":"Spring5","uri":"/spring5/#at-low-level---dynamic-proxy"},{"categories":["Note"],"content":"JDK dp Proxy.newProxyInstance(ClassLoader loader, Class\u003c?\u003e[] interfaces, InvocationHandler h); class loader the interfaces implemented implement InvocationHandler, create proxy object and added functions package com.me.spring.basics.proxy; public interface MyDao { public int add(int a, int b); public String update(String id); } package com.me.spring.basics.proxy; public class MyDaoImpl implements MyDao{ @Override public int add(int a, int b) { System.out.println(\"add() is executed...\"); return a+b; } @Override public String update(String id) { System.out.println(\"update() is executed...\"); return id; } } package com.me.spring.basics.proxy; import java.lang.reflect.InvocationHandler; import java.lang.reflect.Method; import java.lang.reflect.Proxy; import java.util.Arrays; public class JDKProxy { public static void main(String[] args) { MyDaoImpl myDaoImpl = new MyDaoImpl(); MyDao myDao = (MyDao)Proxy.newProxyInstance(MyDaoImpl.class.getClassLoader(), MyDaoImpl.class.getInterfaces(), new MyDaoProxy(myDaoImpl)); System.out.println(myDao.add(1,5)); } } class MyDaoProxy implements InvocationHandler{ private Object obj; public MyDaoProxy(){} public MyDaoProxy(Object obj){ this.obj = obj; } public void bind(Object obj){ this.obj = obj; } @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable { System.out.println(\"Before the function...\" + method.getName() + Arrays.toString(args)); Object res = method.invoke(obj, args); System.out.println(\"After the function...\" + res); return res; } } ","date":"2022-01-10","objectID":"/spring5/:4:2","series":[],"tags":["Spring5"],"title":"Spring5","uri":"/spring5/#jdk-dp"},{"categories":["Note"],"content":"CHLIB dp ","date":"2022-01-10","objectID":"/spring5/:4:3","series":[],"tags":["Spring5"],"title":"Spring5","uri":"/spring5/#chlib-dp"},{"categories":["Note"],"content":"AOP Terms Joinpoint: Insertion points (methods) of AOP. A joinpoint is a point in the execution of the application where an aspect can be plugged in. Pointcut: The specific methods being adviced. Pointcut is an AOP terminology for all the points in the execution of your code where you want this advice method to cut in. Advice: The action taken in joinpoint, the job of an aspect is called Advice.It defines both when and what of the aspect. Spring aspects can work with five kinds of advice @Before @After @Around @AfterThrowing @AfterReturning Advisor: pointcut + advice Aspect: pointcut + advice, but we don’t need to implement the advice interfaces here. The modularization of concern is known as Aspect.In spring,Aspect is a class with special priviliges and are annotaed with @Aspect to represent Aspects. Weaving: Weaving is the process of applying aspects to a target object to create a new proxied object. Proxy: obj created after the target being adviced ","date":"2022-01-10","objectID":"/spring5/:4:4","series":[],"tags":["Spring5"],"title":"Spring5","uri":"/spring5/#aop-terms"},{"categories":["Note"],"content":"AOP ops AspectJ: not a part of Spring but an independent AOP framework xml based annotation based Import dependencies: aop, aspectJ.weaver, aopalliance, cglib pointcut expression execution([access modifier] [return type] [path of class] [method name] ([args])) // example1 --\u003e com.me.dao.BookDao add() execution(* com.me.dao.BookDao.add(..)) // access modifier can be omit // it must include the return type, * indicates any types // example2 --\u003e all methods execution(* com.me.dao.BookDao.*(..)) // example3 --\u003e all methods in all classes execution(* com.me.dao.*(..)) AspectJ (annotation) create a class and methods create the advice class with advice logic in it advice config turn on annotation scan create instances of proxy and proxyee using annotation add @Aspect annotation on proxy config Spring config to turn on proxy obj generation In the proxy class, add advice annotation and pointcut expressions @Around \u003e @Before \u003e @After \u003e @AfterReturning \u003e @AfterThrowing If there is exceptions, @AfterReturning will not run. @After will execute regardless whether exception occurs package com.me.spring.basics.aopanno; import org.springframework.stereotype.Component; @Component public class User { public void add(){ System.out.println(\"add...\"); } } package com.me.spring.basics.aopanno; import org.aspectj.lang.ProceedingJoinPoint; import org.aspectj.lang.annotation.*; import org.springframework.stereotype.Component; @Component @Aspect public class UserProxy { @Around(value = \"execution(* com.me.spring.basics.aopanno.User.add(..))\") public void around(ProceedingJoinPoint proceedingJoinPoint) throws Throwable { System.out.println(\"around-before...\"); proceedingJoinPoint.proceed(); System.out.println(\"around-after...\"); } @Before(value = \"execution(* com.me.spring.basics.aopanno.User.add(..))\") public void before(){ System.out.println(\"before...\"); } @After(value = \"execution(* com.me.spring.basics.aopanno.User.add(..))\") public void after(){ System.out.println(\"after...\"); } @AfterThrowing(value = \"execution(* com.me.spring.basics.aopanno.User.add(..))\") public void afterThrowing(){ System.out.println(\"afterThrowing...\"); } @AfterReturning(value = \"execution(* com.me.spring.basics.aopanno.User.add(..))\") public void afterReturning(){ System.out.println(\"afterReturning...\"); } } \u003c?xml version=\"1.0\" encoding=\"UTF-8\"?\u003e \u003cbeans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:context=\"http://www.springframework.org/schema/context\" xmlns:aop=\"http://www.springframework.org/schema/aop\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop.xsd\"\u003e \u003ccontext:component-scan base-package=\"com.me.spring.basics.aopanno\"\u003e\u003c/context:component-scan\u003e \u003caop:aspectj-autoproxy\u003e\u003c/aop:aspectj-autoproxy\u003e \u003c/beans\u003e Notice: pointcut can be extracted multiple advice on one method can be set to diff priorities package com.me.spring.basics.aopanno; import org.aspectj.lang.ProceedingJoinPoint; import org.aspectj.lang.annotation.*; import org.springframework.stereotype.Component; @Component @Aspect @Order(1) public class UserProxy { @Pointcut(value = \"execution(* com.me.spring.basics.aopanno.User.add(..))\") public void pointcut(){} @Around(value = \"pointcut()\") public void around(ProceedingJoinPoint proceedingJoinPoint) throws Throwable { System.out.println(\"around-before...\"); proceedingJoinPoint.proceed(); System.out.println(\"around-after...\"); } @Before(value = \"pointcut()\") public void before(){ System.out.println(\"before...\"); } @After(value = \"pointcut()\") public void after(){ System.out.println(\"after...\"); } @AfterThrowing(value = \"pointcut()\") public void afterThrowing(){ System.out.println(\"afterThrowing...\"); } @AfterReturning(value = ","date":"2022-01-10","objectID":"/spring5/:4:5","series":[],"tags":["Spring5"],"title":"Spring5","uri":"/spring5/#aop-ops"},{"categories":["Note"],"content":"AOP ops AspectJ: not a part of Spring but an independent AOP framework xml based annotation based Import dependencies: aop, aspectJ.weaver, aopalliance, cglib pointcut expression execution([access modifier] [return type] [path of class] [method name] ([args])) // example1 -- com.me.dao.BookDao add() execution(* com.me.dao.BookDao.add(..)) // access modifier can be omit // it must include the return type, * indicates any types // example2 -- all methods execution(* com.me.dao.BookDao.*(..)) // example3 -- all methods in all classes execution(* com.me.dao.*(..)) AspectJ (annotation) create a class and methods create the advice class with advice logic in it advice config turn on annotation scan create instances of proxy and proxyee using annotation add @Aspect annotation on proxy config Spring config to turn on proxy obj generation In the proxy class, add advice annotation and pointcut expressions @Around @Before @After @AfterReturning @AfterThrowing If there is exceptions, @AfterReturning will not run. @After will execute regardless whether exception occurs package com.me.spring.basics.aopanno; import org.springframework.stereotype.Component; @Component public class User { public void add(){ System.out.println(\"add...\"); } } package com.me.spring.basics.aopanno; import org.aspectj.lang.ProceedingJoinPoint; import org.aspectj.lang.annotation.*; import org.springframework.stereotype.Component; @Component @Aspect public class UserProxy { @Around(value = \"execution(* com.me.spring.basics.aopanno.User.add(..))\") public void around(ProceedingJoinPoint proceedingJoinPoint) throws Throwable { System.out.println(\"around-before...\"); proceedingJoinPoint.proceed(); System.out.println(\"around-after...\"); } @Before(value = \"execution(* com.me.spring.basics.aopanno.User.add(..))\") public void before(){ System.out.println(\"before...\"); } @After(value = \"execution(* com.me.spring.basics.aopanno.User.add(..))\") public void after(){ System.out.println(\"after...\"); } @AfterThrowing(value = \"execution(* com.me.spring.basics.aopanno.User.add(..))\") public void afterThrowing(){ System.out.println(\"afterThrowing...\"); } @AfterReturning(value = \"execution(* com.me.spring.basics.aopanno.User.add(..))\") public void afterReturning(){ System.out.println(\"afterReturning...\"); } } Notice: pointcut can be extracted multiple advice on one method can be set to diff priorities package com.me.spring.basics.aopanno; import org.aspectj.lang.ProceedingJoinPoint; import org.aspectj.lang.annotation.*; import org.springframework.stereotype.Component; @Component @Aspect @Order(1) public class UserProxy { @Pointcut(value = \"execution(* com.me.spring.basics.aopanno.User.add(..))\") public void pointcut(){} @Around(value = \"pointcut()\") public void around(ProceedingJoinPoint proceedingJoinPoint) throws Throwable { System.out.println(\"around-before...\"); proceedingJoinPoint.proceed(); System.out.println(\"around-after...\"); } @Before(value = \"pointcut()\") public void before(){ System.out.println(\"before...\"); } @After(value = \"pointcut()\") public void after(){ System.out.println(\"after...\"); } @AfterThrowing(value = \"pointcut()\") public void afterThrowing(){ System.out.println(\"afterThrowing...\"); } @AfterReturning(value = ","date":"2022-01-10","objectID":"/spring5/:4:5","series":[],"tags":["Spring5"],"title":"Spring5","uri":"/spring5/#pointcut-expression"},{"categories":["Note"],"content":"AOP ops AspectJ: not a part of Spring but an independent AOP framework xml based annotation based Import dependencies: aop, aspectJ.weaver, aopalliance, cglib pointcut expression execution([access modifier] [return type] [path of class] [method name] ([args])) // example1 -- com.me.dao.BookDao add() execution(* com.me.dao.BookDao.add(..)) // access modifier can be omit // it must include the return type, * indicates any types // example2 -- all methods execution(* com.me.dao.BookDao.*(..)) // example3 -- all methods in all classes execution(* com.me.dao.*(..)) AspectJ (annotation) create a class and methods create the advice class with advice logic in it advice config turn on annotation scan create instances of proxy and proxyee using annotation add @Aspect annotation on proxy config Spring config to turn on proxy obj generation In the proxy class, add advice annotation and pointcut expressions @Around @Before @After @AfterReturning @AfterThrowing If there is exceptions, @AfterReturning will not run. @After will execute regardless whether exception occurs package com.me.spring.basics.aopanno; import org.springframework.stereotype.Component; @Component public class User { public void add(){ System.out.println(\"add...\"); } } package com.me.spring.basics.aopanno; import org.aspectj.lang.ProceedingJoinPoint; import org.aspectj.lang.annotation.*; import org.springframework.stereotype.Component; @Component @Aspect public class UserProxy { @Around(value = \"execution(* com.me.spring.basics.aopanno.User.add(..))\") public void around(ProceedingJoinPoint proceedingJoinPoint) throws Throwable { System.out.println(\"around-before...\"); proceedingJoinPoint.proceed(); System.out.println(\"around-after...\"); } @Before(value = \"execution(* com.me.spring.basics.aopanno.User.add(..))\") public void before(){ System.out.println(\"before...\"); } @After(value = \"execution(* com.me.spring.basics.aopanno.User.add(..))\") public void after(){ System.out.println(\"after...\"); } @AfterThrowing(value = \"execution(* com.me.spring.basics.aopanno.User.add(..))\") public void afterThrowing(){ System.out.println(\"afterThrowing...\"); } @AfterReturning(value = \"execution(* com.me.spring.basics.aopanno.User.add(..))\") public void afterReturning(){ System.out.println(\"afterReturning...\"); } } Notice: pointcut can be extracted multiple advice on one method can be set to diff priorities package com.me.spring.basics.aopanno; import org.aspectj.lang.ProceedingJoinPoint; import org.aspectj.lang.annotation.*; import org.springframework.stereotype.Component; @Component @Aspect @Order(1) public class UserProxy { @Pointcut(value = \"execution(* com.me.spring.basics.aopanno.User.add(..))\") public void pointcut(){} @Around(value = \"pointcut()\") public void around(ProceedingJoinPoint proceedingJoinPoint) throws Throwable { System.out.println(\"around-before...\"); proceedingJoinPoint.proceed(); System.out.println(\"around-after...\"); } @Before(value = \"pointcut()\") public void before(){ System.out.println(\"before...\"); } @After(value = \"pointcut()\") public void after(){ System.out.println(\"after...\"); } @AfterThrowing(value = \"pointcut()\") public void afterThrowing(){ System.out.println(\"afterThrowing...\"); } @AfterReturning(value = ","date":"2022-01-10","objectID":"/spring5/:4:5","series":[],"tags":["Spring5"],"title":"Spring5","uri":"/spring5/#aspectj-annotation"},{"categories":["Note"],"content":"AOP ops AspectJ: not a part of Spring but an independent AOP framework xml based annotation based Import dependencies: aop, aspectJ.weaver, aopalliance, cglib pointcut expression execution([access modifier] [return type] [path of class] [method name] ([args])) // example1 -- com.me.dao.BookDao add() execution(* com.me.dao.BookDao.add(..)) // access modifier can be omit // it must include the return type, * indicates any types // example2 -- all methods execution(* com.me.dao.BookDao.*(..)) // example3 -- all methods in all classes execution(* com.me.dao.*(..)) AspectJ (annotation) create a class and methods create the advice class with advice logic in it advice config turn on annotation scan create instances of proxy and proxyee using annotation add @Aspect annotation on proxy config Spring config to turn on proxy obj generation In the proxy class, add advice annotation and pointcut expressions @Around @Before @After @AfterReturning @AfterThrowing If there is exceptions, @AfterReturning will not run. @After will execute regardless whether exception occurs package com.me.spring.basics.aopanno; import org.springframework.stereotype.Component; @Component public class User { public void add(){ System.out.println(\"add...\"); } } package com.me.spring.basics.aopanno; import org.aspectj.lang.ProceedingJoinPoint; import org.aspectj.lang.annotation.*; import org.springframework.stereotype.Component; @Component @Aspect public class UserProxy { @Around(value = \"execution(* com.me.spring.basics.aopanno.User.add(..))\") public void around(ProceedingJoinPoint proceedingJoinPoint) throws Throwable { System.out.println(\"around-before...\"); proceedingJoinPoint.proceed(); System.out.println(\"around-after...\"); } @Before(value = \"execution(* com.me.spring.basics.aopanno.User.add(..))\") public void before(){ System.out.println(\"before...\"); } @After(value = \"execution(* com.me.spring.basics.aopanno.User.add(..))\") public void after(){ System.out.println(\"after...\"); } @AfterThrowing(value = \"execution(* com.me.spring.basics.aopanno.User.add(..))\") public void afterThrowing(){ System.out.println(\"afterThrowing...\"); } @AfterReturning(value = \"execution(* com.me.spring.basics.aopanno.User.add(..))\") public void afterReturning(){ System.out.println(\"afterReturning...\"); } } Notice: pointcut can be extracted multiple advice on one method can be set to diff priorities package com.me.spring.basics.aopanno; import org.aspectj.lang.ProceedingJoinPoint; import org.aspectj.lang.annotation.*; import org.springframework.stereotype.Component; @Component @Aspect @Order(1) public class UserProxy { @Pointcut(value = \"execution(* com.me.spring.basics.aopanno.User.add(..))\") public void pointcut(){} @Around(value = \"pointcut()\") public void around(ProceedingJoinPoint proceedingJoinPoint) throws Throwable { System.out.println(\"around-before...\"); proceedingJoinPoint.proceed(); System.out.println(\"around-after...\"); } @Before(value = \"pointcut()\") public void before(){ System.out.println(\"before...\"); } @After(value = \"pointcut()\") public void after(){ System.out.println(\"after...\"); } @AfterThrowing(value = \"pointcut()\") public void afterThrowing(){ System.out.println(\"afterThrowing...\"); } @AfterReturning(value = ","date":"2022-01-10","objectID":"/spring5/:4:5","series":[],"tags":["Spring5"],"title":"Spring5","uri":"/spring5/#aspectj-xml"},{"categories":["Note"],"content":"JdbcTemplate mysql-connector-java ","date":"2022-01-10","objectID":"/spring5/:5:0","series":[],"tags":["Spring5"],"title":"Spring5","uri":"/spring5/#jdbctemplate"},{"categories":["Note"],"content":"Transaction ","date":"2022-01-10","objectID":"/spring5/:6:0","series":[],"tags":["Spring5"],"title":"Spring5","uri":"/spring5/#transaction"},{"categories":["Note"],"content":"ACID Atomicity: 事务作为一个整体被执行，包含在其中的对数据库的操作要么全部被执行，要么都不执行. Consistency: 事务应确保数据库的状态从一个一致状态转变为另一个一致状态。一致状态的含义是数据库中的数据应满足完整性约束. Isolation: 多个事务并发执行时，一个事务的执行不应影响其他事务的执行. Probs READ UNCOMMITTED READ COMMITTED REPEATABLE READ SERIALIZABLE Durability: 已被提交的事务对数据库的修改应该永久保存在数据库中. ","date":"2022-01-10","objectID":"/spring5/:6:1","series":[],"tags":["Spring5"],"title":"Spring5","uri":"/spring5/#acid"},{"categories":["Note"],"content":"Transaction Manager Transactions are usually added into Service level of JavaEE There are 2 ways of transaction managment in Spring programming(use try-catch-finally to code it) declaration –\u003e AOP at low level xml annotation Spring Transaction Manager API PlatformTransactionManager –\u003e Interface for mybatis and jdbc –\u003e DataSourceTransactionManager Declaration: Annotation Create Transaction Manager in config Turn on transaction annotation add tx namespace In the service class, add transaction annotation on the corresponding methods (or the whole class) @transactional Notice if put it on the class, it’s on every method in it \u003c?xml version=\"1.0\" encoding=\"UTF-8\"?\u003e \u003cbeans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:context=\"http://www.springframework.org/schema/context\" xmlns:aop=\"http://www.springframework.org/schema/aop\" xmlns:tx=\"http://www.springframework.org/schema/tx\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx.xsd\"\u003e \u003c!--turn on component scan--\u003e \u003ccontext:component-scan base-package=\"com.me.spring.transaction\"\u003e\u003c/context:component-scan\u003e \u003c!-- db connection pool --\u003e \u003ccontext:property-placeholder location=\"classpath:jdbc.properties\"/\u003e \u003cbean id=\"dataSource\" class=\"com.alibaba.druid.pool.DruidDataSource\"\u003e \u003c!-- @deprecated -\u003e \u003cproperty name=\"driverClassName\" value=\"${prop.driverClass}\"\u003e\u003c/property\u003e--\u003e \u003cproperty name=\"url\" value=\"${prop.url}\"\u003e\u003c/property\u003e \u003cproperty name=\"username\" value=\"${prop.username}\"\u003e\u003c/property\u003e \u003cproperty name=\"password\" value=\"${prop.password}\"\u003e\u003c/property\u003e \u003c/bean\u003e \u003c!-- JdbcTemplate object --\u003e \u003cbean id=\"jdbcTemplate\" class=\"org.springframework.jdbc.core.JdbcTemplate\"\u003e \u003c!-- Inject dataSource--\u003e \u003cproperty name=\"dataSource\" ref=\"dataSource\"\u003e\u003c/property\u003e \u003c/bean\u003e \u003c!-- Create transaction manager--\u003e \u003cbean id=\"transactionManager\" class=\"org.springframework.jdbc.datasource.DataSourceTransactionManager\"\u003e \u003c!-- Inject data source--\u003e \u003cproperty name=\"dataSource\" ref=\"dataSource\"\u003e\u003c/property\u003e \u003c/bean\u003e \u003c/beans\u003e @Service public class UserService { @Autowired private UserDao userDao; @Transactional public void accountMoney(double amount, String sender, String receiver){ userDao.reduceMoney(amount, sender); userDao.addMoney(amount, receiver); } } public interface UserDao { public void addMoney(double money, String name); public void reduceMoney(double money, String name); } @Repository public class UserDaoImpl implements UserDao{ @Autowired private JdbcTemplate jdbcTemplate; @Override public void addMoney(double amount, String name) { String sql = \"update t_account set money=money-? where username=?\"; jdbcTemplate.update(sql, amount, name); } @Override public void reduceMoney(double amount, String name) { String sql = \"update t_account set money=money+? where username=?\"; jdbcTemplate.update(sql, amount, name); } } @Test public void test01(){ ApplicationContext context = new ClassPathXmlApplicationContext(\"druid.xml\"); UserService userService = context.getBean(\"userService\", UserService.class); userService.accountMoney(100, \"Lucy\", \"Marry\"); } @Transaction(…) propagation –\u003e 事务传播行为 (REQUIRED by default) 多\u003c事务方法\u003e之间进行调用，这个过程中事务是如何进行管理的 REQUIRED –\u003e 表示当前方法必须在一个具有事务的上下文中运行，如有客户端有事务在进行，那么被调用端将在该事务中运行，否则的话重新开启一个事务。(如果被调用端发生异常，那么调用端和被调用端事务都将回滚) REQUIRED_NEW –\u003e 表示当前方法必须运行在它自己的事务中。一个新的事务将启动，而且如果有一个现有的事务在运行的话，则这个方法将在运行期被挂起，直到新的事务提交或者回滚才恢复执行 SUPPORTS –\u003e 表示当前方法不必需要具有一个事务上下文，但是如果有一个事务的话，它也可以在这个事务中运行 NOT_SUPPORTED –\u003e 表示该方法不应该在一个事务中运行。如果有一个事务正在运行，他将在运行期被挂起，直到这个事务提交或者回滚才恢复执行 MANDATORY –\u003e 表示当前方法必须在一个事务中运行，如果没有事务，将抛出异常 NEVER –\u003e 表示当方法务不应该在一个事务中运行，如果存在一个事务，则抛出异常 NESTED –\u003e 表示如果当前方法正有一个事务在运行中，则该方法应该运行在一个嵌套事务中，被嵌套的事务可以","date":"2022-01-10","objectID":"/spring5/:6:2","series":[],"tags":["Spring5"],"title":"Spring5","uri":"/spring5/#transaction-manager"},{"categories":["Note"],"content":"Transaction Manager Transactions are usually added into Service level of JavaEE There are 2 ways of transaction managment in Spring programming(use try-catch-finally to code it) declaration – AOP at low level xml annotation Spring Transaction Manager API PlatformTransactionManager – Interface for mybatis and jdbc – DataSourceTransactionManager Declaration: Annotation Create Transaction Manager in config Turn on transaction annotation add tx namespace In the service class, add transaction annotation on the corresponding methods (or the whole class) @transactional Notice if put it on the class, it’s on every method in it -- @Service public class UserService { @Autowired private UserDao userDao; @Transactional public void accountMoney(double amount, String sender, String receiver){ userDao.reduceMoney(amount, sender); userDao.addMoney(amount, receiver); } } public interface UserDao { public void addMoney(double money, String name); public void reduceMoney(double money, String name); } @Repository public class UserDaoImpl implements UserDao{ @Autowired private JdbcTemplate jdbcTemplate; @Override public void addMoney(double amount, String name) { String sql = \"update t_account set money=money-? where username=?\"; jdbcTemplate.update(sql, amount, name); } @Override public void reduceMoney(double amount, String name) { String sql = \"update t_account set money=money+? where username=?\"; jdbcTemplate.update(sql, amount, name); } } @Test public void test01(){ ApplicationContext context = new ClassPathXmlApplicationContext(\"druid.xml\"); UserService userService = context.getBean(\"userService\", UserService.class); userService.accountMoney(100, \"Lucy\", \"Marry\"); } @Transaction(…) propagation – 事务传播行为 (REQUIRED by default) 多之间进行调用，这个过程中事务是如何进行管理的 REQUIRED – 表示当前方法必须在一个具有事务的上下文中运行，如有客户端有事务在进行，那么被调用端将在该事务中运行，否则的话重新开启一个事务。(如果被调用端发生异常，那么调用端和被调用端事务都将回滚) REQUIRED_NEW – 表示当前方法必须运行在它自己的事务中。一个新的事务将启动，而且如果有一个现有的事务在运行的话，则这个方法将在运行期被挂起，直到新的事务提交或者回滚才恢复执行 SUPPORTS – 表示当前方法不必需要具有一个事务上下文，但是如果有一个事务的话，它也可以在这个事务中运行 NOT_SUPPORTED – 表示该方法不应该在一个事务中运行。如果有一个事务正在运行，他将在运行期被挂起，直到这个事务提交或者回滚才恢复执行 MANDATORY – 表示当前方法必须在一个事务中运行，如果没有事务，将抛出异常 NEVER – 表示当方法务不应该在一个事务中运行，如果存在一个事务，则抛出异常 NESTED – 表示如果当前方法正有一个事务在运行中，则该方法应该运行在一个嵌套事务中，被嵌套的事务可以","date":"2022-01-10","objectID":"/spring5/:6:2","series":[],"tags":["Spring5"],"title":"Spring5","uri":"/spring5/#declaration-annotation"},{"categories":["Note"],"content":"Transaction Manager Transactions are usually added into Service level of JavaEE There are 2 ways of transaction managment in Spring programming(use try-catch-finally to code it) declaration – AOP at low level xml annotation Spring Transaction Manager API PlatformTransactionManager – Interface for mybatis and jdbc – DataSourceTransactionManager Declaration: Annotation Create Transaction Manager in config Turn on transaction annotation add tx namespace In the service class, add transaction annotation on the corresponding methods (or the whole class) @transactional Notice if put it on the class, it’s on every method in it -- @Service public class UserService { @Autowired private UserDao userDao; @Transactional public void accountMoney(double amount, String sender, String receiver){ userDao.reduceMoney(amount, sender); userDao.addMoney(amount, receiver); } } public interface UserDao { public void addMoney(double money, String name); public void reduceMoney(double money, String name); } @Repository public class UserDaoImpl implements UserDao{ @Autowired private JdbcTemplate jdbcTemplate; @Override public void addMoney(double amount, String name) { String sql = \"update t_account set money=money-? where username=?\"; jdbcTemplate.update(sql, amount, name); } @Override public void reduceMoney(double amount, String name) { String sql = \"update t_account set money=money+? where username=?\"; jdbcTemplate.update(sql, amount, name); } } @Test public void test01(){ ApplicationContext context = new ClassPathXmlApplicationContext(\"druid.xml\"); UserService userService = context.getBean(\"userService\", UserService.class); userService.accountMoney(100, \"Lucy\", \"Marry\"); } @Transaction(…) propagation – 事务传播行为 (REQUIRED by default) 多之间进行调用，这个过程中事务是如何进行管理的 REQUIRED – 表示当前方法必须在一个具有事务的上下文中运行，如有客户端有事务在进行，那么被调用端将在该事务中运行，否则的话重新开启一个事务。(如果被调用端发生异常，那么调用端和被调用端事务都将回滚) REQUIRED_NEW – 表示当前方法必须运行在它自己的事务中。一个新的事务将启动，而且如果有一个现有的事务在运行的话，则这个方法将在运行期被挂起，直到新的事务提交或者回滚才恢复执行 SUPPORTS – 表示当前方法不必需要具有一个事务上下文，但是如果有一个事务的话，它也可以在这个事务中运行 NOT_SUPPORTED – 表示该方法不应该在一个事务中运行。如果有一个事务正在运行，他将在运行期被挂起，直到这个事务提交或者回滚才恢复执行 MANDATORY – 表示当前方法必须在一个事务中运行，如果没有事务，将抛出异常 NEVER – 表示当方法务不应该在一个事务中运行，如果存在一个事务，则抛出异常 NESTED – 表示如果当前方法正有一个事务在运行中，则该方法应该运行在一个嵌套事务中，被嵌套的事务可以","date":"2022-01-10","objectID":"/spring5/:6:2","series":[],"tags":["Spring5"],"title":"Spring5","uri":"/spring5/#transactionhttpsjuejincnpost6844903600943022088"},{"categories":["Note"],"content":"Transaction Manager Transactions are usually added into Service level of JavaEE There are 2 ways of transaction managment in Spring programming(use try-catch-finally to code it) declaration – AOP at low level xml annotation Spring Transaction Manager API PlatformTransactionManager – Interface for mybatis and jdbc – DataSourceTransactionManager Declaration: Annotation Create Transaction Manager in config Turn on transaction annotation add tx namespace In the service class, add transaction annotation on the corresponding methods (or the whole class) @transactional Notice if put it on the class, it’s on every method in it -- @Service public class UserService { @Autowired private UserDao userDao; @Transactional public void accountMoney(double amount, String sender, String receiver){ userDao.reduceMoney(amount, sender); userDao.addMoney(amount, receiver); } } public interface UserDao { public void addMoney(double money, String name); public void reduceMoney(double money, String name); } @Repository public class UserDaoImpl implements UserDao{ @Autowired private JdbcTemplate jdbcTemplate; @Override public void addMoney(double amount, String name) { String sql = \"update t_account set money=money-? where username=?\"; jdbcTemplate.update(sql, amount, name); } @Override public void reduceMoney(double amount, String name) { String sql = \"update t_account set money=money+? where username=?\"; jdbcTemplate.update(sql, amount, name); } } @Test public void test01(){ ApplicationContext context = new ClassPathXmlApplicationContext(\"druid.xml\"); UserService userService = context.getBean(\"userService\", UserService.class); userService.accountMoney(100, \"Lucy\", \"Marry\"); } @Transaction(…) propagation – 事务传播行为 (REQUIRED by default) 多之间进行调用，这个过程中事务是如何进行管理的 REQUIRED – 表示当前方法必须在一个具有事务的上下文中运行，如有客户端有事务在进行，那么被调用端将在该事务中运行，否则的话重新开启一个事务。(如果被调用端发生异常，那么调用端和被调用端事务都将回滚) REQUIRED_NEW – 表示当前方法必须运行在它自己的事务中。一个新的事务将启动，而且如果有一个现有的事务在运行的话，则这个方法将在运行期被挂起，直到新的事务提交或者回滚才恢复执行 SUPPORTS – 表示当前方法不必需要具有一个事务上下文，但是如果有一个事务的话，它也可以在这个事务中运行 NOT_SUPPORTED – 表示该方法不应该在一个事务中运行。如果有一个事务正在运行，他将在运行期被挂起，直到这个事务提交或者回滚才恢复执行 MANDATORY – 表示当前方法必须在一个事务中运行，如果没有事务，将抛出异常 NEVER – 表示当方法务不应该在一个事务中运行，如果存在一个事务，则抛出异常 NESTED – 表示如果当前方法正有一个事务在运行中，则该方法应该运行在一个嵌套事务中，被嵌套的事务可以","date":"2022-01-10","objectID":"/spring5/:6:2","series":[],"tags":["Spring5"],"title":"Spring5","uri":"/spring5/#declaration-xml"},{"categories":["Note"],"content":"Transaction Manager Transactions are usually added into Service level of JavaEE There are 2 ways of transaction managment in Spring programming(use try-catch-finally to code it) declaration – AOP at low level xml annotation Spring Transaction Manager API PlatformTransactionManager – Interface for mybatis and jdbc – DataSourceTransactionManager Declaration: Annotation Create Transaction Manager in config Turn on transaction annotation add tx namespace In the service class, add transaction annotation on the corresponding methods (or the whole class) @transactional Notice if put it on the class, it’s on every method in it -- @Service public class UserService { @Autowired private UserDao userDao; @Transactional public void accountMoney(double amount, String sender, String receiver){ userDao.reduceMoney(amount, sender); userDao.addMoney(amount, receiver); } } public interface UserDao { public void addMoney(double money, String name); public void reduceMoney(double money, String name); } @Repository public class UserDaoImpl implements UserDao{ @Autowired private JdbcTemplate jdbcTemplate; @Override public void addMoney(double amount, String name) { String sql = \"update t_account set money=money-? where username=?\"; jdbcTemplate.update(sql, amount, name); } @Override public void reduceMoney(double amount, String name) { String sql = \"update t_account set money=money+? where username=?\"; jdbcTemplate.update(sql, amount, name); } } @Test public void test01(){ ApplicationContext context = new ClassPathXmlApplicationContext(\"druid.xml\"); UserService userService = context.getBean(\"userService\", UserService.class); userService.accountMoney(100, \"Lucy\", \"Marry\"); } @Transaction(…) propagation – 事务传播行为 (REQUIRED by default) 多之间进行调用，这个过程中事务是如何进行管理的 REQUIRED – 表示当前方法必须在一个具有事务的上下文中运行，如有客户端有事务在进行，那么被调用端将在该事务中运行，否则的话重新开启一个事务。(如果被调用端发生异常，那么调用端和被调用端事务都将回滚) REQUIRED_NEW – 表示当前方法必须运行在它自己的事务中。一个新的事务将启动，而且如果有一个现有的事务在运行的话，则这个方法将在运行期被挂起，直到新的事务提交或者回滚才恢复执行 SUPPORTS – 表示当前方法不必需要具有一个事务上下文，但是如果有一个事务的话，它也可以在这个事务中运行 NOT_SUPPORTED – 表示该方法不应该在一个事务中运行。如果有一个事务正在运行，他将在运行期被挂起，直到这个事务提交或者回滚才恢复执行 MANDATORY – 表示当前方法必须在一个事务中运行，如果没有事务，将抛出异常 NEVER – 表示当方法务不应该在一个事务中运行，如果存在一个事务，则抛出异常 NESTED – 表示如果当前方法正有一个事务在运行中，则该方法应该运行在一个嵌套事务中，被嵌套的事务可以","date":"2022-01-10","objectID":"/spring5/:6:2","series":[],"tags":["Spring5"],"title":"Spring5","uri":"/spring5/#declaration-pure-annotation"},{"categories":["Note"],"content":"Logging framework ","date":"2022-01-10","objectID":"/spring5/:7:0","series":[],"tags":["Spring5"],"title":"Spring5","uri":"/spring5/#logging-framework"},{"categories":["Note"],"content":"Log4j2 log4j-api log4j-core log4j-slf4j-impl log4j-api Create log4j2.xml \u003c?xml version=\"1.0\" encoding=\"UTF-8\" ?\u003e \u003c!-- Logging level: OFF \u003e FATAL \u003e ERROR \u003e WARN \u003e INFO \u003e DEBUG \u003e TRACE \u003e ALL --\u003e \u003c!-- The status in Configuration tag is to set the internal info output, it can be omitted. If set to trace, you can see all kinds of detailed output --\u003e \u003cconfiguration status=\"INFO\"\u003e \u003c!-- firstly define all appender --\u003e \u003cappenders\u003e \u003c!-- output logging info to console--\u003e \u003cconsole name=\"Console\" target=\"SYSTEM_OUT\"\u003e \u003c!-- the format of log--\u003e \u003cPatternLayout pattern=\"%d{yyyy-MM-dd HH:mm:ss.SSS} [%t] %-5level %logger{36} - %msg%n\"/\u003e \u003c/console\u003e \u003c/appenders\u003e \u003c!-- define logger, only if the logger is defined and import the appender, the appender takes effect --\u003e \u003cloggers\u003e \u003croot level=\"info\"\u003e \u003cappender-ref ref=\"Console\"/\u003e \u003c/root\u003e \u003c/loggers\u003e \u003c/configuration\u003e Manually log import org.slf4j.Logger; import org.slf4j.LoggerFactory; public class UserLog{ private static final Logger log = LoggerFactory.getLogger(UserLog.class); public static void main(String[] args) { log.info(\"hello, log4j2\"); log.warn(\"hello, log4j2\"); } } ","date":"2022-01-10","objectID":"/spring5/:7:1","series":[],"tags":["Spring5"],"title":"Spring5","uri":"/spring5/#log4j2"},{"categories":["Note"],"content":"Log4j2 log4j-api log4j-core log4j-slf4j-impl log4j-api Create log4j2.xml FATAL ERROR WARN INFO DEBUG TRACE ALL -- Manually log import org.slf4j.Logger; import org.slf4j.LoggerFactory; public class UserLog{ private static final Logger log = LoggerFactory.getLogger(UserLog.class); public static void main(String[] args) { log.info(\"hello, log4j2\"); log.warn(\"hello, log4j2\"); } } ","date":"2022-01-10","objectID":"/spring5/:7:1","series":[],"tags":["Spring5"],"title":"Spring5","uri":"/spring5/#create-log4j2xml"},{"categories":["Note"],"content":"Log4j2 log4j-api log4j-core log4j-slf4j-impl log4j-api Create log4j2.xml FATAL ERROR WARN INFO DEBUG TRACE ALL -- Manually log import org.slf4j.Logger; import org.slf4j.LoggerFactory; public class UserLog{ private static final Logger log = LoggerFactory.getLogger(UserLog.class); public static void main(String[] args) { log.info(\"hello, log4j2\"); log.warn(\"hello, log4j2\"); } } ","date":"2022-01-10","objectID":"/spring5/:7:1","series":[],"tags":["Spring5"],"title":"Spring5","uri":"/spring5/#manually-log"},{"categories":["Note"],"content":"@Nullable Can be used on method, attributes, params method –\u003e meaning return val can be null param –\u003e can be null method(@Nullable String name) attributes –\u003e can be null ","date":"2022-01-10","objectID":"/spring5/:8:0","series":[],"tags":["Spring5"],"title":"Spring5","uri":"/spring5/#nullable"},{"categories":["Note"],"content":"GenericApplicationContext/AnnotationConfigApplicationContext Creating objects using Functional Programming is supported @Test public void test03(){ // create GenericApplicationContext object GenericApplicationContext context = new GenericApplicationContext(); // call refresh() to clean it up and register bean context.refresh(); // just call this once context.registerBean(User.class, ()-\u003enew User()); // get the registered bean in spring User user = (User)context.getBean(\"com.me.spring.basics.User\"); System.out.println(user); // you can also name it context.registerBean(\"namedUser\", User.class, ()-\u003enew User()); User namedUser = (User)context.getBean(\"namedUser\"); System.out.println(namedUser); } ","date":"2022-01-10","objectID":"/spring5/:9:0","series":[],"tags":["Spring5"],"title":"Spring5","uri":"/spring5/#genericapplicationcontextannotationconfigapplicationcontext"},{"categories":["Note"],"content":"JUnit ","date":"2022-01-10","objectID":"/spring5/:10:0","series":[],"tags":["Spring5"],"title":"Spring5","uri":"/spring5/#junit"},{"categories":["Note"],"content":"JUnit4 spring-test JUnit4 package com.me.spring.tests; import com.me.spring.transaction.service.UserService; import org.junit.Test; import org.junit.runner.RunWith; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.test.context.ContextConfiguration; import org.springframework.test.context.junit4.SpringJUnit4ClassRunner; @RunWith(SpringJUnit4ClassRunner.class) // JUnit version @ContextConfiguration({\"classpath:druid.xml\"}) // load config file public class JTest4{ @Autowired private UserService userService; @Test public void test01(){ userService.accountMoney(20, \"Lucy\", \"Marry\"); } } ","date":"2022-01-10","objectID":"/spring5/:10:1","series":[],"tags":["Spring5"],"title":"Spring5","uri":"/spring5/#junit4"},{"categories":["Note"],"content":"JUnit5 JUnit5 package com.me.spring.tests; import com.me.spring.transaction.service.UserService; import org.junit.jupiter.api.Test; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.test.context.junit.jupiter.SpringJUnitConfig; //@ExtendWith(SpringExtension.class) //@ContextConfiguration(\"classpath:druid.xml\") @SpringJUnitConfig(locations = \"classpath:druid.xml\") public class JUnit5 { @Autowired private UserService userService; @Test public void test01(){ userService.accountMoney(20, \"Lucy\", \"Marry\"); } } ","date":"2022-01-10","objectID":"/spring5/:10:2","series":[],"tags":["Spring5"],"title":"Spring5","uri":"/spring5/#junit5"},{"categories":["Note"],"content":"前置没学完 稍后继续 ","date":"2022-01-10","objectID":"/spring5/:11:0","series":[],"tags":["Spring5"],"title":"Spring5","uri":"/spring5/#前置没学完-稍后继续httpswwwbilibilicomvideobv1vf4y127n5p53"},{"categories":["Note"],"content":"Webflux ","date":"2022-01-10","objectID":"/spring5/:12:0","series":[],"tags":["Spring5"],"title":"Spring5","uri":"/spring5/#webflux"},{"categories":["Note"],"content":"Reactive Programming ","date":"2022-01-10","objectID":"/spring5/:12:1","series":[],"tags":["Spring5"],"title":"Spring5","uri":"/spring5/#reactive-programming"},{"categories":["Note"],"content":"Process and Core APIs ","date":"2022-01-10","objectID":"/spring5/:12:2","series":[],"tags":["Spring5"],"title":"Spring5","uri":"/spring5/#process-and-core-apis"},{"categories":["Note"],"content":"SpringWebflux: Annotation Programming ","date":"2022-01-10","objectID":"/spring5/:12:3","series":[],"tags":["Spring5"],"title":"Spring5","uri":"/spring5/#springwebflux-annotation-programming"},{"categories":["Note"],"content":"SpringWebflux: Functional Programming ","date":"2022-01-10","objectID":"/spring5/:12:4","series":[],"tags":["Spring5"],"title":"Spring5","uri":"/spring5/#springwebflux-functional-programming"},{"categories":["Note"],"content":"CSS CSS是什么 CSS怎么用 CSS选择器（重点） 美化网页（文字，阴影，渐变……） 盒子模型 浮动 定位 网页动画（特效） ","date":"2022-01-09","objectID":"/css-cn/:0:0","series":[],"tags":["CSS"],"title":"CSS","uri":"/css-cn/#css"},{"categories":["Note"],"content":"发展 CSS1.0 CSS2.0： DIV块，CSS与HTML结构分离，SEO CSS2.1： 浮动，定位 CSS3.0： 圆角，阴影，动画…… ","date":"2022-01-09","objectID":"/css-cn/:1:0","series":[],"tags":["CSS"],"title":"CSS","uri":"/css-cn/#发展"},{"categories":["Note"],"content":"四种导入方式 \u003c!-- 外部样式：链接式 --\u003e \u003c!DOCTYPE html\u003e \u003chtml lang=\"en\"\u003e \u003chead\u003e \u003cmeta charset=\"UTF-8\"\u003e \u003ctitle\u003eTitle\u003c/title\u003e \u003clink rel=\"stylesheet\" href=\"css/style.css\"/\u003e \u003c/head\u003e \u003cbody\u003e \u003ch1\u003eBig title\u003c/h1\u003e \u003c/body\u003e \u003c/html\u003e h1{ color: red; } \u003c!-- 外部样式：导入式 --\u003e \u003cstyle\u003e @import url(css/style.css) \u003c/style\u003e \u003c!-- 弊端！ 会展现结构之后再渲染！ link会等全部渲染完之后在展现 --\u003e \u003c!-- 内部样式 --\u003e \u003cstyle\u003e h1{color: red;} /* style标签内是css code */ \u003c/style\u003e \u003ch1\u003eBig title\u003c/h1\u003e \u003c!-- 行内样式 --\u003e \u003ch1 style=\"color: red\"\u003eBig title\u003c/h1\u003e **优先级： 就近原则： 谁离这个元素更近，谁优先级高。所以行内元素优先级最高，其他的就看谁离的更近 ** ","date":"2022-01-09","objectID":"/css-cn/:2:0","series":[],"tags":["CSS"],"title":"CSS","uri":"/css-cn/#四种导入方式"},{"categories":["Note"],"content":"选择器 作用 选择页面上的某一个元素或者某一类元素。 ","date":"2022-01-09","objectID":"/css-cn/:3:0","series":[],"tags":["CSS"],"title":"CSS","uri":"/css-cn/#选择器"},{"categories":["Note"],"content":"选择器 作用 选择页面上的某一个元素或者某一类元素。 ","date":"2022-01-09","objectID":"/css-cn/:3:0","series":[],"tags":["CSS"],"title":"CSS","uri":"/css-cn/#作用"},{"categories":["Note"],"content":"基本选择器 标签选择器 类选择器 id选择器 标签选择器 h1{ color: #121432; background: #FFFFFF; border-radius: 15px; font-size: 80px; } 会选中所有的h1标签！ 类选择器 .groupA{ color: #111111; } \u003ch1 class=\"groupA\"\u003e TITLE \u003c/h1\u003e \u003cp class=\"groupA\"\u003e THis is amazing! \u003c/p\u003e id选择器 #item1{ font-size: 20px; } \u003ch1 id=\"item1\"\u003e TITLE \u003c/h1\u003e id必须全局保证唯一！ 优先级 id选择器 \u003e class选择器 \u003e tag选择器 ","date":"2022-01-09","objectID":"/css-cn/:3:1","series":[],"tags":["CSS"],"title":"CSS","uri":"/css-cn/#基本选择器"},{"categories":["Note"],"content":"基本选择器 标签选择器 类选择器 id选择器 标签选择器 h1{ color: #121432; background: #FFFFFF; border-radius: 15px; font-size: 80px; } 会选中所有的h1标签！ 类选择器 .groupA{ color: #111111; } TITLE THis is amazing! id选择器 #item1{ font-size: 20px; } TITLE id必须全局保证唯一！ 优先级 id选择器 class选择器 tag选择器 ","date":"2022-01-09","objectID":"/css-cn/:3:1","series":[],"tags":["CSS"],"title":"CSS","uri":"/css-cn/#标签选择器"},{"categories":["Note"],"content":"基本选择器 标签选择器 类选择器 id选择器 标签选择器 h1{ color: #121432; background: #FFFFFF; border-radius: 15px; font-size: 80px; } 会选中所有的h1标签！ 类选择器 .groupA{ color: #111111; } TITLE THis is amazing! id选择器 #item1{ font-size: 20px; } TITLE id必须全局保证唯一！ 优先级 id选择器 class选择器 tag选择器 ","date":"2022-01-09","objectID":"/css-cn/:3:1","series":[],"tags":["CSS"],"title":"CSS","uri":"/css-cn/#类选择器"},{"categories":["Note"],"content":"基本选择器 标签选择器 类选择器 id选择器 标签选择器 h1{ color: #121432; background: #FFFFFF; border-radius: 15px; font-size: 80px; } 会选中所有的h1标签！ 类选择器 .groupA{ color: #111111; } TITLE THis is amazing! id选择器 #item1{ font-size: 20px; } TITLE id必须全局保证唯一！ 优先级 id选择器 class选择器 tag选择器 ","date":"2022-01-09","objectID":"/css-cn/:3:1","series":[],"tags":["CSS"],"title":"CSS","uri":"/css-cn/#id选择器"},{"categories":["Note"],"content":"基本选择器 标签选择器 类选择器 id选择器 标签选择器 h1{ color: #121432; background: #FFFFFF; border-radius: 15px; font-size: 80px; } 会选中所有的h1标签！ 类选择器 .groupA{ color: #111111; } TITLE THis is amazing! id选择器 #item1{ font-size: 20px; } TITLE id必须全局保证唯一！ 优先级 id选择器 class选择器 tag选择器 ","date":"2022-01-09","objectID":"/css-cn/:3:1","series":[],"tags":["CSS"],"title":"CSS","uri":"/css-cn/#优先级"},{"categories":["Note"],"content":"高级选择器 ","date":"2022-01-09","objectID":"/css-cn/:4:0","series":[],"tags":["CSS"],"title":"CSS","uri":"/css-cn/#高级选择器"},{"categories":["Note"],"content":"层次选择器 /* 后代选择器 */ body p{ /* body之后的p全部选中 */ backgroud: red; } /* 子选择器 */ body\u003ep{ /* body之后的第一代p */ backgroud: red; } /* 相邻兄弟选择器 */ .active+p{ /* active向下且相邻的同辈的才被选中 */ backgroud: red; } /* 通用兄弟选择器 */ .active~p{ /* active向下的同辈的被选中 */ backgroud green; } \u003cbody\u003e \u003cp\u003ep0\u003c/p\u003e \u003cp class=\"active\"\u003ep1\u003c/p\u003e \u003cp\u003ep2\u003c/p\u003e \u003cp\u003ep3\u003c/p\u003e \u003cul\u003e \u003cli\u003e \u003cp\u003ep4\u003c/p\u003e \u003c/li\u003e \u003cli\u003e \u003cp\u003ep5\u003c/p\u003e \u003c/li\u003e \u003cli\u003e \u003cp\u003ep6\u003c/p\u003e \u003c/li\u003e \u003c/ul\u003e \u003c/body\u003e ","date":"2022-01-09","objectID":"/css-cn/:4:1","series":[],"tags":["CSS"],"title":"CSS","uri":"/css-cn/#层次选择器"},{"categories":["Note"],"content":"结构伪类选择器 ul li:first-child{ background: green; } p:nth-child(1){ /* 选中当前元素的父元素的第n个子元素 */ background: blue; } p:nth-type(2){ /* 选中当前元素的父元素的第n个type为p的子元素 */ background: yellow; } a:hover{ background: gold; } \u003cbody\u003e \u003ch1\u003etitle\u003c/h1\u003e \u003cp class=\"active\"\u003ep1\u003c/p\u003e \u003cp\u003ep2\u003c/p\u003e \u003cp\u003ep3\u003c/p\u003e \u003cul\u003e \u003cli\u003eli1\u003c/li\u003e \u003cli\u003eli2\u003c/li\u003e \u003cli\u003eli3\u003c/li\u003e \u003c/ul\u003e \u003ca href=\"\"\u003e123123123\u003c/a\u003e \u003c/body\u003e ","date":"2022-01-09","objectID":"/css-cn/:4:2","series":[],"tags":["CSS"],"title":"CSS","uri":"/css-cn/#结构伪类选择器"},{"categories":["Note"],"content":"属性选择器 .group_link a{ float: left; display: block; height: 50px; width: 50px; border-radius: 8px; background: black; text-align: center; color: white; text-decoration: none; margin-right: 5px; font: bold 20px/50px Arial; } /* 选中存在某属性的元素 */ a[id]{ background: yellow; } a[id=first]{ background: green; } a[class*=\"links\"]{ /* *=是包含 */ background: red; } a[href^=http]{ /* ^=是以什么开头 $=结尾*/ background: red; } \u003cbody\u003e \u003cp class=\"group_link\"\u003e \u003ca href=\"https://www.google.com\" class=\"first item\" id=\"first\"\u003e1\u003c/a\u003e \u003ca href=\"https://www.apple.com\" class=\"active\" target=\"_blank\" title=\"apple\"\u003e2\u003c/a\u003e \u003ca href=\"https://www.amazon.com\" class=\"active\"\u003e3\u003c/a\u003e \u003ca href=\"https://www.linkedin.com\" class=\"active\"\u003e4\u003c/a\u003e \u003ca href=\"image/some.pdf\" class=\"active\"\u003e5\u003c/a\u003e \u003ca href=\"image/some.jpg\" class=\"dim\"\u003e6\u003c/a\u003e \u003ca href=\"image/some.html\" class=\"dim\"\u003e7\u003c/a\u003e \u003ca href=\"image/some\" class=\"dim\"\u003e8\u003c/a\u003e \u003c/p\u003e \u003c/body\u003e ","date":"2022-01-09","objectID":"/css-cn/:4:3","series":[],"tags":["CSS"],"title":"CSS","uri":"/css-cn/#属性选择器"},{"categories":["Note"],"content":"美化网页 ","date":"2022-01-09","objectID":"/css-cn/:5:0","series":[],"tags":["CSS"],"title":"CSS","uri":"/css-cn/#美化网页"},{"categories":["Note"],"content":"字体样式 约定俗成，想要重点突出的问题用span标签。 \u003cspan id=\"emphasize_this\"\u003eHTML\u003c/span\u003e \u003cstyle\u003e #emphasize_this{ font-size: 30px; font-family: Arial, 楷体; font-weight: lighter; color: brown; } p{ font: oblique bolder 12px \"Arial\"; } \u003c/style\u003e ","date":"2022-01-09","objectID":"/css-cn/:5:1","series":[],"tags":["CSS"],"title":"CSS","uri":"/css-cn/#字体样式"},{"categories":["Note"],"content":"文本样式 颜色，对齐，首行缩进，行高，装饰 h1{ color: rgb(0,255,255); text-align: center; } h2{ color: rgba(0,255,255,0.4588); } .p1{ text-indent: 2em; height: 50px; line-height: 50px; /*行高跟高度相同就可以上下居中*/ text-decoration: line-through; } img, span{ vertical-align: middle; } ","date":"2022-01-09","objectID":"/css-cn/:5:2","series":[],"tags":["CSS"],"title":"CSS","uri":"/css-cn/#文本样式"},{"categories":["Note"],"content":"文本阴影 #price{ text-shadow: #3cc7f5 2px 2px 2px; /* 阴影颜色 水平偏移 垂直偏移 阴影半径 */ } ","date":"2022-01-09","objectID":"/css-cn/:5:3","series":[],"tags":["CSS"],"title":"CSS","uri":"/css-cn/#文本阴影"},{"categories":["Note"],"content":"超链接伪类 link visited hover active p:link{ ... } ","date":"2022-01-09","objectID":"/css-cn/:5:4","series":[],"tags":["CSS"],"title":"CSS","uri":"/css-cn/#超链接伪类"},{"categories":["Note"],"content":"背景 /*背景颜色 背景图片*/ div{ width: 1000px; height: 700px; border: 1px solid red; background-image: url(\"path\"); /*默认平铺*/ } .div1{ background-repeat: 10px 20px no-repeat; /* repeat-y repeat-x ... */ /* or use background-positon*/ } .div2{ background-color: #FFFFFF; background-image: linear-gradient(115deg, #FFFFFF 0%, #6284FF 50%, #FF0000 100%) } ","date":"2022-01-09","objectID":"/css-cn/:5:5","series":[],"tags":["CSS"],"title":"CSS","uri":"/css-cn/#背景"},{"categories":["Note"],"content":"盒子模型 margin border padding 边框，内外边距，div居中，圆角边框，阴影 h1{ color: red; } h2{ font-size: 16px; background: aquamarine; line-height: 30px; margin: 0px; } body{ margin: 0; padding: 0; text-decoration: none; } #box{ width: 300px; border: 1px solid greenyellow; } form{ background: aquamarine; } div:nth-of-type(1)\u003einput{ border: 3px solid powderblue; } div:nth-of-type(2)\u003einput{ border: 3px dashed powderblue; } div:nth-of-type(3)\u003einput{ border: 3px dot-dash powderblue; } \u003c!DOCTYPE html\u003e \u003chtml lang=\"en\"\u003e \u003chead\u003e \u003cmeta charset=\"UTF-8\"\u003e \u003ctitle\u003eTitle\u003c/title\u003e \u003clink rel=\"stylesheet\" href=\"css/style.css\"/\u003e \u003c/head\u003e \u003cbody\u003e \u003ch1\u003eLogin\u003c/h1\u003e \u003cdiv id=\"box\"\u003e \u003ch2\u003eMember Login\u003c/h2\u003e \u003cform action=\"#\"\u003e \u003cdiv\u003e \u003cspan\u003eUsername: \u003c/span\u003e \u003cinput type=\"text\"/\u003e \u003c/div\u003e \u003cdiv\u003e \u003cspan\u003ePassword: \u003c/span\u003e \u003cinput type=\"password\"/\u003e \u003c/div\u003e \u003cdiv\u003e \u003cspan\u003eEmail: \u003c/span\u003e \u003cinput type=\"text\"/\u003e \u003c/div\u003e \u003c/form\u003e \u003c/div\u003e \u003c/body\u003e \u003c/html\u003e ","date":"2022-01-09","objectID":"/css-cn/:5:6","series":[],"tags":["CSS"],"title":"CSS","uri":"/css-cn/#盒子模型"},{"categories":["Note"],"content":"内外边距 #box{ width: 300px; border: 1px solid greenyellow; padding: 0 0 0 0; /*上右下左， 如果只写两个，那么第一个是上下的，第二个是左右的*/ } ","date":"2022-01-09","objectID":"/css-cn/:5:7","series":[],"tags":["CSS"],"title":"CSS","uri":"/css-cn/#内外边距"},{"categories":["Note"],"content":"圆角边框 div{ width: 100px; height: 100px; border: 10px solid red; border-radius: 50px 20px; } /* 两个值的话，主对角线和辅对角线对应的1/4圆，我们可以通过设置宽高边界半径来获得半圆或者1/4圆等等*/ ","date":"2022-01-09","objectID":"/css-cn/:5:8","series":[],"tags":["CSS"],"title":"CSS","uri":"/css-cn/#圆角边框"},{"categories":["Note"],"content":"阴影 div{ width: 100px; height: 100px; border: 10px solid red; box-shadow: 10px 10px 30px yellow; } ","date":"2022-01-09","objectID":"/css-cn/:5:9","series":[],"tags":["CSS"],"title":"CSS","uri":"/css-cn/#阴影"},{"categories":["Note"],"content":"居中 div{ width: 300px; height: 20px; margin: 0 auto; /* div块居中 */ text-align: center; /* 块内的text居中 */ } body\u003eimg{ display: block; margin: 0 auto; } h2{ font-size: 16px; background: aquamarine; line-height: 30px; margin: 0px; text-align: center; } \u003ch2\u003e \u003cimg src=\"./assets/avatar.png\" width=\"15\" height=\"15\"/\u003e Member Login \u003c/h2\u003e ","date":"2022-01-09","objectID":"/css-cn/:5:10","series":[],"tags":["CSS"],"title":"CSS","uri":"/css-cn/#居中"},{"categories":["Note"],"content":"浮动 标准文档流 块级元素：独占一行 行内元素：可以被包含在块级元素中 float可以让选中的地方脱离背景框的束缚，浮动起来，会把其他元素挤开，网页大小改变后，会重新排版。 .layer1{ diplay: inline-block; float: left; } ","date":"2022-01-09","objectID":"/css-cn/:5:11","series":[],"tags":["CSS"],"title":"CSS","uri":"/css-cn/#浮动"},{"categories":["Note"],"content":"Dispaly block: 块元素 inline: 行内元素 inline-block: 块元素，但是可以内联 none: 不显示 \u003cdiv\u003ediv\u003c/div\u003e \u003cspan\u003espan\u003c/span\u003e span{ display: inline-block; } div{ display: inline; } other{ clear: both; /*清除浮动效果*/ } ","date":"2022-01-09","objectID":"/css-cn/:5:12","series":[],"tags":["CSS"],"title":"CSS","uri":"/css-cn/#dispaly"},{"categories":["Note"],"content":"父级边框塌陷问题 clear: right 右侧不允许有浮动元素 clear: left clear: both clear: none 解决方法： 增加父级元素的高度 增加一个 空的div标签，清除浮动 \u003cdiv id=\"father\"\u003e \u003cdiv class=\"layer01\"\u003e\u003cimg src=\"path\" alt=\"\"/\u003e\u003c/div\u003e \u003cdiv class=\"layer02\"\u003e\u003cimg src=\"path\" alt=\"\"/\u003e\u003c/div\u003e \u003cdiv class=\"layer03\"\u003e\u003cimg src=\"path\" alt=\"\"/\u003e\u003c/div\u003e \u003cdiv class=\"layer04\"\u003e\u003cimg src=\"path\" alt=\"\"/\u003e\u003c/div\u003e \u003cdiv class=\"clear\"\u003e\u003c/div\u003e \u003c/div\u003e .clear{ float: both; margin: 0; padding: 0; } #father{ border: 1px #000 solid; overflow: hidden; } ","date":"2022-01-09","objectID":"/css-cn/:5:13","series":[],"tags":["CSS"],"title":"CSS","uri":"/css-cn/#父级边框塌陷问题"},{"categories":["Note"],"content":"Overflow 给content设置一个高度和宽度，如果内容超出了这个边界，设置overflow: scroll就可以出现滚动条 我们也可以像上面的father元素一样，在其中设置一个overflow: hidden, 由于father没有设置一个宽高，其宽高由子元素撑起，所以并没有超出的部分会被隐藏。 最认可的方法 或者在father之后加一个伪类 避免了空div的添加 #father:after{ content:''; display: block; clear: both; } 对比 display 方向不可控制 float 浮动起来的话会脱离标准文档流，所以要解决父级边框塌陷的问题 ","date":"2022-01-09","objectID":"/css-cn/:5:14","series":[],"tags":["CSS"],"title":"CSS","uri":"/css-cn/#overflow"},{"categories":["Note"],"content":"Overflow 给content设置一个高度和宽度，如果内容超出了这个边界，设置overflow: scroll就可以出现滚动条 我们也可以像上面的father元素一样，在其中设置一个overflow: hidden, 由于father没有设置一个宽高，其宽高由子元素撑起，所以并没有超出的部分会被隐藏。 最认可的方法 或者在father之后加一个伪类 避免了空div的添加 #father:after{ content:''; display: block; clear: both; } 对比 display 方向不可控制 float 浮动起来的话会脱离标准文档流，所以要解决父级边框塌陷的问题 ","date":"2022-01-09","objectID":"/css-cn/:5:14","series":[],"tags":["CSS"],"title":"CSS","uri":"/css-cn/#最认可的方法"},{"categories":["Note"],"content":"Overflow 给content设置一个高度和宽度，如果内容超出了这个边界，设置overflow: scroll就可以出现滚动条 我们也可以像上面的father元素一样，在其中设置一个overflow: hidden, 由于father没有设置一个宽高，其宽高由子元素撑起，所以并没有超出的部分会被隐藏。 最认可的方法 或者在father之后加一个伪类 避免了空div的添加 #father:after{ content:''; display: block; clear: both; } 对比 display 方向不可控制 float 浮动起来的话会脱离标准文档流，所以要解决父级边框塌陷的问题 ","date":"2022-01-09","objectID":"/css-cn/:5:14","series":[],"tags":["CSS"],"title":"CSS","uri":"/css-cn/#对比"},{"categories":["Note"],"content":"定位 相对定位 position: relative 是相对于自己原来的位置移动 left: 200px; top: -100px; 绝对定位 position: absolute 没有父级元素定位的情况下，基于浏览器边框，浏览器是最大的box 有父级元素定位时，基于父级元素定位，不能超出父级元素。 #father{ position: relative; } #son{ position: absolute; right: 30px; } ","date":"2022-01-09","objectID":"/css-cn/:5:15","series":[],"tags":["CSS"],"title":"CSS","uri":"/css-cn/#定位"},{"categories":["Note"],"content":"定位 相对定位 position: relative 是相对于自己原来的位置移动 left: 200px; top: -100px; 绝对定位 position: absolute 没有父级元素定位的情况下，基于浏览器边框，浏览器是最大的box 有父级元素定位时，基于父级元素定位，不能超出父级元素。 #father{ position: relative; } #son{ position: absolute; right: 30px; } ","date":"2022-01-09","objectID":"/css-cn/:5:15","series":[],"tags":["CSS"],"title":"CSS","uri":"/css-cn/#相对定位"},{"categories":["Note"],"content":"定位 相对定位 position: relative 是相对于自己原来的位置移动 left: 200px; top: -100px; 绝对定位 position: absolute 没有父级元素定位的情况下，基于浏览器边框，浏览器是最大的box 有父级元素定位时，基于父级元素定位，不能超出父级元素。 #father{ position: relative; } #son{ position: absolute; right: 30px; } ","date":"2022-01-09","objectID":"/css-cn/:5:15","series":[],"tags":["CSS"],"title":"CSS","uri":"/css-cn/#绝对定位"},{"categories":["Note"],"content":"固定定位 无论怎么scroll都不会移动，绝对定位是会动的。 sub{ position: fixed; right: 0; bottom: 0; } ","date":"2022-01-09","objectID":"/css-cn/:5:16","series":[],"tags":["CSS"],"title":"CSS","uri":"/css-cn/#固定定位"},{"categories":["Note"],"content":"Z-index layer1{ z-index: 999; /*高度*/ opacity: 0.5; } ","date":"2022-01-09","objectID":"/css-cn/:5:17","series":[],"tags":["CSS"],"title":"CSS","uri":"/css-cn/#z-index"},{"categories":["Note"],"content":"动画 ","date":"2022-01-09","objectID":"/css-cn/:6:0","series":[],"tags":["CSS"],"title":"CSS","uri":"/css-cn/#动画"},{"categories":["Note"],"content":"Docker ","date":"2022-01-09","objectID":"/docker_cn/:0:0","series":[],"tags":["Docker"],"title":"Docker","uri":"/docker_cn/#docker"},{"categories":["Note"],"content":"容器操作 docker version #版本信息 docker info #系统信息 docker images # 可选项 -a --all #列出所有镜像 -q --quiet #只显示镜像的id，-aq常用 docker search \u003cname\u003e docker search mysql # 可选项 --filter=STARS=3000 #stars大于3000的 docker pull \u003cname:tag\u003e #不写tag，默认latest #分层下载 docker rmi -f \u003cid\u003e docker rmi -f $(docker images -aq) docker tutorial advanced ","date":"2022-01-09","objectID":"/docker_cn/:1:0","series":[],"tags":["Docker"],"title":"Docker","uri":"/docker_cn/#容器操作"},{"categories":["Note"],"content":"下载容器 installation omitted 设置开机启动 Go to dockerhub find nginx docker pull nginx or docker pull nginx:1.20.1 docker pull redis:6.2.4 ","date":"2022-01-09","objectID":"/docker_cn/:1:1","series":[],"tags":["Docker"],"title":"Docker","uri":"/docker_cn/#下载容器"},{"categories":["Note"],"content":"查看容器 下载来的镜像都在本地 docker images 查看镜像 docker rmi redis 删除redis镜像，这里redis = redis:latest docker rmi 镜像名:版本号/镜像uid ","date":"2022-01-09","objectID":"/docker_cn/:1:2","series":[],"tags":["Docker"],"title":"Docker","uri":"/docker_cn/#查看容器"},{"categories":["Note"],"content":"启动容器 启动nginx容器（应用容器，映射88端口） docker run [OPTIONS] IMAGE [COMMAND] [ARG...] 一般docker run [OPTIONS] IMAGE就够了 因为剩下的一般有default setting docker run --name=my_nginx -d nginx -d后台运行 -name设置名字 –restart=always 开机自启动 如果一开始没有设置好，我们也可以更新容器的设置项: docker update my_nginx --restart=always docker ps -a 查看所有容器 去掉-a查看运行中的容器 docker rm \u003cID/name\u003e 移除不在运行的容器，加-f可强行移除运行中的容器 docker stop \u003cID/name\u003e 停掉容器 ","date":"2022-01-09","objectID":"/docker_cn/:1:3","series":[],"tags":["Docker"],"title":"Docker","uri":"/docker_cn/#启动容器"},{"categories":["Note"],"content":"端口映射 把容器端口映射到公网IP端口 update不能修改端口，所以需要先删除 docker rm -f my_nginx 然后重新启动： docker run --name=my_nginx -d --restart=always -p 88:80 nginx 把公网88端口映射到容器80端口 如果部署在云服务上，一定要设置安全组规则使端口88能够访问！ ","date":"2022-01-09","objectID":"/docker_cn/:1:4","series":[],"tags":["Docker"],"title":"Docker","uri":"/docker_cn/#端口映射"},{"categories":["Note"],"content":"修改容器内容 ","date":"2022-01-09","objectID":"/docker_cn/:2:0","series":[],"tags":["Docker"],"title":"Docker","uri":"/docker_cn/#修改容器内容"},{"categories":["Note"],"content":"修改内部内容 docker exec -it 341d87f8940f /bin/bash以交互模式启动 所以我们进入了容器内的linux环境的bash终端 具体怎么修改 参照dockerhub对应页面的doc echo \u003ch1\u003e Welcome to my Nginx\u003c/h1\u003e \u003e index.html exit docker ps ","date":"2022-01-09","objectID":"/docker_cn/:2:1","series":[],"tags":["Docker"],"title":"Docker","uri":"/docker_cn/#修改内部内容"},{"categories":["Note"],"content":"提交改变 docker commit -a \"author-name\" -m \"commit msg here\" \u003cID\u003e edited_nginx:v1.0 把更改的容器提交成新的镜像edited_nginx docker run -d -p 88:80 edited_nginx:v1.0 ","date":"2022-01-09","objectID":"/docker_cn/:2:2","series":[],"tags":["Docker"],"title":"Docker","uri":"/docker_cn/#提交改变"},{"categories":["Note"],"content":"镜像保存 如何把镜像给到另一台机器 镜像传输 docker save -o name.tar edited_nginx:v1.0 镜像打包成压缩包 通过ssh scp传输 或者sftp等 docker load -i name.tar读取压缩包 docker images docker run -d -p 88:80 edited_nginx:v1.0 推送到远程仓库 去dockerhub创建一个nginx仓库（在你的用户名下） docker tag nginx:v1.0 name/nginx:v1.0 把镜像名字改成需要的名字（加上repo-name） docker login docker push name/nginx:v1.0 docker logout 其他机器使用docker pull ","date":"2022-01-09","objectID":"/docker_cn/:2:3","series":[],"tags":["Docker"],"title":"Docker","uri":"/docker_cn/#镜像保存"},{"categories":["Note"],"content":"挂载数据外部修改 docker run -d -p 88:80 nginx 修改时每次都要进去，繁琐 假设 nginx的页面藏在/usr/share/nginx/html 我们能不能把它跟本地的文件关联？ docker run --name my_nginx -d -p 88:80 -v /data/html:/usr/share/nginx/html:ro nginx ro就是只读，这个意思是在容器内部只读，在外部仍然可以改 注意这时候很可能/data/html是空的，所以容器的那些也是空的 echo \"something to show\" \u003e /data/html/index.html ","date":"2022-01-09","objectID":"/docker_cn/:2:4","series":[],"tags":["Docker"],"title":"Docker","uri":"/docker_cn/#挂载数据外部修改"},{"categories":["Note"],"content":"其他 docker logs \u003cid\u003e 查看日志，助于排查错误 docker exec -it \u003cid/name\u003e /bin/bash 交互模式 并进入控制台 vi /etc/nginx/nginx.conf 然后可以进入修改配置文件 当然，如果经常要修改的配置文件，可以挂载出来，外部修改 -v是可以挂载多个目标的，空格隔开即可 另外，我们可以将其他容器的文件拷贝出来或者拷贝进其他容器 docker cp \u003cid\u003e:/etc/nginx/nginx.conf /data/conf/nginx.conf 然后在挂载之后，内部配置同步成为外部复制好的配置 ","date":"2022-01-09","objectID":"/docker_cn/:2:5","series":[],"tags":["Docker"],"title":"Docker","uri":"/docker_cn/#其他"},{"categories":["Note"],"content":"进阶实战 ","date":"2022-01-09","objectID":"/docker_cn/:3:0","series":[],"tags":["Docker"],"title":"Docker","uri":"/docker_cn/#进阶实战"},{"categories":["Note"],"content":"编写自己的应用 spring.io ","date":"2022-01-09","objectID":"/docker_cn/:3:1","series":[],"tags":["Docker"],"title":"Docker","uri":"/docker_cn/#编写自己的应用"},{"categories":["Note"],"content":"部署redis docker pull redis 我们希望把redis的 redis.conf和/data挂载出来 并且在docker run命令后面追加redis command去启用使用自定义配置文件启动 docker --name my_redis -d -v /data/redis/redis.conf:/etc/redis/redis.conf -v /data/redis/data:/data -p 6379:6379 run redis:latest redis-server /usr/local/etc/redis/redis.conf 如果映射到了公网，一定要给redis配置账户密码，以防编程矿机。 修改redis.conf appendonly yes requirepass password_here docker restart my_redis ","date":"2022-01-09","objectID":"/docker_cn/:3:2","series":[],"tags":["Docker"],"title":"Docker","uri":"/docker_cn/#部署redis"},{"categories":["Note"],"content":"将应用打包成镜像 以前的步骤 用springBoot打包成可执行jar包 (java -jar name.jar来执行jar进行检查) 把jar包上传服务器 服务器运行java -jar \u003c文件名\u003e 现在 所有机器都安装docker，任何应用都是镜像，所有的机器都能运行。 How? –\u003e Dockerfile FROMopenjdk:8-jdk-slimLABEL maintainer=author_name_here COPY target/java-demo-0.0.1-SNAPSHOT.jar /app.jarENTRYPOINT [\"java\", \"-jar\", \"/app.jar\"] FROM后面是基础环境，这里是jdk8的版本 LABEL 后面是写维护者的名字 COPY是从一个本地目录拷贝到一个容器内的目录，上面是从本地target下的一个文件拷贝到了容器中的根目录下 ENTRYPOINT后面是命令，每一个命令要隔开 docker build -t java-demo:v1.0 . . 指在当前目录下工作，Dockerfile里面的path都以此为根据 -t 后面是tag 如果构建文件不叫Dockerfile，则加上 -f 文件名 docker run -d -p 8080:8080 java-demo:v1.0 多用docker ps检查几遍，因为有问题的话，一般几秒之后就停了。 ","date":"2022-01-09","objectID":"/docker_cn/:3:3","series":[],"tags":["Docker"],"title":"Docker","uri":"/docker_cn/#将应用打包成镜像"},{"categories":["Note"],"content":"将应用打包成镜像 以前的步骤 用springBoot打包成可执行jar包 (java -jar name.jar来执行jar进行检查) 把jar包上传服务器 服务器运行java -jar 现在 所有机器都安装docker，任何应用都是镜像，所有的机器都能运行。 How? – Dockerfile FROMopenjdk:8-jdk-slimLABEL maintainer=author_name_here COPY target/java-demo-0.0.1-SNAPSHOT.jar /app.jarENTRYPOINT [\"java\", \"-jar\", \"/app.jar\"] FROM后面是基础环境，这里是jdk8的版本 LABEL 后面是写维护者的名字 COPY是从一个本地目录拷贝到一个容器内的目录，上面是从本地target下的一个文件拷贝到了容器中的根目录下 ENTRYPOINT后面是命令，每一个命令要隔开 docker build -t java-demo:v1.0 . . 指在当前目录下工作，Dockerfile里面的path都以此为根据 -t 后面是tag 如果构建文件不叫Dockerfile，则加上 -f 文件名 docker run -d -p 8080:8080 java-demo:v1.0 多用docker ps检查几遍，因为有问题的话，一般几秒之后就停了。 ","date":"2022-01-09","objectID":"/docker_cn/:3:3","series":[],"tags":["Docker"],"title":"Docker","uri":"/docker_cn/#以前的步骤"},{"categories":["Note"],"content":"将应用打包成镜像 以前的步骤 用springBoot打包成可执行jar包 (java -jar name.jar来执行jar进行检查) 把jar包上传服务器 服务器运行java -jar 现在 所有机器都安装docker，任何应用都是镜像，所有的机器都能运行。 How? – Dockerfile FROMopenjdk:8-jdk-slimLABEL maintainer=author_name_here COPY target/java-demo-0.0.1-SNAPSHOT.jar /app.jarENTRYPOINT [\"java\", \"-jar\", \"/app.jar\"] FROM后面是基础环境，这里是jdk8的版本 LABEL 后面是写维护者的名字 COPY是从一个本地目录拷贝到一个容器内的目录，上面是从本地target下的一个文件拷贝到了容器中的根目录下 ENTRYPOINT后面是命令，每一个命令要隔开 docker build -t java-demo:v1.0 . . 指在当前目录下工作，Dockerfile里面的path都以此为根据 -t 后面是tag 如果构建文件不叫Dockerfile，则加上 -f 文件名 docker run -d -p 8080:8080 java-demo:v1.0 多用docker ps检查几遍，因为有问题的话，一般几秒之后就停了。 ","date":"2022-01-09","objectID":"/docker_cn/:3:3","series":[],"tags":["Docker"],"title":"Docker","uri":"/docker_cn/#现在"},{"categories":["Note"],"content":"将应用打包成镜像 以前的步骤 用springBoot打包成可执行jar包 (java -jar name.jar来执行jar进行检查) 把jar包上传服务器 服务器运行java -jar 现在 所有机器都安装docker，任何应用都是镜像，所有的机器都能运行。 How? – Dockerfile FROMopenjdk:8-jdk-slimLABEL maintainer=author_name_here COPY target/java-demo-0.0.1-SNAPSHOT.jar /app.jarENTRYPOINT [\"java\", \"-jar\", \"/app.jar\"] FROM后面是基础环境，这里是jdk8的版本 LABEL 后面是写维护者的名字 COPY是从一个本地目录拷贝到一个容器内的目录，上面是从本地target下的一个文件拷贝到了容器中的根目录下 ENTRYPOINT后面是命令，每一个命令要隔开 docker build -t java-demo:v1.0 . . 指在当前目录下工作，Dockerfile里面的path都以此为根据 -t 后面是tag 如果构建文件不叫Dockerfile，则加上 -f 文件名 docker run -d -p 8080:8080 java-demo:v1.0 多用docker ps检查几遍，因为有问题的话，一般几秒之后就停了。 ","date":"2022-01-09","objectID":"/docker_cn/:3:3","series":[],"tags":["Docker"],"title":"Docker","uri":"/docker_cn/#how----dockerfile"},{"categories":["Note"],"content":"将镜像上传仓库 ","date":"2022-01-09","objectID":"/docker_cn/:3:4","series":[],"tags":["Docker"],"title":"Docker","uri":"/docker_cn/#将镜像上传仓库"},{"categories":["Note"],"content":"在其他机器上pull and run ","date":"2022-01-09","objectID":"/docker_cn/:3:5","series":[],"tags":["Docker"],"title":"Docker","uri":"/docker_cn/#在其他机器上pull-and-run"},{"categories":["Note"],"content":"Git vs SVN 版本控制，版本迭代。 GIt and SVN SVN是集中式的版本控制系统，版本库在中央服务器，首先要从中央服务器更新到最新的版本才可以开发。必须联网，对网络有要求。 Git是分布式版本控制系统，没有中央服务器，每个人的电脑就是一个完整的版本库，不需要联网，只需要commit自己的修改给需要的人就可以了。 ","date":"2022-01-09","objectID":"/git-vs-svn/:0:0","series":[],"tags":["git"],"title":"Git vs SVN","uri":"/git-vs-svn/#git-vs-svn"},{"categories":["Note"],"content":"HTML5 ","date":"2022-01-09","objectID":"/html5-cn/:0:0","series":[],"tags":["HTML5"],"title":"HTML5","uri":"/html5-cn/#html5"},{"categories":["Note"],"content":"W3C标准 World Wide Web Consortium W3C标准： 结构化标准语言 HTML XML 表现标准语言 CSS 行为标准语言 DOM ECMAScript ","date":"2022-01-09","objectID":"/html5-cn/:0:1","series":[],"tags":["HTML5"],"title":"HTML5","uri":"/html5-cn/#w3c标准"},{"categories":["Note"],"content":"网页基本信息 \u003c!-- comment --\u003e \u003c!-- DOCTYPE 设定浏览器使用什么规范 --\u003e \u003c!DOCTYPE html\u003e \u003chtml lang=\"en\"\u003e \u003chead\u003e \u003cmeta charset=\"UTF-8\"\u003e \u003c!-- meta描述性标签，他用来描述网站的一些信息，一般用来做SEO--\u003e \u003cmeta name=\"keywords\" content=\"HTML Tutorial\"\u003e \u003cmeta name=\"description\" content=\"Just a HTML Tutorial\"\u003e \u003ctitle\u003eTitle\u003c/title\u003e \u003c!-- 浏览器选项卡上的标题 --\u003e \u003c/head\u003e \u003cbody\u003e \u003c/body\u003e \u003c/html\u003e ","date":"2022-01-09","objectID":"/html5-cn/:1:0","series":[],"tags":["HTML5"],"title":"HTML5","uri":"/html5-cn/#网页基本信息"},{"categories":["Note"],"content":"基本标签 \u003c!--标题标签--\u003e \u003ch1\u003e一级标签\u003c/h1\u003e \u003ch2\u003e二级标签\u003c/h2\u003e \u003ch3\u003e三级标签\u003c/h3\u003e \u003ch4\u003e四级标签\u003c/h4\u003e \u003ch5\u003e五级标签\u003c/h5\u003e \u003ch6\u003e六级标签\u003c/h6\u003e \u003c!--段落标签--\u003e \u003cp\u003e1st line\u003c/p\u003e \u003cp\u003e2nd line\u003c/p\u003e \u003cp\u003e3rd line\u003c/p\u003e \u003c!--换行标签： 更紧凑，属于一段--\u003e 1st line\u003cbr/\u003e 2nd line\u003cbr/\u003e \u003c!--水平线标签--\u003e \u003chr/\u003e \u003c!--粗体，斜体--\u003e 粗体： \u003cb\u003ebold\u003c/b\u003e 斜体： \u003ci\u003eitalic\u003c/i\u003e \u003c!--特殊符号--\u003e 空格： 1\u0026nbsp;\u0026nbsp;\u0026nbsp;2 大于： \u0026gt; 小于： \u0026lt; 版权： \u0026copy; ... ","date":"2022-01-09","objectID":"/html5-cn/:2:0","series":[],"tags":["HTML5"],"title":"HTML5","uri":"/html5-cn/#基本标签"},{"categories":["Note"],"content":"图像标签 \u003cimg src=\"路径 必填\" alt=\"图像的替代文字\" title=\"鼠标悬停提示文字\" width=\"x\" height=\"y\" /\u003e JPG GIF PNG BMP ","date":"2022-01-09","objectID":"/html5-cn/:3:0","series":[],"tags":["HTML5"],"title":"HTML5","uri":"/html5-cn/#图像标签"},{"categories":["Note"],"content":"链接标签 a 标签 \u003ca id=\"top\"\u003e顶部 使用id作为标记\u003c/a\u003e \u003ca href=\"path\" target=\"链接在哪个窗口打开\"\u003e链接文本或图像\u003c/a\u003e \u003ca href=\"https://www.google.com\"\u003egoogle search\u003c/a\u003e \u003ca href=\"https://www.google.com\"\u003e \u003cimg src=\"../img/google_icon.jpg\" alt=\"google\" title=\"google\"\u003e \u003c/a\u003e \u003ca href=\"https://www.google.com\" target=\"_blank\"\u003egoogle search\u003c/a\u003e _blank 在新标签打开 _parent _self 默认的 在自己的页面打开 \u003c!--锚链接 1. 需要一个锚 2. 跳转 --\u003e \u003ca href=\"#top\"\u003e回到顶部\u003c/a\u003e \u003ca href=\" somesite.html#top\"\u003e回到其他网页顶部\u003c/a\u003e \u003c!--功能性链接 邮件链接： mailto: --\u003e \u003ca href=\"mailto:somemail.gmail.com\"\u003e发邮件\u003c/a\u003e ","date":"2022-01-09","objectID":"/html5-cn/:4:0","series":[],"tags":["HTML5"],"title":"HTML5","uri":"/html5-cn/#链接标签"},{"categories":["Note"],"content":"行内元素和块元素 块元素： 无论内容多少，独占一行 p h1-h6… 行内元素： 如果能排得开，几个行内元素可以在一行 a b i… ","date":"2022-01-09","objectID":"/html5-cn/:5:0","series":[],"tags":["HTML5"],"title":"HTML5","uri":"/html5-cn/#行内元素和块元素"},{"categories":["Note"],"content":"列表标签 \u003c!-- 有序列表 --\u003e \u003col\u003e \u003cli\u003e第一条\u003c/li\u003e \u003cli\u003e第二条\u003c/li\u003e \u003c/ol\u003e \u003chr/\u003e \u003c!-- 无序列表 --\u003e \u003cul\u003e \u003cli\u003e第一条\u003c/li\u003e \u003cli\u003e第二条\u003c/li\u003e \u003c/ul\u003e \u003chr/\u003e \u003c!-- 自定义列表 --\u003e \u003cdl\u003e \u003cdt\u003etitle1\u003c/dt\u003e \u003cdd\u003e1\u003c/dd\u003e \u003cdd\u003e2\u003c/dd\u003e \u003cdt\u003etitle2\u003c/dt\u003e \u003cdd\u003e1\u003c/dd\u003e \u003cdd\u003e2\u003c/dd\u003e \u003c/dl\u003e ","date":"2022-01-09","objectID":"/html5-cn/:6:0","series":[],"tags":["HTML5"],"title":"HTML5","uri":"/html5-cn/#列表标签"},{"categories":["Note"],"content":"表格标签 \u003c!-- 表格 --\u003e \u003ctable border=\"1px\"\u003e \u003ctr\u003e \u003ctd colspan=\"3\"\u003e1-1\u003c/td\u003e \u003c/tr\u003e \u003ctr\u003e \u003ctd rowspan=\"2\"\u003e2-1\u003c/td\u003e \u003ctd\u003e2-2\u003c/td\u003e \u003ctd\u003e2-3\u003c/td\u003e \u003c/tr\u003e \u003ctr\u003e \u003ctd\u003e3-1\u003c/td\u003e \u003ctd\u003e3-2\u003c/td\u003e \u003c/tr\u003e \u003c/table\u003e ","date":"2022-01-09","objectID":"/html5-cn/:7:0","series":[],"tags":["HTML5"],"title":"HTML5","uri":"/html5-cn/#表格标签"},{"categories":["Note"],"content":"视频音频 \u003c!-- 音频视频 --\u003e \u003cvideo src=\"../media/xxx.mp4\" controls autoplay\u003e\u003c/video\u003e \u003caudio src=\"../media/xxxx.mp3\" controls autoplay\u003e\u003c/audio\u003e ","date":"2022-01-09","objectID":"/html5-cn/:8:0","series":[],"tags":["HTML5"],"title":"HTML5","uri":"/html5-cn/#视频音频"},{"categories":["Note"],"content":"页面结构 header footer section article aside nav ","date":"2022-01-09","objectID":"/html5-cn/:9:0","series":[],"tags":["HTML5"],"title":"HTML5","uri":"/html5-cn/#页面结构"},{"categories":["Note"],"content":"iframe内联框架 \u003ciframe src=\"path\" name=\"some-name\" frameborder=\"0\" width=\"1000px\" height=\"800px\"\u003e\u003c/iframe\u003e \u003ca href=\"https://www.google.com\" target=\"some-name\"\u003e点击跳转\u003c/a\u003e ","date":"2022-01-09","objectID":"/html5-cn/:10:0","series":[],"tags":["HTML5"],"title":"HTML5","uri":"/html5-cn/#iframe内联框架"},{"categories":["Note"],"content":"表单 \u003cform method=\"post\" action=\"result.html\"\u003e \u003cp\u003ename: \u003cinput name=\"name\" type=\"text\" readonly/\u003e \u003c/p\u003e \u003cp\u003epassword: \u003cinput name=\"pswd\" type=\"password\" value=\"123456\" hidden/\u003e \u003c/p\u003e \u003cp\u003e性别： \u003cinput type=\"radio\" value=\"male\" name=\"gender\"/\u003e男 \u003cinput type=\"radio\" value=\"female\" name=\"gender\"/\u003e女 \u003c/p\u003e \u003cp\u003e爱好： \u003cinput type=\"checkbox\" value=\"sleep\" name=\"hobby\"/\u003e睡觉 \u003cinput type=\"checkbox\" value=\"coding\" name=\"hobby\" checked/\u003e代码 \u003cinput type=\"checkbox\" value=\"daze\" name=\"hobby\"/\u003e发呆 \u003c/p\u003e \u003cp\u003e \u003cinput type=\"button\" name=\"btn1\" value=\"点击变长\"/\u003e \u003cinput type=\"image\" src=\"path\"/\u003e \u003c/p\u003e \u003cp\u003e下拉框： \u003cselect name=\"列表名称\"\u003e \u003coption value=\"cn\" selected\u003e中国\u003c/option\u003e \u003coption value=\"us\"\u003e美国\u003c/option\u003e \u003c/select\u003e \u003c/p\u003e \u003cp\u003e\u003clabel for=\"feedback\"\u003e文本域： \u003c/label\u003e \u003ctextarea name=\"feedback\" cols=\"50\" row=\"10\"\u003econtent here\u003c/textarea\u003e \u003c/p\u003e \u003cp\u003e文件域： \u003cinput type=\"file\" name=\"files\"/\u003e \u003cinput type=\"button\" value=\"upload\" name=\"upload\"/\u003e \u003c/p\u003e \u003cp\u003e邮件： \u003cinput type=\"email\" name=\"email\"/\u003e \u003cinput type=\"url\" name=\"url\"/\u003e \u003c/p\u003e \u003cp\u003e数字： \u003cinput type=:\"number\" name=\"num\" max=\"100\" min=\"1\" step=\"10\"/\u003e \u003c/p\u003e \u003cp\u003e滑块： \u003cinput type=\"range\" min=\"0\" max=\"100\"/\u003e \u003c/p\u003e \u003cp\u003e搜索： \u003cinput type=\"search\" name=\"search\"/\u003e \u003c/p\u003e \u003cp\u003e \u003cinput type=\"submit\" name=\"submit-button\" value=\"submit\" disabled/\u003e \u003cinput type=\"reset\" name=\"reset-button\" value=\"reset\"/\u003e \u003c/p\u003e \u003c/form\u003e 属性 说明 type 指定元素的类型 text password checkbox radio submit reset file hidden image button… name 表单元素的名称 value 元素的初始值，type为radio时必须指定一个值 size 指定表单元素的初始宽度。当type为text或password时，表单元素的大小以字符为单位。对于其他类型，宽度以像素为单位。 maxlength type为text或password时，输入的最大字符数 checked type为radio或checkbox时，指定按钮是否是被选中 ","date":"2022-01-09","objectID":"/html5-cn/:11:0","series":[],"tags":["HTML5"],"title":"HTML5","uri":"/html5-cn/#表单"},{"categories":["Note"],"content":"表单验证 \u003cp\u003ename: \u003cinput name=\"name\" type=\"text\" placeholder=\"请输入用户名\" required/\u003e \u003c/p\u003e \u003cp\u003epassword: \u003cinput name=\"pswd\" type=\"password\" pattern=\"^(?=.*\\d)(?=.*[a-z])(?=.*[A-Z]).{8,10}$\"/\u003e \u003c/p\u003e \u003c!--必须包含大小写字母和数字的组合，不能使用特殊字符，长度在8-10之间--\u003e ","date":"2022-01-09","objectID":"/html5-cn/:11:1","series":[],"tags":["HTML5"],"title":"HTML5","uri":"/html5-cn/#表单验证"},{"categories":["Note"],"content":"JavaSE Environment variable: set JAVA_HOME to the addr of install java Then add %JAVA_HOME%/bin to path. We do so to let Tomcat to recognize the java dir by looking at the JAVA_HOME .java -\u003e javac.exe -\u003e .class -\u003e java.exe -\u003e result bytecode file .class has the name of the class name in .java javac HelloWorld.java then java HelloWorldClassName class HelloWorldClassName { public static void main(String[] args) { System.out.println(\"Hello, World!\"); } } Important You can declare multiple classes in a source code file, but you can only have 1 public class at most in it. if declare a public class, then the source code file name has to be the same name of the class! Depending on the number of class you have in a source file, the compile process may generate 1 or more bytecode files. ","date":"2022-01-09","objectID":"/javase/:0:0","series":[],"tags":["Java"],"title":"JavaSE","uri":"/javase/#javase"},{"categories":["Note"],"content":"Syntax Low Coupling, High Cohesion ","date":"2022-01-09","objectID":"/javase/:1:0","series":[],"tags":["Java"],"title":"JavaSE","uri":"/javase/#syntax"},{"categories":["Note"],"content":"Comment // /**/ /** @author nameOfAuthor @version verOfSourceCode */ Notice this can be extracted by javadoc and produce a document. javadoc -d docName -author -version HelloWorld.java Find the index.html in the docName. Maybe need -encoding UTF-8 Also notice that if you want to illustrate the func(), you should write the /** xxx */ out of the func() not inside it. ","date":"2022-01-09","objectID":"/javase/:1:1","series":[],"tags":["Java"],"title":"JavaSE","uri":"/javase/#comment"},{"categories":["Note"],"content":"Java API Document ","date":"2022-01-09","objectID":"/javase/:1:2","series":[],"tags":["Java"],"title":"JavaSE","uri":"/javase/#java-api-document"},{"categories":["Note"],"content":"Coding Style ","date":"2022-01-09","objectID":"/javase/:1:3","series":[],"tags":["Java"],"title":"JavaSE","uri":"/javase/#coding-style"},{"categories":["Note"],"content":"String Sting is not a primitive data type 而是引用数据类型 When print function has multiple data types doing concatination using +, one String in it will make everything a string and concatinate to one big String. System.out.println('*' + '\\t'); System.out.println('*' + \"\\t\"); System.out.println(\"*\" + '\\t'); System.out.println(\"*\" + \"\\t\"); ","date":"2022-01-09","objectID":"/javase/:1:4","series":[],"tags":["Java"],"title":"JavaSE","uri":"/javase/#string"},{"categories":["Note"],"content":"Var byte b = 5; b = b - 2; //wrong! here 2 is int ","date":"2022-01-09","objectID":"/javase/:1:5","series":[],"tags":["Java"],"title":"JavaSE","uri":"/javase/#var"},{"categories":["Note"],"content":"Base 0b or 0B 0-7 0xA or 0Xa int num1 = 0b1001; int num2 = 0123; int num3 = 0x110A; System.out.println(num1); System.out.println(num2); System.out.println(num3); // all in base of 10 after printing out ","date":"2022-01-09","objectID":"/javase/:1:6","series":[],"tags":["Java"],"title":"JavaSE","uri":"/javase/#base"},{"categories":["Note"],"content":"Operator int res = m % n res has the same sign of m! -12 % 5 == -12 % -5 ","date":"2022-01-09","objectID":"/javase/:1:7","series":[],"tags":["Java"],"title":"JavaSE","uri":"/javase/#operator"},{"categories":["Note"],"content":"Scanner import java.util.Scanner; class ScannerTest{ public static void main(String[] args){ Scanner scan = new Scanner(System.in); String str = scan.nextLine(); int i = scan.nextInt(); } } ","date":"2022-01-09","objectID":"/javase/:1:8","series":[],"tags":["Java"],"title":"JavaSE","uri":"/javase/#scanner"},{"categories":["Note"],"content":"Control Flow with Label label: for (int i = 1; i \u003c 4; i++){ for (int j = 1; j \u003c= 10; j++){ if(j % 4 === 0) continue label; } System.out.println(j); } System.out.println(); ","date":"2022-01-09","objectID":"/javase/:1:9","series":[],"tags":["Java"],"title":"JavaSE","uri":"/javase/#control-flow-with-label"},{"categories":["Note"],"content":"Variable Number of args public static void test(String … strs); The number of String passed in can be any amount including no string at all. ","date":"2022-01-09","objectID":"/javase/:1:10","series":[],"tags":["Java"],"title":"JavaSE","uri":"/javase/#variable-number-of-args"},{"categories":["Note"],"content":"Constructor Orders of the assignment of attributes: implict assignment \u003e explict assignment/assign in code block \u003e constructor \u003e methods or fields Notice If no constructors are declared. There will be a default one being created implictly. The access modifiers would be as same as that of its class. ","date":"2022-01-09","objectID":"/javase/:1:11","series":[],"tags":["Java"],"title":"JavaSE","uri":"/javase/#constructor"},{"categories":["Note"],"content":"Constructor Orders of the assignment of attributes: implict assignment explict assignment/assign in code block constructor methods or fields Notice If no constructors are declared. There will be a default one being created implictly. The access modifiers would be as same as that of its class. ","date":"2022-01-09","objectID":"/javase/:1:11","series":[],"tags":["Java"],"title":"JavaSE","uri":"/javase/#notice"},{"categories":["Note"],"content":"JavaBean have to meet: the class is public have a non-parameter constructor hava attributes and getters and setters JavaBean is the component written in Java and can be reused. ","date":"2022-01-09","objectID":"/javase/:1:12","series":[],"tags":["Java"],"title":"JavaSE","uri":"/javase/#javabean"},{"categories":["Note"],"content":"package and import package is to achieve better management of classes every . indicates a layer in the DOM the package the current file belongs to need to be declared on the first line some packages in JDK java.lang: core packages of Java, containing String, Math, Integer, System, Thread… java.net: internet related classes and interfaces java.io: IO java.util: define some system features, framework of interfaces, datatime… java.text: format related java.sql: JDBC related classes and interfaces java.awt: GUI ","date":"2022-01-09","objectID":"/javase/:1:13","series":[],"tags":["Java"],"title":"JavaSE","uri":"/javase/#package-and-import"},{"categories":["Note"],"content":"package and import package is to achieve better management of classes every . indicates a layer in the DOM the package the current file belongs to need to be declared on the first line some packages in JDK java.lang: core packages of Java, containing String, Math, Integer, System, Thread… java.net: internet related classes and interfaces java.io: IO java.util: define some system features, framework of interfaces, datatime… java.text: format related java.sql: JDBC related classes and interfaces java.awt: GUI ","date":"2022-01-09","objectID":"/javase/:1:13","series":[],"tags":["Java"],"title":"JavaSE","uri":"/javase/#some-packages-in-jdk"},{"categories":["Note"],"content":"MVC View: deal with display view.utils view.ui Controller: deal with logic controller.activity controller.fragment controller.adapter controller.service controller.base Model: deal with data model.bean/domain model.dao model.db ","date":"2022-01-09","objectID":"/javase/:1:14","series":[],"tags":["Java"],"title":"JavaSE","uri":"/javase/#mvc"},{"categories":["Note"],"content":"Overload and Override Overload is determined at compile time Override is determined at runtime ","date":"2022-01-09","objectID":"/javase/:1:15","series":[],"tags":["Java"],"title":"JavaSE","uri":"/javase/#overload-and-override"},{"categories":["Note"],"content":"instanceof Person person = new Male(); if(person instanceof Male){ Male male = (Male) person; male.whoami(); } ","date":"2022-01-09","objectID":"/javase/:1:16","series":[],"tags":["Java"],"title":"JavaSE","uri":"/javase/#instanceof"},{"categories":["Note"],"content":"== and equals() ","date":"2022-01-09","objectID":"/javase/:1:17","series":[],"tags":["Java"],"title":"JavaSE","uri":"/javase/#-and-equals"},{"categories":["Note"],"content":"JUnit add JUnit lib create a class to do the unit test it should be public have a non-parameter constructor declare test method should be public should not have a return type no parameters need to add @Test above the test methods import org.junit.Test; run as junit test ","date":"2022-01-09","objectID":"/javase/:1:18","series":[],"tags":["Java"],"title":"JavaSE","uri":"/javase/#junit"},{"categories":["Note"],"content":"wrapper/auto boxing \u0026 unboxing byte –\u003e Byte long –\u003e Long char –\u003e Character … Object obj = true ? new Integer(1) : new Double(2.0); System.out.println(obj); // The answer is 1.0 // Ternary operator will unify the class of that 2 operants // So Integer will be upgraded to Double Integer i = new Integer(1); Integer j = new Integer(1); System.out.println(i == j); // false Integer m = 1; Integer n = 1; System.out.println(m == n); // true Integer x = 128;// so here it's equivalent to new a Integer Integer y = 128; System.out.println(x == y); // false // int has IntegerCache which stores from -128 to 127 // when doing the boxing, it will first check the related cache ","date":"2022-01-09","objectID":"/javase/:1:19","series":[],"tags":["Java"],"title":"JavaSE","uri":"/javase/#wrapperauto-boxing--unboxing"},{"categories":["Note"],"content":"static static static method cannot be override! since it is loaded when class is loaded You can only call static methods through the class name! like superClass.staticMethod() and subClass.staticMethod() They are not considered as override. ","date":"2022-01-09","objectID":"/javase/:1:20","series":[],"tags":["Java"],"title":"JavaSE","uri":"/javase/#static"},{"categories":["Note"],"content":"code block class Person { String name; int age; static String description = \"a person\"; // code block will be excuted before constructor! {} public Person(){ } public Person(String name, int age) { this.name = name; this.age = age; } public void eat(){ System.out.println(\"eating...\"); } // getter and setter here code block is used to init the class and objects can be modified with static. static code block: will only be excuted once when the class is loaded e.g. we can use this to load the config In this, you can call static or non-static attributes and methods non-static code block: will be excuted every time an object of the class is created ","date":"2022-01-09","objectID":"/javase/:1:21","series":[],"tags":["Java"],"title":"JavaSE","uri":"/javase/#code-block"},{"categories":["Note"],"content":"final final class cannot be extended: String, System, StringBuffer final method cannot be override final attribute have to be init(explictly or in code block or constructor) final var is constant final parameter means it’s a constant static final: global const ","date":"2022-01-09","objectID":"/javase/:1:22","series":[],"tags":["Java"],"title":"JavaSE","uri":"/javase/#final"},{"categories":["Note"],"content":"abstract abstract class: a class having abstract methods in it must be an abstract class cannot be instantiated have a constructor!! you can call it in subclass' constructor class Person{ public Person(int age, String name){ this.age = age; this.name = name; } } class Student extends Person { public Student(int age, String name){ Super(age, name); } } abstract method public abstract void eat(); abstract cannot modify private, static, final class, final method, attributes, and constructor. implict inner class in abstract class method(new Student()); //----------------------------- Person person = new Person(){ @Override public void eat(){} @Override public void breath(){} } method(person); //----------------------------- method(new Person(){ @Override public void eat(){} }); ","date":"2022-01-09","objectID":"/javase/:1:23","series":[],"tags":["Java"],"title":"JavaSE","uri":"/javase/#abstract"},{"categories":["Note"],"content":"abstract abstract class: a class having abstract methods in it must be an abstract class cannot be instantiated have a constructor!! you can call it in subclass' constructor class Person{ public Person(int age, String name){ this.age = age; this.name = name; } } class Student extends Person { public Student(int age, String name){ Super(age, name); } } abstract method public abstract void eat(); abstract cannot modify private, static, final class, final method, attributes, and constructor. implict inner class in abstract class method(new Student()); //----------------------------- Person person = new Person(){ @Override public void eat(){} @Override public void breath(){} } method(person); //----------------------------- method(new Person(){ @Override public void eat(){} }); ","date":"2022-01-09","objectID":"/javase/:1:23","series":[],"tags":["Java"],"title":"JavaSE","uri":"/javase/#implict-inner-class-in-abstract-class"},{"categories":["Note"],"content":"TempateMethod make uncertain part or the part that tends to change accordingly abstract abstract class Template{ public void spendTime(){ long start = System.currentTImeMillis(); code(); // uncertain part! long end = System.currentTImeMillis(); System.out.println(\"Time spent: \" + (end - start)); } public abstract void code(); } Note 多态的概念比较复杂，有多种意义的多态，一个有趣但不严谨的说法是：继承是子类使用父类的方法，而多态则是父类使用子类的方法。 一般，我们使用多态是为了避免在父类里大量重载引起代码臃肿且难于维护。 ","date":"2022-01-09","objectID":"/javase/:1:24","series":[],"tags":["Java"],"title":"JavaSE","uri":"/javase/#tempatemethod"},{"categories":["Note"],"content":"TempateMethod make uncertain part or the part that tends to change accordingly abstract abstract class Template{ public void spendTime(){ long start = System.currentTImeMillis(); code(); // uncertain part! long end = System.currentTImeMillis(); System.out.println(\"Time spent: \" + (end - start)); } public abstract void code(); } Note 多态的概念比较复杂，有多种意义的多态，一个有趣但不严谨的说法是：继承是子类使用父类的方法，而多态则是父类使用子类的方法。 一般，我们使用多态是为了避免在父类里大量重载引起代码臃肿且难于维护。 ","date":"2022-01-09","objectID":"/javase/:1:24","series":[],"tags":["Java"],"title":"JavaSE","uri":"/javase/#note"},{"categories":["Note"],"content":"interface package interface_tutorial; /* * class and interface are on the same level * - before JDK8: you can only define global const and abstract method * \u003e public static final * \u003e public abstract * * - after JDK8: you can also define static method, default method * * in real life, you want to implement interfaces through classes */ public class Interface_tutorial { public static void main(String[] args) { System.out.println(Flyable.MAX_SPEED); Plane plane = new Plane(); plane.fly(); plane.stop(); } } interface Flyable{ public static final int MAX_SPEED = 7900; int MIN_SPEED = 1; // you can omit public static final public abstract void fly(); void stop(); // you can also omit public abstract // you cannot not have constructor in an interface } class Plane implements Flyable { @Override public void fly() { System.out.println(\"Jet fly!\"); } @Override public void stop() { System.out.println(\"Landed!\"); } } package interface_tutorial; public class Computer { public void dataTransfer(USB usb){ // interface is a kind of regulation or a set of rules usb.start(); System.out.println(\"working details...\"); usb.stop(); } public static void main(String[] args) { Computer computer = new Computer(); PS5 ps5 = new PS5(); computer.dataTransfer(ps5); // polymorphism, since you cannot pass in an instance of an interface! } } interface USB { void start(); void stop(); } class Printer implements USB { @Override public void start() { System.out.println(\"Printer data transfer started...\"); } @Override public void stop() { System.out.println(\"Printer data transfer stopped...\"); } } class PS5 implements USB { @Override public void start() { System.out.println(\"PS5 data transfer started...\"); } @Override public void stop() { System.out.println(\"PS5 data transfer stopped...\"); } } JDBC are just aggregations of interfaces to setup the program specification 暴露规则,降低耦合,功能拓展. // also we can do: computer.dataTransfer(new USB() { @Override public void start() { System.out.println(\"implicit device data transfer started...\"); } @Override public void stop() { System.out.println(\"implicit device data transfer stopped...\"); } }); ","date":"2022-01-09","objectID":"/javase/:1:25","series":[],"tags":["Java"],"title":"JavaSE","uri":"/javase/#interface"},{"categories":["Note"],"content":"Proxy package proxy; public class ProxyTest { public static void main(String[] args) { Server server = new Server(); ProxyServer proxyServer = new ProxyServer(server); proxyServer.browse(); } } interface Network { void browse(); } // The Server being proxied class Server implements Network { @Override public void browse(){ System.out.println(\"Real server accesses Internet...\"); } } // Proxy class ProxyServer implements Network { private Network network; public ProxyServer(Network network){ this.network = network; } public void verify(){ System.out.println(\"Verifying info before connecting to the Internet...\"); } @Override public void browse() { verify(); network.browse(); } public Network getNetwork() { return network; } public void setNetwork(Network network) { this.network = network; } } 应用场景 安全代理： 屏蔽对真实角色的直接访问 远程代理：通过代理类处理远程方法调用（RMI） 延迟加载：先加载轻量级的代理对象，真正需要时再加载真实对象。比如一个文档中有图片，打开文件时不可能显示所有图片，可以使用代理模式在需要查看图片时用proxy进行大图的打开 分类 静态代理：写在代码中 动态代理：运行时运用反射 ","date":"2022-01-09","objectID":"/javase/:1:26","series":[],"tags":["Java"],"title":"JavaSE","uri":"/javase/#proxy"},{"categories":["Note"],"content":"Proxy package proxy; public class ProxyTest { public static void main(String[] args) { Server server = new Server(); ProxyServer proxyServer = new ProxyServer(server); proxyServer.browse(); } } interface Network { void browse(); } // The Server being proxied class Server implements Network { @Override public void browse(){ System.out.println(\"Real server accesses Internet...\"); } } // Proxy class ProxyServer implements Network { private Network network; public ProxyServer(Network network){ this.network = network; } public void verify(){ System.out.println(\"Verifying info before connecting to the Internet...\"); } @Override public void browse() { verify(); network.browse(); } public Network getNetwork() { return network; } public void setNetwork(Network network) { this.network = network; } } 应用场景 安全代理： 屏蔽对真实角色的直接访问 远程代理：通过代理类处理远程方法调用（RMI） 延迟加载：先加载轻量级的代理对象，真正需要时再加载真实对象。比如一个文档中有图片，打开文件时不可能显示所有图片，可以使用代理模式在需要查看图片时用proxy进行大图的打开 分类 静态代理：写在代码中 动态代理：运行时运用反射 ","date":"2022-01-09","objectID":"/javase/:1:26","series":[],"tags":["Java"],"title":"JavaSE","uri":"/javase/#应用场景"},{"categories":["Note"],"content":"Proxy package proxy; public class ProxyTest { public static void main(String[] args) { Server server = new Server(); ProxyServer proxyServer = new ProxyServer(server); proxyServer.browse(); } } interface Network { void browse(); } // The Server being proxied class Server implements Network { @Override public void browse(){ System.out.println(\"Real server accesses Internet...\"); } } // Proxy class ProxyServer implements Network { private Network network; public ProxyServer(Network network){ this.network = network; } public void verify(){ System.out.println(\"Verifying info before connecting to the Internet...\"); } @Override public void browse() { verify(); network.browse(); } public Network getNetwork() { return network; } public void setNetwork(Network network) { this.network = network; } } 应用场景 安全代理： 屏蔽对真实角色的直接访问 远程代理：通过代理类处理远程方法调用（RMI） 延迟加载：先加载轻量级的代理对象，真正需要时再加载真实对象。比如一个文档中有图片，打开文件时不可能显示所有图片，可以使用代理模式在需要查看图片时用proxy进行大图的打开 分类 静态代理：写在代码中 动态代理：运行时运用反射 ","date":"2022-01-09","objectID":"/javase/:1:26","series":[],"tags":["Java"],"title":"JavaSE","uri":"/javase/#分类"},{"categories":["Note"],"content":"Interface （supplementary） After Java8, you can define static and default method in interface the static methods in interface only can be called by interfaces, you cannot call them from the classes implementing the interfaces. default methods can be called by the instances of the classes implementing its interface, and it can be overrode but you shouldn’t do that the most of time. if one’s super class and the interface it implemented have a method with same name, if this method is not overrode, the one of its super class will be called by default!!! if one implements multiple interfaces who have a method with same name, and the method is not overrode –\u003e error how to call a overrode method from the current class' super class or interfaces implemented? // methodA and methodB have been overrode super.methodB(); // call it from super class interfaceA.super.methodA(); // call it from the interfaces implemented ","date":"2022-01-09","objectID":"/javase/:1:27","series":[],"tags":["Java"],"title":"JavaSE","uri":"/javase/#interface-supplementary"},{"categories":["Note"],"content":"Inner Class Declare a Class B inside Class A, B is inner class and A is outer class. Member Inner Class v.s. Local Inner Class(declared in methods, code blocks, constructors) public class InnerTest { public static void main(String[] args) { // create static member inner class Person.Body body = new Person.Body(); body.intro(); // create non-static member inner class Person person = new Person(); Person.Foot foot = person.new Foot(); foot.intro(); // it seems we cannot directly 'new' a local inner class object in the main... // we have to make it work in the relative methods... } } class Person { String name = \"Jacky\"; public void method(){ int localNum = 10; // if this var is accessed in the inner class declared in this method, then this var must be final(you don't need to put final here since it's automatically done implicitly). The reason is due to the lifetime. num here belong to the outer class, but you want to use that local var in inner class method, so you have to make it final so that outer class can send a copy of num, and you cannot change it since it's a copy and your change won't affect the original num in outer class. // local inner class class Hand { String name = \"Jacky's Hand\"; public void intro(){ //num = 20; HERE IS WRONG, Variable 'num' is accessed from within inner class, needs to be final or effectively final! System.out.println(\"This is hand...\"); } } } { // local inner class class Head { String name = \"Jacky's Head\"; public void intro(){ System.out.println(\"This is head...\"); } public void speak(String name){ System.out.println(name); // parameter System.out.println(this.name); // inner class attribute System.out.println(Person.this.name); // outer class attribute } // return a class that implemented the interface // public Comparable getComparable(){ // class MyComparable implements Comparable { // @Override // public int compareTo(Object obj){ // return 0; // } // } // // return new MyComparable(); // } // OR! Here we actually implicitly creat an anonymous inner class having the same name of the interface! public Comparable getComparable(){ return new Comparable() { @Override public int compareTo(Object o) { return 0; } }; } } } // non-static member inner class class Foot { String name = \"Jacky's Foot\"; public void intro() { System.out.println(\"This is foot...\"); } } // static member inner class static class Body { String name = \"Jacky's Body\"; public void intro(){ System.out.println(\"This is body...\"); } } } Notice: inner class can be modified by static and private and all other access modifiers! How to instantiate member inner class' object How to distinguish the attributes of inner and outer classes in the inner class method How to use the local inner class in real life ","date":"2022-01-09","objectID":"/javase/:1:28","series":[],"tags":["Java"],"title":"JavaSE","uri":"/javase/#inner-class"},{"categories":["Note"],"content":"Inner Class Declare a Class B inside Class A, B is inner class and A is outer class. Member Inner Class v.s. Local Inner Class(declared in methods, code blocks, constructors) public class InnerTest { public static void main(String[] args) { // create static member inner class Person.Body body = new Person.Body(); body.intro(); // create non-static member inner class Person person = new Person(); Person.Foot foot = person.new Foot(); foot.intro(); // it seems we cannot directly 'new' a local inner class object in the main... // we have to make it work in the relative methods... } } class Person { String name = \"Jacky\"; public void method(){ int localNum = 10; // if this var is accessed in the inner class declared in this method, then this var must be final(you don't need to put final here since it's automatically done implicitly). The reason is due to the lifetime. num here belong to the outer class, but you want to use that local var in inner class method, so you have to make it final so that outer class can send a copy of num, and you cannot change it since it's a copy and your change won't affect the original num in outer class. // local inner class class Hand { String name = \"Jacky's Hand\"; public void intro(){ //num = 20; HERE IS WRONG, Variable 'num' is accessed from within inner class, needs to be final or effectively final! System.out.println(\"This is hand...\"); } } } { // local inner class class Head { String name = \"Jacky's Head\"; public void intro(){ System.out.println(\"This is head...\"); } public void speak(String name){ System.out.println(name); // parameter System.out.println(this.name); // inner class attribute System.out.println(Person.this.name); // outer class attribute } // return a class that implemented the interface // public Comparable getComparable(){ // class MyComparable implements Comparable { // @Override // public int compareTo(Object obj){ // return 0; // } // } // // return new MyComparable(); // } // OR! Here we actually implicitly creat an anonymous inner class having the same name of the interface! public Comparable getComparable(){ return new Comparable() { @Override public int compareTo(Object o) { return 0; } }; } } } // non-static member inner class class Foot { String name = \"Jacky's Foot\"; public void intro() { System.out.println(\"This is foot...\"); } } // static member inner class static class Body { String name = \"Jacky's Body\"; public void intro(){ System.out.println(\"This is body...\"); } } } Notice: inner class can be modified by static and private and all other access modifiers! How to instantiate member inner class' object How to distinguish the attributes of inner and outer classes in the inner class method How to use the local inner class in real life ","date":"2022-01-09","objectID":"/javase/:1:28","series":[],"tags":["Java"],"title":"JavaSE","uri":"/javase/#member-inner-class-vs-local-inner-classdeclared-in-methods-code-blocks-constructors"},{"categories":["Note"],"content":"Exception import org.testng.annotations.Test; import java.io.File; import java.io.FileInputStream; import java.io.FileNotFoundException; import java.io.IOException; public class Exceptions { public static void main(String[] args) { } @Test public void test1(){ String str = \"abc\"; int num = 0; try{ num = Integer.parseInt(str); System.out.println(\"Parsing...\"); }catch (NumberFormatException e){ System.out.println(\"Catching the format exception...\"); System.out.println(e.getMessage()); e.printStackTrace(); }catch (NullPointerException e){ System.out.println(\"Catching null pointers...\"); System.out.println(e.getMessage()); e.printStackTrace(); }catch (Exception e){ System.out.println(\"Catching unexpected exceptions...\"); System.out.println(e.getMessage()); e.printStackTrace(); } System.out.println(num); } @Test public void test2_1() { FileInputStream fis = null; try{ File file = new File(\"hello.txt\"); fis = new FileInputStream(file); int data = fis.read(); while(data != -1){ System.out.print((char)data); data = fis.read(); } fis.close(); }catch (FileNotFoundException e) { e.printStackTrace(); } catch (IOException e) { e.printStackTrace(); }finally { try { if(fis != null) fis.close(); } catch (IOException e) { e.printStackTrace(); } } } @Test public void test2_2() throws IOException { // throws them to upper level, until they are thrown by the main... FileInputStream fis = null; try{ File file = new File(\"hello.txt\"); fis = new FileInputStream(file); int data = fis.read(); while(data != -1){ System.out.print((char)data); data = fis.read(); } fis.close(); }catch (FileNotFoundException e) { e.printStackTrace(); } catch (IOException e) { e.printStackTrace(); }finally { if(fis != null) fis.close(); } } // finally-block will be executed even when catch block has exceptions or there is return statement in try\u0026catch block // We have to terminate db-connection, IO stream, or things like network socket manually, since JVM cannot gc them @Test public int Test3(){ int a = 100; int b = 0; try{ System.out.println(a/b); return 1; }catch(ArithmeticException e){ e.printStackTrace(); return 2; }catch (Exception e){ e.printStackTrace(); return 3; }finally { System.out.println(\"Nailed it!\"); } } } try-catch-finally will deal with the exceptions and the code after it will be executed. throws will throw the exceptions to the caller, and the code after it will not be executed. /* * Rules for exception overridden * The overrode current class' method cannot throw broader level of exception than its super class! * Say if you have a method A, and in A, you have 3 consecutive method called where the next need the result of the last. * Those methods should throw the exceptions to A, and A will use try-catch-finally to deal with them. * Since we do not to need to run the code after, if there are dependencies. */ import java.io.FileNotFoundException; import java.io.IOException; public class ExceptionOverride { public static void main(String[] args) { ExceptionOverride eo = new ExceptionOverride(); eo.display(new SubClass()); // polymorphism --\u003e thus the super class need to at least handle all exceptions to its subclasses } public void display(SuperClass s){ try{ s.method(); }catch (IOException e){ e.printStackTrace(); } } } class SuperClass { public void method() throws IOException { } } class SubClass extends SuperClass { public void method() throws FileNotFoundException { } } throw in try-catch-finally and throws, the exception object is created by the system. throw gives you the option to manually create the exception object. public class Throw { public static void main(String[] args) { Student s = new Student(); s.register(-100); } } class Student{ private int id; public void register(int id){ if (id \u003e 0){ this.id = id; }else{ throw new RuntimeException(\"illegal data\"); } } } Customized Exception /* * How to? * 1. inherit from existed exceptions: RuntimeException, Exception * 2. provide a global val: serialVersionUID * 3. provide a overloaded constructor * ","date":"2022-01-09","objectID":"/javase/:1:29","series":[],"tags":["Java"],"title":"JavaSE","uri":"/javase/#exception"},{"categories":["Note"],"content":"Exception import org.testng.annotations.Test; import java.io.File; import java.io.FileInputStream; import java.io.FileNotFoundException; import java.io.IOException; public class Exceptions { public static void main(String[] args) { } @Test public void test1(){ String str = \"abc\"; int num = 0; try{ num = Integer.parseInt(str); System.out.println(\"Parsing...\"); }catch (NumberFormatException e){ System.out.println(\"Catching the format exception...\"); System.out.println(e.getMessage()); e.printStackTrace(); }catch (NullPointerException e){ System.out.println(\"Catching null pointers...\"); System.out.println(e.getMessage()); e.printStackTrace(); }catch (Exception e){ System.out.println(\"Catching unexpected exceptions...\"); System.out.println(e.getMessage()); e.printStackTrace(); } System.out.println(num); } @Test public void test2_1() { FileInputStream fis = null; try{ File file = new File(\"hello.txt\"); fis = new FileInputStream(file); int data = fis.read(); while(data != -1){ System.out.print((char)data); data = fis.read(); } fis.close(); }catch (FileNotFoundException e) { e.printStackTrace(); } catch (IOException e) { e.printStackTrace(); }finally { try { if(fis != null) fis.close(); } catch (IOException e) { e.printStackTrace(); } } } @Test public void test2_2() throws IOException { // throws them to upper level, until they are thrown by the main... FileInputStream fis = null; try{ File file = new File(\"hello.txt\"); fis = new FileInputStream(file); int data = fis.read(); while(data != -1){ System.out.print((char)data); data = fis.read(); } fis.close(); }catch (FileNotFoundException e) { e.printStackTrace(); } catch (IOException e) { e.printStackTrace(); }finally { if(fis != null) fis.close(); } } // finally-block will be executed even when catch block has exceptions or there is return statement in try\u0026catch block // We have to terminate db-connection, IO stream, or things like network socket manually, since JVM cannot gc them @Test public int Test3(){ int a = 100; int b = 0; try{ System.out.println(a/b); return 1; }catch(ArithmeticException e){ e.printStackTrace(); return 2; }catch (Exception e){ e.printStackTrace(); return 3; }finally { System.out.println(\"Nailed it!\"); } } } try-catch-finally will deal with the exceptions and the code after it will be executed. throws will throw the exceptions to the caller, and the code after it will not be executed. /* * Rules for exception overridden * The overrode current class' method cannot throw broader level of exception than its super class! * Say if you have a method A, and in A, you have 3 consecutive method called where the next need the result of the last. * Those methods should throw the exceptions to A, and A will use try-catch-finally to deal with them. * Since we do not to need to run the code after, if there are dependencies. */ import java.io.FileNotFoundException; import java.io.IOException; public class ExceptionOverride { public static void main(String[] args) { ExceptionOverride eo = new ExceptionOverride(); eo.display(new SubClass()); // polymorphism -- thus the super class need to at least handle all exceptions to its subclasses } public void display(SuperClass s){ try{ s.method(); }catch (IOException e){ e.printStackTrace(); } } } class SuperClass { public void method() throws IOException { } } class SubClass extends SuperClass { public void method() throws FileNotFoundException { } } throw in try-catch-finally and throws, the exception object is created by the system. throw gives you the option to manually create the exception object. public class Throw { public static void main(String[] args) { Student s = new Student(); s.register(-100); } } class Student{ private int id; public void register(int id){ if (id 0){ this.id = id; }else{ throw new RuntimeException(\"illegal data\"); } } } Customized Exception /* * How to? * 1. inherit from existed exceptions: RuntimeException, Exception * 2. provide a global val: serialVersionUID * 3. provide a overloaded constructor * ","date":"2022-01-09","objectID":"/javase/:1:29","series":[],"tags":["Java"],"title":"JavaSE","uri":"/javase/#throw"},{"categories":["Note"],"content":"Exception import org.testng.annotations.Test; import java.io.File; import java.io.FileInputStream; import java.io.FileNotFoundException; import java.io.IOException; public class Exceptions { public static void main(String[] args) { } @Test public void test1(){ String str = \"abc\"; int num = 0; try{ num = Integer.parseInt(str); System.out.println(\"Parsing...\"); }catch (NumberFormatException e){ System.out.println(\"Catching the format exception...\"); System.out.println(e.getMessage()); e.printStackTrace(); }catch (NullPointerException e){ System.out.println(\"Catching null pointers...\"); System.out.println(e.getMessage()); e.printStackTrace(); }catch (Exception e){ System.out.println(\"Catching unexpected exceptions...\"); System.out.println(e.getMessage()); e.printStackTrace(); } System.out.println(num); } @Test public void test2_1() { FileInputStream fis = null; try{ File file = new File(\"hello.txt\"); fis = new FileInputStream(file); int data = fis.read(); while(data != -1){ System.out.print((char)data); data = fis.read(); } fis.close(); }catch (FileNotFoundException e) { e.printStackTrace(); } catch (IOException e) { e.printStackTrace(); }finally { try { if(fis != null) fis.close(); } catch (IOException e) { e.printStackTrace(); } } } @Test public void test2_2() throws IOException { // throws them to upper level, until they are thrown by the main... FileInputStream fis = null; try{ File file = new File(\"hello.txt\"); fis = new FileInputStream(file); int data = fis.read(); while(data != -1){ System.out.print((char)data); data = fis.read(); } fis.close(); }catch (FileNotFoundException e) { e.printStackTrace(); } catch (IOException e) { e.printStackTrace(); }finally { if(fis != null) fis.close(); } } // finally-block will be executed even when catch block has exceptions or there is return statement in try\u0026catch block // We have to terminate db-connection, IO stream, or things like network socket manually, since JVM cannot gc them @Test public int Test3(){ int a = 100; int b = 0; try{ System.out.println(a/b); return 1; }catch(ArithmeticException e){ e.printStackTrace(); return 2; }catch (Exception e){ e.printStackTrace(); return 3; }finally { System.out.println(\"Nailed it!\"); } } } try-catch-finally will deal with the exceptions and the code after it will be executed. throws will throw the exceptions to the caller, and the code after it will not be executed. /* * Rules for exception overridden * The overrode current class' method cannot throw broader level of exception than its super class! * Say if you have a method A, and in A, you have 3 consecutive method called where the next need the result of the last. * Those methods should throw the exceptions to A, and A will use try-catch-finally to deal with them. * Since we do not to need to run the code after, if there are dependencies. */ import java.io.FileNotFoundException; import java.io.IOException; public class ExceptionOverride { public static void main(String[] args) { ExceptionOverride eo = new ExceptionOverride(); eo.display(new SubClass()); // polymorphism -- thus the super class need to at least handle all exceptions to its subclasses } public void display(SuperClass s){ try{ s.method(); }catch (IOException e){ e.printStackTrace(); } } } class SuperClass { public void method() throws IOException { } } class SubClass extends SuperClass { public void method() throws FileNotFoundException { } } throw in try-catch-finally and throws, the exception object is created by the system. throw gives you the option to manually create the exception object. public class Throw { public static void main(String[] args) { Student s = new Student(); s.register(-100); } } class Student{ private int id; public void register(int id){ if (id 0){ this.id = id; }else{ throw new RuntimeException(\"illegal data\"); } } } Customized Exception /* * How to? * 1. inherit from existed exceptions: RuntimeException, Exception * 2. provide a global val: serialVersionUID * 3. provide a overloaded constructor * ","date":"2022-01-09","objectID":"/javase/:1:29","series":[],"tags":["Java"],"title":"JavaSE","uri":"/javase/#customized-exception"},{"categories":["Note"],"content":"Advanced Java Features ","date":"2022-01-09","objectID":"/javase/:2:0","series":[],"tags":["Java"],"title":"JavaSE","uri":"/javase/#advanced-java-features"},{"categories":["Note"],"content":"Muti-Thread Method 1 /* * How to create a thread? * Method 1: Inheritance * 1. create a class A extends Thread * 2. override the run() * 3. create an instance `a` of A * 4. call a.start() * */ public class ThreadDeclare { public static void main(String[] args) { MyThread myThread = new MyThread(); myThread.start(); // new thread // Since we don't use it again once the thread is started, we can do it like: new MyThread().start(); // main thread for (int i = 0; i \u003c 100; i++) { if (i % 2 != 0){ System.out.println(Thread.currentThread().getName() + \":\" + Thread.currentThread().getPriority() + \":\" + i); } } } } class MyThread extends Thread { @Override public void run(){ for (int i = 0; i \u003c 100; i++) { if (i % 2 == 0){ System.out.println(Thread.currentThread().getName() + \":\" + Thread.currentThread().getPriority() + \":\" + i); } } } } We have to call start to start a new thread, if you call run, then it’s running in the same thread. Can we use the same thread instance to start a new thread? NO!!! Because the status of the thread object is not 0 any longer. Frequently used methods of Thread Class void start(): start a new thread and call run() run(): what is executed while the thread is running String getName(): return the name of the thread void setName(String name): set the name of the thread static Thread currentThread(): return the current thread, often used in main thread and Runnable realization. staic void yield(): pause the current thread, give the chance to another thread with an same or higher priority. If there isn’t any thread having the same priority, then ignore this method join(): caller thread will be blocked until the callee thread finishes static void sleep(long millies): put itself into sleep for a time, throw a InterruptedException stop(): force to end the lifetime of a thread, not recommanded boolean isAlive(): return boolean Method 2 /* * Method 2: implement Runnable interface * 1. Create a class A implemented Runnable interface * 2. implement run() of the Runnable interface in A * 3. create an instance `a` of A * 4. pass `a` to the Thread constructor to create a Thread object o * 5. o.start() * * notice that we always can choose to do this implicitly: new Thread(a).start(); * */ public class Runnable { public static void main(String[] args) { RunThread rt = new RunThread(); new Thread(rt).start(); // why here the run() of the interface get called instead of that of the Thread object? // Because in the run() of Thread class calls the run() of the Runnable interface! new Thread(rt).start(); } } class RunThread implements java.lang.Runnable { @Override public void run(){ for (int i = 0; i \u003c 100; i++) { if (i % 2 == 0){ System.out.println(Thread.currentThread().getName() + \":\" + i); } } } } // NOTICE: not thread safe! public class TicketSell { public static void main(String[] args) { Window window = new Window(); Thread t1 = new Thread(window); Thread t2 = new Thread(window); Thread t3 = new Thread(window); t1.setName(\"Window01\"); t2.setName(\"Window02\"); t3.setName(\"Window03\"); t1.start(); t2.start(); t3.start(); } } class Window implements java.lang.Runnable{ private static int ticketNum = 100; @Override public void run(){ while (true){ if (ticketNum \u003e 0){ System.out.println(Thread.currentThread().getName() + \"sold --\u003e ticketID: \" + ticketNum); ticketNum--; }else break; } } } It’s obvious that the 2nd method is better in terms of data sharing and convenience of inheritance. Lifetime of Thread State: NEW: thread state for a thread which has not yet started RUNNABLE: ready BLOCKED: thread blocked waiting for a monitor lock WAITING: in the waiting state TIMED_WAITING: waiting thread with a specified waiting time TERMINATED NEW –\u003e start() –\u003e RUNNABLE(ready but not nescessary be running) Sync Sync Method 1: Synchronized Monitor can be any object Those threads must use the same lock!!! public class TicketSell { public static void main(String[] args) { Window window = new Window(); Thread t1 = new Thread(window); Thread ","date":"2022-01-09","objectID":"/javase/:2:1","series":[],"tags":["Java"],"title":"JavaSE","uri":"/javase/#muti-thread"},{"categories":["Note"],"content":"Muti-Thread Method 1 /* * How to create a thread? * Method 1: Inheritance * 1. create a class A extends Thread * 2. override the run() * 3. create an instance `a` of A * 4. call a.start() * */ public class ThreadDeclare { public static void main(String[] args) { MyThread myThread = new MyThread(); myThread.start(); // new thread // Since we don't use it again once the thread is started, we can do it like: new MyThread().start(); // main thread for (int i = 0; i 0){ System.out.println(Thread.currentThread().getName() + \"sold -- ticketID: \" + ticketNum); ticketNum--; }else break; } } } It’s obvious that the 2nd method is better in terms of data sharing and convenience of inheritance. Lifetime of Thread State: NEW: thread state for a thread which has not yet started RUNNABLE: ready BLOCKED: thread blocked waiting for a monitor lock WAITING: in the waiting state TIMED_WAITING: waiting thread with a specified waiting time TERMINATED NEW – start() – RUNNABLE(ready but not nescessary be running) Sync Sync Method 1: Synchronized Monitor can be any object Those threads must use the same lock!!! public class TicketSell { public static void main(String[] args) { Window window = new Window(); Thread t1 = new Thread(window); Thread ","date":"2022-01-09","objectID":"/javase/:2:1","series":[],"tags":["Java"],"title":"JavaSE","uri":"/javase/#method-1"},{"categories":["Note"],"content":"Muti-Thread Method 1 /* * How to create a thread? * Method 1: Inheritance * 1. create a class A extends Thread * 2. override the run() * 3. create an instance `a` of A * 4. call a.start() * */ public class ThreadDeclare { public static void main(String[] args) { MyThread myThread = new MyThread(); myThread.start(); // new thread // Since we don't use it again once the thread is started, we can do it like: new MyThread().start(); // main thread for (int i = 0; i 0){ System.out.println(Thread.currentThread().getName() + \"sold -- ticketID: \" + ticketNum); ticketNum--; }else break; } } } It’s obvious that the 2nd method is better in terms of data sharing and convenience of inheritance. Lifetime of Thread State: NEW: thread state for a thread which has not yet started RUNNABLE: ready BLOCKED: thread blocked waiting for a monitor lock WAITING: in the waiting state TIMED_WAITING: waiting thread with a specified waiting time TERMINATED NEW – start() – RUNNABLE(ready but not nescessary be running) Sync Sync Method 1: Synchronized Monitor can be any object Those threads must use the same lock!!! public class TicketSell { public static void main(String[] args) { Window window = new Window(); Thread t1 = new Thread(window); Thread ","date":"2022-01-09","objectID":"/javase/:2:1","series":[],"tags":["Java"],"title":"JavaSE","uri":"/javase/#frequently-used-methods-of-thread-class"},{"categories":["Note"],"content":"Muti-Thread Method 1 /* * How to create a thread? * Method 1: Inheritance * 1. create a class A extends Thread * 2. override the run() * 3. create an instance `a` of A * 4. call a.start() * */ public class ThreadDeclare { public static void main(String[] args) { MyThread myThread = new MyThread(); myThread.start(); // new thread // Since we don't use it again once the thread is started, we can do it like: new MyThread().start(); // main thread for (int i = 0; i 0){ System.out.println(Thread.currentThread().getName() + \"sold -- ticketID: \" + ticketNum); ticketNum--; }else break; } } } It’s obvious that the 2nd method is better in terms of data sharing and convenience of inheritance. Lifetime of Thread State: NEW: thread state for a thread which has not yet started RUNNABLE: ready BLOCKED: thread blocked waiting for a monitor lock WAITING: in the waiting state TIMED_WAITING: waiting thread with a specified waiting time TERMINATED NEW – start() – RUNNABLE(ready but not nescessary be running) Sync Sync Method 1: Synchronized Monitor can be any object Those threads must use the same lock!!! public class TicketSell { public static void main(String[] args) { Window window = new Window(); Thread t1 = new Thread(window); Thread ","date":"2022-01-09","objectID":"/javase/:2:1","series":[],"tags":["Java"],"title":"JavaSE","uri":"/javase/#method-2"},{"categories":["Note"],"content":"Muti-Thread Method 1 /* * How to create a thread? * Method 1: Inheritance * 1. create a class A extends Thread * 2. override the run() * 3. create an instance `a` of A * 4. call a.start() * */ public class ThreadDeclare { public static void main(String[] args) { MyThread myThread = new MyThread(); myThread.start(); // new thread // Since we don't use it again once the thread is started, we can do it like: new MyThread().start(); // main thread for (int i = 0; i 0){ System.out.println(Thread.currentThread().getName() + \"sold -- ticketID: \" + ticketNum); ticketNum--; }else break; } } } It’s obvious that the 2nd method is better in terms of data sharing and convenience of inheritance. Lifetime of Thread State: NEW: thread state for a thread which has not yet started RUNNABLE: ready BLOCKED: thread blocked waiting for a monitor lock WAITING: in the waiting state TIMED_WAITING: waiting thread with a specified waiting time TERMINATED NEW – start() – RUNNABLE(ready but not nescessary be running) Sync Sync Method 1: Synchronized Monitor can be any object Those threads must use the same lock!!! public class TicketSell { public static void main(String[] args) { Window window = new Window(); Thread t1 = new Thread(window); Thread ","date":"2022-01-09","objectID":"/javase/:2:1","series":[],"tags":["Java"],"title":"JavaSE","uri":"/javase/#lifetime-of-thread"},{"categories":["Note"],"content":"Muti-Thread Method 1 /* * How to create a thread? * Method 1: Inheritance * 1. create a class A extends Thread * 2. override the run() * 3. create an instance `a` of A * 4. call a.start() * */ public class ThreadDeclare { public static void main(String[] args) { MyThread myThread = new MyThread(); myThread.start(); // new thread // Since we don't use it again once the thread is started, we can do it like: new MyThread().start(); // main thread for (int i = 0; i 0){ System.out.println(Thread.currentThread().getName() + \"sold -- ticketID: \" + ticketNum); ticketNum--; }else break; } } } It’s obvious that the 2nd method is better in terms of data sharing and convenience of inheritance. Lifetime of Thread State: NEW: thread state for a thread which has not yet started RUNNABLE: ready BLOCKED: thread blocked waiting for a monitor lock WAITING: in the waiting state TIMED_WAITING: waiting thread with a specified waiting time TERMINATED NEW – start() – RUNNABLE(ready but not nescessary be running) Sync Sync Method 1: Synchronized Monitor can be any object Those threads must use the same lock!!! public class TicketSell { public static void main(String[] args) { Window window = new Window(); Thread t1 = new Thread(window); Thread ","date":"2022-01-09","objectID":"/javase/:2:1","series":[],"tags":["Java"],"title":"JavaSE","uri":"/javase/#sync"},{"categories":["Note"],"content":"Muti-Thread Method 1 /* * How to create a thread? * Method 1: Inheritance * 1. create a class A extends Thread * 2. override the run() * 3. create an instance `a` of A * 4. call a.start() * */ public class ThreadDeclare { public static void main(String[] args) { MyThread myThread = new MyThread(); myThread.start(); // new thread // Since we don't use it again once the thread is started, we can do it like: new MyThread().start(); // main thread for (int i = 0; i 0){ System.out.println(Thread.currentThread().getName() + \"sold -- ticketID: \" + ticketNum); ticketNum--; }else break; } } } It’s obvious that the 2nd method is better in terms of data sharing and convenience of inheritance. Lifetime of Thread State: NEW: thread state for a thread which has not yet started RUNNABLE: ready BLOCKED: thread blocked waiting for a monitor lock WAITING: in the waiting state TIMED_WAITING: waiting thread with a specified waiting time TERMINATED NEW – start() – RUNNABLE(ready but not nescessary be running) Sync Sync Method 1: Synchronized Monitor can be any object Those threads must use the same lock!!! public class TicketSell { public static void main(String[] args) { Window window = new Window(); Thread t1 = new Thread(window); Thread ","date":"2022-01-09","objectID":"/javase/:2:1","series":[],"tags":["Java"],"title":"JavaSE","uri":"/javase/#singleton"},{"categories":["Note"],"content":"Muti-Thread Method 1 /* * How to create a thread? * Method 1: Inheritance * 1. create a class A extends Thread * 2. override the run() * 3. create an instance `a` of A * 4. call a.start() * */ public class ThreadDeclare { public static void main(String[] args) { MyThread myThread = new MyThread(); myThread.start(); // new thread // Since we don't use it again once the thread is started, we can do it like: new MyThread().start(); // main thread for (int i = 0; i 0){ System.out.println(Thread.currentThread().getName() + \"sold -- ticketID: \" + ticketNum); ticketNum--; }else break; } } } It’s obvious that the 2nd method is better in terms of data sharing and convenience of inheritance. Lifetime of Thread State: NEW: thread state for a thread which has not yet started RUNNABLE: ready BLOCKED: thread blocked waiting for a monitor lock WAITING: in the waiting state TIMED_WAITING: waiting thread with a specified waiting time TERMINATED NEW – start() – RUNNABLE(ready but not nescessary be running) Sync Sync Method 1: Synchronized Monitor can be any object Those threads must use the same lock!!! public class TicketSell { public static void main(String[] args) { Window window = new Window(); Thread t1 = new Thread(window); Thread ","date":"2022-01-09","objectID":"/javase/:2:1","series":[],"tags":["Java"],"title":"JavaSE","uri":"/javase/#lock-after-jdk5-sync-method-3"},{"categories":["Note"],"content":"Muti-Thread Method 1 /* * How to create a thread? * Method 1: Inheritance * 1. create a class A extends Thread * 2. override the run() * 3. create an instance `a` of A * 4. call a.start() * */ public class ThreadDeclare { public static void main(String[] args) { MyThread myThread = new MyThread(); myThread.start(); // new thread // Since we don't use it again once the thread is started, we can do it like: new MyThread().start(); // main thread for (int i = 0; i 0){ System.out.println(Thread.currentThread().getName() + \"sold -- ticketID: \" + ticketNum); ticketNum--; }else break; } } } It’s obvious that the 2nd method is better in terms of data sharing and convenience of inheritance. Lifetime of Thread State: NEW: thread state for a thread which has not yet started RUNNABLE: ready BLOCKED: thread blocked waiting for a monitor lock WAITING: in the waiting state TIMED_WAITING: waiting thread with a specified waiting time TERMINATED NEW – start() – RUNNABLE(ready but not nescessary be running) Sync Sync Method 1: Synchronized Monitor can be any object Those threads must use the same lock!!! public class TicketSell { public static void main(String[] args) { Window window = new Window(); Thread t1 = new Thread(window); Thread ","date":"2022-01-09","objectID":"/javase/:2:1","series":[],"tags":["Java"],"title":"JavaSE","uri":"/javase/#thread-communication"},{"categories":["Note"],"content":"Muti-Thread Method 1 /* * How to create a thread? * Method 1: Inheritance * 1. create a class A extends Thread * 2. override the run() * 3. create an instance `a` of A * 4. call a.start() * */ public class ThreadDeclare { public static void main(String[] args) { MyThread myThread = new MyThread(); myThread.start(); // new thread // Since we don't use it again once the thread is started, we can do it like: new MyThread().start(); // main thread for (int i = 0; i 0){ System.out.println(Thread.currentThread().getName() + \"sold -- ticketID: \" + ticketNum); ticketNum--; }else break; } } } It’s obvious that the 2nd method is better in terms of data sharing and convenience of inheritance. Lifetime of Thread State: NEW: thread state for a thread which has not yet started RUNNABLE: ready BLOCKED: thread blocked waiting for a monitor lock WAITING: in the waiting state TIMED_WAITING: waiting thread with a specified waiting time TERMINATED NEW – start() – RUNNABLE(ready but not nescessary be running) Sync Sync Method 1: Synchronized Monitor can be any object Those threads must use the same lock!!! public class TicketSell { public static void main(String[] args) { Window window = new Window(); Thread t1 = new Thread(window); Thread ","date":"2022-01-09","objectID":"/javase/:2:1","series":[],"tags":["Java"],"title":"JavaSE","uri":"/javase/#great-practice-probhttpswwwbilibilicomvideobv1kb411w75np443"},{"categories":["Note"],"content":"Muti-Thread Method 1 /* * How to create a thread? * Method 1: Inheritance * 1. create a class A extends Thread * 2. override the run() * 3. create an instance `a` of A * 4. call a.start() * */ public class ThreadDeclare { public static void main(String[] args) { MyThread myThread = new MyThread(); myThread.start(); // new thread // Since we don't use it again once the thread is started, we can do it like: new MyThread().start(); // main thread for (int i = 0; i 0){ System.out.println(Thread.currentThread().getName() + \"sold -- ticketID: \" + ticketNum); ticketNum--; }else break; } } } It’s obvious that the 2nd method is better in terms of data sharing and convenience of inheritance. Lifetime of Thread State: NEW: thread state for a thread which has not yet started RUNNABLE: ready BLOCKED: thread blocked waiting for a monitor lock WAITING: in the waiting state TIMED_WAITING: waiting thread with a specified waiting time TERMINATED NEW – start() – RUNNABLE(ready but not nescessary be running) Sync Sync Method 1: Synchronized Monitor can be any object Those threads must use the same lock!!! public class TicketSell { public static void main(String[] args) { Window window = new Window(); Thread t1 = new Thread(window); Thread ","date":"2022-01-09","objectID":"/javase/:2:1","series":[],"tags":["Java"],"title":"JavaSE","uri":"/javase/#method-3-callable-interface"},{"categories":["Note"],"content":"Muti-Thread Method 1 /* * How to create a thread? * Method 1: Inheritance * 1. create a class A extends Thread * 2. override the run() * 3. create an instance `a` of A * 4. call a.start() * */ public class ThreadDeclare { public static void main(String[] args) { MyThread myThread = new MyThread(); myThread.start(); // new thread // Since we don't use it again once the thread is started, we can do it like: new MyThread().start(); // main thread for (int i = 0; i 0){ System.out.println(Thread.currentThread().getName() + \"sold -- ticketID: \" + ticketNum); ticketNum--; }else break; } } } It’s obvious that the 2nd method is better in terms of data sharing and convenience of inheritance. Lifetime of Thread State: NEW: thread state for a thread which has not yet started RUNNABLE: ready BLOCKED: thread blocked waiting for a monitor lock WAITING: in the waiting state TIMED_WAITING: waiting thread with a specified waiting time TERMINATED NEW – start() – RUNNABLE(ready but not nescessary be running) Sync Sync Method 1: Synchronized Monitor can be any object Those threads must use the same lock!!! public class TicketSell { public static void main(String[] args) { Window window = new Window(); Thread t1 = new Thread(window); Thread ","date":"2022-01-09","objectID":"/javase/:2:1","series":[],"tags":["Java"],"title":"JavaSE","uri":"/javase/#tread-pool-method-4"},{"categories":["Note"],"content":"Frequently Used Classes String class import org.testng.annotations.Test; public class StringTest { @Test public void test() { String s1 = \"Java\"; String s2 = \"Test\"; String s3 = \"JavaTest\"; String s4 = \"Java\" + \"Test\"; String s5 = s1 + \"Test\"; // s1 point to a pointer in the heap, and the pointer points to \"Java\" in the constant pool String s6 = s1 + s2; String s7 = s5.intern(); // find the literal in constant pool and return it final String s8 = s1 + s2; System.out.println(s3 == s4); //T System.out.println(s3 == s5); //F System.out.println(s3 == s6); //F System.out.println(s5 == s6); //F System.out.println(s3 == s7); //T System.out.println(s3 == s8); // F Look at this! System.out.println(s3.getClass()); // same System.out.println(s8.getClass()); System.out.println(s3.hashCode()); // same System.out.println(s8.hashCode()); System.out.println(System.identityHashCode(s3)); // diff System.out.println(System.identityHashCode(s8)); } } StringBuffer and StringBuilder String, StringBuffer, StringBuilder diff? String: immutable StringBuffer: mutable, thread-safe, low efficiency StringBuilder: mutable, not thread-safe, high efficiency Efficiency: StringBuilder \u003e StringBuffer » String @Test public void testStringBuffer(){ String str = null; StringBuffer sb = new StringBuffer(); sb.append(str); System.out.println(sb.length()); // 4 System.out.println(sb); // \"null\" StringBuffer sb1 = new StringBuffer(str); // NullPointerException System.out.println(sb1); } Date import org.testng.annotations.Test; import java.util.Date; import static java.lang.Thread.sleep; public class DateTest { @Test public void test01(){ long time = System.currentTimeMillis(); // return the time diff from 1970.1.1 00:00:00 in millisecond System.out.println(time); } // java.util.Date // |---java.sql.Date // this is used in sql @Test public void Test02() throws InterruptedException { // Constructor 1 Date date1 = new Date(); System.out.println(date1.toString()); System.out.println(date1.getTime()); // Constructor 2 Date date2 = new Date(294475929283L); System.out.println(date2.toString()); // sql.Date java.sql.Date date3 = new java.sql.Date(4365435414324L); System.out.println(date3); // util.Date --\u003e sql.Date // except forced cast it Date date4 = new Date(); java.sql.Date date5 = new java.sql.Date(date4.getTime()); System.out.println(date5); } } java.text.SimpleDateFormat import org.testng.annotations.Test; import java.text.ParseException; import java.text.SimpleDateFormat; import java.util.Date; // 1. date --\u003e string // 2. string --\u003e date public class SimpleDateFormatTest { @Test public void testSimpleDateFormat() throws ParseException { SimpleDateFormat sdf = new SimpleDateFormat(); Date date = new Date(); // date --\u003e String String dateFormatted = sdf.format(date); System.out.println(dateFormatted); // String --\u003e date String sb = \"1/1/22, 8:00 PM\"; Date dateParsed = sdf.parse(sb); System.out.println(dateParsed); SimpleDateFormat sdf1 = new SimpleDateFormat(\"yyyy-MM-dd HH:mm:ss\"); // if you want a specific pattern String dateFormatted1 = sdf1.format(date); System.out.println(dateFormatted1); // date --\u003e String Date date1 = sdf1.parse(\"2022-01-02 18:12:58\"); System.out.println(date1); } } Calendar import org.testng.annotations.Test; import java.util.Calendar; import java.util.Date; import java.util.Scanner; public class CalendarTest { // Calendar is an abstract class @Test public void testCalendar(){ // Instantiation // 1. create instance of its subclass GregorianCalendar // 2. call the static method getInstance() Calendar calendar = Calendar.getInstance(); System.out.println(calendar.getClass()); //GregorianCalendar // Usage: get() set() add() getTime() setTime() int dayOfMonth = calendar.get(Calendar.DAY_OF_MONTH); System.out.println(dayOfMonth); System.out.println(calendar.get(Calendar.DAY_OF_YEAR)); calendar.set(Calendar.DAY_OF_YEAR, 365); System.out.println(calendar.get(Calendar.DAY_OF_YEAR)); calendar.add(Calendar.DAY_OF_YEAR, -100); System.out.println(calendar.ge","date":"2022-01-09","objectID":"/javase/:2:2","series":[],"tags":["Java"],"title":"JavaSE","uri":"/javase/#frequently-used-classes"},{"categories":["Note"],"content":"Frequently Used Classes String class import org.testng.annotations.Test; public class StringTest { @Test public void test() { String s1 = \"Java\"; String s2 = \"Test\"; String s3 = \"JavaTest\"; String s4 = \"Java\" + \"Test\"; String s5 = s1 + \"Test\"; // s1 point to a pointer in the heap, and the pointer points to \"Java\" in the constant pool String s6 = s1 + s2; String s7 = s5.intern(); // find the literal in constant pool and return it final String s8 = s1 + s2; System.out.println(s3 == s4); //T System.out.println(s3 == s5); //F System.out.println(s3 == s6); //F System.out.println(s5 == s6); //F System.out.println(s3 == s7); //T System.out.println(s3 == s8); // F Look at this! System.out.println(s3.getClass()); // same System.out.println(s8.getClass()); System.out.println(s3.hashCode()); // same System.out.println(s8.hashCode()); System.out.println(System.identityHashCode(s3)); // diff System.out.println(System.identityHashCode(s8)); } } StringBuffer and StringBuilder String, StringBuffer, StringBuilder diff? String: immutable StringBuffer: mutable, thread-safe, low efficiency StringBuilder: mutable, not thread-safe, high efficiency Efficiency: StringBuilder StringBuffer » String @Test public void testStringBuffer(){ String str = null; StringBuffer sb = new StringBuffer(); sb.append(str); System.out.println(sb.length()); // 4 System.out.println(sb); // \"null\" StringBuffer sb1 = new StringBuffer(str); // NullPointerException System.out.println(sb1); } Date import org.testng.annotations.Test; import java.util.Date; import static java.lang.Thread.sleep; public class DateTest { @Test public void test01(){ long time = System.currentTimeMillis(); // return the time diff from 1970.1.1 00:00:00 in millisecond System.out.println(time); } // java.util.Date // |---java.sql.Date // this is used in sql @Test public void Test02() throws InterruptedException { // Constructor 1 Date date1 = new Date(); System.out.println(date1.toString()); System.out.println(date1.getTime()); // Constructor 2 Date date2 = new Date(294475929283L); System.out.println(date2.toString()); // sql.Date java.sql.Date date3 = new java.sql.Date(4365435414324L); System.out.println(date3); // util.Date -- sql.Date // except forced cast it Date date4 = new Date(); java.sql.Date date5 = new java.sql.Date(date4.getTime()); System.out.println(date5); } } java.text.SimpleDateFormat import org.testng.annotations.Test; import java.text.ParseException; import java.text.SimpleDateFormat; import java.util.Date; // 1. date -- string // 2. string -- date public class SimpleDateFormatTest { @Test public void testSimpleDateFormat() throws ParseException { SimpleDateFormat sdf = new SimpleDateFormat(); Date date = new Date(); // date -- String String dateFormatted = sdf.format(date); System.out.println(dateFormatted); // String -- date String sb = \"1/1/22, 8:00 PM\"; Date dateParsed = sdf.parse(sb); System.out.println(dateParsed); SimpleDateFormat sdf1 = new SimpleDateFormat(\"yyyy-MM-dd HH:mm:ss\"); // if you want a specific pattern String dateFormatted1 = sdf1.format(date); System.out.println(dateFormatted1); // date -- String Date date1 = sdf1.parse(\"2022-01-02 18:12:58\"); System.out.println(date1); } } Calendar import org.testng.annotations.Test; import java.util.Calendar; import java.util.Date; import java.util.Scanner; public class CalendarTest { // Calendar is an abstract class @Test public void testCalendar(){ // Instantiation // 1. create instance of its subclass GregorianCalendar // 2. call the static method getInstance() Calendar calendar = Calendar.getInstance(); System.out.println(calendar.getClass()); //GregorianCalendar // Usage: get() set() add() getTime() setTime() int dayOfMonth = calendar.get(Calendar.DAY_OF_MONTH); System.out.println(dayOfMonth); System.out.println(calendar.get(Calendar.DAY_OF_YEAR)); calendar.set(Calendar.DAY_OF_YEAR, 365); System.out.println(calendar.get(Calendar.DAY_OF_YEAR)); calendar.add(Calendar.DAY_OF_YEAR, -100); System.out.println(calendar.ge","date":"2022-01-09","objectID":"/javase/:2:2","series":[],"tags":["Java"],"title":"JavaSE","uri":"/javase/#string-class"},{"categories":["Note"],"content":"Frequently Used Classes String class import org.testng.annotations.Test; public class StringTest { @Test public void test() { String s1 = \"Java\"; String s2 = \"Test\"; String s3 = \"JavaTest\"; String s4 = \"Java\" + \"Test\"; String s5 = s1 + \"Test\"; // s1 point to a pointer in the heap, and the pointer points to \"Java\" in the constant pool String s6 = s1 + s2; String s7 = s5.intern(); // find the literal in constant pool and return it final String s8 = s1 + s2; System.out.println(s3 == s4); //T System.out.println(s3 == s5); //F System.out.println(s3 == s6); //F System.out.println(s5 == s6); //F System.out.println(s3 == s7); //T System.out.println(s3 == s8); // F Look at this! System.out.println(s3.getClass()); // same System.out.println(s8.getClass()); System.out.println(s3.hashCode()); // same System.out.println(s8.hashCode()); System.out.println(System.identityHashCode(s3)); // diff System.out.println(System.identityHashCode(s8)); } } StringBuffer and StringBuilder String, StringBuffer, StringBuilder diff? String: immutable StringBuffer: mutable, thread-safe, low efficiency StringBuilder: mutable, not thread-safe, high efficiency Efficiency: StringBuilder StringBuffer » String @Test public void testStringBuffer(){ String str = null; StringBuffer sb = new StringBuffer(); sb.append(str); System.out.println(sb.length()); // 4 System.out.println(sb); // \"null\" StringBuffer sb1 = new StringBuffer(str); // NullPointerException System.out.println(sb1); } Date import org.testng.annotations.Test; import java.util.Date; import static java.lang.Thread.sleep; public class DateTest { @Test public void test01(){ long time = System.currentTimeMillis(); // return the time diff from 1970.1.1 00:00:00 in millisecond System.out.println(time); } // java.util.Date // |---java.sql.Date // this is used in sql @Test public void Test02() throws InterruptedException { // Constructor 1 Date date1 = new Date(); System.out.println(date1.toString()); System.out.println(date1.getTime()); // Constructor 2 Date date2 = new Date(294475929283L); System.out.println(date2.toString()); // sql.Date java.sql.Date date3 = new java.sql.Date(4365435414324L); System.out.println(date3); // util.Date -- sql.Date // except forced cast it Date date4 = new Date(); java.sql.Date date5 = new java.sql.Date(date4.getTime()); System.out.println(date5); } } java.text.SimpleDateFormat import org.testng.annotations.Test; import java.text.ParseException; import java.text.SimpleDateFormat; import java.util.Date; // 1. date -- string // 2. string -- date public class SimpleDateFormatTest { @Test public void testSimpleDateFormat() throws ParseException { SimpleDateFormat sdf = new SimpleDateFormat(); Date date = new Date(); // date -- String String dateFormatted = sdf.format(date); System.out.println(dateFormatted); // String -- date String sb = \"1/1/22, 8:00 PM\"; Date dateParsed = sdf.parse(sb); System.out.println(dateParsed); SimpleDateFormat sdf1 = new SimpleDateFormat(\"yyyy-MM-dd HH:mm:ss\"); // if you want a specific pattern String dateFormatted1 = sdf1.format(date); System.out.println(dateFormatted1); // date -- String Date date1 = sdf1.parse(\"2022-01-02 18:12:58\"); System.out.println(date1); } } Calendar import org.testng.annotations.Test; import java.util.Calendar; import java.util.Date; import java.util.Scanner; public class CalendarTest { // Calendar is an abstract class @Test public void testCalendar(){ // Instantiation // 1. create instance of its subclass GregorianCalendar // 2. call the static method getInstance() Calendar calendar = Calendar.getInstance(); System.out.println(calendar.getClass()); //GregorianCalendar // Usage: get() set() add() getTime() setTime() int dayOfMonth = calendar.get(Calendar.DAY_OF_MONTH); System.out.println(dayOfMonth); System.out.println(calendar.get(Calendar.DAY_OF_YEAR)); calendar.set(Calendar.DAY_OF_YEAR, 365); System.out.println(calendar.get(Calendar.DAY_OF_YEAR)); calendar.add(Calendar.DAY_OF_YEAR, -100); System.out.println(calendar.ge","date":"2022-01-09","objectID":"/javase/:2:2","series":[],"tags":["Java"],"title":"JavaSE","uri":"/javase/#stringbuffer-and-stringbuilder"},{"categories":["Note"],"content":"Frequently Used Classes String class import org.testng.annotations.Test; public class StringTest { @Test public void test() { String s1 = \"Java\"; String s2 = \"Test\"; String s3 = \"JavaTest\"; String s4 = \"Java\" + \"Test\"; String s5 = s1 + \"Test\"; // s1 point to a pointer in the heap, and the pointer points to \"Java\" in the constant pool String s6 = s1 + s2; String s7 = s5.intern(); // find the literal in constant pool and return it final String s8 = s1 + s2; System.out.println(s3 == s4); //T System.out.println(s3 == s5); //F System.out.println(s3 == s6); //F System.out.println(s5 == s6); //F System.out.println(s3 == s7); //T System.out.println(s3 == s8); // F Look at this! System.out.println(s3.getClass()); // same System.out.println(s8.getClass()); System.out.println(s3.hashCode()); // same System.out.println(s8.hashCode()); System.out.println(System.identityHashCode(s3)); // diff System.out.println(System.identityHashCode(s8)); } } StringBuffer and StringBuilder String, StringBuffer, StringBuilder diff? String: immutable StringBuffer: mutable, thread-safe, low efficiency StringBuilder: mutable, not thread-safe, high efficiency Efficiency: StringBuilder StringBuffer » String @Test public void testStringBuffer(){ String str = null; StringBuffer sb = new StringBuffer(); sb.append(str); System.out.println(sb.length()); // 4 System.out.println(sb); // \"null\" StringBuffer sb1 = new StringBuffer(str); // NullPointerException System.out.println(sb1); } Date import org.testng.annotations.Test; import java.util.Date; import static java.lang.Thread.sleep; public class DateTest { @Test public void test01(){ long time = System.currentTimeMillis(); // return the time diff from 1970.1.1 00:00:00 in millisecond System.out.println(time); } // java.util.Date // |---java.sql.Date // this is used in sql @Test public void Test02() throws InterruptedException { // Constructor 1 Date date1 = new Date(); System.out.println(date1.toString()); System.out.println(date1.getTime()); // Constructor 2 Date date2 = new Date(294475929283L); System.out.println(date2.toString()); // sql.Date java.sql.Date date3 = new java.sql.Date(4365435414324L); System.out.println(date3); // util.Date -- sql.Date // except forced cast it Date date4 = new Date(); java.sql.Date date5 = new java.sql.Date(date4.getTime()); System.out.println(date5); } } java.text.SimpleDateFormat import org.testng.annotations.Test; import java.text.ParseException; import java.text.SimpleDateFormat; import java.util.Date; // 1. date -- string // 2. string -- date public class SimpleDateFormatTest { @Test public void testSimpleDateFormat() throws ParseException { SimpleDateFormat sdf = new SimpleDateFormat(); Date date = new Date(); // date -- String String dateFormatted = sdf.format(date); System.out.println(dateFormatted); // String -- date String sb = \"1/1/22, 8:00 PM\"; Date dateParsed = sdf.parse(sb); System.out.println(dateParsed); SimpleDateFormat sdf1 = new SimpleDateFormat(\"yyyy-MM-dd HH:mm:ss\"); // if you want a specific pattern String dateFormatted1 = sdf1.format(date); System.out.println(dateFormatted1); // date -- String Date date1 = sdf1.parse(\"2022-01-02 18:12:58\"); System.out.println(date1); } } Calendar import org.testng.annotations.Test; import java.util.Calendar; import java.util.Date; import java.util.Scanner; public class CalendarTest { // Calendar is an abstract class @Test public void testCalendar(){ // Instantiation // 1. create instance of its subclass GregorianCalendar // 2. call the static method getInstance() Calendar calendar = Calendar.getInstance(); System.out.println(calendar.getClass()); //GregorianCalendar // Usage: get() set() add() getTime() setTime() int dayOfMonth = calendar.get(Calendar.DAY_OF_MONTH); System.out.println(dayOfMonth); System.out.println(calendar.get(Calendar.DAY_OF_YEAR)); calendar.set(Calendar.DAY_OF_YEAR, 365); System.out.println(calendar.get(Calendar.DAY_OF_YEAR)); calendar.add(Calendar.DAY_OF_YEAR, -100); System.out.println(calendar.ge","date":"2022-01-09","objectID":"/javase/:2:2","series":[],"tags":["Java"],"title":"JavaSE","uri":"/javase/#date"},{"categories":["Note"],"content":"Frequently Used Classes String class import org.testng.annotations.Test; public class StringTest { @Test public void test() { String s1 = \"Java\"; String s2 = \"Test\"; String s3 = \"JavaTest\"; String s4 = \"Java\" + \"Test\"; String s5 = s1 + \"Test\"; // s1 point to a pointer in the heap, and the pointer points to \"Java\" in the constant pool String s6 = s1 + s2; String s7 = s5.intern(); // find the literal in constant pool and return it final String s8 = s1 + s2; System.out.println(s3 == s4); //T System.out.println(s3 == s5); //F System.out.println(s3 == s6); //F System.out.println(s5 == s6); //F System.out.println(s3 == s7); //T System.out.println(s3 == s8); // F Look at this! System.out.println(s3.getClass()); // same System.out.println(s8.getClass()); System.out.println(s3.hashCode()); // same System.out.println(s8.hashCode()); System.out.println(System.identityHashCode(s3)); // diff System.out.println(System.identityHashCode(s8)); } } StringBuffer and StringBuilder String, StringBuffer, StringBuilder diff? String: immutable StringBuffer: mutable, thread-safe, low efficiency StringBuilder: mutable, not thread-safe, high efficiency Efficiency: StringBuilder StringBuffer » String @Test public void testStringBuffer(){ String str = null; StringBuffer sb = new StringBuffer(); sb.append(str); System.out.println(sb.length()); // 4 System.out.println(sb); // \"null\" StringBuffer sb1 = new StringBuffer(str); // NullPointerException System.out.println(sb1); } Date import org.testng.annotations.Test; import java.util.Date; import static java.lang.Thread.sleep; public class DateTest { @Test public void test01(){ long time = System.currentTimeMillis(); // return the time diff from 1970.1.1 00:00:00 in millisecond System.out.println(time); } // java.util.Date // |---java.sql.Date // this is used in sql @Test public void Test02() throws InterruptedException { // Constructor 1 Date date1 = new Date(); System.out.println(date1.toString()); System.out.println(date1.getTime()); // Constructor 2 Date date2 = new Date(294475929283L); System.out.println(date2.toString()); // sql.Date java.sql.Date date3 = new java.sql.Date(4365435414324L); System.out.println(date3); // util.Date -- sql.Date // except forced cast it Date date4 = new Date(); java.sql.Date date5 = new java.sql.Date(date4.getTime()); System.out.println(date5); } } java.text.SimpleDateFormat import org.testng.annotations.Test; import java.text.ParseException; import java.text.SimpleDateFormat; import java.util.Date; // 1. date -- string // 2. string -- date public class SimpleDateFormatTest { @Test public void testSimpleDateFormat() throws ParseException { SimpleDateFormat sdf = new SimpleDateFormat(); Date date = new Date(); // date -- String String dateFormatted = sdf.format(date); System.out.println(dateFormatted); // String -- date String sb = \"1/1/22, 8:00 PM\"; Date dateParsed = sdf.parse(sb); System.out.println(dateParsed); SimpleDateFormat sdf1 = new SimpleDateFormat(\"yyyy-MM-dd HH:mm:ss\"); // if you want a specific pattern String dateFormatted1 = sdf1.format(date); System.out.println(dateFormatted1); // date -- String Date date1 = sdf1.parse(\"2022-01-02 18:12:58\"); System.out.println(date1); } } Calendar import org.testng.annotations.Test; import java.util.Calendar; import java.util.Date; import java.util.Scanner; public class CalendarTest { // Calendar is an abstract class @Test public void testCalendar(){ // Instantiation // 1. create instance of its subclass GregorianCalendar // 2. call the static method getInstance() Calendar calendar = Calendar.getInstance(); System.out.println(calendar.getClass()); //GregorianCalendar // Usage: get() set() add() getTime() setTime() int dayOfMonth = calendar.get(Calendar.DAY_OF_MONTH); System.out.println(dayOfMonth); System.out.println(calendar.get(Calendar.DAY_OF_YEAR)); calendar.set(Calendar.DAY_OF_YEAR, 365); System.out.println(calendar.get(Calendar.DAY_OF_YEAR)); calendar.add(Calendar.DAY_OF_YEAR, -100); System.out.println(calendar.ge","date":"2022-01-09","objectID":"/javase/:2:2","series":[],"tags":["Java"],"title":"JavaSE","uri":"/javase/#javatextsimpledateformat"},{"categories":["Note"],"content":"Frequently Used Classes String class import org.testng.annotations.Test; public class StringTest { @Test public void test() { String s1 = \"Java\"; String s2 = \"Test\"; String s3 = \"JavaTest\"; String s4 = \"Java\" + \"Test\"; String s5 = s1 + \"Test\"; // s1 point to a pointer in the heap, and the pointer points to \"Java\" in the constant pool String s6 = s1 + s2; String s7 = s5.intern(); // find the literal in constant pool and return it final String s8 = s1 + s2; System.out.println(s3 == s4); //T System.out.println(s3 == s5); //F System.out.println(s3 == s6); //F System.out.println(s5 == s6); //F System.out.println(s3 == s7); //T System.out.println(s3 == s8); // F Look at this! System.out.println(s3.getClass()); // same System.out.println(s8.getClass()); System.out.println(s3.hashCode()); // same System.out.println(s8.hashCode()); System.out.println(System.identityHashCode(s3)); // diff System.out.println(System.identityHashCode(s8)); } } StringBuffer and StringBuilder String, StringBuffer, StringBuilder diff? String: immutable StringBuffer: mutable, thread-safe, low efficiency StringBuilder: mutable, not thread-safe, high efficiency Efficiency: StringBuilder StringBuffer » String @Test public void testStringBuffer(){ String str = null; StringBuffer sb = new StringBuffer(); sb.append(str); System.out.println(sb.length()); // 4 System.out.println(sb); // \"null\" StringBuffer sb1 = new StringBuffer(str); // NullPointerException System.out.println(sb1); } Date import org.testng.annotations.Test; import java.util.Date; import static java.lang.Thread.sleep; public class DateTest { @Test public void test01(){ long time = System.currentTimeMillis(); // return the time diff from 1970.1.1 00:00:00 in millisecond System.out.println(time); } // java.util.Date // |---java.sql.Date // this is used in sql @Test public void Test02() throws InterruptedException { // Constructor 1 Date date1 = new Date(); System.out.println(date1.toString()); System.out.println(date1.getTime()); // Constructor 2 Date date2 = new Date(294475929283L); System.out.println(date2.toString()); // sql.Date java.sql.Date date3 = new java.sql.Date(4365435414324L); System.out.println(date3); // util.Date -- sql.Date // except forced cast it Date date4 = new Date(); java.sql.Date date5 = new java.sql.Date(date4.getTime()); System.out.println(date5); } } java.text.SimpleDateFormat import org.testng.annotations.Test; import java.text.ParseException; import java.text.SimpleDateFormat; import java.util.Date; // 1. date -- string // 2. string -- date public class SimpleDateFormatTest { @Test public void testSimpleDateFormat() throws ParseException { SimpleDateFormat sdf = new SimpleDateFormat(); Date date = new Date(); // date -- String String dateFormatted = sdf.format(date); System.out.println(dateFormatted); // String -- date String sb = \"1/1/22, 8:00 PM\"; Date dateParsed = sdf.parse(sb); System.out.println(dateParsed); SimpleDateFormat sdf1 = new SimpleDateFormat(\"yyyy-MM-dd HH:mm:ss\"); // if you want a specific pattern String dateFormatted1 = sdf1.format(date); System.out.println(dateFormatted1); // date -- String Date date1 = sdf1.parse(\"2022-01-02 18:12:58\"); System.out.println(date1); } } Calendar import org.testng.annotations.Test; import java.util.Calendar; import java.util.Date; import java.util.Scanner; public class CalendarTest { // Calendar is an abstract class @Test public void testCalendar(){ // Instantiation // 1. create instance of its subclass GregorianCalendar // 2. call the static method getInstance() Calendar calendar = Calendar.getInstance(); System.out.println(calendar.getClass()); //GregorianCalendar // Usage: get() set() add() getTime() setTime() int dayOfMonth = calendar.get(Calendar.DAY_OF_MONTH); System.out.println(dayOfMonth); System.out.println(calendar.get(Calendar.DAY_OF_YEAR)); calendar.set(Calendar.DAY_OF_YEAR, 365); System.out.println(calendar.get(Calendar.DAY_OF_YEAR)); calendar.add(Calendar.DAY_OF_YEAR, -100); System.out.println(calendar.ge","date":"2022-01-09","objectID":"/javase/:2:2","series":[],"tags":["Java"],"title":"JavaSE","uri":"/javase/#calendar"},{"categories":["Note"],"content":"Frequently Used Classes String class import org.testng.annotations.Test; public class StringTest { @Test public void test() { String s1 = \"Java\"; String s2 = \"Test\"; String s3 = \"JavaTest\"; String s4 = \"Java\" + \"Test\"; String s5 = s1 + \"Test\"; // s1 point to a pointer in the heap, and the pointer points to \"Java\" in the constant pool String s6 = s1 + s2; String s7 = s5.intern(); // find the literal in constant pool and return it final String s8 = s1 + s2; System.out.println(s3 == s4); //T System.out.println(s3 == s5); //F System.out.println(s3 == s6); //F System.out.println(s5 == s6); //F System.out.println(s3 == s7); //T System.out.println(s3 == s8); // F Look at this! System.out.println(s3.getClass()); // same System.out.println(s8.getClass()); System.out.println(s3.hashCode()); // same System.out.println(s8.hashCode()); System.out.println(System.identityHashCode(s3)); // diff System.out.println(System.identityHashCode(s8)); } } StringBuffer and StringBuilder String, StringBuffer, StringBuilder diff? String: immutable StringBuffer: mutable, thread-safe, low efficiency StringBuilder: mutable, not thread-safe, high efficiency Efficiency: StringBuilder StringBuffer » String @Test public void testStringBuffer(){ String str = null; StringBuffer sb = new StringBuffer(); sb.append(str); System.out.println(sb.length()); // 4 System.out.println(sb); // \"null\" StringBuffer sb1 = new StringBuffer(str); // NullPointerException System.out.println(sb1); } Date import org.testng.annotations.Test; import java.util.Date; import static java.lang.Thread.sleep; public class DateTest { @Test public void test01(){ long time = System.currentTimeMillis(); // return the time diff from 1970.1.1 00:00:00 in millisecond System.out.println(time); } // java.util.Date // |---java.sql.Date // this is used in sql @Test public void Test02() throws InterruptedException { // Constructor 1 Date date1 = new Date(); System.out.println(date1.toString()); System.out.println(date1.getTime()); // Constructor 2 Date date2 = new Date(294475929283L); System.out.println(date2.toString()); // sql.Date java.sql.Date date3 = new java.sql.Date(4365435414324L); System.out.println(date3); // util.Date -- sql.Date // except forced cast it Date date4 = new Date(); java.sql.Date date5 = new java.sql.Date(date4.getTime()); System.out.println(date5); } } java.text.SimpleDateFormat import org.testng.annotations.Test; import java.text.ParseException; import java.text.SimpleDateFormat; import java.util.Date; // 1. date -- string // 2. string -- date public class SimpleDateFormatTest { @Test public void testSimpleDateFormat() throws ParseException { SimpleDateFormat sdf = new SimpleDateFormat(); Date date = new Date(); // date -- String String dateFormatted = sdf.format(date); System.out.println(dateFormatted); // String -- date String sb = \"1/1/22, 8:00 PM\"; Date dateParsed = sdf.parse(sb); System.out.println(dateParsed); SimpleDateFormat sdf1 = new SimpleDateFormat(\"yyyy-MM-dd HH:mm:ss\"); // if you want a specific pattern String dateFormatted1 = sdf1.format(date); System.out.println(dateFormatted1); // date -- String Date date1 = sdf1.parse(\"2022-01-02 18:12:58\"); System.out.println(date1); } } Calendar import org.testng.annotations.Test; import java.util.Calendar; import java.util.Date; import java.util.Scanner; public class CalendarTest { // Calendar is an abstract class @Test public void testCalendar(){ // Instantiation // 1. create instance of its subclass GregorianCalendar // 2. call the static method getInstance() Calendar calendar = Calendar.getInstance(); System.out.println(calendar.getClass()); //GregorianCalendar // Usage: get() set() add() getTime() setTime() int dayOfMonth = calendar.get(Calendar.DAY_OF_MONTH); System.out.println(dayOfMonth); System.out.println(calendar.get(Calendar.DAY_OF_YEAR)); calendar.set(Calendar.DAY_OF_YEAR, 365); System.out.println(calendar.get(Calendar.DAY_OF_YEAR)); calendar.add(Calendar.DAY_OF_YEAR, -100); System.out.println(calendar.ge","date":"2022-01-09","objectID":"/javase/:2:2","series":[],"tags":["Java"],"title":"JavaSE","uri":"/javase/#jdk8-new-apis-about-date-and-time"},{"categories":["Note"],"content":"Frequently Used Classes String class import org.testng.annotations.Test; public class StringTest { @Test public void test() { String s1 = \"Java\"; String s2 = \"Test\"; String s3 = \"JavaTest\"; String s4 = \"Java\" + \"Test\"; String s5 = s1 + \"Test\"; // s1 point to a pointer in the heap, and the pointer points to \"Java\" in the constant pool String s6 = s1 + s2; String s7 = s5.intern(); // find the literal in constant pool and return it final String s8 = s1 + s2; System.out.println(s3 == s4); //T System.out.println(s3 == s5); //F System.out.println(s3 == s6); //F System.out.println(s5 == s6); //F System.out.println(s3 == s7); //T System.out.println(s3 == s8); // F Look at this! System.out.println(s3.getClass()); // same System.out.println(s8.getClass()); System.out.println(s3.hashCode()); // same System.out.println(s8.hashCode()); System.out.println(System.identityHashCode(s3)); // diff System.out.println(System.identityHashCode(s8)); } } StringBuffer and StringBuilder String, StringBuffer, StringBuilder diff? String: immutable StringBuffer: mutable, thread-safe, low efficiency StringBuilder: mutable, not thread-safe, high efficiency Efficiency: StringBuilder StringBuffer » String @Test public void testStringBuffer(){ String str = null; StringBuffer sb = new StringBuffer(); sb.append(str); System.out.println(sb.length()); // 4 System.out.println(sb); // \"null\" StringBuffer sb1 = new StringBuffer(str); // NullPointerException System.out.println(sb1); } Date import org.testng.annotations.Test; import java.util.Date; import static java.lang.Thread.sleep; public class DateTest { @Test public void test01(){ long time = System.currentTimeMillis(); // return the time diff from 1970.1.1 00:00:00 in millisecond System.out.println(time); } // java.util.Date // |---java.sql.Date // this is used in sql @Test public void Test02() throws InterruptedException { // Constructor 1 Date date1 = new Date(); System.out.println(date1.toString()); System.out.println(date1.getTime()); // Constructor 2 Date date2 = new Date(294475929283L); System.out.println(date2.toString()); // sql.Date java.sql.Date date3 = new java.sql.Date(4365435414324L); System.out.println(date3); // util.Date -- sql.Date // except forced cast it Date date4 = new Date(); java.sql.Date date5 = new java.sql.Date(date4.getTime()); System.out.println(date5); } } java.text.SimpleDateFormat import org.testng.annotations.Test; import java.text.ParseException; import java.text.SimpleDateFormat; import java.util.Date; // 1. date -- string // 2. string -- date public class SimpleDateFormatTest { @Test public void testSimpleDateFormat() throws ParseException { SimpleDateFormat sdf = new SimpleDateFormat(); Date date = new Date(); // date -- String String dateFormatted = sdf.format(date); System.out.println(dateFormatted); // String -- date String sb = \"1/1/22, 8:00 PM\"; Date dateParsed = sdf.parse(sb); System.out.println(dateParsed); SimpleDateFormat sdf1 = new SimpleDateFormat(\"yyyy-MM-dd HH:mm:ss\"); // if you want a specific pattern String dateFormatted1 = sdf1.format(date); System.out.println(dateFormatted1); // date -- String Date date1 = sdf1.parse(\"2022-01-02 18:12:58\"); System.out.println(date1); } } Calendar import org.testng.annotations.Test; import java.util.Calendar; import java.util.Date; import java.util.Scanner; public class CalendarTest { // Calendar is an abstract class @Test public void testCalendar(){ // Instantiation // 1. create instance of its subclass GregorianCalendar // 2. call the static method getInstance() Calendar calendar = Calendar.getInstance(); System.out.println(calendar.getClass()); //GregorianCalendar // Usage: get() set() add() getTime() setTime() int dayOfMonth = calendar.get(Calendar.DAY_OF_MONTH); System.out.println(dayOfMonth); System.out.println(calendar.get(Calendar.DAY_OF_YEAR)); calendar.set(Calendar.DAY_OF_YEAR, 365); System.out.println(calendar.get(Calendar.DAY_OF_YEAR)); calendar.add(Calendar.DAY_OF_YEAR, -100); System.out.println(calendar.ge","date":"2022-01-09","objectID":"/javase/:2:2","series":[],"tags":["Java"],"title":"JavaSE","uri":"/javase/#instant"},{"categories":["Note"],"content":"Frequently Used Classes String class import org.testng.annotations.Test; public class StringTest { @Test public void test() { String s1 = \"Java\"; String s2 = \"Test\"; String s3 = \"JavaTest\"; String s4 = \"Java\" + \"Test\"; String s5 = s1 + \"Test\"; // s1 point to a pointer in the heap, and the pointer points to \"Java\" in the constant pool String s6 = s1 + s2; String s7 = s5.intern(); // find the literal in constant pool and return it final String s8 = s1 + s2; System.out.println(s3 == s4); //T System.out.println(s3 == s5); //F System.out.println(s3 == s6); //F System.out.println(s5 == s6); //F System.out.println(s3 == s7); //T System.out.println(s3 == s8); // F Look at this! System.out.println(s3.getClass()); // same System.out.println(s8.getClass()); System.out.println(s3.hashCode()); // same System.out.println(s8.hashCode()); System.out.println(System.identityHashCode(s3)); // diff System.out.println(System.identityHashCode(s8)); } } StringBuffer and StringBuilder String, StringBuffer, StringBuilder diff? String: immutable StringBuffer: mutable, thread-safe, low efficiency StringBuilder: mutable, not thread-safe, high efficiency Efficiency: StringBuilder StringBuffer » String @Test public void testStringBuffer(){ String str = null; StringBuffer sb = new StringBuffer(); sb.append(str); System.out.println(sb.length()); // 4 System.out.println(sb); // \"null\" StringBuffer sb1 = new StringBuffer(str); // NullPointerException System.out.println(sb1); } Date import org.testng.annotations.Test; import java.util.Date; import static java.lang.Thread.sleep; public class DateTest { @Test public void test01(){ long time = System.currentTimeMillis(); // return the time diff from 1970.1.1 00:00:00 in millisecond System.out.println(time); } // java.util.Date // |---java.sql.Date // this is used in sql @Test public void Test02() throws InterruptedException { // Constructor 1 Date date1 = new Date(); System.out.println(date1.toString()); System.out.println(date1.getTime()); // Constructor 2 Date date2 = new Date(294475929283L); System.out.println(date2.toString()); // sql.Date java.sql.Date date3 = new java.sql.Date(4365435414324L); System.out.println(date3); // util.Date -- sql.Date // except forced cast it Date date4 = new Date(); java.sql.Date date5 = new java.sql.Date(date4.getTime()); System.out.println(date5); } } java.text.SimpleDateFormat import org.testng.annotations.Test; import java.text.ParseException; import java.text.SimpleDateFormat; import java.util.Date; // 1. date -- string // 2. string -- date public class SimpleDateFormatTest { @Test public void testSimpleDateFormat() throws ParseException { SimpleDateFormat sdf = new SimpleDateFormat(); Date date = new Date(); // date -- String String dateFormatted = sdf.format(date); System.out.println(dateFormatted); // String -- date String sb = \"1/1/22, 8:00 PM\"; Date dateParsed = sdf.parse(sb); System.out.println(dateParsed); SimpleDateFormat sdf1 = new SimpleDateFormat(\"yyyy-MM-dd HH:mm:ss\"); // if you want a specific pattern String dateFormatted1 = sdf1.format(date); System.out.println(dateFormatted1); // date -- String Date date1 = sdf1.parse(\"2022-01-02 18:12:58\"); System.out.println(date1); } } Calendar import org.testng.annotations.Test; import java.util.Calendar; import java.util.Date; import java.util.Scanner; public class CalendarTest { // Calendar is an abstract class @Test public void testCalendar(){ // Instantiation // 1. create instance of its subclass GregorianCalendar // 2. call the static method getInstance() Calendar calendar = Calendar.getInstance(); System.out.println(calendar.getClass()); //GregorianCalendar // Usage: get() set() add() getTime() setTime() int dayOfMonth = calendar.get(Calendar.DAY_OF_MONTH); System.out.println(dayOfMonth); System.out.println(calendar.get(Calendar.DAY_OF_YEAR)); calendar.set(Calendar.DAY_OF_YEAR, 365); System.out.println(calendar.get(Calendar.DAY_OF_YEAR)); calendar.add(Calendar.DAY_OF_YEAR, -100); System.out.println(calendar.ge","date":"2022-01-09","objectID":"/javase/:2:2","series":[],"tags":["Java"],"title":"JavaSE","uri":"/javase/#datetimeformatter"},{"categories":["Note"],"content":"Frequently Used Classes String class import org.testng.annotations.Test; public class StringTest { @Test public void test() { String s1 = \"Java\"; String s2 = \"Test\"; String s3 = \"JavaTest\"; String s4 = \"Java\" + \"Test\"; String s5 = s1 + \"Test\"; // s1 point to a pointer in the heap, and the pointer points to \"Java\" in the constant pool String s6 = s1 + s2; String s7 = s5.intern(); // find the literal in constant pool and return it final String s8 = s1 + s2; System.out.println(s3 == s4); //T System.out.println(s3 == s5); //F System.out.println(s3 == s6); //F System.out.println(s5 == s6); //F System.out.println(s3 == s7); //T System.out.println(s3 == s8); // F Look at this! System.out.println(s3.getClass()); // same System.out.println(s8.getClass()); System.out.println(s3.hashCode()); // same System.out.println(s8.hashCode()); System.out.println(System.identityHashCode(s3)); // diff System.out.println(System.identityHashCode(s8)); } } StringBuffer and StringBuilder String, StringBuffer, StringBuilder diff? String: immutable StringBuffer: mutable, thread-safe, low efficiency StringBuilder: mutable, not thread-safe, high efficiency Efficiency: StringBuilder StringBuffer » String @Test public void testStringBuffer(){ String str = null; StringBuffer sb = new StringBuffer(); sb.append(str); System.out.println(sb.length()); // 4 System.out.println(sb); // \"null\" StringBuffer sb1 = new StringBuffer(str); // NullPointerException System.out.println(sb1); } Date import org.testng.annotations.Test; import java.util.Date; import static java.lang.Thread.sleep; public class DateTest { @Test public void test01(){ long time = System.currentTimeMillis(); // return the time diff from 1970.1.1 00:00:00 in millisecond System.out.println(time); } // java.util.Date // |---java.sql.Date // this is used in sql @Test public void Test02() throws InterruptedException { // Constructor 1 Date date1 = new Date(); System.out.println(date1.toString()); System.out.println(date1.getTime()); // Constructor 2 Date date2 = new Date(294475929283L); System.out.println(date2.toString()); // sql.Date java.sql.Date date3 = new java.sql.Date(4365435414324L); System.out.println(date3); // util.Date -- sql.Date // except forced cast it Date date4 = new Date(); java.sql.Date date5 = new java.sql.Date(date4.getTime()); System.out.println(date5); } } java.text.SimpleDateFormat import org.testng.annotations.Test; import java.text.ParseException; import java.text.SimpleDateFormat; import java.util.Date; // 1. date -- string // 2. string -- date public class SimpleDateFormatTest { @Test public void testSimpleDateFormat() throws ParseException { SimpleDateFormat sdf = new SimpleDateFormat(); Date date = new Date(); // date -- String String dateFormatted = sdf.format(date); System.out.println(dateFormatted); // String -- date String sb = \"1/1/22, 8:00 PM\"; Date dateParsed = sdf.parse(sb); System.out.println(dateParsed); SimpleDateFormat sdf1 = new SimpleDateFormat(\"yyyy-MM-dd HH:mm:ss\"); // if you want a specific pattern String dateFormatted1 = sdf1.format(date); System.out.println(dateFormatted1); // date -- String Date date1 = sdf1.parse(\"2022-01-02 18:12:58\"); System.out.println(date1); } } Calendar import org.testng.annotations.Test; import java.util.Calendar; import java.util.Date; import java.util.Scanner; public class CalendarTest { // Calendar is an abstract class @Test public void testCalendar(){ // Instantiation // 1. create instance of its subclass GregorianCalendar // 2. call the static method getInstance() Calendar calendar = Calendar.getInstance(); System.out.println(calendar.getClass()); //GregorianCalendar // Usage: get() set() add() getTime() setTime() int dayOfMonth = calendar.get(Calendar.DAY_OF_MONTH); System.out.println(dayOfMonth); System.out.println(calendar.get(Calendar.DAY_OF_YEAR)); calendar.set(Calendar.DAY_OF_YEAR, 365); System.out.println(calendar.get(Calendar.DAY_OF_YEAR)); calendar.add(Calendar.DAY_OF_YEAR, -100); System.out.println(calendar.ge","date":"2022-01-09","objectID":"/javase/:2:2","series":[],"tags":["Java"],"title":"JavaSE","uri":"/javase/#other-api-about-date-and-time"},{"categories":["Note"],"content":"Frequently Used Classes String class import org.testng.annotations.Test; public class StringTest { @Test public void test() { String s1 = \"Java\"; String s2 = \"Test\"; String s3 = \"JavaTest\"; String s4 = \"Java\" + \"Test\"; String s5 = s1 + \"Test\"; // s1 point to a pointer in the heap, and the pointer points to \"Java\" in the constant pool String s6 = s1 + s2; String s7 = s5.intern(); // find the literal in constant pool and return it final String s8 = s1 + s2; System.out.println(s3 == s4); //T System.out.println(s3 == s5); //F System.out.println(s3 == s6); //F System.out.println(s5 == s6); //F System.out.println(s3 == s7); //T System.out.println(s3 == s8); // F Look at this! System.out.println(s3.getClass()); // same System.out.println(s8.getClass()); System.out.println(s3.hashCode()); // same System.out.println(s8.hashCode()); System.out.println(System.identityHashCode(s3)); // diff System.out.println(System.identityHashCode(s8)); } } StringBuffer and StringBuilder String, StringBuffer, StringBuilder diff? String: immutable StringBuffer: mutable, thread-safe, low efficiency StringBuilder: mutable, not thread-safe, high efficiency Efficiency: StringBuilder StringBuffer » String @Test public void testStringBuffer(){ String str = null; StringBuffer sb = new StringBuffer(); sb.append(str); System.out.println(sb.length()); // 4 System.out.println(sb); // \"null\" StringBuffer sb1 = new StringBuffer(str); // NullPointerException System.out.println(sb1); } Date import org.testng.annotations.Test; import java.util.Date; import static java.lang.Thread.sleep; public class DateTest { @Test public void test01(){ long time = System.currentTimeMillis(); // return the time diff from 1970.1.1 00:00:00 in millisecond System.out.println(time); } // java.util.Date // |---java.sql.Date // this is used in sql @Test public void Test02() throws InterruptedException { // Constructor 1 Date date1 = new Date(); System.out.println(date1.toString()); System.out.println(date1.getTime()); // Constructor 2 Date date2 = new Date(294475929283L); System.out.println(date2.toString()); // sql.Date java.sql.Date date3 = new java.sql.Date(4365435414324L); System.out.println(date3); // util.Date -- sql.Date // except forced cast it Date date4 = new Date(); java.sql.Date date5 = new java.sql.Date(date4.getTime()); System.out.println(date5); } } java.text.SimpleDateFormat import org.testng.annotations.Test; import java.text.ParseException; import java.text.SimpleDateFormat; import java.util.Date; // 1. date -- string // 2. string -- date public class SimpleDateFormatTest { @Test public void testSimpleDateFormat() throws ParseException { SimpleDateFormat sdf = new SimpleDateFormat(); Date date = new Date(); // date -- String String dateFormatted = sdf.format(date); System.out.println(dateFormatted); // String -- date String sb = \"1/1/22, 8:00 PM\"; Date dateParsed = sdf.parse(sb); System.out.println(dateParsed); SimpleDateFormat sdf1 = new SimpleDateFormat(\"yyyy-MM-dd HH:mm:ss\"); // if you want a specific pattern String dateFormatted1 = sdf1.format(date); System.out.println(dateFormatted1); // date -- String Date date1 = sdf1.parse(\"2022-01-02 18:12:58\"); System.out.println(date1); } } Calendar import org.testng.annotations.Test; import java.util.Calendar; import java.util.Date; import java.util.Scanner; public class CalendarTest { // Calendar is an abstract class @Test public void testCalendar(){ // Instantiation // 1. create instance of its subclass GregorianCalendar // 2. call the static method getInstance() Calendar calendar = Calendar.getInstance(); System.out.println(calendar.getClass()); //GregorianCalendar // Usage: get() set() add() getTime() setTime() int dayOfMonth = calendar.get(Calendar.DAY_OF_MONTH); System.out.println(dayOfMonth); System.out.println(calendar.get(Calendar.DAY_OF_YEAR)); calendar.set(Calendar.DAY_OF_YEAR, 365); System.out.println(calendar.get(Calendar.DAY_OF_YEAR)); calendar.add(Calendar.DAY_OF_YEAR, -100); System.out.println(calendar.ge","date":"2022-01-09","objectID":"/javase/:2:2","series":[],"tags":["Java"],"title":"JavaSE","uri":"/javase/#comparator"},{"categories":["Note"],"content":"Frequently Used Classes String class import org.testng.annotations.Test; public class StringTest { @Test public void test() { String s1 = \"Java\"; String s2 = \"Test\"; String s3 = \"JavaTest\"; String s4 = \"Java\" + \"Test\"; String s5 = s1 + \"Test\"; // s1 point to a pointer in the heap, and the pointer points to \"Java\" in the constant pool String s6 = s1 + s2; String s7 = s5.intern(); // find the literal in constant pool and return it final String s8 = s1 + s2; System.out.println(s3 == s4); //T System.out.println(s3 == s5); //F System.out.println(s3 == s6); //F System.out.println(s5 == s6); //F System.out.println(s3 == s7); //T System.out.println(s3 == s8); // F Look at this! System.out.println(s3.getClass()); // same System.out.println(s8.getClass()); System.out.println(s3.hashCode()); // same System.out.println(s8.hashCode()); System.out.println(System.identityHashCode(s3)); // diff System.out.println(System.identityHashCode(s8)); } } StringBuffer and StringBuilder String, StringBuffer, StringBuilder diff? String: immutable StringBuffer: mutable, thread-safe, low efficiency StringBuilder: mutable, not thread-safe, high efficiency Efficiency: StringBuilder StringBuffer » String @Test public void testStringBuffer(){ String str = null; StringBuffer sb = new StringBuffer(); sb.append(str); System.out.println(sb.length()); // 4 System.out.println(sb); // \"null\" StringBuffer sb1 = new StringBuffer(str); // NullPointerException System.out.println(sb1); } Date import org.testng.annotations.Test; import java.util.Date; import static java.lang.Thread.sleep; public class DateTest { @Test public void test01(){ long time = System.currentTimeMillis(); // return the time diff from 1970.1.1 00:00:00 in millisecond System.out.println(time); } // java.util.Date // |---java.sql.Date // this is used in sql @Test public void Test02() throws InterruptedException { // Constructor 1 Date date1 = new Date(); System.out.println(date1.toString()); System.out.println(date1.getTime()); // Constructor 2 Date date2 = new Date(294475929283L); System.out.println(date2.toString()); // sql.Date java.sql.Date date3 = new java.sql.Date(4365435414324L); System.out.println(date3); // util.Date -- sql.Date // except forced cast it Date date4 = new Date(); java.sql.Date date5 = new java.sql.Date(date4.getTime()); System.out.println(date5); } } java.text.SimpleDateFormat import org.testng.annotations.Test; import java.text.ParseException; import java.text.SimpleDateFormat; import java.util.Date; // 1. date -- string // 2. string -- date public class SimpleDateFormatTest { @Test public void testSimpleDateFormat() throws ParseException { SimpleDateFormat sdf = new SimpleDateFormat(); Date date = new Date(); // date -- String String dateFormatted = sdf.format(date); System.out.println(dateFormatted); // String -- date String sb = \"1/1/22, 8:00 PM\"; Date dateParsed = sdf.parse(sb); System.out.println(dateParsed); SimpleDateFormat sdf1 = new SimpleDateFormat(\"yyyy-MM-dd HH:mm:ss\"); // if you want a specific pattern String dateFormatted1 = sdf1.format(date); System.out.println(dateFormatted1); // date -- String Date date1 = sdf1.parse(\"2022-01-02 18:12:58\"); System.out.println(date1); } } Calendar import org.testng.annotations.Test; import java.util.Calendar; import java.util.Date; import java.util.Scanner; public class CalendarTest { // Calendar is an abstract class @Test public void testCalendar(){ // Instantiation // 1. create instance of its subclass GregorianCalendar // 2. call the static method getInstance() Calendar calendar = Calendar.getInstance(); System.out.println(calendar.getClass()); //GregorianCalendar // Usage: get() set() add() getTime() setTime() int dayOfMonth = calendar.get(Calendar.DAY_OF_MONTH); System.out.println(dayOfMonth); System.out.println(calendar.get(Calendar.DAY_OF_YEAR)); calendar.set(Calendar.DAY_OF_YEAR, 365); System.out.println(calendar.get(Calendar.DAY_OF_YEAR)); calendar.add(Calendar.DAY_OF_YEAR, -100); System.out.println(calendar.ge","date":"2022-01-09","objectID":"/javase/:2:2","series":[],"tags":["Java"],"title":"JavaSE","uri":"/javase/#system-math-biginteger-bigdecimal"},{"categories":["Note"],"content":"Enum values() valueOf(String str) toString() public class EnumClass { public static void main(String[] args) { System.out.println(Season.SPRING); System.out.println(Season.SPRING.getName()); System.out.println(Season.SPRING.getDes()); System.out.println(Food.SOUP); Season[] values = Season.values(); for (Season value : values) { System.out.println(values[i]); } Season season = Season.valueOf(\"SPRING\"); System.out.println(season); } } enum Food{SOUP, NOODLE, MEAT, VEGETABLE} enum Season{ SPRING(\"Spring\", \"warm\"), SUMMER(\"Summer\", \"hot\"), AUTUMN(\"Fall\", \"chill\"), WINTER(\"Winter\", \"cold\"); private final String name; private final String des; private Season(String name, String des){ this.name = name; this.des = des; } public String getName() { return name; } public String getDes() { return des; } // @Override // public String toString() { // return \"Season{\" + // \"name='\" + name + '\\'' + // \", des='\" + des + '\\'' + // '}'; // } } Using enum to implement interfaces interface Info{ void show(); } enum Food implements Info{ SOUP{ @Override public void show(){ System.out.println(\"Better than water\"); } }, NOODLE { @Override public void show() { System.out.println(\"Best Carbohydrate\"); } }, MEAT{ @Override public void show() { System.out.println(\"The soul of life\"); } }, VEGETABLE{ @Override public void show() { System.out.println(\"damn...\"); } } //@Override // if we override show() here, it override everyone's //... } ","date":"2022-01-09","objectID":"/javase/:2:3","series":[],"tags":["Java"],"title":"JavaSE","uri":"/javase/#enum"},{"categories":["Note"],"content":"Enum values() valueOf(String str) toString() public class EnumClass { public static void main(String[] args) { System.out.println(Season.SPRING); System.out.println(Season.SPRING.getName()); System.out.println(Season.SPRING.getDes()); System.out.println(Food.SOUP); Season[] values = Season.values(); for (Season value : values) { System.out.println(values[i]); } Season season = Season.valueOf(\"SPRING\"); System.out.println(season); } } enum Food{SOUP, NOODLE, MEAT, VEGETABLE} enum Season{ SPRING(\"Spring\", \"warm\"), SUMMER(\"Summer\", \"hot\"), AUTUMN(\"Fall\", \"chill\"), WINTER(\"Winter\", \"cold\"); private final String name; private final String des; private Season(String name, String des){ this.name = name; this.des = des; } public String getName() { return name; } public String getDes() { return des; } // @Override // public String toString() { // return \"Season{\" + // \"name='\" + name + '\\'' + // \", des='\" + des + '\\'' + // '}'; // } } Using enum to implement interfaces interface Info{ void show(); } enum Food implements Info{ SOUP{ @Override public void show(){ System.out.println(\"Better than water\"); } }, NOODLE { @Override public void show() { System.out.println(\"Best Carbohydrate\"); } }, MEAT{ @Override public void show() { System.out.println(\"The soul of life\"); } }, VEGETABLE{ @Override public void show() { System.out.println(\"damn...\"); } } //@Override // if we override show() here, it override everyone's //... } ","date":"2022-01-09","objectID":"/javase/:2:3","series":[],"tags":["Java"],"title":"JavaSE","uri":"/javase/#using-enum-to-implement-interfaces"},{"categories":["Note"],"content":"Annotation // For javaDoc @author @version @see @since @param // for method, and can have more than one @return // for method @exception //for method, and can have more than one // Compile time check @Override @Deprecated @SupperessWarnings(\"unused\") @SupperessWarnings({\"unused\", \"rawtypes\"}) ... // Junit @Test(timeout = 1000) @Test(expected = Exception.class) // the 5 below should be used along @Test rather than use them alone @BeforeClass // for static method, executed at the init of class @AfterClass // for static method, executed after all other methods @Before // for non-static methods, executed before every @Test @After // for non-static methods @Ignore // mark the unfinished test method to ignore them // keyword: @interface java.lang.Annotation Interface Annotation’s member var is defined as non-param methods! You can use all 8 primitive type and String, Class, enum, Annotation as the type Its method name and return val are the annotation’s name and type you can use default to assign default val if there is only 1 member var, naming it as value is suggested if the annotation has no member, then it’s called mark, otherwise metadata Annotation if there are params for the annotation then you have to appoint their vals, unless they have default vals. paramName = val if there is only one param and the name is value, we can omit value= @Mark @MyAnnotation(value = \"val\") @MyAnnotation(\"val\") class Person{ } @interface MyAnnotation{ String value() default \"d\"; } @interface Mark{} Annotation can help tracing to code’s dependency to realize the function of config files. e.g.: Servlet3.0 support annotation, so we don’t need to deploy Servlet functions in web.xml // meta annotation @Retention @Target @Documented @Inherited @Retention includes a member var RetentionPolicy RetentionPolicy.SOURCE: compiler will discard it RetentionPolicy.CLASS: when the java program is running, JVM will not retain this for default RetentionPolicy.RUNTIME: retained when the java program is running, and can be obtained through reflection @Target regulates what elements the annotaion can act on CONTRUCTOR FIELD: attributes PACKAGE PARAMETER LOCAL_VARIABLE TYPE: class, interface including annotation, and enum METHOD @Documented means all the annotations modified by this can be exacted into the javadoc notice that @Documented must be set to @Retention(RetentionPolicy.RUNTIME) @Inherited means that all annotation modified by this can be inherited annoataions on a class will be inherited by its subclass automatically Features in JDK8 support repeatable annotation Declare @Repeatable on MyAnnotation, and the arg is MyAnnotations.class the @Target and @Retention and @Iherited must be same on both MyAnnotation and MyAnnotations import java.lang.annotation.*; import static java.lang.annotation.ElementType.*; public class AnnoTest {} @Repeatable(MyAnnotations.class) @Inherited @Retention(RetentionPolicy.RUNTIME) @Target({TYPE, FIELD, METHOD, PARAMETER, CONSTRUCTOR, LOCAL_VARIABLE}) @interface MyAnnotation{ String value(); } @Inherited @Retention(RetentionPolicy.RUNTIME) @Target({TYPE, FIELD, METHOD, PARAMETER, CONSTRUCTOR, LOCAL_VARIABLE}) @interface MyAnnotations{ MyAnnotation[] value(); } @MyAnnotation(\"hi\") @MyAnnotation(\"hello\") class TestClass{} Added 2 ElementType member: ElementType.TYPE_PARAMETER: can be used on type var’s declaration –\u003e e.g.: generic type declaration ElementType.TYPE_USE: can be used on any type args class Generic\u003c@MyAnnotation(\"hey\") T\u003e{ public void show(){ ArrayList\u003c@MyAnnotation(\"yo\") String\u003e list = new ArrayList\u003c\u003e(); } } ","date":"2022-01-09","objectID":"/javase/:2:4","series":[],"tags":["Java"],"title":"JavaSE","uri":"/javase/#annotation"},{"categories":["Note"],"content":"Annotation // For javaDoc @author @version @see @since @param // for method, and can have more than one @return // for method @exception //for method, and can have more than one // Compile time check @Override @Deprecated @SupperessWarnings(\"unused\") @SupperessWarnings({\"unused\", \"rawtypes\"}) ... // Junit @Test(timeout = 1000) @Test(expected = Exception.class) // the 5 below should be used along @Test rather than use them alone @BeforeClass // for static method, executed at the init of class @AfterClass // for static method, executed after all other methods @Before // for non-static methods, executed before every @Test @After // for non-static methods @Ignore // mark the unfinished test method to ignore them // keyword: @interface java.lang.Annotation Interface Annotation’s member var is defined as non-param methods! You can use all 8 primitive type and String, Class, enum, Annotation as the type Its method name and return val are the annotation’s name and type you can use default to assign default val if there is only 1 member var, naming it as value is suggested if the annotation has no member, then it’s called mark, otherwise metadata Annotation if there are params for the annotation then you have to appoint their vals, unless they have default vals. paramName = val if there is only one param and the name is value, we can omit value= @Mark @MyAnnotation(value = \"val\") @MyAnnotation(\"val\") class Person{ } @interface MyAnnotation{ String value() default \"d\"; } @interface Mark{} Annotation can help tracing to code’s dependency to realize the function of config files. e.g.: Servlet3.0 support annotation, so we don’t need to deploy Servlet functions in web.xml // meta annotation @Retention @Target @Documented @Inherited @Retention includes a member var RetentionPolicy RetentionPolicy.SOURCE: compiler will discard it RetentionPolicy.CLASS: when the java program is running, JVM will not retain this for default RetentionPolicy.RUNTIME: retained when the java program is running, and can be obtained through reflection @Target regulates what elements the annotaion can act on CONTRUCTOR FIELD: attributes PACKAGE PARAMETER LOCAL_VARIABLE TYPE: class, interface including annotation, and enum METHOD @Documented means all the annotations modified by this can be exacted into the javadoc notice that @Documented must be set to @Retention(RetentionPolicy.RUNTIME) @Inherited means that all annotation modified by this can be inherited annoataions on a class will be inherited by its subclass automatically Features in JDK8 support repeatable annotation Declare @Repeatable on MyAnnotation, and the arg is MyAnnotations.class the @Target and @Retention and @Iherited must be same on both MyAnnotation and MyAnnotations import java.lang.annotation.*; import static java.lang.annotation.ElementType.*; public class AnnoTest {} @Repeatable(MyAnnotations.class) @Inherited @Retention(RetentionPolicy.RUNTIME) @Target({TYPE, FIELD, METHOD, PARAMETER, CONSTRUCTOR, LOCAL_VARIABLE}) @interface MyAnnotation{ String value(); } @Inherited @Retention(RetentionPolicy.RUNTIME) @Target({TYPE, FIELD, METHOD, PARAMETER, CONSTRUCTOR, LOCAL_VARIABLE}) @interface MyAnnotations{ MyAnnotation[] value(); } @MyAnnotation(\"hi\") @MyAnnotation(\"hello\") class TestClass{} Added 2 ElementType member: ElementType.TYPE_PARAMETER: can be used on type var’s declaration – e.g.: generic type declaration ElementType.TYPE_USE: can be used on any type args class Generic{ public void show(){ ArrayListlist = new ArrayList(); } } ","date":"2022-01-09","objectID":"/javase/:2:4","series":[],"tags":["Java"],"title":"JavaSE","uri":"/javase/#features-in-jdk8"},{"categories":["Note"],"content":"Collection Collection List: ArrayList, LinkedList, Vector Set: HashSet, LinkedHashSet, TreeSet Map: HashMap, LinkedHashMap, TreeMap, Hashtable, Properties import org.testng.annotations.Test; import java.util.ArrayList; import java.util.Collection; import java.util.Date; import java.util.Iterator; public class CollectionTest { @Test public void test1(){ Collection c = new ArrayList(); c.add(\"A\"); c.add(\"BB\"); c.add(123); // auto-boxing c.add(new Date()); System.out.println(c.size()); // num of elements in c Collection c1 = new ArrayList(); c1.add(\"A\"); c1.addAll(c); // add all elements in c into c1 System.out.println(c1.size()); System.out.println(c1); // isEmpty() System.out.println(c.isEmpty()); // clear() c.clear(); System.out.println(c.size()); System.out.println(c.isEmpty()); // check jdk doc to learn other APIs Iterator iter = c1.iterator(); while(iter.hasNext()){ Object obj = iter.next(); if(\"A\".equals(obj)){ iter.remove(); // this just remove the element in this iterator not the collection!! }else System.out.println(obj); } } } List interface Ordered and Repeatable ArrayList: Not thread-safe, effcient, use Object[] elementData at low level LinkedList: good for frequent insertion and deletion, use doubly linked list for storage at low level Vector: Thread-safe, less efficiency, use Object[] elementData at low level ArrayList Source Code: In JDK7, when the object is created, an Object[] array of length 10 is created. If you call add() and the exceeds the capacity, enlarge it by 1.5 time. But if you pass in size when you init the ArrayList, then you will get the Object[] with the exact size, which is recommended. In JDK8, lazy mode, the array is created after you first call add() Vector: started with 10, enlarged by 2. Set Interface Unordered and non-repeatable HashSet: Not thread-safe, can store null |—-LinkedHashSet: can traversal itself like a linked list TreeSet: can be sorted HashSet: Calculate the hashCode() and go to the corresponding index, if there is an element, call equals() of the element added. If same, discard; if not, make them a linked lists If the length exceeds 8, make it a red-black tree. In JDK8, the added element appends to the tail. Notice: The class that is being added to Set must override hashCode() and equals() and maintain consistency, which means the same object should have the same hash code. Tip: Use same elements for the algos in hashCode() and equals(). HashSet’s lower level is HashMap. LinkedHashList: Based on the HashSet, added Node containing the element. TreeSet: Cannot add different objects of different classes! Since we need to compare them for natural sorting or customized sorting. Implement Comparable and rewrite compareTo(). Or, we can use Comparator\u003c\u003e as what we discussed before. TreeSet uses red-black tree. Map Interface HashMap: mainly used. Non-thread-safe, high efficiency. Can store null as key and val. |—-LinkedHashMap: Better than HashMap for frequently traversal. TreeMap Hashtable: old implementation. Thread-safe, lower efficiency. Cannot store null as key and val. |—-Properties: Used for configs, the key and val are String. In Map –\u003e Key: Set, Value: Collection Since keys cannot repeat, but vals can be same. In the class of the key, equals() and hashCode() must be overrode. In the class of the val, equals() needs to be overrode. JDK7: HashMap starts with Entry[] table of length 16. map.put(key1, value1); Firstly, key1.hashCode() will get the index in the Entry[]. If the place is empty, success; else, key1.equals(existedKey) is called for every existed key in there. If same, replace the old val with the new val; else, success. Enlarge by 2. JDK8: 1. new HashMap(): doesn’t create a 16 long array 2. Use Node[] instead of Entity[] 3. Create the 16 long array when firstly call put() 4. array + linked list –\u003e array + linked list + red-black tree(len of linked list \u003e= 8 and length of arr \u003e 64) DEFAULT_INITIAL_CAPACITY: 16 MAXIMUM_CAPACITY: 2^30 DEFAULT_LOAD_FACTOR TREEIFY_THRESHOLD","date":"2022-01-09","objectID":"/javase/:2:5","series":[],"tags":["Java"],"title":"JavaSE","uri":"/javase/#collection"},{"categories":["Note"],"content":"Collection Collection List: ArrayList, LinkedList, Vector Set: HashSet, LinkedHashSet, TreeSet Map: HashMap, LinkedHashMap, TreeMap, Hashtable, Properties import org.testng.annotations.Test; import java.util.ArrayList; import java.util.Collection; import java.util.Date; import java.util.Iterator; public class CollectionTest { @Test public void test1(){ Collection c = new ArrayList(); c.add(\"A\"); c.add(\"BB\"); c.add(123); // auto-boxing c.add(new Date()); System.out.println(c.size()); // num of elements in c Collection c1 = new ArrayList(); c1.add(\"A\"); c1.addAll(c); // add all elements in c into c1 System.out.println(c1.size()); System.out.println(c1); // isEmpty() System.out.println(c.isEmpty()); // clear() c.clear(); System.out.println(c.size()); System.out.println(c.isEmpty()); // check jdk doc to learn other APIs Iterator iter = c1.iterator(); while(iter.hasNext()){ Object obj = iter.next(); if(\"A\".equals(obj)){ iter.remove(); // this just remove the element in this iterator not the collection!! }else System.out.println(obj); } } } List interface Ordered and Repeatable ArrayList: Not thread-safe, effcient, use Object[] elementData at low level LinkedList: good for frequent insertion and deletion, use doubly linked list for storage at low level Vector: Thread-safe, less efficiency, use Object[] elementData at low level ArrayList Source Code: In JDK7, when the object is created, an Object[] array of length 10 is created. If you call add() and the exceeds the capacity, enlarge it by 1.5 time. But if you pass in size when you init the ArrayList, then you will get the Object[] with the exact size, which is recommended. In JDK8, lazy mode, the array is created after you first call add() Vector: started with 10, enlarged by 2. Set Interface Unordered and non-repeatable HashSet: Not thread-safe, can store null |—-LinkedHashSet: can traversal itself like a linked list TreeSet: can be sorted HashSet: Calculate the hashCode() and go to the corresponding index, if there is an element, call equals() of the element added. If same, discard; if not, make them a linked lists If the length exceeds 8, make it a red-black tree. In JDK8, the added element appends to the tail. Notice: The class that is being added to Set must override hashCode() and equals() and maintain consistency, which means the same object should have the same hash code. Tip: Use same elements for the algos in hashCode() and equals(). HashSet’s lower level is HashMap. LinkedHashList: Based on the HashSet, added Node containing the element. TreeSet: Cannot add different objects of different classes! Since we need to compare them for natural sorting or customized sorting. Implement Comparable and rewrite compareTo(). Or, we can use Comparator as what we discussed before. TreeSet uses red-black tree. Map Interface HashMap: mainly used. Non-thread-safe, high efficiency. Can store null as key and val. |—-LinkedHashMap: Better than HashMap for frequently traversal. TreeMap Hashtable: old implementation. Thread-safe, lower efficiency. Cannot store null as key and val. |—-Properties: Used for configs, the key and val are String. In Map – Key: Set, Value: Collection Since keys cannot repeat, but vals can be same. In the class of the key, equals() and hashCode() must be overrode. In the class of the val, equals() needs to be overrode. JDK7: HashMap starts with Entry[] table of length 16. map.put(key1, value1); Firstly, key1.hashCode() will get the index in the Entry[]. If the place is empty, success; else, key1.equals(existedKey) is called for every existed key in there. If same, replace the old val with the new val; else, success. Enlarge by 2. JDK8: 1. new HashMap(): doesn’t create a 16 long array 2. Use Node[] instead of Entity[] 3. Create the 16 long array when firstly call put() 4. array + linked list – array + linked list + red-black tree(len of linked list = 8 and length of arr 64) DEFAULT_INITIAL_CAPACITY: 16 MAXIMUM_CAPACITY: 2^30 DEFAULT_LOAD_FACTOR TREEIFY_THRESHOLD","date":"2022-01-09","objectID":"/javase/:2:5","series":[],"tags":["Java"],"title":"JavaSE","uri":"/javase/#list-interface"},{"categories":["Note"],"content":"Collection Collection List: ArrayList, LinkedList, Vector Set: HashSet, LinkedHashSet, TreeSet Map: HashMap, LinkedHashMap, TreeMap, Hashtable, Properties import org.testng.annotations.Test; import java.util.ArrayList; import java.util.Collection; import java.util.Date; import java.util.Iterator; public class CollectionTest { @Test public void test1(){ Collection c = new ArrayList(); c.add(\"A\"); c.add(\"BB\"); c.add(123); // auto-boxing c.add(new Date()); System.out.println(c.size()); // num of elements in c Collection c1 = new ArrayList(); c1.add(\"A\"); c1.addAll(c); // add all elements in c into c1 System.out.println(c1.size()); System.out.println(c1); // isEmpty() System.out.println(c.isEmpty()); // clear() c.clear(); System.out.println(c.size()); System.out.println(c.isEmpty()); // check jdk doc to learn other APIs Iterator iter = c1.iterator(); while(iter.hasNext()){ Object obj = iter.next(); if(\"A\".equals(obj)){ iter.remove(); // this just remove the element in this iterator not the collection!! }else System.out.println(obj); } } } List interface Ordered and Repeatable ArrayList: Not thread-safe, effcient, use Object[] elementData at low level LinkedList: good for frequent insertion and deletion, use doubly linked list for storage at low level Vector: Thread-safe, less efficiency, use Object[] elementData at low level ArrayList Source Code: In JDK7, when the object is created, an Object[] array of length 10 is created. If you call add() and the exceeds the capacity, enlarge it by 1.5 time. But if you pass in size when you init the ArrayList, then you will get the Object[] with the exact size, which is recommended. In JDK8, lazy mode, the array is created after you first call add() Vector: started with 10, enlarged by 2. Set Interface Unordered and non-repeatable HashSet: Not thread-safe, can store null |—-LinkedHashSet: can traversal itself like a linked list TreeSet: can be sorted HashSet: Calculate the hashCode() and go to the corresponding index, if there is an element, call equals() of the element added. If same, discard; if not, make them a linked lists If the length exceeds 8, make it a red-black tree. In JDK8, the added element appends to the tail. Notice: The class that is being added to Set must override hashCode() and equals() and maintain consistency, which means the same object should have the same hash code. Tip: Use same elements for the algos in hashCode() and equals(). HashSet’s lower level is HashMap. LinkedHashList: Based on the HashSet, added Node containing the element. TreeSet: Cannot add different objects of different classes! Since we need to compare them for natural sorting or customized sorting. Implement Comparable and rewrite compareTo(). Or, we can use Comparator as what we discussed before. TreeSet uses red-black tree. Map Interface HashMap: mainly used. Non-thread-safe, high efficiency. Can store null as key and val. |—-LinkedHashMap: Better than HashMap for frequently traversal. TreeMap Hashtable: old implementation. Thread-safe, lower efficiency. Cannot store null as key and val. |—-Properties: Used for configs, the key and val are String. In Map – Key: Set, Value: Collection Since keys cannot repeat, but vals can be same. In the class of the key, equals() and hashCode() must be overrode. In the class of the val, equals() needs to be overrode. JDK7: HashMap starts with Entry[] table of length 16. map.put(key1, value1); Firstly, key1.hashCode() will get the index in the Entry[]. If the place is empty, success; else, key1.equals(existedKey) is called for every existed key in there. If same, replace the old val with the new val; else, success. Enlarge by 2. JDK8: 1. new HashMap(): doesn’t create a 16 long array 2. Use Node[] instead of Entity[] 3. Create the 16 long array when firstly call put() 4. array + linked list – array + linked list + red-black tree(len of linked list = 8 and length of arr 64) DEFAULT_INITIAL_CAPACITY: 16 MAXIMUM_CAPACITY: 2^30 DEFAULT_LOAD_FACTOR TREEIFY_THRESHOLD","date":"2022-01-09","objectID":"/javase/:2:5","series":[],"tags":["Java"],"title":"JavaSE","uri":"/javase/#set-interface"},{"categories":["Note"],"content":"Collection Collection List: ArrayList, LinkedList, Vector Set: HashSet, LinkedHashSet, TreeSet Map: HashMap, LinkedHashMap, TreeMap, Hashtable, Properties import org.testng.annotations.Test; import java.util.ArrayList; import java.util.Collection; import java.util.Date; import java.util.Iterator; public class CollectionTest { @Test public void test1(){ Collection c = new ArrayList(); c.add(\"A\"); c.add(\"BB\"); c.add(123); // auto-boxing c.add(new Date()); System.out.println(c.size()); // num of elements in c Collection c1 = new ArrayList(); c1.add(\"A\"); c1.addAll(c); // add all elements in c into c1 System.out.println(c1.size()); System.out.println(c1); // isEmpty() System.out.println(c.isEmpty()); // clear() c.clear(); System.out.println(c.size()); System.out.println(c.isEmpty()); // check jdk doc to learn other APIs Iterator iter = c1.iterator(); while(iter.hasNext()){ Object obj = iter.next(); if(\"A\".equals(obj)){ iter.remove(); // this just remove the element in this iterator not the collection!! }else System.out.println(obj); } } } List interface Ordered and Repeatable ArrayList: Not thread-safe, effcient, use Object[] elementData at low level LinkedList: good for frequent insertion and deletion, use doubly linked list for storage at low level Vector: Thread-safe, less efficiency, use Object[] elementData at low level ArrayList Source Code: In JDK7, when the object is created, an Object[] array of length 10 is created. If you call add() and the exceeds the capacity, enlarge it by 1.5 time. But if you pass in size when you init the ArrayList, then you will get the Object[] with the exact size, which is recommended. In JDK8, lazy mode, the array is created after you first call add() Vector: started with 10, enlarged by 2. Set Interface Unordered and non-repeatable HashSet: Not thread-safe, can store null |—-LinkedHashSet: can traversal itself like a linked list TreeSet: can be sorted HashSet: Calculate the hashCode() and go to the corresponding index, if there is an element, call equals() of the element added. If same, discard; if not, make them a linked lists If the length exceeds 8, make it a red-black tree. In JDK8, the added element appends to the tail. Notice: The class that is being added to Set must override hashCode() and equals() and maintain consistency, which means the same object should have the same hash code. Tip: Use same elements for the algos in hashCode() and equals(). HashSet’s lower level is HashMap. LinkedHashList: Based on the HashSet, added Node containing the element. TreeSet: Cannot add different objects of different classes! Since we need to compare them for natural sorting or customized sorting. Implement Comparable and rewrite compareTo(). Or, we can use Comparator as what we discussed before. TreeSet uses red-black tree. Map Interface HashMap: mainly used. Non-thread-safe, high efficiency. Can store null as key and val. |—-LinkedHashMap: Better than HashMap for frequently traversal. TreeMap Hashtable: old implementation. Thread-safe, lower efficiency. Cannot store null as key and val. |—-Properties: Used for configs, the key and val are String. In Map – Key: Set, Value: Collection Since keys cannot repeat, but vals can be same. In the class of the key, equals() and hashCode() must be overrode. In the class of the val, equals() needs to be overrode. JDK7: HashMap starts with Entry[] table of length 16. map.put(key1, value1); Firstly, key1.hashCode() will get the index in the Entry[]. If the place is empty, success; else, key1.equals(existedKey) is called for every existed key in there. If same, replace the old val with the new val; else, success. Enlarge by 2. JDK8: 1. new HashMap(): doesn’t create a 16 long array 2. Use Node[] instead of Entity[] 3. Create the 16 long array when firstly call put() 4. array + linked list – array + linked list + red-black tree(len of linked list = 8 and length of arr 64) DEFAULT_INITIAL_CAPACITY: 16 MAXIMUM_CAPACITY: 2^30 DEFAULT_LOAD_FACTOR TREEIFY_THRESHOLD","date":"2022-01-09","objectID":"/javase/:2:5","series":[],"tags":["Java"],"title":"JavaSE","uri":"/javase/#map-interface"},{"categories":["Note"],"content":"Collections Utils to operate on Collection and Map Sorting (static) reverse(List) shuffle(List) sort(List) sort(List, Comparator) swap(List, int, int) Searching and Substitution Object max(Collection) Object max(Collection, Comparator) …min… int frequency(Collection, Object) void copy(List dest, List src) boolean replaceAll(List list, Object oldVal, Object newVal) ","date":"2022-01-09","objectID":"/javase/:2:6","series":[],"tags":["Java"],"title":"JavaSE","uri":"/javase/#collections"},{"categories":["Note"],"content":"Generic Collection and Collections support Generic type It cannot be a primitive type(need boxing) If not giving a specific type at init, it’s java.lang.Object by default public class GenericTest { public static void main(String[] args) { Order\u003cString\u003e order = new Order\u003c\u003e(); String s = \"Wow!\"; order.setOrderT(s); // We've specified the type at inheritance so that we don't need to point it out again at init SubOrder subOrder = new SubOrder(); } } class SomeOrder\u003cT\u003e extends Order\u003cT\u003e{ } class SubOrder extends Order\u003cString\u003e { String subName; int subId; } class Order\u003cT\u003e { String orderName; int orderId; T orderT; public Order(){} public Order(String orderName, int orderId, T orderT){ this.orderId = orderId; this.orderName = orderName; this.orderT = orderT; } public String getOrderName() { return orderName; } public void setOrderName(String orderName) { this.orderName = orderName; } public int getOrderId() { return orderId; } public void setOrderId(int orderId) { this.orderId = orderId; } public T getOrderT() { return orderT; } public void setOrderT(T orderT) { this.orderT = orderT; } } Generic Class and Interface If having multi-param –\u003e \u003cE1, E2, E3\u003e The constructor of generic class is public GenericClass(){}, NOT public GenericClass\u003cE\u003e(){} Although ArrayList\u003cInteger\u003e and ArrayList\u003cString\u003e are diff, only 1 ArrayList is loaded to JVM at runtime They are treated as diff at compile time, but same thing at runtime. So you can pass the compile if anything wrong. CANNOT use Generic type in static method(since the param must be specified at init, you might not know the exact type when you call the static method) and Exception. Cannot use new E[], but you can use E[] elements = (E[]) new Object[cap] since the Object[] elementData in ArrayList source code has no generic type Subclass inherit the generic type class Father\u003cT1, T2\u003e{} class Son1 extends Father{} // equivalent to extents Father\u003cObject, Object\u003e class Son2 extends Father\u003cInteger, Integer\u003e{} class Son3\u003cT1, T2\u003e extends Father\u003cT1, T2\u003e{} class Son4\u003cT2\u003e extends Father\u003cInteger, T2\u003e{} Generic Method \u003cT\u003e T[] toArray(T[] a); –\u003e Yes public static \u003cE\u003e List\u003cE\u003e copyFromArrayToList(E[] arr){} –\u003e Yes int[] toArray(T[] a); –\u003e No Generic method has nothing to do with whether its class or interface is generic. In the method, there must be generic structure, the generic type in param and class’s param don’t matter. Why we need \u003cT\u003e –\u003e if not, the compiler will see the \u003cE\u003e in List\u003cE\u003e as an actual class, not a generic type. Can be static because the generic type in Generic method is specified when being called rather than at init, it’s not related to the generic type of its class. ? List\u003cString\u003e list1 = new ArrayList\u003cString\u003e(); List\u003cInteger\u003e list2 = new ArrayList\u003cInteger\u003e(); list1.add(\"AA\"); list1.add(\"BB\"); list1.add(\"CC\"); list2.add(111); list2.add(222); list2.add(333); List\u003c?\u003e list = new ArrayList(); list = new ArrayList\u003cString\u003e(); list = list1; System.out.println(list); list = list2; System.out.println(list); list.add(null); // list.add(\"DD\"); // CANNOT add anything in a List\u003c?\u003e rather than null // you can read anything to Object Object o = list.get(0); System.out.println(o); We can appoint the upper limit and lower limit of the ? using extends and super only allow Number and its subclasses only allow Number and its superclass and upper levels only allow classes implemented Comparator interface Cannot assign superclass to its subclass ","date":"2022-01-09","objectID":"/javase/:2:7","series":[],"tags":["Java"],"title":"JavaSE","uri":"/javase/#generic"},{"categories":["Note"],"content":"Generic Collection and Collections support Generic type It cannot be a primitive type(need boxing) If not giving a specific type at init, it’s java.lang.Object by default public class GenericTest { public static void main(String[] args) { Order order = new Order(); String s = \"Wow!\"; order.setOrderT(s); // We've specified the type at inheritance so that we don't need to point it out again at init SubOrder subOrder = new SubOrder(); } } class SomeOrder extends Order{ } class SubOrder extends Order { String subName; int subId; } class Order { String orderName; int orderId; T orderT; public Order(){} public Order(String orderName, int orderId, T orderT){ this.orderId = orderId; this.orderName = orderName; this.orderT = orderT; } public String getOrderName() { return orderName; } public void setOrderName(String orderName) { this.orderName = orderName; } public int getOrderId() { return orderId; } public void setOrderId(int orderId) { this.orderId = orderId; } public T getOrderT() { return orderT; } public void setOrderT(T orderT) { this.orderT = orderT; } } Generic Class and Interface If having multi-param – The constructor of generic class is public GenericClass(){}, NOT public GenericClass(){} Although ArrayList and ArrayList are diff, only 1 ArrayList is loaded to JVM at runtime They are treated as diff at compile time, but same thing at runtime. So you can pass the compile if anything wrong. CANNOT use Generic type in static method(since the param must be specified at init, you might not know the exact type when you call the static method) and Exception. Cannot use new E[], but you can use E[] elements = (E[]) new Object[cap] since the Object[] elementData in ArrayList source code has no generic type Subclass inherit the generic type class Father{} class Son1 extends Father{} // equivalent to extents Fatherclass Son2 extends Father{} class Son3extends Father{} class Son4 extends Father{} Generic Method T[] toArray(T[] a); – Yes public static List copyFromArrayToList(E[] arr){} – Yes int[] toArray(T[] a); – No Generic method has nothing to do with whether its class or interface is generic. In the method, there must be generic structure, the generic type in param and class’s param don’t matter. Why we need – if not, the compiler will see the in List as an actual class, not a generic type. Can be static because the generic type in Generic method is specified when being called rather than at init, it’s not related to the generic type of its class. ? List list1 = new ArrayList(); List list2 = new ArrayList(); list1.add(\"AA\"); list1.add(\"BB\"); list1.add(\"CC\"); list2.add(111); list2.add(222); list2.add(333); List list = new ArrayList(); list = new ArrayList(); list = list1; System.out.println(list); list = list2; System.out.println(list); list.add(null); // list.add(\"DD\"); // CANNOT add anything in a List rather than null // you can read anything to Object Object o = list.get(0); System.out.println(o); We can appoint the upper limit and lower limit of the ? using extends and super only allow Number and its subclasses only allow Number and its superclass and upper levels only allow classes implemented Comparator interface Cannot assign superclass to its subclass ","date":"2022-01-09","objectID":"/javase/:2:7","series":[],"tags":["Java"],"title":"JavaSE","uri":"/javase/#generic-class-and-interface"},{"categories":["Note"],"content":"Generic Collection and Collections support Generic type It cannot be a primitive type(need boxing) If not giving a specific type at init, it’s java.lang.Object by default public class GenericTest { public static void main(String[] args) { Order order = new Order(); String s = \"Wow!\"; order.setOrderT(s); // We've specified the type at inheritance so that we don't need to point it out again at init SubOrder subOrder = new SubOrder(); } } class SomeOrder extends Order{ } class SubOrder extends Order { String subName; int subId; } class Order { String orderName; int orderId; T orderT; public Order(){} public Order(String orderName, int orderId, T orderT){ this.orderId = orderId; this.orderName = orderName; this.orderT = orderT; } public String getOrderName() { return orderName; } public void setOrderName(String orderName) { this.orderName = orderName; } public int getOrderId() { return orderId; } public void setOrderId(int orderId) { this.orderId = orderId; } public T getOrderT() { return orderT; } public void setOrderT(T orderT) { this.orderT = orderT; } } Generic Class and Interface If having multi-param – The constructor of generic class is public GenericClass(){}, NOT public GenericClass(){} Although ArrayList and ArrayList are diff, only 1 ArrayList is loaded to JVM at runtime They are treated as diff at compile time, but same thing at runtime. So you can pass the compile if anything wrong. CANNOT use Generic type in static method(since the param must be specified at init, you might not know the exact type when you call the static method) and Exception. Cannot use new E[], but you can use E[] elements = (E[]) new Object[cap] since the Object[] elementData in ArrayList source code has no generic type Subclass inherit the generic type class Father{} class Son1 extends Father{} // equivalent to extents Fatherclass Son2 extends Father{} class Son3extends Father{} class Son4 extends Father{} Generic Method T[] toArray(T[] a); – Yes public static List copyFromArrayToList(E[] arr){} – Yes int[] toArray(T[] a); – No Generic method has nothing to do with whether its class or interface is generic. In the method, there must be generic structure, the generic type in param and class’s param don’t matter. Why we need – if not, the compiler will see the in List as an actual class, not a generic type. Can be static because the generic type in Generic method is specified when being called rather than at init, it’s not related to the generic type of its class. ? List list1 = new ArrayList(); List list2 = new ArrayList(); list1.add(\"AA\"); list1.add(\"BB\"); list1.add(\"CC\"); list2.add(111); list2.add(222); list2.add(333); List list = new ArrayList(); list = new ArrayList(); list = list1; System.out.println(list); list = list2; System.out.println(list); list.add(null); // list.add(\"DD\"); // CANNOT add anything in a List rather than null // you can read anything to Object Object o = list.get(0); System.out.println(o); We can appoint the upper limit and lower limit of the ? using extends and super only allow Number and its subclasses only allow Number and its superclass and upper levels only allow classes implemented Comparator interface Cannot assign superclass to its subclass ","date":"2022-01-09","objectID":"/javase/:2:7","series":[],"tags":["Java"],"title":"JavaSE","uri":"/javase/#generic-method"},{"categories":["Note"],"content":"Generic Collection and Collections support Generic type It cannot be a primitive type(need boxing) If not giving a specific type at init, it’s java.lang.Object by default public class GenericTest { public static void main(String[] args) { Order order = new Order(); String s = \"Wow!\"; order.setOrderT(s); // We've specified the type at inheritance so that we don't need to point it out again at init SubOrder subOrder = new SubOrder(); } } class SomeOrder extends Order{ } class SubOrder extends Order { String subName; int subId; } class Order { String orderName; int orderId; T orderT; public Order(){} public Order(String orderName, int orderId, T orderT){ this.orderId = orderId; this.orderName = orderName; this.orderT = orderT; } public String getOrderName() { return orderName; } public void setOrderName(String orderName) { this.orderName = orderName; } public int getOrderId() { return orderId; } public void setOrderId(int orderId) { this.orderId = orderId; } public T getOrderT() { return orderT; } public void setOrderT(T orderT) { this.orderT = orderT; } } Generic Class and Interface If having multi-param – The constructor of generic class is public GenericClass(){}, NOT public GenericClass(){} Although ArrayList and ArrayList are diff, only 1 ArrayList is loaded to JVM at runtime They are treated as diff at compile time, but same thing at runtime. So you can pass the compile if anything wrong. CANNOT use Generic type in static method(since the param must be specified at init, you might not know the exact type when you call the static method) and Exception. Cannot use new E[], but you can use E[] elements = (E[]) new Object[cap] since the Object[] elementData in ArrayList source code has no generic type Subclass inherit the generic type class Father{} class Son1 extends Father{} // equivalent to extents Fatherclass Son2 extends Father{} class Son3extends Father{} class Son4 extends Father{} Generic Method T[] toArray(T[] a); – Yes public static List copyFromArrayToList(E[] arr){} – Yes int[] toArray(T[] a); – No Generic method has nothing to do with whether its class or interface is generic. In the method, there must be generic structure, the generic type in param and class’s param don’t matter. Why we need – if not, the compiler will see the in List as an actual class, not a generic type. Can be static because the generic type in Generic method is specified when being called rather than at init, it’s not related to the generic type of its class. ? List list1 = new ArrayList(); List list2 = new ArrayList(); list1.add(\"AA\"); list1.add(\"BB\"); list1.add(\"CC\"); list2.add(111); list2.add(222); list2.add(333); List list = new ArrayList(); list = new ArrayList(); list = list1; System.out.println(list); list = list2; System.out.println(list); list.add(null); // list.add(\"DD\"); // CANNOT add anything in a List rather than null // you can read anything to Object Object o = list.get(0); System.out.println(o); We can appoint the upper limit and lower limit of the ? using extends and super only allow Number and its subclasses only allow Number and its superclass and upper levels only allow classes implemented Comparator interface Cannot assign superclass to its subclass ","date":"2022-01-09","objectID":"/javase/:2:7","series":[],"tags":["Java"],"title":"JavaSE","uri":"/javase/#heading"},{"categories":["Note"],"content":"Generic Collection and Collections support Generic type It cannot be a primitive type(need boxing) If not giving a specific type at init, it’s java.lang.Object by default public class GenericTest { public static void main(String[] args) { Order order = new Order(); String s = \"Wow!\"; order.setOrderT(s); // We've specified the type at inheritance so that we don't need to point it out again at init SubOrder subOrder = new SubOrder(); } } class SomeOrder extends Order{ } class SubOrder extends Order { String subName; int subId; } class Order { String orderName; int orderId; T orderT; public Order(){} public Order(String orderName, int orderId, T orderT){ this.orderId = orderId; this.orderName = orderName; this.orderT = orderT; } public String getOrderName() { return orderName; } public void setOrderName(String orderName) { this.orderName = orderName; } public int getOrderId() { return orderId; } public void setOrderId(int orderId) { this.orderId = orderId; } public T getOrderT() { return orderT; } public void setOrderT(T orderT) { this.orderT = orderT; } } Generic Class and Interface If having multi-param – The constructor of generic class is public GenericClass(){}, NOT public GenericClass(){} Although ArrayList and ArrayList are diff, only 1 ArrayList is loaded to JVM at runtime They are treated as diff at compile time, but same thing at runtime. So you can pass the compile if anything wrong. CANNOT use Generic type in static method(since the param must be specified at init, you might not know the exact type when you call the static method) and Exception. Cannot use new E[], but you can use E[] elements = (E[]) new Object[cap] since the Object[] elementData in ArrayList source code has no generic type Subclass inherit the generic type class Father{} class Son1 extends Father{} // equivalent to extents Fatherclass Son2 extends Father{} class Son3extends Father{} class Son4 extends Father{} Generic Method T[] toArray(T[] a); – Yes public static List copyFromArrayToList(E[] arr){} – Yes int[] toArray(T[] a); – No Generic method has nothing to do with whether its class or interface is generic. In the method, there must be generic structure, the generic type in param and class’s param don’t matter. Why we need – if not, the compiler will see the in List as an actual class, not a generic type. Can be static because the generic type in Generic method is specified when being called rather than at init, it’s not related to the generic type of its class. ? List list1 = new ArrayList(); List list2 = new ArrayList(); list1.add(\"AA\"); list1.add(\"BB\"); list1.add(\"CC\"); list2.add(111); list2.add(222); list2.add(333); List list = new ArrayList(); list = new ArrayList(); list = list1; System.out.println(list); list = list2; System.out.println(list); list.add(null); // list.add(\"DD\"); // CANNOT add anything in a List rather than null // you can read anything to Object Object o = list.get(0); System.out.println(o); We can appoint the upper limit and lower limit of the ? using extends and super only allow Number and its subclasses only allow Number and its superclass and upper levels only allow classes implemented Comparator interface Cannot assign superclass to its subclass ","date":"2022-01-09","objectID":"/javase/:2:7","series":[],"tags":["Java"],"title":"JavaSE","uri":"/javase/#cannot-assign-superclass-to-its-subclass"},{"categories":["Note"],"content":"IO Stream File /* * An object of a File class can be a file or a file directory * java.io * */ import org.testng.annotations.Test; import java.io.File; public class Files { @Test public void Test1(){ File file = new File(\".\" + File.pathSeparator + \"hello.txt\"); File dir = new File(\".\", \"Hey_dir\"); File file1 = new File(dir, \"yo.txt\"); } } String getAbsolutePath() String getPath() String getName() String getParent() long length() long lastModified() String[] list() File[] listFiles() boolean renameTo(File dest): rename to a new path boolean isDirectory() boolean isFile() boolean exists() boolean canRead() boolean canWrite() boolean isHidden() boolean createNewFile() boolean mkdir() boolean mkdirs(): if parent path doesn’t exist, create it as well boolean delete(): if it’s a dir, there should not have any subdir or files in it! IO Stream Classify abstract base class bit stream byte stream input InputStream Reader output OutputStream Writer bit stream is good for pics, video, and audio… byte stream is good for text-based file 抽象基类 节点流(文件流) 缓冲流(处理流的一种) 转换流(处理流的一种) 打印流(same) 数据流 对象流 InputStream FileInputStream BufferedInputStream InputStreamReader NA DataInputStream ObjectInputStream OutputStream FileOutputStream BufferedReader OutputStreamWriter PrintStream DataOutputStream ObjectOutputStream Reader FileReader BufferedReader NA NA NA NA Writer FileWriter BufferedWriter NA PrintWriter NA NA RandomAccessFile can be both input and output long getFilePointer(): get the pointer void seek(long pos): set the position of the pointer import org.testng.annotations.Test; import javax.xml.namespace.QName; import java.io.*; import java.nio.charset.StandardCharsets; import java.util.Locale; /* * 根据操作数据单位：字节流，字符流 * 根据流向：输入流输出流 * 根据角色：节点流，处理流 * */ public class IOStream { @Test public void testFileReader(){ FileReader fr = null; try { // 1. create file object File file = new File(\"./src/io/java/hello.txt\"); // this file has to be existed, or it'll throw FileNotFoundException System.out.println(file.getAbsolutePath()); // 2. create a stream fr = new FileReader(file); // 3. read data // read() returns the char read in, if EOF return -1 int data; while ((data = fr.read()) != -1){ System.out.print((char)data); } } catch (IOException e) { e.printStackTrace(); } finally { // We have to ensure the stream got closed! // 4. close stream try { if (fr != null) fr.close(); // gc cannot close this, we have to do it manually } catch (IOException e) { e.printStackTrace(); } } } @Test public void testFileReaderUpgraded(){ FileReader fr = null; try { File file = new File(\"./src/io/java/hello.txt\"); fr = new FileReader(file); char[] cbuf = new char[8]; int len; while ((len = fr.read(cbuf)) != -1) { // Every time it reads chars if size of cbuf for (int i = 0; i \u003c len; i++) // for (int i = 0; i \u003c cbuf.length; i++) WILL NOT WORK!!! since the very last time, cbuf is not updated // String str = new String(cbuf, 0, len); This will work // System.out.print(str); System.out.print(cbuf[i]); } } catch (IOException e) { e.printStackTrace(); } finally { if (fr != null) try { fr.close(); } catch (IOException e) { e.printStackTrace(); } } } @Test public void testFileWriter() throws IOException { /* * If file is not existed, create one * * Else, overwrite it if didn't set append to true for the FileWriter stream * */ File file = new File(\"./src/io/java/hello_out.txt\"); FileWriter fw = new FileWriter(file, false); fw.write(\"Hey, how are you?\"); fw.close(); } @Test public void testFileReaderAndWrite(){ FileReader fr = null; FileWriter fw = null; try { File srcFile = new File(\"./src/io/java/hello.txt\"); File destFile = new File(\"./src/io/java/hello_out.txt\"); fr = new FileReader(srcFile); fw = new FileWriter(destFile); char[] cbuf = new char[5]; int len; while ((len = fr.read(cbuf)) != -1){ fw.write(cbuf, 0, len); } } catch (IOException e) { e.printStackTrace(); } finally { if (fw != null) try { fw.close(); } catch (IOException e) { e.printStackTrace(); } if (fr != null) try { fr.cl","date":"2022-01-09","objectID":"/javase/:2:8","series":[],"tags":["Java"],"title":"JavaSE","uri":"/javase/#io-stream"},{"categories":["Note"],"content":"IO Stream File /* * An object of a File class can be a file or a file directory * java.io * */ import org.testng.annotations.Test; import java.io.File; public class Files { @Test public void Test1(){ File file = new File(\".\" + File.pathSeparator + \"hello.txt\"); File dir = new File(\".\", \"Hey_dir\"); File file1 = new File(dir, \"yo.txt\"); } } String getAbsolutePath() String getPath() String getName() String getParent() long length() long lastModified() String[] list() File[] listFiles() boolean renameTo(File dest): rename to a new path boolean isDirectory() boolean isFile() boolean exists() boolean canRead() boolean canWrite() boolean isHidden() boolean createNewFile() boolean mkdir() boolean mkdirs(): if parent path doesn’t exist, create it as well boolean delete(): if it’s a dir, there should not have any subdir or files in it! IO Stream Classify abstract base class bit stream byte stream input InputStream Reader output OutputStream Writer bit stream is good for pics, video, and audio… byte stream is good for text-based file 抽象基类 节点流(文件流) 缓冲流(处理流的一种) 转换流(处理流的一种) 打印流(same) 数据流 对象流 InputStream FileInputStream BufferedInputStream InputStreamReader NA DataInputStream ObjectInputStream OutputStream FileOutputStream BufferedReader OutputStreamWriter PrintStream DataOutputStream ObjectOutputStream Reader FileReader BufferedReader NA NA NA NA Writer FileWriter BufferedWriter NA PrintWriter NA NA RandomAccessFile can be both input and output long getFilePointer(): get the pointer void seek(long pos): set the position of the pointer import org.testng.annotations.Test; import javax.xml.namespace.QName; import java.io.*; import java.nio.charset.StandardCharsets; import java.util.Locale; /* * 根据操作数据单位：字节流，字符流 * 根据流向：输入流输出流 * 根据角色：节点流，处理流 * */ public class IOStream { @Test public void testFileReader(){ FileReader fr = null; try { // 1. create file object File file = new File(\"./src/io/java/hello.txt\"); // this file has to be existed, or it'll throw FileNotFoundException System.out.println(file.getAbsolutePath()); // 2. create a stream fr = new FileReader(file); // 3. read data // read() returns the char read in, if EOF return -1 int data; while ((data = fr.read()) != -1){ System.out.print((char)data); } } catch (IOException e) { e.printStackTrace(); } finally { // We have to ensure the stream got closed! // 4. close stream try { if (fr != null) fr.close(); // gc cannot close this, we have to do it manually } catch (IOException e) { e.printStackTrace(); } } } @Test public void testFileReaderUpgraded(){ FileReader fr = null; try { File file = new File(\"./src/io/java/hello.txt\"); fr = new FileReader(file); char[] cbuf = new char[8]; int len; while ((len = fr.read(cbuf)) != -1) { // Every time it reads chars if size of cbuf for (int i = 0; i ","date":"2022-01-09","objectID":"/javase/:2:8","series":[],"tags":["Java"],"title":"JavaSE","uri":"/javase/#file"},{"categories":["Note"],"content":"IO Stream File /* * An object of a File class can be a file or a file directory * java.io * */ import org.testng.annotations.Test; import java.io.File; public class Files { @Test public void Test1(){ File file = new File(\".\" + File.pathSeparator + \"hello.txt\"); File dir = new File(\".\", \"Hey_dir\"); File file1 = new File(dir, \"yo.txt\"); } } String getAbsolutePath() String getPath() String getName() String getParent() long length() long lastModified() String[] list() File[] listFiles() boolean renameTo(File dest): rename to a new path boolean isDirectory() boolean isFile() boolean exists() boolean canRead() boolean canWrite() boolean isHidden() boolean createNewFile() boolean mkdir() boolean mkdirs(): if parent path doesn’t exist, create it as well boolean delete(): if it’s a dir, there should not have any subdir or files in it! IO Stream Classify abstract base class bit stream byte stream input InputStream Reader output OutputStream Writer bit stream is good for pics, video, and audio… byte stream is good for text-based file 抽象基类 节点流(文件流) 缓冲流(处理流的一种) 转换流(处理流的一种) 打印流(same) 数据流 对象流 InputStream FileInputStream BufferedInputStream InputStreamReader NA DataInputStream ObjectInputStream OutputStream FileOutputStream BufferedReader OutputStreamWriter PrintStream DataOutputStream ObjectOutputStream Reader FileReader BufferedReader NA NA NA NA Writer FileWriter BufferedWriter NA PrintWriter NA NA RandomAccessFile can be both input and output long getFilePointer(): get the pointer void seek(long pos): set the position of the pointer import org.testng.annotations.Test; import javax.xml.namespace.QName; import java.io.*; import java.nio.charset.StandardCharsets; import java.util.Locale; /* * 根据操作数据单位：字节流，字符流 * 根据流向：输入流输出流 * 根据角色：节点流，处理流 * */ public class IOStream { @Test public void testFileReader(){ FileReader fr = null; try { // 1. create file object File file = new File(\"./src/io/java/hello.txt\"); // this file has to be existed, or it'll throw FileNotFoundException System.out.println(file.getAbsolutePath()); // 2. create a stream fr = new FileReader(file); // 3. read data // read() returns the char read in, if EOF return -1 int data; while ((data = fr.read()) != -1){ System.out.print((char)data); } } catch (IOException e) { e.printStackTrace(); } finally { // We have to ensure the stream got closed! // 4. close stream try { if (fr != null) fr.close(); // gc cannot close this, we have to do it manually } catch (IOException e) { e.printStackTrace(); } } } @Test public void testFileReaderUpgraded(){ FileReader fr = null; try { File file = new File(\"./src/io/java/hello.txt\"); fr = new FileReader(file); char[] cbuf = new char[8]; int len; while ((len = fr.read(cbuf)) != -1) { // Every time it reads chars if size of cbuf for (int i = 0; i ","date":"2022-01-09","objectID":"/javase/:2:8","series":[],"tags":["Java"],"title":"JavaSE","uri":"/javase/#io-stream-classify"},{"categories":["Note"],"content":"IO Stream File /* * An object of a File class can be a file or a file directory * java.io * */ import org.testng.annotations.Test; import java.io.File; public class Files { @Test public void Test1(){ File file = new File(\".\" + File.pathSeparator + \"hello.txt\"); File dir = new File(\".\", \"Hey_dir\"); File file1 = new File(dir, \"yo.txt\"); } } String getAbsolutePath() String getPath() String getName() String getParent() long length() long lastModified() String[] list() File[] listFiles() boolean renameTo(File dest): rename to a new path boolean isDirectory() boolean isFile() boolean exists() boolean canRead() boolean canWrite() boolean isHidden() boolean createNewFile() boolean mkdir() boolean mkdirs(): if parent path doesn’t exist, create it as well boolean delete(): if it’s a dir, there should not have any subdir or files in it! IO Stream Classify abstract base class bit stream byte stream input InputStream Reader output OutputStream Writer bit stream is good for pics, video, and audio… byte stream is good for text-based file 抽象基类 节点流(文件流) 缓冲流(处理流的一种) 转换流(处理流的一种) 打印流(same) 数据流 对象流 InputStream FileInputStream BufferedInputStream InputStreamReader NA DataInputStream ObjectInputStream OutputStream FileOutputStream BufferedReader OutputStreamWriter PrintStream DataOutputStream ObjectOutputStream Reader FileReader BufferedReader NA NA NA NA Writer FileWriter BufferedWriter NA PrintWriter NA NA RandomAccessFile can be both input and output long getFilePointer(): get the pointer void seek(long pos): set the position of the pointer import org.testng.annotations.Test; import javax.xml.namespace.QName; import java.io.*; import java.nio.charset.StandardCharsets; import java.util.Locale; /* * 根据操作数据单位：字节流，字符流 * 根据流向：输入流输出流 * 根据角色：节点流，处理流 * */ public class IOStream { @Test public void testFileReader(){ FileReader fr = null; try { // 1. create file object File file = new File(\"./src/io/java/hello.txt\"); // this file has to be existed, or it'll throw FileNotFoundException System.out.println(file.getAbsolutePath()); // 2. create a stream fr = new FileReader(file); // 3. read data // read() returns the char read in, if EOF return -1 int data; while ((data = fr.read()) != -1){ System.out.print((char)data); } } catch (IOException e) { e.printStackTrace(); } finally { // We have to ensure the stream got closed! // 4. close stream try { if (fr != null) fr.close(); // gc cannot close this, we have to do it manually } catch (IOException e) { e.printStackTrace(); } } } @Test public void testFileReaderUpgraded(){ FileReader fr = null; try { File file = new File(\"./src/io/java/hello.txt\"); fr = new FileReader(file); char[] cbuf = new char[8]; int len; while ((len = fr.read(cbuf)) != -1) { // Every time it reads chars if size of cbuf for (int i = 0; i ","date":"2022-01-09","objectID":"/javase/:2:8","series":[],"tags":["Java"],"title":"JavaSE","uri":"/javase/#nio"},{"categories":["Note"],"content":"Networking IO InetAddress class –\u003e IP loopback Internet protocol (IP) address: 127.0.0.1 –\u003e localhost Port num: 16-bit int 0-1023: for pre-defined services HTTP:80 FTP:21 Telnet:23 1024-49151: for apps or processes mysql:3306 Tomcat:8080 Oracle:1521 49152-65535: for dynamic or private ports The combination of port and IP –\u003e Socket import org.testng.annotations.Test; import java.net.InetAddress; import java.net.UnknownHostException; public class Networking { @Test public void testIP(){ try { InetAddress inet1 = InetAddress.getByName(\"192.168.1.189\"); System.out.println(inet1); InetAddress inet2 = InetAddress.getByName(\"www.google.com\"); System.out.println(inet2); // get local ip InetAddress inet3 = InetAddress.getLocalHost(); System.out.println(inet3); System.out.println(inet3.getHostName()); System.out.println(inet3.getHostAddress()); } catch (UnknownHostException e) { e.printStackTrace(); } } } ","date":"2022-01-09","objectID":"/javase/:2:9","series":[],"tags":["Java"],"title":"JavaSE","uri":"/javase/#networking-io"},{"categories":["Note"],"content":"Reflection (see another md file) import org.testng.annotations.Test; import java.io.InputStream; import java.lang.reflect.InvocationTargetException; import java.util.Properties; public class ReflectionTest { @Test public void testProps() throws Exception{ Properties props = new Properties(); ClassLoader classLoader = ReflectionTest.class.getClassLoader(); InputStream is = classLoader.getResourceAsStream(\"./jdbc.properties\"); // under the same dir of this class props.load(is); String user = props.getProperty(\"user\"); String password = props.getProperty(\"password\"); System.out.println(\"user = \" + user + \"\\npassword = \" + password); } @Test public void testInstance() throws NoSuchMethodException, InvocationTargetException, InstantiationException, IllegalAccessException { Class clazz = PersonType.class; // To use this way, the class has to have a public non-param constructor // the javabean needs a public non-param constructor so that the subclass can call super() when it extends this runtime class PersonType object = (PersonType) clazz.getDeclaredConstructor().newInstance(); System.out.println(object); } } class PersonType{ private String name; private int age; public PersonType(){} public PersonType(String name, int age){ this.name = name; this.age = age; } public String getName() { return name; } public void setName(String name) { this.name = name; } public int getAge() { return age; } public void setAge(int age) { this.age = age; } @Override public String toString() { return \"Person{\" + \"name='\" + name + '\\'' + \", age=\" + age + '}'; } } Dynamic Proxy import java.lang.reflect.InvocationHandler; import java.lang.reflect.Method; import java.lang.reflect.Proxy; public class DynamicProxy { public static void main(String[] args) { SuperMan superMan = new SuperMan(); Human proxyInstance = (Human) ProxyFactory.getProxyInstance(superMan); System.out.println(proxyInstance.getBelief()); proxyInstance.eat(\"Spicy soup!\"); } } interface Human{ String getBelief(); void eat(String food); } class SuperMan implements Human{ @Override public String getBelief() { return \"I believe I can fly!\"; } @Override public void eat(String food) { System.out.println(\"I love \" + food); } } class ProxyFactory{ public static Object getProxyInstance(Object obj){ MyInvocationHandler myInvocationHandler = new MyInvocationHandler(); myInvocationHandler.bind(obj); return Proxy.newProxyInstance(obj.getClass().getClassLoader(), obj.getClass().getInterfaces(), myInvocationHandler); } } class MyInvocationHandler implements InvocationHandler{ private Object obj; public void bind(Object obj){ this.obj = obj; } @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable { Object returnValue = method.invoke(obj, args); return returnValue; } } AOP import java.lang.reflect.InvocationHandler; import java.lang.reflect.Method; import java.lang.reflect.Proxy; public class DynamicProxy { public static void main(String[] args) { SuperMan superMan = new SuperMan(); Human proxyInstance = (Human) ProxyFactory.getProxyInstance(superMan); System.out.println(proxyInstance.getBelief()); proxyInstance.eat(\"Spicy soup!\"); } } class HumanUtil{ public void method1(){ System.out.println(\"method1\"); } public void method2(){ System.out.println(\"method2\"); } } interface Human{ String getBelief(); void eat(String food); } class SuperMan implements Human{ @Override public String getBelief() { return \"I believe I can fly!\"; } @Override public void eat(String food) { System.out.println(\"I love \" + food); } } class ProxyFactory{ public static Object getProxyInstance(Object obj){ MyInvocationHandler myInvocationHandler = new MyInvocationHandler(); myInvocationHandler.bind(obj); return Proxy.newProxyInstance(obj.getClass().getClassLoader(), obj.getClass().getInterfaces(), myInvocationHandler); } } class MyInvocationHandler implements InvocationHandler{ private Object obj; public void bind(Object obj){ this.obj = obj; } @Override public Object invoke(Object proxy, Method m","date":"2022-01-09","objectID":"/javase/:2:10","series":[],"tags":["Java"],"title":"JavaSE","uri":"/javase/#reflection-see-another-md-file"},{"categories":["Note"],"content":"Reflection (see another md file) import org.testng.annotations.Test; import java.io.InputStream; import java.lang.reflect.InvocationTargetException; import java.util.Properties; public class ReflectionTest { @Test public void testProps() throws Exception{ Properties props = new Properties(); ClassLoader classLoader = ReflectionTest.class.getClassLoader(); InputStream is = classLoader.getResourceAsStream(\"./jdbc.properties\"); // under the same dir of this class props.load(is); String user = props.getProperty(\"user\"); String password = props.getProperty(\"password\"); System.out.println(\"user = \" + user + \"\\npassword = \" + password); } @Test public void testInstance() throws NoSuchMethodException, InvocationTargetException, InstantiationException, IllegalAccessException { Class clazz = PersonType.class; // To use this way, the class has to have a public non-param constructor // the javabean needs a public non-param constructor so that the subclass can call super() when it extends this runtime class PersonType object = (PersonType) clazz.getDeclaredConstructor().newInstance(); System.out.println(object); } } class PersonType{ private String name; private int age; public PersonType(){} public PersonType(String name, int age){ this.name = name; this.age = age; } public String getName() { return name; } public void setName(String name) { this.name = name; } public int getAge() { return age; } public void setAge(int age) { this.age = age; } @Override public String toString() { return \"Person{\" + \"name='\" + name + '\\'' + \", age=\" + age + '}'; } } Dynamic Proxy import java.lang.reflect.InvocationHandler; import java.lang.reflect.Method; import java.lang.reflect.Proxy; public class DynamicProxy { public static void main(String[] args) { SuperMan superMan = new SuperMan(); Human proxyInstance = (Human) ProxyFactory.getProxyInstance(superMan); System.out.println(proxyInstance.getBelief()); proxyInstance.eat(\"Spicy soup!\"); } } interface Human{ String getBelief(); void eat(String food); } class SuperMan implements Human{ @Override public String getBelief() { return \"I believe I can fly!\"; } @Override public void eat(String food) { System.out.println(\"I love \" + food); } } class ProxyFactory{ public static Object getProxyInstance(Object obj){ MyInvocationHandler myInvocationHandler = new MyInvocationHandler(); myInvocationHandler.bind(obj); return Proxy.newProxyInstance(obj.getClass().getClassLoader(), obj.getClass().getInterfaces(), myInvocationHandler); } } class MyInvocationHandler implements InvocationHandler{ private Object obj; public void bind(Object obj){ this.obj = obj; } @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable { Object returnValue = method.invoke(obj, args); return returnValue; } } AOP import java.lang.reflect.InvocationHandler; import java.lang.reflect.Method; import java.lang.reflect.Proxy; public class DynamicProxy { public static void main(String[] args) { SuperMan superMan = new SuperMan(); Human proxyInstance = (Human) ProxyFactory.getProxyInstance(superMan); System.out.println(proxyInstance.getBelief()); proxyInstance.eat(\"Spicy soup!\"); } } class HumanUtil{ public void method1(){ System.out.println(\"method1\"); } public void method2(){ System.out.println(\"method2\"); } } interface Human{ String getBelief(); void eat(String food); } class SuperMan implements Human{ @Override public String getBelief() { return \"I believe I can fly!\"; } @Override public void eat(String food) { System.out.println(\"I love \" + food); } } class ProxyFactory{ public static Object getProxyInstance(Object obj){ MyInvocationHandler myInvocationHandler = new MyInvocationHandler(); myInvocationHandler.bind(obj); return Proxy.newProxyInstance(obj.getClass().getClassLoader(), obj.getClass().getInterfaces(), myInvocationHandler); } } class MyInvocationHandler implements InvocationHandler{ private Object obj; public void bind(Object obj){ this.obj = obj; } @Override public Object invoke(Object proxy, Method m","date":"2022-01-09","objectID":"/javase/:2:10","series":[],"tags":["Java"],"title":"JavaSE","uri":"/javase/#dynamic-proxy"},{"categories":["Note"],"content":"Reflection (see another md file) import org.testng.annotations.Test; import java.io.InputStream; import java.lang.reflect.InvocationTargetException; import java.util.Properties; public class ReflectionTest { @Test public void testProps() throws Exception{ Properties props = new Properties(); ClassLoader classLoader = ReflectionTest.class.getClassLoader(); InputStream is = classLoader.getResourceAsStream(\"./jdbc.properties\"); // under the same dir of this class props.load(is); String user = props.getProperty(\"user\"); String password = props.getProperty(\"password\"); System.out.println(\"user = \" + user + \"\\npassword = \" + password); } @Test public void testInstance() throws NoSuchMethodException, InvocationTargetException, InstantiationException, IllegalAccessException { Class clazz = PersonType.class; // To use this way, the class has to have a public non-param constructor // the javabean needs a public non-param constructor so that the subclass can call super() when it extends this runtime class PersonType object = (PersonType) clazz.getDeclaredConstructor().newInstance(); System.out.println(object); } } class PersonType{ private String name; private int age; public PersonType(){} public PersonType(String name, int age){ this.name = name; this.age = age; } public String getName() { return name; } public void setName(String name) { this.name = name; } public int getAge() { return age; } public void setAge(int age) { this.age = age; } @Override public String toString() { return \"Person{\" + \"name='\" + name + '\\'' + \", age=\" + age + '}'; } } Dynamic Proxy import java.lang.reflect.InvocationHandler; import java.lang.reflect.Method; import java.lang.reflect.Proxy; public class DynamicProxy { public static void main(String[] args) { SuperMan superMan = new SuperMan(); Human proxyInstance = (Human) ProxyFactory.getProxyInstance(superMan); System.out.println(proxyInstance.getBelief()); proxyInstance.eat(\"Spicy soup!\"); } } interface Human{ String getBelief(); void eat(String food); } class SuperMan implements Human{ @Override public String getBelief() { return \"I believe I can fly!\"; } @Override public void eat(String food) { System.out.println(\"I love \" + food); } } class ProxyFactory{ public static Object getProxyInstance(Object obj){ MyInvocationHandler myInvocationHandler = new MyInvocationHandler(); myInvocationHandler.bind(obj); return Proxy.newProxyInstance(obj.getClass().getClassLoader(), obj.getClass().getInterfaces(), myInvocationHandler); } } class MyInvocationHandler implements InvocationHandler{ private Object obj; public void bind(Object obj){ this.obj = obj; } @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable { Object returnValue = method.invoke(obj, args); return returnValue; } } AOP import java.lang.reflect.InvocationHandler; import java.lang.reflect.Method; import java.lang.reflect.Proxy; public class DynamicProxy { public static void main(String[] args) { SuperMan superMan = new SuperMan(); Human proxyInstance = (Human) ProxyFactory.getProxyInstance(superMan); System.out.println(proxyInstance.getBelief()); proxyInstance.eat(\"Spicy soup!\"); } } class HumanUtil{ public void method1(){ System.out.println(\"method1\"); } public void method2(){ System.out.println(\"method2\"); } } interface Human{ String getBelief(); void eat(String food); } class SuperMan implements Human{ @Override public String getBelief() { return \"I believe I can fly!\"; } @Override public void eat(String food) { System.out.println(\"I love \" + food); } } class ProxyFactory{ public static Object getProxyInstance(Object obj){ MyInvocationHandler myInvocationHandler = new MyInvocationHandler(); myInvocationHandler.bind(obj); return Proxy.newProxyInstance(obj.getClass().getClassLoader(), obj.getClass().getInterfaces(), myInvocationHandler); } } class MyInvocationHandler implements InvocationHandler{ private Object obj; public void bind(Object obj){ this.obj = obj; } @Override public Object invoke(Object proxy, Method m","date":"2022-01-09","objectID":"/javase/:2:10","series":[],"tags":["Java"],"title":"JavaSE","uri":"/javase/#aop"},{"categories":["Note"],"content":"Java 8 Features ","date":"2022-01-09","objectID":"/javase/:3:0","series":[],"tags":["Java"],"title":"JavaSE","uri":"/javase/#java-8-features"},{"categories":["Note"],"content":"Lambda import org.testng.annotations.Test; import java.net.InetAddress; import java.util.Comparator; public class LambdaTest { @Test public void test1(){ java.lang.Runnable r1 = new java.lang.Runnable() { @Override public void run() { System.out.println(\"Yes!\"); } }; r1.run(); System.out.println(\"-------------------------------------\"); java.lang.Runnable r2 = () -\u003e System.out.println(\"Yes!!!\"); r2.run(); } @Test public void test2(){ Comparator\u003cInteger\u003e com1 = new Comparator\u003cInteger\u003e() { @Override public int compare(Integer o1, Integer o2) { return 0; } }; int res1 = com1.compare(12,21); System.out.println(res1); System.out.println(\"-------------------------------------\"); // lambda Comparator\u003cInteger\u003e com2 = (o1,o2) -\u003e Integer.compare(o1,o2); System.out.println(com2.compare(32,21)); System.out.println(\"-------------------------------------\"); // method ref Comparator\u003cInteger\u003e com3 = Integer :: compare; System.out.println(com3.compare(56,51)); } } ","date":"2022-01-09","objectID":"/javase/:3:1","series":[],"tags":["Java"],"title":"JavaSE","uri":"/javase/#lambda"},{"categories":["Note"],"content":"Functional Interface @FunctionalInterface The interface that only have 1 method Lambda –\u003e the instance of Functional interface Consumer\u003cT\u003e --\u003e void accept\u003cT t\u003e Supplier\u003cT\u003e --\u003e T get() Function\u003cT,R\u003e --\u003e R apply(T t) Predicate\u003cT\u003e --\u003e boolean test(T t) … @Test public void test3(){ happyTime(400, money -\u003e System.out.println(\"Bought a bottle of water...\")); } public void happyTime(double money, Consumer\u003cDouble\u003e consumer){ consumer.accept(money); } @Test public void test4(){ List\u003cString\u003e list = Arrays.asList(\"NY\", \"FL\", \"TX\", \"CA\", \"NC\"); List\u003cString\u003e c = filterString(list, s -\u003e s.contains(\"C\")); System.out.println(c); } public List\u003cString\u003e filterString(List\u003cString\u003e list, Predicate\u003cString\u003e predicate){ ArrayList\u003cString\u003e filterList = new ArrayList\u003c\u003e(); for (String s : list) { if (predicate.test(s)){ filterList.add(s); } } return filterList; } ","date":"2022-01-09","objectID":"/javase/:3:2","series":[],"tags":["Java"],"title":"JavaSE","uri":"/javase/#functional-interface"},{"categories":["Note"],"content":"Method Reference (constructor, array) When the function passed to lambda has had an implementation, we can use method ref // param type and return type must be same! @Test public void test5(){ // object :: non-static method // Consumer --\u003e void accept(T t) // PrintStream --\u003e void println(T t) PrintStream ps = System.out; Consumer\u003cString\u003e con1 = ps::println; con1.accept(\"New York\"); // Supplier --\u003e T get() // Employee --\u003e String getName() Employee emp = new Employee(1001, \"Tom\", 23, 5600); Supplier\u003cString\u003e sup = emp::getName; System.out.println(sup.get()); // class :: static method --\u003e t1 must be the caller, and the method has a param t2 // Comparator --\u003e int compare(T t1, T t2) // Integer --\u003e int compare(T t1, T t2) Comparator\u003cInteger\u003e com1 = Integer::compare; System.out.println(com1.compare(1,2)); // class :: method instance // Comparator --\u003e int compare(T t1, T t2) // String -\u003e int t1.compareTo(t2) Comparator\u003cString\u003e com2 = String::compareTo; System.out.println(com2.compare(\"Dam\",\"Dan\")); } @Test public void test6(){ // constructor ref // Supplier --\u003e T get() // Employee --\u003e default constructor Supplier\u003cEmployee\u003e sup1 = Employee::new; // array ref // Function --\u003e R apply(T t) // Function\u003cInteger, Double[]\u003e func1 = Double[]::new; Double[] arr1 = func1.apply(10); System.out.println(Arrays.toString(arr1)); } class Employee{ int id; public String name; public int age; public int salary; public Employee(int id, String name, int age, int salary){ this.age = age; this.name = name; this.salary = salary; } public String getName() { return name; } } ","date":"2022-01-09","objectID":"/javase/:3:3","series":[],"tags":["Java"],"title":"JavaSE","uri":"/javase/#method-reference-constructor-array"},{"categories":["Note"],"content":"Stream API Stream API is powerful in terms of operations on Collection. Stream doesn’t store data Stream doesn’t change to original data stream only execute when the result is needed –\u003e lazy mode Create Stream –\u003e Intermediate Ops –\u003e Termination import org.testng.annotations.Test; import java.util.*; import java.util.function.ToIntFunction; import java.util.stream.Collector; import java.util.stream.Collectors; import java.util.stream.IntStream; import java.util.stream.Stream; public class StreamTest { // 1. Creation @Test public void test(){ List\u003cString\u003e list = new ArrayList\u003c\u003e(); // through Collection Stream\u003cString\u003e stream = list.stream(); Stream\u003cString\u003e parallelStream = list.parallelStream(); // read at a time, does not ensure the order // through Arrays --\u003e static \u003cT\u003e Stream\u003cT\u003e stream(T[] array) int[] arr = new int[]{1,2,3,4,5,6}; IntStream stream1 = Arrays.stream(arr); // through Stream's of() Stream\u003cInteger\u003e integerStream = Stream.of(1, 2, 3, 4, 5, 6, 7, 8); // infinite stream // public static\u003cT\u003e Stream\u003cT\u003e iterator(final T seed, final UnaryOperator\u003cT\u003e f) Stream.iterate(0, t -\u003e t+2).limit(10).forEach(System.out::println); //public static\u003cT\u003e Stream\u003cT\u003e generate(Supplier\u003cT\u003e s) Stream.generate(Math::random).limit(10).forEach(System.out::println); } // 2. intermediate // filter(Predicate p) --\u003e receive Lambda, filter out some elements // limit(n) --\u003e cut off stream, the elements will not exceed a critical val // skip(n) --\u003e skip element, return a stream discarding the first n elements, if there are less than n elements, return a empty stream // distinct() --\u003e filter, use hashCode() equals() to get distinct elements @Test public void test2(){ List\u003cString\u003e list = new ArrayList\u003c\u003e(); Stream\u003cString\u003e stream = list.stream(); stream.filter(e -\u003e e.length() \u003e 10).forEach(System.out::println); stream = list.stream(); stream.limit(10).forEach(System.out::println); stream = list.stream(); stream.skip(5).forEach(System.out::println); stream = list.stream(); stream.distinct().forEach(System.out::println); } // map(Function f) // flatMap(Function f) @Test public void test3(){ List\u003cString\u003e list = Arrays.asList(\"aa\", \"bb\", \"cc\", \"dd\"); list.stream().map(str -\u003e str.toUpperCase()).forEach(System.out::println); list.stream().flatMap(StreamTest::fromStringToStream).forEach(System.out::println); } static Stream\u003cCharacter\u003e fromStringToStream(String str){ List\u003cCharacter\u003e list = new ArrayList\u003c\u003e(); for (Character c : str.toCharArray()){ list.add(c); } return list.stream(); } // sorted() // sorted(Comparator com) @Test public void test4(){ // the class need to implement the corresponding interface } // 3. Termination // allMatch(Predicate p) // anyMatch(Predicate p) // noneMatch(Predicate p) // findFirst(Predicate p) // findAny(Predicate p) // count // max(Comparator c) // min(Comparator c) // forEach(Consumer c) @Test public void test5(){ } // reduce(T identity, BinaryOperator b) --\u003e combine the elements in stream repeatedly, return T // reduce(BinaryOperator b) --\u003e combine the elements in stream repeatedly, return Optional\u003cT\u003e @Test public void test6(){ List\u003cInteger\u003e list = Arrays.asList(1,2,3,4,5,6,7,8,9,0,10); Integer sum = list.stream().reduce(0, Integer::sum); System.out.println(sum); Optional\u003cInteger\u003e sum1 = list.stream().reduce(Integer::sum); System.out.println(sum1); } // collect(Collector c) --\u003e convert stream to another form @Test public void test7(){ List\u003cInteger\u003e list = Arrays.asList(1,2,3,4,5,6,7,8,9,0,10,1,1,2); Set\u003cInteger\u003e set = list.stream().collect(Collectors.toSet()); System.out.println(set); Double collect = list.stream().collect(Collectors.averagingInt(i -\u003e i * i)); System.out.println(collect); } } ","date":"2022-01-09","objectID":"/javase/:3:4","series":[],"tags":["Java"],"title":"JavaSE","uri":"/javase/#stream-api"},{"categories":["Note"],"content":"Optional class @Test public void test8(){ List\u003cInteger\u003e list = Arrays.asList(1,2,3,4,5,6,7); Optional\u003cList\u003cInteger\u003e\u003e optionalIntegers = Optional.of(list); System.out.println(optionalIntegers); list = null; // Optional\u003cList\u003cInteger\u003e\u003e optional = Optional.of(list); of(T t) --\u003e t cannot be null } // Avoid NullPointerException public String getStr(String str){ Optional\u003cString\u003e optionalStr = Optional.ofNullable(str); String res = optionalStr.orElse(\"You got a NULL!\"); return res; } optionalData.get() –\u003e must make sure it’s not null ","date":"2022-01-09","objectID":"/javase/:3:5","series":[],"tags":["Java"],"title":"JavaSE","uri":"/javase/#optional-class"},{"categories":["Note"],"content":"JDK 9-11 JDK 9 Modules jShell private method in interfaces diamond operator try String –\u003e from store as char[] to store as byte[] of() enhanced Stream API new HTTP client API javadoc support HTML5 Deprecated API Nashorm dynamic compiler JDK 10 –\u003e local var type inference JDK 11 –\u003e ZGC ","date":"2022-01-09","objectID":"/javase/:4:0","series":[],"tags":["Java"],"title":"JavaSE","uri":"/javase/#jdk-9-11"},{"categories":["Note"],"content":"浏览器 ｜ 表示层-\u003e 视图层-\u003e HTML5/CSS/JS/JSP ｜ -\u003e 控制层-\u003e Servlet/Action/Handler ｜ 业务逻辑层(Spring IOC AOP) ｜ 持久化层(JDBC/DBUtils/Spring JDBCTemplate/Hibernate/MyBatis) ｜ DB(MySQL/Oracle) 目前的问题： 一个项目就是一个工程 如果一个项目非常庞大，就不适合继续使用package来划分模块。最好是每一个模块对应一个工程，利于协作分工。借助于Maven就可以将一个项目拆分成多个工程，工程之间可以互相访问沟通。 项目中需要的jar包必须手动复制粘贴到WEB-INF/lib目录下 同样的jar包重复出现在不同的工程中。臃肿不轻巧。 Maven可以让jar包仅仅保存在仓库中，让有需要的工程引用这个文件接口，不需要把jar包复制过来。 jar包需要别人替我们准备好或到官网下载 不同技术的官网提供jar包下载的形式是五花八门的。 有些技术的官网就是通过Maven或SVN等专门的工具来提供下载。 如果是以非正规方式下载的jar包，内容也可能不规范。 借助Maven可以用一种规范的方式下载jar包。因为所有知名框架或第三方工具的jar包以及按照统一的规范存放在了Maven的中央仓库中。 一个jar包的依赖需要自己手动加入到项目中 ","date":"2022-01-09","objectID":"/maven/:0:0","series":[],"tags":["Maven"],"title":"Maven","uri":"/maven/#"},{"categories":["Note"],"content":"Maven clean –\u003e compile –\u003e compile-test –\u003e package –\u003e install –\u003e deploy clean compile test-compile package: 打包 install: 将打包得到的文件安装到仓库 deploy: 将动态Web工程生成的war包复制到Servlet容器的指定目录下，使其可以运行 ","date":"2022-01-09","objectID":"/maven/:0:0","series":[],"tags":["Maven"],"title":"Maven","uri":"/maven/#maven"},{"categories":["Note"],"content":"POM (Project Object Model) DOM(Document Object Model) ","date":"2022-01-09","objectID":"/maven/:1:0","series":[],"tags":["Maven"],"title":"Maven","uri":"/maven/#pom-project-object-model"},{"categories":["Note"],"content":"Coordinates GAV: groupid: com.myteam.projectName artifactid: moduleName version: 1.0.0 \u003cgroupId\u003e org.springframework\u003c/groupId\u003e \u003cartifactId\u003espring-core\u003c/artifactId\u003e \u003cversion\u003e4.0.0.RELEASE\u003c/version\u003e The path of the module will be: org/springframework/spring-core/4.0.0.RELEASE/spring-core-4.0.0.RELEASE.jar ","date":"2022-01-09","objectID":"/maven/:2:0","series":[],"tags":["Maven"],"title":"Maven","uri":"/maven/#coordinates"},{"categories":["Note"],"content":"Repo local repository: ~/.m2 by default remote repository private(LAN) –\u003e usually refer to Nexus central(on Internet, for worldwide Maven services) central mirror(to release the press of central) First check of the module is in Nexus, if not, go to Maven Central to download to Nexus. What’s in the repo? plug-ins of Maven jar of 3rd party tool or framework the maven project built by ourselves ","date":"2022-01-09","objectID":"/maven/:3:0","series":[],"tags":["Maven"],"title":"Maven","uri":"/maven/#repo"},{"categories":["Note"],"content":"Dependency While compiling, Maven will try to find the dependencies in local repo, it will fail if they are not there. Use install command. Scope compile –\u003e main and test –\u003e will be in the package test –\u003e test –\u003e will not be in the package provided –\u003e main and test –\u003e will not be in the package (only participate development, will not participate deploy and run, for the run stage, the server will provide the module) ","date":"2022-01-09","objectID":"/maven/:4:0","series":[],"tags":["Maven"],"title":"Maven","uri":"/maven/#dependency"},{"categories":["Note"],"content":"Lifecycle Clean Lifecycle pre-clean clean post-clean Default Lifecycle: core part, which responsiable for compile, test, package, install, and deploy… pre-default default post-default Site Lifecycle: generate project report, site, and release site pre-site site post-site We can do mvn clean install site for everything in one time. ","date":"2022-01-09","objectID":"/maven/:5:0","series":[],"tags":["Maven"],"title":"Maven","uri":"/maven/#lifecycle"},{"categories":["Note"],"content":"Plug-in and Goal Lifecycle Goal Plug-in compile compile maven-compile-plugin test-compile testCompile maven-compile-plugin The phases of lifecycle define the tasks to execute. The phase and the goal of plug-in is corresponding. Similar goal will use a specific plug-in to achieve. We can see goals as commands to invoke the plug-in functions. ","date":"2022-01-09","objectID":"/maven/:6:0","series":[],"tags":["Maven"],"title":"Maven","uri":"/maven/#plug-in-and-goal"},{"categories":["Note"],"content":"Advanced Dependency Transitivity test and provided scope’s dependencies cannot transmit A depends on X, B depends on A, then B will include X Exclude a dependency (only work in the current proj and all sub projs) \u003cexclusions\u003e \u003cexclusion\u003e \u003cgroupId\u003ecommons-logging\u003c/gourpId\u003e \u003cartifactId\u003ecommons-logging\u003c/artifactId\u003e \u003c/exclusion\u003e \u003c/exclusions\u003e A –\u003e B –\u003e C log4j.1.2.1? log4j.1.2.14 log4j.1.2.17 If A depends on B and B depends on C, C use 17 and B use 14, what does A use by default? 14, since the path is nearer! A -\u003e B -\u003e log4j.1.2.14 == 2 A -\u003e B -\u003e C -\u003e log4j.1.2.17 == 3 But what if B and C have the same length of path? Then it’s decided by the order of the declaration in A, for example, if B is declared first, then A goes with B’s log4j’s version. Version Managment How to upgrade to several module from version 1.0.0 to 2.0.0? use properties tag then reference it at where you need it \u003cproperties\u003e \u003ccom.ace.spring.version\u003e5.0.0.RELEASE\u003c/com.ace.spring.version\u003e \u003c/properties\u003e ... \u003cversion\u003e${com.ace.spring.version}\u003c/version\u003e ... ","date":"2022-01-09","objectID":"/maven/:7:0","series":[],"tags":["Maven"],"title":"Maven","uri":"/maven/#advanced-dependency"},{"categories":["Note"],"content":"Inheritence Case: A –\u003e junit4.0 B –\u003e junit4.0 C –\u003e junit4.9 How to manage the version of all junit? (Notice that module in test scope cannot transit to others) Set the dependency in the higher level proj, and do not set it again in current level projs. Create a Maven proj, here we call it S. (Notice: Packaging tag must be POM) Let all sub projs depends on S Delete all duplicated coordinates between proj and its super-proj S Use properties tag to manage junit Delete the junit version tag in all S' sub classes \u003c!-- This is the pom.xml in sub classes of S --\u003e \u003cparent\u003e \u003c!-- Here is the super proj's coordinate --\u003e \u003cgourpId\u003ecom.ace.myProj.maven\u003c/groupId\u003e \u003cartifactId\u003eParent\u003c/artifactId\u003e \u003cversion\u003e0.0.1-SNAPSHOT\u003c/version\u003e \u003c!-- relative path starting from this proj --\u003e \u003crelativePath\u003e../Parent/pom.xml\u003c/relativePath\u003e \u003c/parent\u003e ```xml \u003c!-- This is the pom.xml of S --\u003e \u003cdependencyManagement\u003e \u003cdependencies\u003e \u003cdependency\u003e \u003cgroupId\u003ejunit\u003c/groupId\u003e \u003cartifactId\u003ejunit\u003c/artifactId\u003e \u003cversion\u003e4.9\u003c/version\u003e \u003cscope\u003etest\u003c/scope\u003e \u003c/dependency\u003e \u003c/dependencies\u003e \u003c/dependencyManagement\u003e ","date":"2022-01-09","objectID":"/maven/:8:0","series":[],"tags":["Maven"],"title":"Maven","uri":"/maven/#inheritence"},{"categories":["Note"],"content":"Aggregation You have to install the super proj before install the current one! Can we have a one-stop solution? \u003c!-- Aggregation config --\u003e \u003cmodules\u003e \u003cmodule\u003e../A\u003c/module\u003e \u003cmodule\u003e../B\u003c/module\u003e \u003cmodule\u003e../C\u003c/module\u003e \u003c/modules\u003e Now we can just mvn install under the super proj path Notice: If the order doesn’t matter since Maven will figure it out. ","date":"2022-01-09","objectID":"/maven/:9:0","series":[],"tags":["Maven"],"title":"Maven","uri":"/maven/#aggregation"},{"categories":["Note"],"content":"Deploy Usually, we manually put it in Tomcat’s dir and use command catalina run to deploy. But NOW! \u003c!-- Special config during building --\u003e \u003cbuild\u003e \u003cfinalName\u003eTheBigWeb\u003c/finalName\u003e \u003c!-- plug-ins needed during building --\u003e \u003cplugins\u003e \u003cplugin\u003e \u003c!-- cargo is a company focus on booting Servlet containers --\u003e \u003c!-- https://mvnrepository.com/artifact/org.codehaus.cargo/cargo-core-uberjar --\u003e \u003cgroupId\u003eorg.codehaus.cargo\u003c/groupId\u003e \u003cartifactId\u003ecargo-core-uberjar\u003c/artifactId\u003e \u003cversion\u003e1.9.9\u003c/version\u003e \u003c!-- config for plugin --\u003e \u003cconfiguration\u003e \u003c!-- path for containers in curr sys --\u003e \u003ccontainer\u003e \u003ccontainerId\u003etomcat6x\u003c/containerId\u003e \u003chome\u003e~/Dev/testMavenCargoContainer\u003c/home\u003e \u003c/container\u003e \u003cconfiguration\u003e \u003ctype\u003eexisting\u003c/type\u003e \u003chome\u003e~/Dev/testMavenCargoContainer\u003c/home\u003e \u003c!-- if the Tomcat port is 8080 then we do not need this --\u003e \u003cproperties\u003e \u003ccargo.servlet.port\u003e8989\u003c/cargo.servlet.port\u003e \u003c/properties\u003e \u003c/configuration\u003e \u003c/configuration\u003e \u003c!-- config for when will this plugin run --\u003e \u003cexecutions\u003e \u003cexecution\u003e \u003cid\u003ecargo-run\u003c/id\u003e \u003cphase\u003einstall\u003c/phase\u003e \u003cgoals\u003e \u003cgoal\u003erun\u003c/goal\u003e \u003c/goals\u003e \u003c/execution\u003e \u003c/executions\u003e \u003c/plugin\u003e \u003c/plugins\u003e \u003c/build\u003e ","date":"2022-01-09","objectID":"/maven/:10:0","series":[],"tags":["Maven"],"title":"Maven","uri":"/maven/#deploy"},{"categories":["Note"],"content":"The Website! ","date":"2022-01-09","objectID":"/maven/:11:0","series":[],"tags":["Maven"],"title":"Maven","uri":"/maven/#the-websitehttpsmvnrepositorycom"},{"categories":["Note"],"content":"Serialization and Deserialization in Java ","date":"2022-01-09","objectID":"/serialization-java/:0:0","series":[],"tags":["Serialization"],"title":"Serialization","uri":"/serialization-java/#serialization-and-deserialization-in-java"},{"categories":["Note"],"content":"What 把Java对象转换为字节序列的过程———–\u003e 序列化 把字节序列恢复为Java对象的过程———–\u003e 反序列化 ","date":"2022-01-09","objectID":"/serialization-java/:0:1","series":[],"tags":["Serialization"],"title":"Serialization","uri":"/serialization-java/#what"},{"categories":["Note"],"content":"Why Java objects exist in the heap of JVM. They will be gone once JVM stops running. Thus, we have to store them in byte form for the purpose of persistency or tranferring to remote machines. ","date":"2022-01-09","objectID":"/serialization-java/:0:2","series":[],"tags":["Serialization"],"title":"Serialization","uri":"/serialization-java/#why"},{"categories":["Note"],"content":"Functions Release the pressure of the memory and enhance data persistency. Make the transportation of java objects on Internet possible. ","date":"2022-01-09","objectID":"/serialization-java/:0:3","series":[],"tags":["Serialization"],"title":"Serialization","uri":"/serialization-java/#functions"},{"categories":["Note"],"content":"APIs java.io.Serializable java.io.Externalizable writeExternal() readExternal() java.io.ObjectOutputStream java.io.ObjectInputSream ","date":"2022-01-09","objectID":"/serialization-java/:0:4","series":[],"tags":["Serialization"],"title":"Serialization","uri":"/serialization-java/#apis"},{"categories":["Note"],"content":"Code ref ","date":"2022-01-09","objectID":"/serialization-java/:0:5","series":[],"tags":["Serialization"],"title":"Serialization","uri":"/serialization-java/#code"},{"categories":["Music"],"content":"Wing Wing –by Hyukoh pi teul bi teul keo leo ga neun na e ta li o neul do ui mi eom neun do ha lu ga heul leo ga jyo sa sang do gi li gi li ha neun geo la min neun na neun com ceo leom tu geun du geun geo lil yi li ceo nyeo eop jyo wing ying wing ying ha lu sa li do ceo lyang han na leul pi wut deu xi meol li na la ga jyo pi ying pi ying to la ga neun se sang do na leul pi wut deu xi kye sok gum teul dae jyo tell me tell me, please don’t tell ca la li teut ji mo tan pyeo ni nae gen co eul geo ya tell me tell me, please don’t tell ca la li po ji mo tan pyeo ni nae gen co eul geo ya ai ai ai ai … sam lam deul puk zeok dae neun cul geun gi le qi ha ceo len com ceo leom ka deu jik go ta bol yi li ceo nyeo eop jyo qi be seo twing gul dwing gul ha li leop seo pin dung dae neun nae mo seum neo mu co la hae seo ceong mal coe song ha jyo wing ying wing ying ha lu sa li do ceo lyang han na leul pi wut deu xi meol li na la ga jyo pi ying bi ying to la ga neun se sang do na leul pi wut deu xi kye sok gum teul dae jyo sae aeng sae aeng kal ba lam do sang ceo nan nae ma eu meul eo zeo ji neun mo tal geo ya du wuk du wuk deo leo ji neun nun mu li eon zen ga neun yi se sang eul teo peul geo ya tell me tell me, please don’t tell ca la li teut ji mo tan pyeo ni ne gen co eul geo ya tell me tell me, please don’t tell ca la li po ji mo tan pyeo ni ne gen co eul geo ya tell me tell me, please don’t tell ca la li neu gyeo bo ji mo tan pyeo ni co eul geo ya tell me tell me, please don’t tell ca la li sa la bo ji mo tan pyeo ni co eul geo ya First four lines again wing ying… ","date":"2022-01-09","objectID":"/wing-wing-lyrics/:0:0","series":[],"tags":["Hyukoh"],"title":"Wiing Wiing","uri":"/wing-wing-lyrics/#wing-wing---by-hyukoh"},{"categories":["Note"],"content":"设计模式 Watch the Video Watch the Video2 ","date":"2022-01-09","objectID":"/design-pattern-cn/:0:0","series":[],"tags":["Design Pattern"],"title":"设计模式","uri":"/design-pattern-cn/#设计模式"},{"categories":["Note"],"content":"设计模式： 模式名称 问题，或应用范围 解决方案 效果及其权衡（优缺点） 创建型模式： 单例模式， 工厂模式，抽象工厂模式，建造者模式，原型模式 结构型模式： 适配器模式，桥接模式，装饰模式，组合模式，外观模式， 享元模式，代理模式 行为型模式： 模板方法模式，命令模式，迭代器模式，观察者模式，中介者模式，备忘录模式，解释器模式，状态模式，策略模式，职责链模式，访问者模式 ","date":"2022-01-09","objectID":"/design-pattern-cn/:0:1","series":[],"tags":["Design Pattern"],"title":"设计模式","uri":"/design-pattern-cn/#设计模式-1"},{"categories":["Note"],"content":"设计模式： 模式名称 问题，或应用范围 解决方案 效果及其权衡（优缺点） 创建型模式： 单例模式， 工厂模式，抽象工厂模式，建造者模式，原型模式 结构型模式： 适配器模式，桥接模式，装饰模式，组合模式，外观模式， 享元模式，代理模式 行为型模式： 模板方法模式，命令模式，迭代器模式，观察者模式，中介者模式，备忘录模式，解释器模式，状态模式，策略模式，职责链模式，访问者模式 ","date":"2022-01-09","objectID":"/design-pattern-cn/:0:1","series":[],"tags":["Design Pattern"],"title":"设计模式","uri":"/design-pattern-cn/#创建型模式"},{"categories":["Note"],"content":"设计模式： 模式名称 问题，或应用范围 解决方案 效果及其权衡（优缺点） 创建型模式： 单例模式， 工厂模式，抽象工厂模式，建造者模式，原型模式 结构型模式： 适配器模式，桥接模式，装饰模式，组合模式，外观模式， 享元模式，代理模式 行为型模式： 模板方法模式，命令模式，迭代器模式，观察者模式，中介者模式，备忘录模式，解释器模式，状态模式，策略模式，职责链模式，访问者模式 ","date":"2022-01-09","objectID":"/design-pattern-cn/:0:1","series":[],"tags":["Design Pattern"],"title":"设计模式","uri":"/design-pattern-cn/#结构型模式"},{"categories":["Note"],"content":"设计模式： 模式名称 问题，或应用范围 解决方案 效果及其权衡（优缺点） 创建型模式： 单例模式， 工厂模式，抽象工厂模式，建造者模式，原型模式 结构型模式： 适配器模式，桥接模式，装饰模式，组合模式，外观模式， 享元模式，代理模式 行为型模式： 模板方法模式，命令模式，迭代器模式，观察者模式，中介者模式，备忘录模式，解释器模式，状态模式，策略模式，职责链模式，访问者模式 ","date":"2022-01-09","objectID":"/design-pattern-cn/:0:1","series":[],"tags":["Design Pattern"],"title":"设计模式","uri":"/design-pattern-cn/#行为型模式"},{"categories":["Note"],"content":"OOP七大原则： 开闭原则： 对扩展开放，对修改关闭 里氏替换原则： 继承必须确保超类所拥有的性质在子类中仍然成立。（”正方形不是长方形”） 依赖倒置原则： 要面向接口编程，不要面向实现编程。（高层的模块不应该依赖低层的模块，依赖抽象，不依赖细节） 单一职责原则： 控制类的粒度大小，将对象解耦，提高其内聚性。（一个对象不应该承担过多的职责，一个方法最好做好一件事，原子性。） 接口隔离原则： 要为各个类建立它们需要的专用接口。 迪米特法则： 只与你的朋友交谈，不跟陌生人交谈。（A–\u003eB–\u003eC，A与C不要通信，以此降低类之间的耦合性，提高模块的独立性，但是弊端是会产生中间件和提高系统复杂性，要权衡。） 合成复用原则： 尽量先使用组合或者聚合等关联关系来实现，其次才考虑使用继承关系来实现。（区分has a和is a的关系，首先用has a的关系来解决，如果要使用继承的关系，就要确保原则2。原则2和7实际是原则1的具体规范。） ","date":"2022-01-09","objectID":"/design-pattern-cn/:0:2","series":[],"tags":["Design Pattern"],"title":"设计模式","uri":"/design-pattern-cn/#oop七大原则"},{"categories":["Note"],"content":"单例模式-Singleton ","date":"2022-01-09","objectID":"/design-pattern-cn/:1:0","series":[],"tags":["Design Pattern"],"title":"设计模式","uri":"/design-pattern-cn/#单例模式-singleton"},{"categories":["Note"],"content":"核心作用 保证一个类只有一个实例，并且提供一个访问该实例的全局访问点。 ","date":"2022-01-09","objectID":"/design-pattern-cn/:1:1","series":[],"tags":["Design Pattern"],"title":"设计模式","uri":"/design-pattern-cn/#核心作用"},{"categories":["Note"],"content":"常见场景 Windows的任务管理器 Windows回收站 项目中，读取配置文件的类，一般也只有一个对象，没必要每次都去new对象读取 网站的计数器一般也会采用单例模式，可以保证同步 数据库连接池的设计一般也是单例模式 在Servlet编程中，每个Servlet也是单例的 在Spring中，每个Bean默认的就是单例 ","date":"2022-01-09","objectID":"/design-pattern-cn/:1:2","series":[],"tags":["Design Pattern"],"title":"设计模式","uri":"/design-pattern-cn/#常见场景"},{"categories":["Note"],"content":"八种写法 先把构造方法设为私有。 private ClassName(); 饿汉式 类加载到内存后，就实例化一个单例，JVM保证线程安全。 简单实用，推荐。 唯一缺点： 不管你用到与否，类装载时就完成了实例化。 Class.forName(\"name\") 可以懒加载，但是一旦加载，实例化就完成了。 public static final ClassName INSTANCE = new ClassName(); public static ClassName getInstance() {return INSTANCE;} 懒汉式 达到了按需初始化的目的， 但是线程不安全。 private static ClassName INSTANCE; public static ClassName getInstance() { if (INSTANCE == null) { INSTANCE = new ClassName(); } } 当一个线程判断INSTANCE为空，但还没有创建实例的时候，另一个线程进入，也判断INSTANCE为空，并且创建了实例… 可以通过加锁来解决，但是效率会下降。 带有双重检查的懒汉式曾经被认为是最完美的方案。然而实际应用中，并不一定需要。 public static ClassName getInstance() { if (INSTANCE == null) { synchronized (ClassName.class) { try { ...; } catch (InterruptedException e) { e.printStackTrace(); } INSTANCE = new ClassName; } } return INSTANCE; } 静态内部类 JVM保证单例, JVM加载类的时候只加载一次。 加载外部类时不会加载内部类，这样可以实现懒加载。 这是另一种完美解法。 private static ClassNameHolder { private final static ClassName INSTANCE = new ClassName(); } public static ClassName getInstance() { return ClassNameHolder.INSTANCE; } Java 创始人在Effective Java中写的一种单例模式 不仅可以解决线程同步，还可以防止反序列化。 public enum ClassName { INSTANCE; public void methods() {} public static void main(String[] args) { for (int i = 0; i \u003c 100; i++) { new Thread(()-\u003e{ System.out.println(ClassName.INSTANCE.hashCode()); }).start(); } } } 为什么单例模式要防止反序列化？ Java的反射可以通过class文件，把class load到内存，并且new一个实例。 所以通过反序列化的方式，Java可以利用反射的特性，来制造实例。 在其他的写法中，阻止反序列化非常的繁琐。 枚举单例不会被反序列化的原因是： 枚举类没有构造方法！ 所以你就算拿到它的class也没法构造它的对象。 注： 枚举：通过反射破解枚举发现不成功： 1、普通的反编译会欺骗开发者，说enum枚举是无参构造 2、实际enum为有参构造（见后面）； 3、通过反射破解枚举会发现抛出异常 Exception in thread “main” java.lang.IllegalArgumentException: Cannot reflectively create enum objects at java.lang.reflect.Constructor.newInstance(Constructor.java:417) at com.ph.single.Test.main(EnumSingle.java:19) 讲解反射破坏 around 11:00 public class LazyMan { private LazyMan() {} private volatile static LazyMan lazyMan; } public static void main(String[] args) throws Exception { LazyMan instance = LazyMan.getInstance(); Constructor\u003cLazyMan\u003e declaredConstructor = LazyMan.class.getDeclaredConstructor(null); declaredConstructor.setAccessible(true); LazyMan instance2 = declaredConstructor.newInstance(); // 无视私有构造器 System.out.println(instance); System.out.println(instance2); } public class LazyMan { private LazyMan() { synchronized (LazyMan.class) { if (lazyMan != null) { throw new RuntimeException(\"不要试图使用反射破坏异常\"); } } } private volatile static LazyMan lazyMan; } public static void main(String[] args) throws Exception { LazyMan instance = LazyMan.getInstance(); // 由于此处使lazyMan不为空，上面防御手段生效 Constructor\u003cLazyMan\u003e declaredConstructor = LazyMan.class.getDeclaredConstructor(null); declaredConstructor.setAccessible(true); LazyMan instance2 = declaredConstructor.newInstance(); // 无视私有构造器 System.out.println(instance); System.out.println(instance2); } public class LazyMan { private LazyMan() { synchronized (LazyMan.class) { if (lazyMan != null) { throw new RuntimeException(\"不要试图使用反射破坏异常\"); } } } private volatile static LazyMan lazyMan; } public static void main(String[] args) throws Exception { Constructor\u003cLazyMan\u003e declaredConstructor = LazyMan.class.getDeclaredConstructor(null); declaredConstructor.setAccessible(true); LazyMan instance = declaredConstructor.newInstance(); // 无视私有构造器 LazyMan instance2 = declaredConstructor.newInstance(); // 现在我们没有通过getInstance()去出发懒汉式，new出来的对象的指针不会交给LazyMan System.out.println(instance); System.out.println(instance2); } public class LazyMan { private static boolean someKey = false; // 设置标志位 private LazyMan() { synchronized (LazyMan.class) { if (someKey == false) { someKey = true;} //当第一次构造之后，被标记 else { throw new RuntimeException(\"不要试图使用反射破坏异常\"); } } } private volatile static LazyMan lazyMan; } public static void main(String[] args) throws Exception { Constructor\u003cLazyMan\u003e declaredConstructor = LazyMan.class.getDeclaredConstructor(null); declaredConstructor.setAccessible(true); LazyMan instance = declaredConstructor.newInstance(); // 无视私有构造器 LazyMan instance2 = declaredConstructor.newInstance(); System.out.println(instanc","date":"2022-01-09","objectID":"/design-pattern-cn/:1:3","series":[],"tags":["Design Pattern"],"title":"设计模式","uri":"/design-pattern-cn/#八种写法"},{"categories":["Note"],"content":"八种写法 先把构造方法设为私有。 private ClassName(); 饿汉式 类加载到内存后，就实例化一个单例，JVM保证线程安全。 简单实用，推荐。 唯一缺点： 不管你用到与否，类装载时就完成了实例化。 Class.forName(\"name\") 可以懒加载，但是一旦加载，实例化就完成了。 public static final ClassName INSTANCE = new ClassName(); public static ClassName getInstance() {return INSTANCE;} 懒汉式 达到了按需初始化的目的， 但是线程不安全。 private static ClassName INSTANCE; public static ClassName getInstance() { if (INSTANCE == null) { INSTANCE = new ClassName(); } } 当一个线程判断INSTANCE为空，但还没有创建实例的时候，另一个线程进入，也判断INSTANCE为空，并且创建了实例… 可以通过加锁来解决，但是效率会下降。 带有双重检查的懒汉式曾经被认为是最完美的方案。然而实际应用中，并不一定需要。 public static ClassName getInstance() { if (INSTANCE == null) { synchronized (ClassName.class) { try { ...; } catch (InterruptedException e) { e.printStackTrace(); } INSTANCE = new ClassName; } } return INSTANCE; } 静态内部类 JVM保证单例, JVM加载类的时候只加载一次。 加载外部类时不会加载内部类，这样可以实现懒加载。 这是另一种完美解法。 private static ClassNameHolder { private final static ClassName INSTANCE = new ClassName(); } public static ClassName getInstance() { return ClassNameHolder.INSTANCE; } Java 创始人在Effective Java中写的一种单例模式 不仅可以解决线程同步，还可以防止反序列化。 public enum ClassName { INSTANCE; public void methods() {} public static void main(String[] args) { for (int i = 0; i { System.out.println(ClassName.INSTANCE.hashCode()); }).start(); } } } 为什么单例模式要防止反序列化？ Java的反射可以通过class文件，把class load到内存，并且new一个实例。 所以通过反序列化的方式，Java可以利用反射的特性，来制造实例。 在其他的写法中，阻止反序列化非常的繁琐。 枚举单例不会被反序列化的原因是： 枚举类没有构造方法！ 所以你就算拿到它的class也没法构造它的对象。 注： 枚举：通过反射破解枚举发现不成功： 1、普通的反编译会欺骗开发者，说enum枚举是无参构造 2、实际enum为有参构造（见后面）； 3、通过反射破解枚举会发现抛出异常 Exception in thread “main” java.lang.IllegalArgumentException: Cannot reflectively create enum objects at java.lang.reflect.Constructor.newInstance(Constructor.java:417) at com.ph.single.Test.main(EnumSingle.java:19) 讲解反射破坏 around 11:00 public class LazyMan { private LazyMan() {} private volatile static LazyMan lazyMan; } public static void main(String[] args) throws Exception { LazyMan instance = LazyMan.getInstance(); Constructor declaredConstructor = LazyMan.class.getDeclaredConstructor(null); declaredConstructor.setAccessible(true); LazyMan instance2 = declaredConstructor.newInstance(); // 无视私有构造器 System.out.println(instance); System.out.println(instance2); } public class LazyMan { private LazyMan() { synchronized (LazyMan.class) { if (lazyMan != null) { throw new RuntimeException(\"不要试图使用反射破坏异常\"); } } } private volatile static LazyMan lazyMan; } public static void main(String[] args) throws Exception { LazyMan instance = LazyMan.getInstance(); // 由于此处使lazyMan不为空，上面防御手段生效 Constructor declaredConstructor = LazyMan.class.getDeclaredConstructor(null); declaredConstructor.setAccessible(true); LazyMan instance2 = declaredConstructor.newInstance(); // 无视私有构造器 System.out.println(instance); System.out.println(instance2); } public class LazyMan { private LazyMan() { synchronized (LazyMan.class) { if (lazyMan != null) { throw new RuntimeException(\"不要试图使用反射破坏异常\"); } } } private volatile static LazyMan lazyMan; } public static void main(String[] args) throws Exception { Constructor declaredConstructor = LazyMan.class.getDeclaredConstructor(null); declaredConstructor.setAccessible(true); LazyMan instance = declaredConstructor.newInstance(); // 无视私有构造器 LazyMan instance2 = declaredConstructor.newInstance(); // 现在我们没有通过getInstance()去出发懒汉式，new出来的对象的指针不会交给LazyMan System.out.println(instance); System.out.println(instance2); } public class LazyMan { private static boolean someKey = false; // 设置标志位 private LazyMan() { synchronized (LazyMan.class) { if (someKey == false) { someKey = true;} //当第一次构造之后，被标记 else { throw new RuntimeException(\"不要试图使用反射破坏异常\"); } } } private volatile static LazyMan lazyMan; } public static void main(String[] args) throws Exception { Constructor declaredConstructor = LazyMan.class.getDeclaredConstructor(null); declaredConstructor.setAccessible(true); LazyMan instance = declaredConstructor.newInstance(); // 无视私有构造器 LazyMan instance2 = declaredConstructor.newInstance(); System.out.println(instanc","date":"2022-01-09","objectID":"/design-pattern-cn/:1:3","series":[],"tags":["Design Pattern"],"title":"设计模式","uri":"/design-pattern-cn/#为什么单例模式要防止反序列化"},{"categories":["Note"],"content":"工厂模式 ","date":"2022-01-09","objectID":"/design-pattern-cn/:2:0","series":[],"tags":["Design Pattern"],"title":"设计模式","uri":"/design-pattern-cn/#工厂模式"},{"categories":["Note"],"content":"作用 实现了创建者和调用者的分离 详细分类： 简单工厂模式 工厂方法模式 抽象工厂模式 OOP七大原则 开闭原则 依赖倒转原则 迪米特法则 ","date":"2022-01-09","objectID":"/design-pattern-cn/:2:1","series":[],"tags":["Design Pattern"],"title":"设计模式","uri":"/design-pattern-cn/#作用"},{"categories":["Note"],"content":"核心本质 实例化对象不能使用new，用工厂方法代替 将选择实现类，创建对象统一管理和控制。从而将调用者跟我们的实现类解耦 ","date":"2022-01-09","objectID":"/design-pattern-cn/:2:2","series":[],"tags":["Design Pattern"],"title":"设计模式","uri":"/design-pattern-cn/#核心本质"},{"categories":["Note"],"content":"三种模式 package com.me.factory.simple; public class Camaro implements Car { public void name() { System.out.println(\"Camaro\"); } } public class Tesla implements Car { public void name() { System.out.println(\"Tesla\"); } } public class Consumer { public static void main(String[] args) { Car car = new Camaro(); Car car2 = new Tesla(); } } 简单工厂模式 用来生产同一等级结构中的任意产品（对于增加新的产品，需要覆盖已有代码） // 方法1 package com.me.factory.simple; public class CarFactory { public static Car getCar(String car) { if (car.equals(\"Camaro\")) { return new Camaro(); } else if (car.equals(\"Tesla\")) { return new Tesla(); } else { return null; } } } public class Consumer { public static void main(String[] args) { Car car = CarFactory.getCar(\"Camaro\"); Car car2 = CarFactory.getCar(\"Tesla\"); } } // 这里的问题是： 如果我想加入新车，那么就要修改getCar()代码，违反了开闭原则！ // 方法2 public static getCamaro() {...} public static getTesla() {...} // 这里有相似的问题，仍然需要修改原有的class内容去给工厂添加新的methods //（简单）静态工厂模式 的弊端就是不修改代码的情况下是做不到增加新产品的 工厂方法模式 用来生产同一等级结构中的固定产品（支持增加任意产品） 在简单工厂的基础上，添加了中间层。 //工厂方法模式 public interface CarFactory { Car getCar(); } public class TeslaFactory implements CarFactory { @override public Car getCar() { return new Tesla(); } } public class CamaroFactory implements CarFactory { @override public Car getCar() { return new Camaro(); } } public class Consumer { public static void main(String[] args) { Car car = new CamaroFactory().getCar(\"Camaro\"); Car car2 = new TeslaFactory().getCar(\"Tesla\"); } } 结构复杂度： 简单工厂模式好 代码复杂度： 简单工厂模式好 编程复杂度： 简单工厂模式好 管理复杂度： 简单工厂模式好 根据设计原则： 工厂方法模式 根据实际业务： 更多的是简单工厂模式 抽象工厂模式 围绕一个超级工厂创建其他工厂，即其他工厂的工厂。 ","date":"2022-01-09","objectID":"/design-pattern-cn/:2:3","series":[],"tags":["Design Pattern"],"title":"设计模式","uri":"/design-pattern-cn/#三种模式"},{"categories":["Note"],"content":"抽象工厂模式 ","date":"2022-01-09","objectID":"/design-pattern-cn/:3:0","series":[],"tags":["Design Pattern"],"title":"设计模式","uri":"/design-pattern-cn/#抽象工厂模式"},{"categories":["Note"],"content":"定义 抽象工厂模式提供了一个创建一系列相关或者相互依赖对象的接口，无需指定它们具体的类。 ","date":"2022-01-09","objectID":"/design-pattern-cn/:3:1","series":[],"tags":["Design Pattern"],"title":"设计模式","uri":"/design-pattern-cn/#定义"},{"categories":["Note"],"content":"适用场景 客户端（应用层）不依赖于产品类实例如何被创建、实现等细节。 强调一系列相关的产品对象（属于同一产品族）一起使用创建对象需要大量的重复代码 提供一个产品类的库，所有产品以相同的接口出现，从而使得客户端不依赖于具体的实现 ","date":"2022-01-09","objectID":"/design-pattern-cn/:3:2","series":[],"tags":["Design Pattern"],"title":"设计模式","uri":"/design-pattern-cn/#适用场景"},{"categories":["Note"],"content":"优点 具体产品在应用层的代码隔离，无需关心创建的细节 将一个系列的产品统一到一起创建 ","date":"2022-01-09","objectID":"/design-pattern-cn/:3:3","series":[],"tags":["Design Pattern"],"title":"设计模式","uri":"/design-pattern-cn/#优点"},{"categories":["Note"],"content":"缺点 规定了所有可能被创建的产品合集，产品簇中扩展新的产品困难 增加了系统的抽象性和理解难度 抽象工厂在二维上创建： 产品族和产品等级 iPhone和google Pixel是同一个产品等级，iPhone和iPad是同一个产品族。 //手机产品接口 public interface PhoneProduct { void start(); void shutdown(); void call(); void sendSMS(); } //路由器产品接口 public interface RouterProduct { void start(); void shutdown(); void openWifi(); void setting(); } //iPhone public class iPhone implements PhoneProduct { @override public void start() { System.out.println(\"iPhone is booting up...\"); } ... } //VerizonRouter public class VerizonRouter implements RouterProduct { @override public void start() { System.out.println(\"VerizonRouter is booting up...\"); } ... } // 抽象产品工厂 public class ProductFactory { // 生产手机 PhoneProduct PhoneProduct(); // 生产路由器 RouterProduct RouterProduct(); } // 苹果工厂 public class AppleFactory implements ProductFactory { @override public PhoneProduct PhoneProduct() { return new iPhone(); } @override public RouterProduct RouterProduct() { return new iRouter(); } } // 生产实例 public class Client{ public static void main(String[] args) { AppleFactory appleFactory = new AppleFactory(); PhoneProduct phone = appleFactory.PhoneProduct(); phone.start(); } } 如果我们要家一个笔记本产品族，那么我们只需要在抽象产品工厂里添加这个品类。具体实现由各个品牌工厂负责。 ","date":"2022-01-09","objectID":"/design-pattern-cn/:3:4","series":[],"tags":["Design Pattern"],"title":"设计模式","uri":"/design-pattern-cn/#缺点"},{"categories":["Note"],"content":"工厂模式小结（包括抽象工厂模式） 简单工厂模式（静态工厂模式）虽然不符合设计原则，但是实际应用最多。 工厂方法模式 可以在不修改已有的class的前提下，通过增加新的工厂类实现扩展。 抽象工厂模式 不可以增加产品，但是可以增加产品族。 应用场景 JDK中Calendar的getInstance方法 JDBC中的Connection对象的获取 Spring中IOC容器创建管理bean对象 反射中Class对象的newInstance方法 ","date":"2022-01-09","objectID":"/design-pattern-cn/:3:5","series":[],"tags":["Design Pattern"],"title":"设计模式","uri":"/design-pattern-cn/#工厂模式小结包括抽象工厂模式"},{"categories":["Note"],"content":"工厂模式小结（包括抽象工厂模式） 简单工厂模式（静态工厂模式）虽然不符合设计原则，但是实际应用最多。 工厂方法模式 可以在不修改已有的class的前提下，通过增加新的工厂类实现扩展。 抽象工厂模式 不可以增加产品，但是可以增加产品族。 应用场景 JDK中Calendar的getInstance方法 JDBC中的Connection对象的获取 Spring中IOC容器创建管理bean对象 反射中Class对象的newInstance方法 ","date":"2022-01-09","objectID":"/design-pattern-cn/:3:5","series":[],"tags":["Design Pattern"],"title":"设计模式","uri":"/design-pattern-cn/#应用场景"},{"categories":["Note"],"content":"建造者模式 建造者模式属于创建型模式，他提供了一种创建对象的最佳方式。 ","date":"2022-01-09","objectID":"/design-pattern-cn/:4:0","series":[],"tags":["Design Pattern"],"title":"设计模式","uri":"/design-pattern-cn/#建造者模式"},{"categories":["Note"],"content":"定义 将一个复杂对象的构建与他的表示分离，使得同样的构建过程可以创建不同的表示。 ","date":"2022-01-09","objectID":"/design-pattern-cn/:4:1","series":[],"tags":["Design Pattern"],"title":"设计模式","uri":"/design-pattern-cn/#定义-1"},{"categories":["Note"],"content":"主要作用 在用户不知道对象的建造过程和细节的情况下就可以直接创建复杂的对象。 用户只需要给定复杂对象的类型和内容，建造者模式负责按顺序创建复杂对象（隐藏建造过程和细节） ","date":"2022-01-09","objectID":"/design-pattern-cn/:4:2","series":[],"tags":["Design Pattern"],"title":"设计模式","uri":"/design-pattern-cn/#主要作用"},{"categories":["Note"],"content":"例子 工厂（建造者模式）： 负责制造汽车（组装过程和细节在工厂内） 汽车购买者（用户）： 只要说出需要的型号和配置，不需要了解制造组装过程 // 抽象的建造者 public abstract class Builder { abstract void buildA(); abstract void buildB(); abstract void buildC(); abstract void buildD(); abstract Product getProduct(); } // 产品： 房子 public class Product { private String A; private String B; private String C; private String D; public String getA() {return A} public String setA(String a) {A = a;} } // 具体的建造者： 工人 public class Worker extends Builder { private Product product; public Worker() { product = new Product(); //这一步很重要，是工人创建产品。 } @Override void A() { product.setA(\"地基种类1\"); System.out.println(\"地基建造完毕\"); } ... } // 指挥： 核心。 负责指挥构建一个工程，工程如何构建，由此决定。 public class Director { // 指挥工人建造房子 public Product build(Builder builder) { builder.buildA(); builder.buildB(); builder.buildC(); builder.buildD(); return builder.getProduct(); } } public class Test { public static void main(String[] args) { // 构建指挥 Director director = new Director(); // 指挥工人构建产品 Product product = director.build(new Worker()); // 测试产品 System.out.println(product.getA()); } } 上面的例子是Builder模式的常规用法，Director在Builder模式中具有很重要的作用，它用于指导具体构建者如何构建产品，控制调用先后次序，并向调用者返回完整的产品类，但是有些情况下需要简化系统结构，可以把Director和抽象建造者进行结合。 通过静态内部类方式实现零件无序装配构造，这种方式使用更加灵活，更符合定义。内部有复杂对象的默认实现，使用是可以根据用户需求自由定义更改内容，并无需改变具体的构造方式。就可以产出不同的复杂产品。 比如：麦当劳的套餐，服务员（具体建造者）可以随意搭配产品组成套餐。我们不需要构造指挥者，因为我们把指挥者的功能交给了用户来操作，使得产品的创建更加简单灵活。 // Builder public abstract class Builder{ abstract Builder buildBurger(String option); abstract Builder buildBeverage(String option); abstract Builder buildSide(String option); abstract Builder buildDessert(String option; abstract Product getProduct(); } // Product public class Product { private String burger = \"Regular Burger\"; private String beverage = \"Regular coke\"; private String side = \"Regular fries\"; private String dessert = \"Regular smoothie\"; } // Worker public class Worker extends Builder { private Product product; public Worker() { product = new Product(); } @Override Builder buildBurger(String option) { product.setBuildBurger(option); return this; } ... @Override Product getProduct() { return product; } } public class Test { public static void main(String[] args) { Worker worker = new Worker(); //链式编程： 在原来的基础上，可以自由组合，如果不组合，也有默认的套餐 Product product = worker.buildBurger(\"Spicy Deluxe\").buildBeverage(\"Diet Coke\").getProduct(); System.out.println(product.toString()); } } ","date":"2022-01-09","objectID":"/design-pattern-cn/:4:3","series":[],"tags":["Design Pattern"],"title":"设计模式","uri":"/design-pattern-cn/#例子"},{"categories":["Note"],"content":"建造者模式小结 优点 产品的建造和表示分离，实现了解耦。客户端不必知道产品内部组成的细节。 将复杂的产品的创建步骤分解在不同的方法之中，让创建过程更清晰。 具体的建造者类之间是相互独立的，利于系统扩展。增加新的具体的建造者无需修改原有类库的代码，符合开闭原则。 缺点 建造者模式所创建的产品一般具有较多的共同点，其组成部分相似。如果产品之间的差异性很大，则不适合！ 如果产品的内部变化复杂，可能会导致需要定义很多具体的建造者来实现变化，导致系统庞大。 应用场景 需要生成的产品对象有复杂的内部结构，这些产品对象具备共性。 隔离复杂对象的创建和使用，并使得相同的创建过程可以创建不同的产品。 适合一个有较多零件（属性）和产品（对象）的创建过程。 与抽象工程相比较： 建造者模式返回一个组装好的完整产品，而抽象工厂模式返回一系列相关的产品。这些产品位于不同的产品等级结构，构成一个产品族。 抽象工厂模式中，客户端实例化工厂类，然后调用工厂方法获取产品对象。而建造者模式中，客户端可不直接调用建造者的相关方法，而是通过指挥者类来指导如何生成对象，包括对象的组装过程和建造步骤，它侧重于一步一步构造一个复杂对象，返回一个完整的对象。 如果将抽象工厂模式看成汽车配件生产工厂，生产一个产品族的产品，那么建造者模式就是一个汽车组装工厂，通过对部件的组装可以返回一辆完整的汽车。 ","date":"2022-01-09","objectID":"/design-pattern-cn/:4:4","series":[],"tags":["Design Pattern"],"title":"设计模式","uri":"/design-pattern-cn/#建造者模式小结"},{"categories":["Note"],"content":"建造者模式小结 优点 产品的建造和表示分离，实现了解耦。客户端不必知道产品内部组成的细节。 将复杂的产品的创建步骤分解在不同的方法之中，让创建过程更清晰。 具体的建造者类之间是相互独立的，利于系统扩展。增加新的具体的建造者无需修改原有类库的代码，符合开闭原则。 缺点 建造者模式所创建的产品一般具有较多的共同点，其组成部分相似。如果产品之间的差异性很大，则不适合！ 如果产品的内部变化复杂，可能会导致需要定义很多具体的建造者来实现变化，导致系统庞大。 应用场景 需要生成的产品对象有复杂的内部结构，这些产品对象具备共性。 隔离复杂对象的创建和使用，并使得相同的创建过程可以创建不同的产品。 适合一个有较多零件（属性）和产品（对象）的创建过程。 与抽象工程相比较： 建造者模式返回一个组装好的完整产品，而抽象工厂模式返回一系列相关的产品。这些产品位于不同的产品等级结构，构成一个产品族。 抽象工厂模式中，客户端实例化工厂类，然后调用工厂方法获取产品对象。而建造者模式中，客户端可不直接调用建造者的相关方法，而是通过指挥者类来指导如何生成对象，包括对象的组装过程和建造步骤，它侧重于一步一步构造一个复杂对象，返回一个完整的对象。 如果将抽象工厂模式看成汽车配件生产工厂，生产一个产品族的产品，那么建造者模式就是一个汽车组装工厂，通过对部件的组装可以返回一辆完整的汽车。 ","date":"2022-01-09","objectID":"/design-pattern-cn/:4:4","series":[],"tags":["Design Pattern"],"title":"设计模式","uri":"/design-pattern-cn/#优点-1"},{"categories":["Note"],"content":"建造者模式小结 优点 产品的建造和表示分离，实现了解耦。客户端不必知道产品内部组成的细节。 将复杂的产品的创建步骤分解在不同的方法之中，让创建过程更清晰。 具体的建造者类之间是相互独立的，利于系统扩展。增加新的具体的建造者无需修改原有类库的代码，符合开闭原则。 缺点 建造者模式所创建的产品一般具有较多的共同点，其组成部分相似。如果产品之间的差异性很大，则不适合！ 如果产品的内部变化复杂，可能会导致需要定义很多具体的建造者来实现变化，导致系统庞大。 应用场景 需要生成的产品对象有复杂的内部结构，这些产品对象具备共性。 隔离复杂对象的创建和使用，并使得相同的创建过程可以创建不同的产品。 适合一个有较多零件（属性）和产品（对象）的创建过程。 与抽象工程相比较： 建造者模式返回一个组装好的完整产品，而抽象工厂模式返回一系列相关的产品。这些产品位于不同的产品等级结构，构成一个产品族。 抽象工厂模式中，客户端实例化工厂类，然后调用工厂方法获取产品对象。而建造者模式中，客户端可不直接调用建造者的相关方法，而是通过指挥者类来指导如何生成对象，包括对象的组装过程和建造步骤，它侧重于一步一步构造一个复杂对象，返回一个完整的对象。 如果将抽象工厂模式看成汽车配件生产工厂，生产一个产品族的产品，那么建造者模式就是一个汽车组装工厂，通过对部件的组装可以返回一辆完整的汽车。 ","date":"2022-01-09","objectID":"/design-pattern-cn/:4:4","series":[],"tags":["Design Pattern"],"title":"设计模式","uri":"/design-pattern-cn/#缺点-1"},{"categories":["Note"],"content":"建造者模式小结 优点 产品的建造和表示分离，实现了解耦。客户端不必知道产品内部组成的细节。 将复杂的产品的创建步骤分解在不同的方法之中，让创建过程更清晰。 具体的建造者类之间是相互独立的，利于系统扩展。增加新的具体的建造者无需修改原有类库的代码，符合开闭原则。 缺点 建造者模式所创建的产品一般具有较多的共同点，其组成部分相似。如果产品之间的差异性很大，则不适合！ 如果产品的内部变化复杂，可能会导致需要定义很多具体的建造者来实现变化，导致系统庞大。 应用场景 需要生成的产品对象有复杂的内部结构，这些产品对象具备共性。 隔离复杂对象的创建和使用，并使得相同的创建过程可以创建不同的产品。 适合一个有较多零件（属性）和产品（对象）的创建过程。 与抽象工程相比较： 建造者模式返回一个组装好的完整产品，而抽象工厂模式返回一系列相关的产品。这些产品位于不同的产品等级结构，构成一个产品族。 抽象工厂模式中，客户端实例化工厂类，然后调用工厂方法获取产品对象。而建造者模式中，客户端可不直接调用建造者的相关方法，而是通过指挥者类来指导如何生成对象，包括对象的组装过程和建造步骤，它侧重于一步一步构造一个复杂对象，返回一个完整的对象。 如果将抽象工厂模式看成汽车配件生产工厂，生产一个产品族的产品，那么建造者模式就是一个汽车组装工厂，通过对部件的组装可以返回一辆完整的汽车。 ","date":"2022-01-09","objectID":"/design-pattern-cn/:4:4","series":[],"tags":["Design Pattern"],"title":"设计模式","uri":"/design-pattern-cn/#应用场景-1"},{"categories":["Note"],"content":"建造者模式小结 优点 产品的建造和表示分离，实现了解耦。客户端不必知道产品内部组成的细节。 将复杂的产品的创建步骤分解在不同的方法之中，让创建过程更清晰。 具体的建造者类之间是相互独立的，利于系统扩展。增加新的具体的建造者无需修改原有类库的代码，符合开闭原则。 缺点 建造者模式所创建的产品一般具有较多的共同点，其组成部分相似。如果产品之间的差异性很大，则不适合！ 如果产品的内部变化复杂，可能会导致需要定义很多具体的建造者来实现变化，导致系统庞大。 应用场景 需要生成的产品对象有复杂的内部结构，这些产品对象具备共性。 隔离复杂对象的创建和使用，并使得相同的创建过程可以创建不同的产品。 适合一个有较多零件（属性）和产品（对象）的创建过程。 与抽象工程相比较： 建造者模式返回一个组装好的完整产品，而抽象工厂模式返回一系列相关的产品。这些产品位于不同的产品等级结构，构成一个产品族。 抽象工厂模式中，客户端实例化工厂类，然后调用工厂方法获取产品对象。而建造者模式中，客户端可不直接调用建造者的相关方法，而是通过指挥者类来指导如何生成对象，包括对象的组装过程和建造步骤，它侧重于一步一步构造一个复杂对象，返回一个完整的对象。 如果将抽象工厂模式看成汽车配件生产工厂，生产一个产品族的产品，那么建造者模式就是一个汽车组装工厂，通过对部件的组装可以返回一辆完整的汽车。 ","date":"2022-01-09","objectID":"/design-pattern-cn/:4:4","series":[],"tags":["Design Pattern"],"title":"设计模式","uri":"/design-pattern-cn/#与抽象工程相比较"},{"categories":["Note"],"content":"原型模式 克隆 Prototype Cloneable接口 clone()方法 基于一个原型对象， 通过cloneable接口，重写clone()方法，避免重复复杂的构建程序，直接复制粘贴出另一个相同的克隆(不是相同的对象，是深拷贝！)，java中的cloneable是native接口，也就是调用的C++ public class Video implements Cloneable { private Date createTime; private String name; @Override protected Object clone() throws CloneNotSupportedException { return super.clone(); } public Video(){}; public Video(String name, Date createTime) { this.name = name; this.createTime = createTime; } ...(get,set,toString)... } public class Youtube { public static void main(String[] args) throws CloneNotSupportedException{ Date date = new Date(); Video v = new Video(name: \"tutorial\", date); Video v2 = (Video) v1.clone(); System.out.println(v.hashCode()); System.out.println(v2.hashCode()); } } // 但是这样的date是浅copy！ 解决方法： 序列化，反序列化 (效率底) 改造Clone() (更方便) @Override protected Object clone() throws CloneNotSupportedException { Object obj = super.clone(); Video v = (Video) obj; v.createTime = (Video) this.createTime.clone(); return obj; } Spring Bean: 单例模式，原型模式 原型模式 + 工厂模式 –\u003e 把new替换为原型模式 ","date":"2022-01-09","objectID":"/design-pattern-cn/:5:0","series":[],"tags":["Design Pattern"],"title":"设计模式","uri":"/design-pattern-cn/#原型模式"},{"categories":["Note"],"content":"适配器模式 结构型模式: 从程序的结构上实现松耦合,从而扩大整体的类结构,用来解决更大的问题. ","date":"2022-01-09","objectID":"/design-pattern-cn/:6:0","series":[],"tags":["Design Pattern"],"title":"设计模式","uri":"/design-pattern-cn/#适配器模式"},{"categories":["Note"],"content":"适配器模式 结构型模式: 从程序的结构上实现松耦合,从而扩大整体的类结构,用来解决更大的问题. ","date":"2022-01-09","objectID":"/design-pattern-cn/:6:0","series":[],"tags":["Design Pattern"],"title":"设计模式","uri":"/design-pattern-cn/#结构型模式-从程序的结构上实现松耦合从而扩大整体的类结构用来解决更大的问题"},{"categories":["Note"],"content":"How to Speak –by Patrick Winston ","date":"2022-01-02","objectID":"/how-to-speak/:0:0","series":[],"tags":["Communication"],"title":"How to Speak","uri":"/how-to-speak/#how-to-speak---by-patrick-winston"},{"categories":["Note"],"content":"How to Start A joke? – Not recommended. The reason is while the others are not quite concentrate on the talk, your joke may just fall flat. A Promise? – Great idea e.g.: “At the end of this 60 mins, you will know things about speaking you don’t know now, and something among those will make a difference in your life.” ","date":"2022-01-02","objectID":"/how-to-speak/:1:0","series":[],"tags":["Communication"],"title":"How to Speak","uri":"/how-to-speak/#how-to-start"},{"categories":["Note"],"content":"4 Samples Cycle the Subjects You’ll need to talk about the subject multiple times with different approaches, or people will not remember. Build a Fence Build a fence on your idea so that it can be distinguished from others' ideas. Since poeple might be confused about how it might be related to sth else. Verbal Punctuation You need to put a landmark announcing that it’s a good time to get back on. people will occasionally fog out and need to get back on the bus. Question Don’t make it too hard or easy. ","date":"2022-01-02","objectID":"/how-to-speak/:1:1","series":[],"tags":["Communication"],"title":"How to Speak","uri":"/how-to-speak/#4-samples"},{"categories":["Note"],"content":"4 Samples Cycle the Subjects You’ll need to talk about the subject multiple times with different approaches, or people will not remember. Build a Fence Build a fence on your idea so that it can be distinguished from others' ideas. Since poeple might be confused about how it might be related to sth else. Verbal Punctuation You need to put a landmark announcing that it’s a good time to get back on. people will occasionally fog out and need to get back on the bus. Question Don’t make it too hard or easy. ","date":"2022-01-02","objectID":"/how-to-speak/:1:1","series":[],"tags":["Communication"],"title":"How to Speak","uri":"/how-to-speak/#cycle-the-subjects"},{"categories":["Note"],"content":"4 Samples Cycle the Subjects You’ll need to talk about the subject multiple times with different approaches, or people will not remember. Build a Fence Build a fence on your idea so that it can be distinguished from others' ideas. Since poeple might be confused about how it might be related to sth else. Verbal Punctuation You need to put a landmark announcing that it’s a good time to get back on. people will occasionally fog out and need to get back on the bus. Question Don’t make it too hard or easy. ","date":"2022-01-02","objectID":"/how-to-speak/:1:1","series":[],"tags":["Communication"],"title":"How to Speak","uri":"/how-to-speak/#build-a-fence"},{"categories":["Note"],"content":"4 Samples Cycle the Subjects You’ll need to talk about the subject multiple times with different approaches, or people will not remember. Build a Fence Build a fence on your idea so that it can be distinguished from others' ideas. Since poeple might be confused about how it might be related to sth else. Verbal Punctuation You need to put a landmark announcing that it’s a good time to get back on. people will occasionally fog out and need to get back on the bus. Question Don’t make it too hard or easy. ","date":"2022-01-02","objectID":"/how-to-speak/:1:1","series":[],"tags":["Communication"],"title":"How to Speak","uri":"/how-to-speak/#verbal-punctuation"},{"categories":["Note"],"content":"4 Samples Cycle the Subjects You’ll need to talk about the subject multiple times with different approaches, or people will not remember. Build a Fence Build a fence on your idea so that it can be distinguished from others' ideas. Since poeple might be confused about how it might be related to sth else. Verbal Punctuation You need to put a landmark announcing that it’s a good time to get back on. people will occasionally fog out and need to get back on the bus. Question Don’t make it too hard or easy. ","date":"2022-01-02","objectID":"/how-to-speak/:1:1","series":[],"tags":["Communication"],"title":"How to Speak","uri":"/how-to-speak/#question"},{"categories":["Note"],"content":"The Tools ","date":"2022-01-02","objectID":"/how-to-speak/:2:0","series":[],"tags":["Communication"],"title":"How to Speak","uri":"/how-to-speak/#the-tools"},{"categories":["Note"],"content":"Time and Space Time: 11AM Place: Well lit, cased(check the place first), populated(more than half full) ","date":"2022-01-02","objectID":"/how-to-speak/:2:1","series":[],"tags":["Communication"],"title":"How to Speak","uri":"/how-to-speak/#time-and-space"},{"categories":["Note"],"content":"Board Graphic Quality Speed(match the speed of people absorbing ideas) Target(your hands have something to point at) ","date":"2022-01-02","objectID":"/how-to-speak/:2:2","series":[],"tags":["Communication"],"title":"How to Speak","uri":"/how-to-speak/#board"},{"categories":["Note"],"content":"Props ","date":"2022-01-02","objectID":"/how-to-speak/:2:3","series":[],"tags":["Communication"],"title":"How to Speak","uri":"/how-to-speak/#props"},{"categories":["Note"],"content":"Job Talks ","date":"2022-01-02","objectID":"/how-to-speak/:2:4","series":[],"tags":["Communication"],"title":"How to Speak","uri":"/how-to-speak/#job-talks"},{"categories":["Note"],"content":"Getting ","date":"2022-01-02","objectID":"/how-to-speak/:2:5","series":[],"tags":["Communication"],"title":"How to Speak","uri":"/how-to-speak/#getting"},{"categories":["Note"],"content":"Famous Watch on Youtube ","date":"2022-01-02","objectID":"/how-to-speak/:2:6","series":[],"tags":["Communication"],"title":"How to Speak","uri":"/how-to-speak/#famous"},{"categories":["Note"],"content":"Advice Read book for learning in depth Learn and talk to successful people (in terms of indie dev, not the money) Your friends may not know your field, though they may support you mentally or the otherwise Don’t be satisfied with only talking about your ideas with your friends Books can also be seen as a communication to successes Getting Real The smarter, faster, easier way to build a successful web application Becoming big is not the only way to success Small, elegant, and targeted application may be better You can develop something for yourself first What’s your problem? If you have a problem, it’s likely many else are bothered in the same way And this is your market It’s a problem when it’s a problem You launch a app without the ability to bill your customers? Make Opinionated Software Bullshit: software should always be as flexible as possible The best software has a vision If they don’t like your vision, then there are plenty of others out there Don’t try to chasing people you’ll never make happy Don’t be a yes-man You should only consider features if they’re willing to stand on the porch for three days waiting to be let in You can listen but don’t act all the time The initial response is “not now” If a request for a feature keeps coming back, that’s when we should take a deeper look Less Software Each time you increase the amount of code, your software grows exponentially more complicated Bugs always emerge from the feature you don’t use Ride the Blog Wave Start off by creating a blog that not only touts your product but offers helpful advices, tips, tricks, etc. It will attract readers with a week thanks to the helpful, informative, and interesting bits and anecdotes we post on a daily basis. ","date":"2021-12-25","objectID":"/advice/:0:1","series":[],"tags":["Advice"],"title":"Advice for Solo Dev","uri":"/advice/#advice"},{"categories":["Note"],"content":"Marketing Lessons: Grateful Dead Share journey, blog, videos, which will get you a fan base Just be yourself, which is more attractive for most people online The marketplace is incredibly forgiving of mistakes Owns up to a mistake immediately Explains how or why it happened and how you are fixing it Don’t forget to say thanks Stop hiding your personality behind the scene Don’t create a new account for your new product every time People can’t see the reason and motivations for it Give the best deals to existing customers and tell your fans first Show the people who invest their time and money in your company that you care Don’t try to use the best deals for your new target customers only The way to reach your marketplace is to create tons of remarkable, free content, like blogs, videos, white papers, and e-books. Cultivate more and you’ll receive more But remember that great product comes first ","date":"2021-12-25","objectID":"/advice/:0:2","series":[],"tags":["Advice"],"title":"Advice for Solo Dev","uri":"/advice/#marketing-lessons-grateful-dead"},{"categories":["Note"],"content":"The Goal by Eliyahu M. Goldratt Problems Hard to concentrate because your head is full of things Can’t prioritize tasks due to too many things to do Feeling restless and uneasy because you are always chased by something Unstable mind and uncontrollable motivation Solutions What is the fundamental skill for continuously improving your productivity by yourself DO LESS Less code Less marketing Less user support So you get more room to the further When you are productive you are accomplishing something in terms of your goal The easier way is to solve your own problem as a motivation of your development Whatever the bottlenecks produce in an hour is the equivalent of what the plant produces in an hour. So… an hour lost at a bottleneck is an hour lost for the entire system Step1. Identify the system’s bottlenecks Step2. decide how to exploit the bottlenecks Step3. Subordinate everything else to the above decision Step4. Elevate the system’s bottlenecks Step5. If in a previous step, a bottleneck has been broken go back to step 1 Anything can be a bottleneck Software design Physical \u0026 mental health Relationships with your family, friends, colleagues, customers, etc. Home \u0026 work environment Equipment etc. Have a daily habit to checking or reflecting yourself After reading a book. Put it into practice immediately! Don’t do it in your way but do it exactly as what the book says as possible as you can from youtube channel: devaslife ","date":"2021-12-25","objectID":"/advice/:0:3","series":[],"tags":["Advice"],"title":"Advice for Solo Dev","uri":"/advice/#the-goal-by-eliyahu-m-goldratt"},{"categories":["Note"],"content":"The Goal by Eliyahu M. Goldratt Problems Hard to concentrate because your head is full of things Can’t prioritize tasks due to too many things to do Feeling restless and uneasy because you are always chased by something Unstable mind and uncontrollable motivation Solutions What is the fundamental skill for continuously improving your productivity by yourself DO LESS Less code Less marketing Less user support So you get more room to the further When you are productive you are accomplishing something in terms of your goal The easier way is to solve your own problem as a motivation of your development Whatever the bottlenecks produce in an hour is the equivalent of what the plant produces in an hour. So… an hour lost at a bottleneck is an hour lost for the entire system Step1. Identify the system’s bottlenecks Step2. decide how to exploit the bottlenecks Step3. Subordinate everything else to the above decision Step4. Elevate the system’s bottlenecks Step5. If in a previous step, a bottleneck has been broken go back to step 1 Anything can be a bottleneck Software design Physical \u0026 mental health Relationships with your family, friends, colleagues, customers, etc. Home \u0026 work environment Equipment etc. Have a daily habit to checking or reflecting yourself After reading a book. Put it into practice immediately! Don’t do it in your way but do it exactly as what the book says as possible as you can from youtube channel: devaslife ","date":"2021-12-25","objectID":"/advice/:0:3","series":[],"tags":["Advice"],"title":"Advice for Solo Dev","uri":"/advice/#problems"},{"categories":["Note"],"content":"The Goal by Eliyahu M. Goldratt Problems Hard to concentrate because your head is full of things Can’t prioritize tasks due to too many things to do Feeling restless and uneasy because you are always chased by something Unstable mind and uncontrollable motivation Solutions What is the fundamental skill for continuously improving your productivity by yourself DO LESS Less code Less marketing Less user support So you get more room to the further When you are productive you are accomplishing something in terms of your goal The easier way is to solve your own problem as a motivation of your development Whatever the bottlenecks produce in an hour is the equivalent of what the plant produces in an hour. So… an hour lost at a bottleneck is an hour lost for the entire system Step1. Identify the system’s bottlenecks Step2. decide how to exploit the bottlenecks Step3. Subordinate everything else to the above decision Step4. Elevate the system’s bottlenecks Step5. If in a previous step, a bottleneck has been broken go back to step 1 Anything can be a bottleneck Software design Physical \u0026 mental health Relationships with your family, friends, colleagues, customers, etc. Home \u0026 work environment Equipment etc. Have a daily habit to checking or reflecting yourself After reading a book. Put it into practice immediately! Don’t do it in your way but do it exactly as what the book says as possible as you can from youtube channel: devaslife ","date":"2021-12-25","objectID":"/advice/:0:3","series":[],"tags":["Advice"],"title":"Advice for Solo Dev","uri":"/advice/#solutions"},{"categories":["Note"],"content":"Bellman-Ford Generic S.P. Algo review Complexity could be exponential time (even for +ve weights) might not even terminate if there is a -ve weight cycle reachable from the source Bellman-Ford(G,W,s) to solve prob 2 above Initialize() for i=1 to |v|-1 for each edge(u,v)∈E Relax(u,v,w) for each edge(u,v)∈E if d[v] \u003e d[u] + w(u,v) then report -ve cycle exists O(VE) Correctness Theorem: If G = (V,E) contains no -ve weight cycles then after B-F executes, d[v] = ẟ[s,v] for all v∈V Corollary: If a value d[v] fails to converge after |v|-1 passes, there exists a -ve weight cycle reachable from s Proof by induction Proof Notice B-F algo doesn’t sovle the -ve cycle but give an option to abort for the sake of termination It gives the option of aborting and keep the algo complexity away from exponential time (NP-Hard Prob) B-F Explanation ","date":"2021-12-25","objectID":"/bellman-ford/:0:1","series":[],"tags":["Algorithm"],"title":"Bellman Ford","uri":"/bellman-ford/#bellman-ford"},{"categories":["Note"],"content":"Bellman-Ford Generic S.P. Algo review Complexity could be exponential time (even for +ve weights) might not even terminate if there is a -ve weight cycle reachable from the source Bellman-Ford(G,W,s) to solve prob 2 above Initialize() for i=1 to |v|-1 for each edge(u,v)∈E Relax(u,v,w) for each edge(u,v)∈E if d[v] d[u] + w(u,v) then report -ve cycle exists O(VE) Correctness Theorem: If G = (V,E) contains no -ve weight cycles then after B-F executes, d[v] = ẟ[s,v] for all v∈V Corollary: If a value d[v] fails to converge after |v|-1 passes, there exists a -ve weight cycle reachable from s Proof by induction Proof Notice B-F algo doesn’t sovle the -ve cycle but give an option to abort for the sake of termination It gives the option of aborting and keep the algo complexity away from exponential time (NP-Hard Prob) B-F Explanation ","date":"2021-12-25","objectID":"/bellman-ford/:0:1","series":[],"tags":["Algorithm"],"title":"Bellman Ford","uri":"/bellman-ford/#generic-sp-algo-review"},{"categories":["Note"],"content":"Bellman-Ford Generic S.P. Algo review Complexity could be exponential time (even for +ve weights) might not even terminate if there is a -ve weight cycle reachable from the source Bellman-Ford(G,W,s) to solve prob 2 above Initialize() for i=1 to |v|-1 for each edge(u,v)∈E Relax(u,v,w) for each edge(u,v)∈E if d[v] d[u] + w(u,v) then report -ve cycle exists O(VE) Correctness Theorem: If G = (V,E) contains no -ve weight cycles then after B-F executes, d[v] = ẟ[s,v] for all v∈V Corollary: If a value d[v] fails to converge after |v|-1 passes, there exists a -ve weight cycle reachable from s Proof by induction Proof Notice B-F algo doesn’t sovle the -ve cycle but give an option to abort for the sake of termination It gives the option of aborting and keep the algo complexity away from exponential time (NP-Hard Prob) B-F Explanation ","date":"2021-12-25","objectID":"/bellman-ford/:0:1","series":[],"tags":["Algorithm"],"title":"Bellman Ford","uri":"/bellman-ford/#bellman-fordgws-to-solve-prob-2-above"},{"categories":["Note"],"content":"Bellman-Ford Generic S.P. Algo review Complexity could be exponential time (even for +ve weights) might not even terminate if there is a -ve weight cycle reachable from the source Bellman-Ford(G,W,s) to solve prob 2 above Initialize() for i=1 to |v|-1 for each edge(u,v)∈E Relax(u,v,w) for each edge(u,v)∈E if d[v] d[u] + w(u,v) then report -ve cycle exists O(VE) Correctness Theorem: If G = (V,E) contains no -ve weight cycles then after B-F executes, d[v] = ẟ[s,v] for all v∈V Corollary: If a value d[v] fails to converge after |v|-1 passes, there exists a -ve weight cycle reachable from s Proof by induction Proof Notice B-F algo doesn’t sovle the -ve cycle but give an option to abort for the sake of termination It gives the option of aborting and keep the algo complexity away from exponential time (NP-Hard Prob) B-F Explanation ","date":"2021-12-25","objectID":"/bellman-ford/:0:1","series":[],"tags":["Algorithm"],"title":"Bellman Ford","uri":"/bellman-ford/#notice"},{"categories":["Note"],"content":"Breadth-First Search (BFS) Basic Graph Review Graph search find paths from one state to another Recall: graph G = (V,E) V = set of vertices E = set of edges undirected e = {v,w} unordered pairs directed e = (v,w) ordered pairs Aplications of graph search web crawling social networking (search the friend near you than friends of a friend) network broadcast garbage collection model checking check mathematical conj. solving puzzle of game Pocket Cube: 2x2x2 configuration graph vertex for each possible state of cube number of vertices: 8! x 38 = 264,539,520 on every cube there are 8 vertices that can be permulated inside itself then every cube has 3 rotation state there are 8 cubes in total you can actually divide it by 24 since there are 24 symmetries you also can divide it by 3 since only one third of the cofiguration spaces are reachable edge for each possible move ​ undirected solved state -\u003e next possible states -\u003e…-\u003einitial states the number of layers is called the diameter for the best algo, the worst case is 11 for 3x3x3 it’s 20 for nxnxn Θ(n2/lgn) Graph Representation Adjacency lists array Adj of |V| linked lists for each vertex u∈V, Adj[u] stores u’s neighbors, which can be reached in one step object oriented: v.neighbors = Adj[v] implicit representation: Adj(u) is a function or v.neighbors() is method of the class Θ(V+E) BFS goal: visit all nodes reachable from given s∈V O(V+E) time look at the nodes reachable in 0 moves, 1 moves,… careful to avoid duplicates BFS(s,Adj): level = {s: φ} parent = {s: None} i = 1 frontier = [s] #\u003c- frontier is the set of nodes reached in prev level, which is level i-1 while frontier: next = [] for u in frontier: for v in Adj[u]: if v not in level: level[v] = i parent[v] = u next.append(v) frontier = next i+=1 Shortest Path if we take v parent[v] parent[parent[v]] … until we get s we just find a shortest path from s to v the length will be the level of v ","date":"2021-12-25","objectID":"/breadth-first-search-bfs/:0:1","series":[],"tags":["Algorithm"],"title":"BFS","uri":"/breadth-first-search-bfs/#breadth-first-search-bfs"},{"categories":["Note"],"content":"Breadth-First Search (BFS) Basic Graph Review Graph search find paths from one state to another Recall: graph G = (V,E) V = set of vertices E = set of edges undirected e = {v,w} unordered pairs directed e = (v,w) ordered pairs Aplications of graph search web crawling social networking (search the friend near you than friends of a friend) network broadcast garbage collection model checking check mathematical conj. solving puzzle of game Pocket Cube: 2x2x2 configuration graph vertex for each possible state of cube number of vertices: 8! x 38 = 264,539,520 on every cube there are 8 vertices that can be permulated inside itself then every cube has 3 rotation state there are 8 cubes in total you can actually divide it by 24 since there are 24 symmetries you also can divide it by 3 since only one third of the cofiguration spaces are reachable edge for each possible move ​ undirected solved state - next possible states -…-initial states the number of layers is called the diameter for the best algo, the worst case is 11 for 3x3x3 it’s 20 for nxnxn Θ(n2/lgn) Graph Representation Adjacency lists array Adj of |V| linked lists for each vertex u∈V, Adj[u] stores u’s neighbors, which can be reached in one step object oriented: v.neighbors = Adj[v] implicit representation: Adj(u) is a function or v.neighbors() is method of the class Θ(V+E) BFS goal: visit all nodes reachable from given s∈V O(V+E) time look at the nodes reachable in 0 moves, 1 moves,… careful to avoid duplicates BFS(s,Adj): level = {s: φ} parent = {s: None} i = 1 frontier = [s] #","date":"2021-12-25","objectID":"/breadth-first-search-bfs/:0:1","series":[],"tags":["Algorithm"],"title":"BFS","uri":"/breadth-first-search-bfs/#basic-graph-review"},{"categories":["Note"],"content":"Breadth-First Search (BFS) Basic Graph Review Graph search find paths from one state to another Recall: graph G = (V,E) V = set of vertices E = set of edges undirected e = {v,w} unordered pairs directed e = (v,w) ordered pairs Aplications of graph search web crawling social networking (search the friend near you than friends of a friend) network broadcast garbage collection model checking check mathematical conj. solving puzzle of game Pocket Cube: 2x2x2 configuration graph vertex for each possible state of cube number of vertices: 8! x 38 = 264,539,520 on every cube there are 8 vertices that can be permulated inside itself then every cube has 3 rotation state there are 8 cubes in total you can actually divide it by 24 since there are 24 symmetries you also can divide it by 3 since only one third of the cofiguration spaces are reachable edge for each possible move ​ undirected solved state - next possible states -…-initial states the number of layers is called the diameter for the best algo, the worst case is 11 for 3x3x3 it’s 20 for nxnxn Θ(n2/lgn) Graph Representation Adjacency lists array Adj of |V| linked lists for each vertex u∈V, Adj[u] stores u’s neighbors, which can be reached in one step object oriented: v.neighbors = Adj[v] implicit representation: Adj(u) is a function or v.neighbors() is method of the class Θ(V+E) BFS goal: visit all nodes reachable from given s∈V O(V+E) time look at the nodes reachable in 0 moves, 1 moves,… careful to avoid duplicates BFS(s,Adj): level = {s: φ} parent = {s: None} i = 1 frontier = [s] #","date":"2021-12-25","objectID":"/breadth-first-search-bfs/:0:1","series":[],"tags":["Algorithm"],"title":"BFS","uri":"/breadth-first-search-bfs/#graph-search"},{"categories":["Note"],"content":"Breadth-First Search (BFS) Basic Graph Review Graph search find paths from one state to another Recall: graph G = (V,E) V = set of vertices E = set of edges undirected e = {v,w} unordered pairs directed e = (v,w) ordered pairs Aplications of graph search web crawling social networking (search the friend near you than friends of a friend) network broadcast garbage collection model checking check mathematical conj. solving puzzle of game Pocket Cube: 2x2x2 configuration graph vertex for each possible state of cube number of vertices: 8! x 38 = 264,539,520 on every cube there are 8 vertices that can be permulated inside itself then every cube has 3 rotation state there are 8 cubes in total you can actually divide it by 24 since there are 24 symmetries you also can divide it by 3 since only one third of the cofiguration spaces are reachable edge for each possible move ​ undirected solved state - next possible states -…-initial states the number of layers is called the diameter for the best algo, the worst case is 11 for 3x3x3 it’s 20 for nxnxn Θ(n2/lgn) Graph Representation Adjacency lists array Adj of |V| linked lists for each vertex u∈V, Adj[u] stores u’s neighbors, which can be reached in one step object oriented: v.neighbors = Adj[v] implicit representation: Adj(u) is a function or v.neighbors() is method of the class Θ(V+E) BFS goal: visit all nodes reachable from given s∈V O(V+E) time look at the nodes reachable in 0 moves, 1 moves,… careful to avoid duplicates BFS(s,Adj): level = {s: φ} parent = {s: None} i = 1 frontier = [s] #","date":"2021-12-25","objectID":"/breadth-first-search-bfs/:0:1","series":[],"tags":["Algorithm"],"title":"BFS","uri":"/breadth-first-search-bfs/#recall-graph-g--ve"},{"categories":["Note"],"content":"Breadth-First Search (BFS) Basic Graph Review Graph search find paths from one state to another Recall: graph G = (V,E) V = set of vertices E = set of edges undirected e = {v,w} unordered pairs directed e = (v,w) ordered pairs Aplications of graph search web crawling social networking (search the friend near you than friends of a friend) network broadcast garbage collection model checking check mathematical conj. solving puzzle of game Pocket Cube: 2x2x2 configuration graph vertex for each possible state of cube number of vertices: 8! x 38 = 264,539,520 on every cube there are 8 vertices that can be permulated inside itself then every cube has 3 rotation state there are 8 cubes in total you can actually divide it by 24 since there are 24 symmetries you also can divide it by 3 since only one third of the cofiguration spaces are reachable edge for each possible move ​ undirected solved state - next possible states -…-initial states the number of layers is called the diameter for the best algo, the worst case is 11 for 3x3x3 it’s 20 for nxnxn Θ(n2/lgn) Graph Representation Adjacency lists array Adj of |V| linked lists for each vertex u∈V, Adj[u] stores u’s neighbors, which can be reached in one step object oriented: v.neighbors = Adj[v] implicit representation: Adj(u) is a function or v.neighbors() is method of the class Θ(V+E) BFS goal: visit all nodes reachable from given s∈V O(V+E) time look at the nodes reachable in 0 moves, 1 moves,… careful to avoid duplicates BFS(s,Adj): level = {s: φ} parent = {s: None} i = 1 frontier = [s] #","date":"2021-12-25","objectID":"/breadth-first-search-bfs/:0:1","series":[],"tags":["Algorithm"],"title":"BFS","uri":"/breadth-first-search-bfs/#aplications-of-graph-search"},{"categories":["Note"],"content":"Breadth-First Search (BFS) Basic Graph Review Graph search find paths from one state to another Recall: graph G = (V,E) V = set of vertices E = set of edges undirected e = {v,w} unordered pairs directed e = (v,w) ordered pairs Aplications of graph search web crawling social networking (search the friend near you than friends of a friend) network broadcast garbage collection model checking check mathematical conj. solving puzzle of game Pocket Cube: 2x2x2 configuration graph vertex for each possible state of cube number of vertices: 8! x 38 = 264,539,520 on every cube there are 8 vertices that can be permulated inside itself then every cube has 3 rotation state there are 8 cubes in total you can actually divide it by 24 since there are 24 symmetries you also can divide it by 3 since only one third of the cofiguration spaces are reachable edge for each possible move ​ undirected solved state - next possible states -…-initial states the number of layers is called the diameter for the best algo, the worst case is 11 for 3x3x3 it’s 20 for nxnxn Θ(n2/lgn) Graph Representation Adjacency lists array Adj of |V| linked lists for each vertex u∈V, Adj[u] stores u’s neighbors, which can be reached in one step object oriented: v.neighbors = Adj[v] implicit representation: Adj(u) is a function or v.neighbors() is method of the class Θ(V+E) BFS goal: visit all nodes reachable from given s∈V O(V+E) time look at the nodes reachable in 0 moves, 1 moves,… careful to avoid duplicates BFS(s,Adj): level = {s: φ} parent = {s: None} i = 1 frontier = [s] #","date":"2021-12-25","objectID":"/breadth-first-search-bfs/:0:1","series":[],"tags":["Algorithm"],"title":"BFS","uri":"/breadth-first-search-bfs/#pocket-cube-2x2x2"},{"categories":["Note"],"content":"Breadth-First Search (BFS) Basic Graph Review Graph search find paths from one state to another Recall: graph G = (V,E) V = set of vertices E = set of edges undirected e = {v,w} unordered pairs directed e = (v,w) ordered pairs Aplications of graph search web crawling social networking (search the friend near you than friends of a friend) network broadcast garbage collection model checking check mathematical conj. solving puzzle of game Pocket Cube: 2x2x2 configuration graph vertex for each possible state of cube number of vertices: 8! x 38 = 264,539,520 on every cube there are 8 vertices that can be permulated inside itself then every cube has 3 rotation state there are 8 cubes in total you can actually divide it by 24 since there are 24 symmetries you also can divide it by 3 since only one third of the cofiguration spaces are reachable edge for each possible move ​ undirected solved state - next possible states -…-initial states the number of layers is called the diameter for the best algo, the worst case is 11 for 3x3x3 it’s 20 for nxnxn Θ(n2/lgn) Graph Representation Adjacency lists array Adj of |V| linked lists for each vertex u∈V, Adj[u] stores u’s neighbors, which can be reached in one step object oriented: v.neighbors = Adj[v] implicit representation: Adj(u) is a function or v.neighbors() is method of the class Θ(V+E) BFS goal: visit all nodes reachable from given s∈V O(V+E) time look at the nodes reachable in 0 moves, 1 moves,… careful to avoid duplicates BFS(s,Adj): level = {s: φ} parent = {s: None} i = 1 frontier = [s] #","date":"2021-12-25","objectID":"/breadth-first-search-bfs/:0:1","series":[],"tags":["Algorithm"],"title":"BFS","uri":"/breadth-first-search-bfs/#graph-representation"},{"categories":["Note"],"content":"Breadth-First Search (BFS) Basic Graph Review Graph search find paths from one state to another Recall: graph G = (V,E) V = set of vertices E = set of edges undirected e = {v,w} unordered pairs directed e = (v,w) ordered pairs Aplications of graph search web crawling social networking (search the friend near you than friends of a friend) network broadcast garbage collection model checking check mathematical conj. solving puzzle of game Pocket Cube: 2x2x2 configuration graph vertex for each possible state of cube number of vertices: 8! x 38 = 264,539,520 on every cube there are 8 vertices that can be permulated inside itself then every cube has 3 rotation state there are 8 cubes in total you can actually divide it by 24 since there are 24 symmetries you also can divide it by 3 since only one third of the cofiguration spaces are reachable edge for each possible move ​ undirected solved state - next possible states -…-initial states the number of layers is called the diameter for the best algo, the worst case is 11 for 3x3x3 it’s 20 for nxnxn Θ(n2/lgn) Graph Representation Adjacency lists array Adj of |V| linked lists for each vertex u∈V, Adj[u] stores u’s neighbors, which can be reached in one step object oriented: v.neighbors = Adj[v] implicit representation: Adj(u) is a function or v.neighbors() is method of the class Θ(V+E) BFS goal: visit all nodes reachable from given s∈V O(V+E) time look at the nodes reachable in 0 moves, 1 moves,… careful to avoid duplicates BFS(s,Adj): level = {s: φ} parent = {s: None} i = 1 frontier = [s] #","date":"2021-12-25","objectID":"/breadth-first-search-bfs/:0:1","series":[],"tags":["Algorithm"],"title":"BFS","uri":"/breadth-first-search-bfs/#adjacency-lists"},{"categories":["Note"],"content":"Breadth-First Search (BFS) Basic Graph Review Graph search find paths from one state to another Recall: graph G = (V,E) V = set of vertices E = set of edges undirected e = {v,w} unordered pairs directed e = (v,w) ordered pairs Aplications of graph search web crawling social networking (search the friend near you than friends of a friend) network broadcast garbage collection model checking check mathematical conj. solving puzzle of game Pocket Cube: 2x2x2 configuration graph vertex for each possible state of cube number of vertices: 8! x 38 = 264,539,520 on every cube there are 8 vertices that can be permulated inside itself then every cube has 3 rotation state there are 8 cubes in total you can actually divide it by 24 since there are 24 symmetries you also can divide it by 3 since only one third of the cofiguration spaces are reachable edge for each possible move ​ undirected solved state - next possible states -…-initial states the number of layers is called the diameter for the best algo, the worst case is 11 for 3x3x3 it’s 20 for nxnxn Θ(n2/lgn) Graph Representation Adjacency lists array Adj of |V| linked lists for each vertex u∈V, Adj[u] stores u’s neighbors, which can be reached in one step object oriented: v.neighbors = Adj[v] implicit representation: Adj(u) is a function or v.neighbors() is method of the class Θ(V+E) BFS goal: visit all nodes reachable from given s∈V O(V+E) time look at the nodes reachable in 0 moves, 1 moves,… careful to avoid duplicates BFS(s,Adj): level = {s: φ} parent = {s: None} i = 1 frontier = [s] #","date":"2021-12-25","objectID":"/breadth-first-search-bfs/:0:1","series":[],"tags":["Algorithm"],"title":"BFS","uri":"/breadth-first-search-bfs/#bfs"},{"categories":["Note"],"content":"Breadth-First Search (BFS) Basic Graph Review Graph search find paths from one state to another Recall: graph G = (V,E) V = set of vertices E = set of edges undirected e = {v,w} unordered pairs directed e = (v,w) ordered pairs Aplications of graph search web crawling social networking (search the friend near you than friends of a friend) network broadcast garbage collection model checking check mathematical conj. solving puzzle of game Pocket Cube: 2x2x2 configuration graph vertex for each possible state of cube number of vertices: 8! x 38 = 264,539,520 on every cube there are 8 vertices that can be permulated inside itself then every cube has 3 rotation state there are 8 cubes in total you can actually divide it by 24 since there are 24 symmetries you also can divide it by 3 since only one third of the cofiguration spaces are reachable edge for each possible move ​ undirected solved state - next possible states -…-initial states the number of layers is called the diameter for the best algo, the worst case is 11 for 3x3x3 it’s 20 for nxnxn Θ(n2/lgn) Graph Representation Adjacency lists array Adj of |V| linked lists for each vertex u∈V, Adj[u] stores u’s neighbors, which can be reached in one step object oriented: v.neighbors = Adj[v] implicit representation: Adj(u) is a function or v.neighbors() is method of the class Θ(V+E) BFS goal: visit all nodes reachable from given s∈V O(V+E) time look at the nodes reachable in 0 moves, 1 moves,… careful to avoid duplicates BFS(s,Adj): level = {s: φ} parent = {s: None} i = 1 frontier = [s] #","date":"2021-12-25","objectID":"/breadth-first-search-bfs/:0:1","series":[],"tags":["Algorithm"],"title":"BFS","uri":"/breadth-first-search-bfs/#shortest-path"},{"categories":["Note"],"content":"Bisection Search def bisect_search1(L, e): if L == []: return False elif len(L) == 1: return L[0] == e else: half = len(L)//2 if L[half] \u003e e: return bisect_search1( L[:half], e) else: return bisect_search1( L[half:], e) O(nlgn) for this one It takes lgn steps until the len(L) is 1. In every step, it takes O(n) to copy a list. Revision aiming to achieve O(lgn) def bisect_search2(L, e): def bisect_search_helper(L, e, low, high): if high == low: return L[low] == e mid = (low + high)//2 if L[mid] == e: return True elif L[mid] \u003e e: if low == mid: #nothing left to search return False else: return bisect_search_helper(L, e, low, mid - 1) else: return bisect_search_helper(L, e, mid + 1, high) if len(L) == 0: return False else: return bisect_search_helper(L, e, 0, len(L) - 1) Program Efficiency Big O O(1) denotes constant running time O(logn) denotes logarithmic running time O(n) denotes linear running time O(nlogn) denotes log-linear running time O(n^c) denotes polynomial running time(c is a constant) O(c^n) denotes exponential running time(c is a constant being raised to a power based on the size of the input) ","date":"2021-12-25","objectID":"/binary-search/:0:0","series":[],"tags":["Algorithm"],"title":"Binary Search","uri":"/binary-search/#"},{"categories":["Note"],"content":"C# advanced Delegate 委托 vs 接口 委托可以解决的问题，接口也可以 什么时候更适合用委托？ 接口只能定义一个方法 需要多播能力 订阅者需要多次实现接口 委托的兼容性 委托类型：委托类型之间互不相容，即使方法签名也一样 delegate void D1(); delegate void D2(); D1 d1 = Method1; D2 d2 = d1;//Compile-time error 委托实例：如果委托实例拥有相同的方法，那么就认为二者相等 delegate void D(); ... D d1 = Method1; D d2 = Method1; Console.WriteLine(d1 == d2);//True 参数：当调用方法时，args可以比param更具体 委托可以接受比它的目标方法更具体的参数类型，这个性质叫做ContraVariance，逆变 delegate void StringAction (string s); class Test { static void Main() { StringAction sa = new StringAction (ActOnObject);//调用的方法的param是object sa(\"hello\");//传入的是string，比object更具体 } static void ActOnObject (object o) =\u003e Console.WriteLine (o);//hello } 返回类型：调用方法时，你可以得到一个比请求的类型更具体的类型的返回结果。 委托的目标方法可以返回比委托描述里更具体的类型的返回结果，Covariance，协变 delegate object ObjectRetriever();//委托的返回类型是object class Test { static void Main() { ObjectRetriever o = new ObjectRetriever (RetrieveString); object result = o(); Console.WriteLine (result);//hello } static string RetrieveString() =\u003e \"hello\";//调用方法的返回类型是子类string } 多线程 术语 抢占 当线程与其他线程交织的一刻，即被抢占了 线程的一些属性 线程开始后IsAlive变为true直到线程结束 线程的结束条件：线程构造函数传入的委托结束了执行 线程结束后，无法重启 每个线程的Name属性只能设置一次 静态的Thread.CurrentThread属性，会返回当前执行的线程 Join and Sleep 线程池 不可以设置池线程的Name（调试不方便，但有办法解决） 池线程都是后台线程 阻塞池线程可使性能降低 你可以自由的更改池线程的优先级 当它释放回池的时候优先级将还原为正常状态 可以通过Thread.CurrentThread.IsThreadPoolThread属性来判断是否执行在池线程上 进入线程池 最简单的显式的在池线程运行代码的方式就是使用Task.Run //Task is in System.Threading.Tasks Task.Run (() =\u003e Console.WriteLine(\"Greetings from the thread pool\")); 谁使用了线程池 并行编程结构 等等 线程池中的整洁 线程是提供了一个功能：确保临时超出 ","date":"2021-12-25","objectID":"/c#-advanced/:0:0","series":[],"tags":["C#"],"title":"C# Advanced","uri":"/c#-advanced/#c-advanced"},{"categories":["Note"],"content":"C# advanced Delegate 委托 vs 接口 委托可以解决的问题，接口也可以 什么时候更适合用委托？ 接口只能定义一个方法 需要多播能力 订阅者需要多次实现接口 委托的兼容性 委托类型：委托类型之间互不相容，即使方法签名也一样 delegate void D1(); delegate void D2(); D1 d1 = Method1; D2 d2 = d1;//Compile-time error 委托实例：如果委托实例拥有相同的方法，那么就认为二者相等 delegate void D(); ... D d1 = Method1; D d2 = Method1; Console.WriteLine(d1 == d2);//True 参数：当调用方法时，args可以比param更具体 委托可以接受比它的目标方法更具体的参数类型，这个性质叫做ContraVariance，逆变 delegate void StringAction (string s); class Test { static void Main() { StringAction sa = new StringAction (ActOnObject);//调用的方法的param是object sa(\"hello\");//传入的是string，比object更具体 } static void ActOnObject (object o) = Console.WriteLine (o);//hello } 返回类型：调用方法时，你可以得到一个比请求的类型更具体的类型的返回结果。 委托的目标方法可以返回比委托描述里更具体的类型的返回结果，Covariance，协变 delegate object ObjectRetriever();//委托的返回类型是object class Test { static void Main() { ObjectRetriever o = new ObjectRetriever (RetrieveString); object result = o(); Console.WriteLine (result);//hello } static string RetrieveString() = \"hello\";//调用方法的返回类型是子类string } 多线程 术语 抢占 当线程与其他线程交织的一刻，即被抢占了 线程的一些属性 线程开始后IsAlive变为true直到线程结束 线程的结束条件：线程构造函数传入的委托结束了执行 线程结束后，无法重启 每个线程的Name属性只能设置一次 静态的Thread.CurrentThread属性，会返回当前执行的线程 Join and Sleep 线程池 不可以设置池线程的Name（调试不方便，但有办法解决） 池线程都是后台线程 阻塞池线程可使性能降低 你可以自由的更改池线程的优先级 当它释放回池的时候优先级将还原为正常状态 可以通过Thread.CurrentThread.IsThreadPoolThread属性来判断是否执行在池线程上 进入线程池 最简单的显式的在池线程运行代码的方式就是使用Task.Run //Task is in System.Threading.Tasks Task.Run (() = Console.WriteLine(\"Greetings from the thread pool\")); 谁使用了线程池 并行编程结构 等等 线程池中的整洁 线程是提供了一个功能：确保临时超出 ","date":"2021-12-25","objectID":"/c#-advanced/:0:0","series":[],"tags":["C#"],"title":"C# Advanced","uri":"/c#-advanced/#delegate"},{"categories":["Note"],"content":"C# advanced Delegate 委托 vs 接口 委托可以解决的问题，接口也可以 什么时候更适合用委托？ 接口只能定义一个方法 需要多播能力 订阅者需要多次实现接口 委托的兼容性 委托类型：委托类型之间互不相容，即使方法签名也一样 delegate void D1(); delegate void D2(); D1 d1 = Method1; D2 d2 = d1;//Compile-time error 委托实例：如果委托实例拥有相同的方法，那么就认为二者相等 delegate void D(); ... D d1 = Method1; D d2 = Method1; Console.WriteLine(d1 == d2);//True 参数：当调用方法时，args可以比param更具体 委托可以接受比它的目标方法更具体的参数类型，这个性质叫做ContraVariance，逆变 delegate void StringAction (string s); class Test { static void Main() { StringAction sa = new StringAction (ActOnObject);//调用的方法的param是object sa(\"hello\");//传入的是string，比object更具体 } static void ActOnObject (object o) = Console.WriteLine (o);//hello } 返回类型：调用方法时，你可以得到一个比请求的类型更具体的类型的返回结果。 委托的目标方法可以返回比委托描述里更具体的类型的返回结果，Covariance，协变 delegate object ObjectRetriever();//委托的返回类型是object class Test { static void Main() { ObjectRetriever o = new ObjectRetriever (RetrieveString); object result = o(); Console.WriteLine (result);//hello } static string RetrieveString() = \"hello\";//调用方法的返回类型是子类string } 多线程 术语 抢占 当线程与其他线程交织的一刻，即被抢占了 线程的一些属性 线程开始后IsAlive变为true直到线程结束 线程的结束条件：线程构造函数传入的委托结束了执行 线程结束后，无法重启 每个线程的Name属性只能设置一次 静态的Thread.CurrentThread属性，会返回当前执行的线程 Join and Sleep 线程池 不可以设置池线程的Name（调试不方便，但有办法解决） 池线程都是后台线程 阻塞池线程可使性能降低 你可以自由的更改池线程的优先级 当它释放回池的时候优先级将还原为正常状态 可以通过Thread.CurrentThread.IsThreadPoolThread属性来判断是否执行在池线程上 进入线程池 最简单的显式的在池线程运行代码的方式就是使用Task.Run //Task is in System.Threading.Tasks Task.Run (() = Console.WriteLine(\"Greetings from the thread pool\")); 谁使用了线程池 并行编程结构 等等 线程池中的整洁 线程是提供了一个功能：确保临时超出 ","date":"2021-12-25","objectID":"/c#-advanced/:0:0","series":[],"tags":["C#"],"title":"C# Advanced","uri":"/c#-advanced/#多线程"},{"categories":["Note"],"content":"C# advanced Delegate 委托 vs 接口 委托可以解决的问题，接口也可以 什么时候更适合用委托？ 接口只能定义一个方法 需要多播能力 订阅者需要多次实现接口 委托的兼容性 委托类型：委托类型之间互不相容，即使方法签名也一样 delegate void D1(); delegate void D2(); D1 d1 = Method1; D2 d2 = d1;//Compile-time error 委托实例：如果委托实例拥有相同的方法，那么就认为二者相等 delegate void D(); ... D d1 = Method1; D d2 = Method1; Console.WriteLine(d1 == d2);//True 参数：当调用方法时，args可以比param更具体 委托可以接受比它的目标方法更具体的参数类型，这个性质叫做ContraVariance，逆变 delegate void StringAction (string s); class Test { static void Main() { StringAction sa = new StringAction (ActOnObject);//调用的方法的param是object sa(\"hello\");//传入的是string，比object更具体 } static void ActOnObject (object o) = Console.WriteLine (o);//hello } 返回类型：调用方法时，你可以得到一个比请求的类型更具体的类型的返回结果。 委托的目标方法可以返回比委托描述里更具体的类型的返回结果，Covariance，协变 delegate object ObjectRetriever();//委托的返回类型是object class Test { static void Main() { ObjectRetriever o = new ObjectRetriever (RetrieveString); object result = o(); Console.WriteLine (result);//hello } static string RetrieveString() = \"hello\";//调用方法的返回类型是子类string } 多线程 术语 抢占 当线程与其他线程交织的一刻，即被抢占了 线程的一些属性 线程开始后IsAlive变为true直到线程结束 线程的结束条件：线程构造函数传入的委托结束了执行 线程结束后，无法重启 每个线程的Name属性只能设置一次 静态的Thread.CurrentThread属性，会返回当前执行的线程 Join and Sleep 线程池 不可以设置池线程的Name（调试不方便，但有办法解决） 池线程都是后台线程 阻塞池线程可使性能降低 你可以自由的更改池线程的优先级 当它释放回池的时候优先级将还原为正常状态 可以通过Thread.CurrentThread.IsThreadPoolThread属性来判断是否执行在池线程上 进入线程池 最简单的显式的在池线程运行代码的方式就是使用Task.Run //Task is in System.Threading.Tasks Task.Run (() = Console.WriteLine(\"Greetings from the thread pool\")); 谁使用了线程池 并行编程结构 等等 线程池中的整洁 线程是提供了一个功能：确保临时超出 ","date":"2021-12-25","objectID":"/c#-advanced/:0:0","series":[],"tags":["C#"],"title":"C# Advanced","uri":"/c#-advanced/#术语"},{"categories":["Note"],"content":"C# advanced Delegate 委托 vs 接口 委托可以解决的问题，接口也可以 什么时候更适合用委托？ 接口只能定义一个方法 需要多播能力 订阅者需要多次实现接口 委托的兼容性 委托类型：委托类型之间互不相容，即使方法签名也一样 delegate void D1(); delegate void D2(); D1 d1 = Method1; D2 d2 = d1;//Compile-time error 委托实例：如果委托实例拥有相同的方法，那么就认为二者相等 delegate void D(); ... D d1 = Method1; D d2 = Method1; Console.WriteLine(d1 == d2);//True 参数：当调用方法时，args可以比param更具体 委托可以接受比它的目标方法更具体的参数类型，这个性质叫做ContraVariance，逆变 delegate void StringAction (string s); class Test { static void Main() { StringAction sa = new StringAction (ActOnObject);//调用的方法的param是object sa(\"hello\");//传入的是string，比object更具体 } static void ActOnObject (object o) = Console.WriteLine (o);//hello } 返回类型：调用方法时，你可以得到一个比请求的类型更具体的类型的返回结果。 委托的目标方法可以返回比委托描述里更具体的类型的返回结果，Covariance，协变 delegate object ObjectRetriever();//委托的返回类型是object class Test { static void Main() { ObjectRetriever o = new ObjectRetriever (RetrieveString); object result = o(); Console.WriteLine (result);//hello } static string RetrieveString() = \"hello\";//调用方法的返回类型是子类string } 多线程 术语 抢占 当线程与其他线程交织的一刻，即被抢占了 线程的一些属性 线程开始后IsAlive变为true直到线程结束 线程的结束条件：线程构造函数传入的委托结束了执行 线程结束后，无法重启 每个线程的Name属性只能设置一次 静态的Thread.CurrentThread属性，会返回当前执行的线程 Join and Sleep 线程池 不可以设置池线程的Name（调试不方便，但有办法解决） 池线程都是后台线程 阻塞池线程可使性能降低 你可以自由的更改池线程的优先级 当它释放回池的时候优先级将还原为正常状态 可以通过Thread.CurrentThread.IsThreadPoolThread属性来判断是否执行在池线程上 进入线程池 最简单的显式的在池线程运行代码的方式就是使用Task.Run //Task is in System.Threading.Tasks Task.Run (() = Console.WriteLine(\"Greetings from the thread pool\")); 谁使用了线程池 并行编程结构 等等 线程池中的整洁 线程是提供了一个功能：确保临时超出 ","date":"2021-12-25","objectID":"/c#-advanced/:0:0","series":[],"tags":["C#"],"title":"C# Advanced","uri":"/c#-advanced/#线程的一些属性"},{"categories":["Note"],"content":"C# advanced Delegate 委托 vs 接口 委托可以解决的问题，接口也可以 什么时候更适合用委托？ 接口只能定义一个方法 需要多播能力 订阅者需要多次实现接口 委托的兼容性 委托类型：委托类型之间互不相容，即使方法签名也一样 delegate void D1(); delegate void D2(); D1 d1 = Method1; D2 d2 = d1;//Compile-time error 委托实例：如果委托实例拥有相同的方法，那么就认为二者相等 delegate void D(); ... D d1 = Method1; D d2 = Method1; Console.WriteLine(d1 == d2);//True 参数：当调用方法时，args可以比param更具体 委托可以接受比它的目标方法更具体的参数类型，这个性质叫做ContraVariance，逆变 delegate void StringAction (string s); class Test { static void Main() { StringAction sa = new StringAction (ActOnObject);//调用的方法的param是object sa(\"hello\");//传入的是string，比object更具体 } static void ActOnObject (object o) = Console.WriteLine (o);//hello } 返回类型：调用方法时，你可以得到一个比请求的类型更具体的类型的返回结果。 委托的目标方法可以返回比委托描述里更具体的类型的返回结果，Covariance，协变 delegate object ObjectRetriever();//委托的返回类型是object class Test { static void Main() { ObjectRetriever o = new ObjectRetriever (RetrieveString); object result = o(); Console.WriteLine (result);//hello } static string RetrieveString() = \"hello\";//调用方法的返回类型是子类string } 多线程 术语 抢占 当线程与其他线程交织的一刻，即被抢占了 线程的一些属性 线程开始后IsAlive变为true直到线程结束 线程的结束条件：线程构造函数传入的委托结束了执行 线程结束后，无法重启 每个线程的Name属性只能设置一次 静态的Thread.CurrentThread属性，会返回当前执行的线程 Join and Sleep 线程池 不可以设置池线程的Name（调试不方便，但有办法解决） 池线程都是后台线程 阻塞池线程可使性能降低 你可以自由的更改池线程的优先级 当它释放回池的时候优先级将还原为正常状态 可以通过Thread.CurrentThread.IsThreadPoolThread属性来判断是否执行在池线程上 进入线程池 最简单的显式的在池线程运行代码的方式就是使用Task.Run //Task is in System.Threading.Tasks Task.Run (() = Console.WriteLine(\"Greetings from the thread pool\")); 谁使用了线程池 并行编程结构 等等 线程池中的整洁 线程是提供了一个功能：确保临时超出 ","date":"2021-12-25","objectID":"/c#-advanced/:0:0","series":[],"tags":["C#"],"title":"C# Advanced","uri":"/c#-advanced/#join-and-sleep"},{"categories":["Note"],"content":"C# advanced Delegate 委托 vs 接口 委托可以解决的问题，接口也可以 什么时候更适合用委托？ 接口只能定义一个方法 需要多播能力 订阅者需要多次实现接口 委托的兼容性 委托类型：委托类型之间互不相容，即使方法签名也一样 delegate void D1(); delegate void D2(); D1 d1 = Method1; D2 d2 = d1;//Compile-time error 委托实例：如果委托实例拥有相同的方法，那么就认为二者相等 delegate void D(); ... D d1 = Method1; D d2 = Method1; Console.WriteLine(d1 == d2);//True 参数：当调用方法时，args可以比param更具体 委托可以接受比它的目标方法更具体的参数类型，这个性质叫做ContraVariance，逆变 delegate void StringAction (string s); class Test { static void Main() { StringAction sa = new StringAction (ActOnObject);//调用的方法的param是object sa(\"hello\");//传入的是string，比object更具体 } static void ActOnObject (object o) = Console.WriteLine (o);//hello } 返回类型：调用方法时，你可以得到一个比请求的类型更具体的类型的返回结果。 委托的目标方法可以返回比委托描述里更具体的类型的返回结果，Covariance，协变 delegate object ObjectRetriever();//委托的返回类型是object class Test { static void Main() { ObjectRetriever o = new ObjectRetriever (RetrieveString); object result = o(); Console.WriteLine (result);//hello } static string RetrieveString() = \"hello\";//调用方法的返回类型是子类string } 多线程 术语 抢占 当线程与其他线程交织的一刻，即被抢占了 线程的一些属性 线程开始后IsAlive变为true直到线程结束 线程的结束条件：线程构造函数传入的委托结束了执行 线程结束后，无法重启 每个线程的Name属性只能设置一次 静态的Thread.CurrentThread属性，会返回当前执行的线程 Join and Sleep 线程池 不可以设置池线程的Name（调试不方便，但有办法解决） 池线程都是后台线程 阻塞池线程可使性能降低 你可以自由的更改池线程的优先级 当它释放回池的时候优先级将还原为正常状态 可以通过Thread.CurrentThread.IsThreadPoolThread属性来判断是否执行在池线程上 进入线程池 最简单的显式的在池线程运行代码的方式就是使用Task.Run //Task is in System.Threading.Tasks Task.Run (() = Console.WriteLine(\"Greetings from the thread pool\")); 谁使用了线程池 并行编程结构 等等 线程池中的整洁 线程是提供了一个功能：确保临时超出 ","date":"2021-12-25","objectID":"/c#-advanced/:0:0","series":[],"tags":["C#"],"title":"C# Advanced","uri":"/c#-advanced/#线程池"},{"categories":["Note"],"content":" #include \u003ciostream\u003e#include \u003cfstream\u003e#include \u003cstring\u003e#include \u003cvector\u003e int main() { std::cout \u003c\u003c \"Hello World\" \u003c\u003c std::endl; const double PI = 3.1415926; char myGrade = 'A'; bool isHappy = true; float favNum = 3; int myAge = 80; // short int, long int, unsigned int std::cout \u003c\u003c \"Size of int\" \u003c\u003c sizeof(myGrade) \u003c\u003c std::endl; string numberGuessed; int intNumberGuessed = 0; do { std::cout \u003c\u003c \"Guess between 1 and 10: \"; getline(cin, numberGuessed); intNumberGuessed = stoi(numberGuessed); } while(intNumberGuessed != 4); string birthdayString = \"Birthday\"; char* happyArr = \"Happy\"; std::cout \u003c\u003c \"hello\" \u003c\u003c yourName \u003c\u003c std::endl; std::cout \u003c\u003c happyArr + birthdayString \u003c\u003c std::endl; string yourName; std::cout \u003c\u003c \"What is your name?\" \u003c\u003c std::endl; getline(cin, yourName); std::cout \u003c\u003c yourName \u003c\u003c std::endl; //stoi(), stod() //str.size() str.empty() str.append(str2) str.compare(str2) str.assign(str2) str.assign(str2, 0, 5) str.find(\"str1\", 0) returns the starting index of the substring //str.insert(5, \"Justin\") //str.erase(int startPoint, int len) //str.replace(int startPoint, int len, \"The string your want to replace\") vector \u003cint\u003e lotteryNumVect(10); int lotteryNumArray[5] = {3, 4, 1, 9, 0}; return 0; } Difference between free() and delete free() is a function in a library, while delete is an operator free() de-allocate the memory, while delete will also call the destructor function detele is faster since operator is faster than calling a function The length of memory that pointers indicate int* func() { int arr[100] = {0}; int* ptr = arr; return ptr; } //The func return a pointer containing only the beginning address of the arr, there is not no info about the length int* func() { int* ptr = (int*)malloc(100 * sizeof(int)); return ptr; } //The malloc function will store some bytes of extra info in the allocated memory including the length So if the ptr points to a memory created by malloc(), then length = sizeof(ptr) / sizeof(type) Polymorphism class Animal { public: void print() { std::cout \u003c\u003c \"I'm a/an animal!\" \u003c\u003c std::endl; } } class Dog:public Animal { public: void print() { std::cout \u003c\u003c \"I'm a/an dog!\" \u003c\u003c std::endl; } } class Spot:public Dog { public: void print() { std::cout \u003c\u003c \"I'm a/an spot!\" \u003c\u003c std::endl; } } If Animal ptr = new Animal and call the function, it will run the print() of Animal class. If Animal ptr = new Dog and call the function, it will run the print() of Animal class. If Dog ptr = new Dog and call the function, it will run the print() of Dog class. 2 3 4 happens because the the compiler knows the types of the object from the type of the pointer. If Animal ptr = new Animal and call the function and the print() of Animal is virtual, it will run the print() of Animal class. If Animal ptr = new Dog and call the function and the print() of Animal is virtual, it will run the print() of Dog class. If Animal ptr = new 。spot and call the function and the print() of Animal is virtual, it will run the print() of Spot class. 1 成员函数重载特征： a 相同的范围（在同一个类中） b 函数名字相同 c 参数不同 d virtual关键字可有可无 2 **重写（覆盖)**是指派生类函数覆盖基类函数，特征是： a 不同的范围，分别位于基类和派生类中 b 函数的名字相同 c 参数相同 d 基类函数必须有virtual关键字 3 **重定义(隐藏)**是指派生类的函数屏蔽了与其同名的基类函数，规则如下： a 如果派生类的函数和基类的函数同名，但是参数不同，此时，不管有无virtual，基类的函数被隐藏。 b 如果派生类的函数与基类的函数同名，并且参数也相同，但是基类函数没有vitual关键字，此时，基类的函数被隐藏。（如果父类的成员和子类的成员属性名称相同，我们可以通过作用域操作符来显式的使用父类的成员，如果我们不使用作用域操作符，默认使用的是子类的成员属性。） 虚函数作用及上三条总结 **基类和子类都有同一个函数，定义一个*基类指针*指向子类对象，用指针调用该函数，如果函数为非虚则调用基类函数，否则调用子类函数（第2条）。若指针与指向对象相同，则各自调用各自的函数（子类时第3条）。 《C++ Primer》第五版，P537 页：“当我面在派生类中覆盖某个虚函数时，可以再一次使用virtual关键字指出该函数的性质。然而这么做并非必须，因为一旦某个函数被声明为虚函数，则在所有派生类中它都是虚函数” ****C++的多态性****用一句话概括就是：在基类的函数前加上virtual关键字，在派生类中重写该函数，运行时将会根据对象的实际类型来调用相应的函数。如果对象类型是派生类，就调用派生类的函数；如果对象类型是基类，就调用基类的函数 虚继承 虚继承详解 内存对齐 Memory Alignment C/C++内存对齐详解 Template typename和class在模版语法中的区别 Inline 内联函数 看后半部分 ","date":"2021-12-25","objectID":"/c-review/:0:0","series":[],"tags":["C++"],"title":"C++ Review","uri":"/c-review/#"},{"categories":["Note"],"content":"C++ ","date":"2021-12-25","objectID":"/c-review/:0:0","series":[],"tags":["C++"],"title":"C++ Review","uri":"/c-review/#c"},{"categories":["Note"],"content":"gdb/lldb ","date":"2021-12-25","objectID":"/c-review/:0:1","series":[],"tags":["C++"],"title":"C++ Review","uri":"/c-review/#gdblldb"},{"categories":["Note"],"content":"Key Words const ","date":"2021-12-25","objectID":"/c-review/:0:2","series":[],"tags":["C++"],"title":"C++ Review","uri":"/c-review/#key-words"},{"categories":["Note"],"content":"New in C++ ","date":"2021-12-25","objectID":"/c-review/:1:0","series":[],"tags":["C++"],"title":"C++ Review","uri":"/c-review/#new-in-c"},{"categories":["Note"],"content":"String basic #include \u003cstring\u003eusing namespace std; int main() { string str1; string str2 = \"init\"; string str3(\"init\"); string str4{\"init\"}; string str = \"This is a test!\"; char c = str.at(0); str.substr(3,6) //s is a int thisIndex = str.find(\"This\"); str.replace(thisIndex, 4, \"That\"); return 0; } cin and getline ","date":"2021-12-25","objectID":"/c-review/:1:1","series":[],"tags":["C++"],"title":"C++ Review","uri":"/c-review/#string"},{"categories":["Note"],"content":"String basic #include using namespace std; int main() { string str1; string str2 = \"init\"; string str3(\"init\"); string str4{\"init\"}; string str = \"This is a test!\"; char c = str.at(0); str.substr(3,6) //s is a int thisIndex = str.find(\"This\"); str.replace(thisIndex, 4, \"That\"); return 0; } cin and getline ","date":"2021-12-25","objectID":"/c-review/:1:1","series":[],"tags":["C++"],"title":"C++ Review","uri":"/c-review/#basic"},{"categories":["Note"],"content":"String basic #include using namespace std; int main() { string str1; string str2 = \"init\"; string str3(\"init\"); string str4{\"init\"}; string str = \"This is a test!\"; char c = str.at(0); str.substr(3,6) //s is a int thisIndex = str.find(\"This\"); str.replace(thisIndex, 4, \"That\"); return 0; } cin and getline ","date":"2021-12-25","objectID":"/c-review/:1:1","series":[],"tags":["C++"],"title":"C++ Review","uri":"/c-review/#cin-and-getline"},{"categories":["Note"],"content":"Type conversions implicit conversion static_cast\u003ctype\u003e(expression) static_cast\u003cint\u003e(num1 + num2) ","date":"2021-12-25","objectID":"/c-review/:1:2","series":[],"tags":["C++"],"title":"C++ Review","uri":"/c-review/#type-conversions"},{"categories":["Note"],"content":"Boolean #include \u003ciostream\u003eusing namespace std; int main() { bool isMale; int weight = 90; isMale = (weight \u003e= 85); return 0; } ","date":"2021-12-25","objectID":"/c-review/:1:3","series":[],"tags":["C++"],"title":"C++ Review","uri":"/c-review/#boolean"},{"categories":["Note"],"content":"Default parameter values #include \u003ciostream\u003eusing namespace std; void DataPrint(string sex, string name, int age, printStyle = 0); int main() { DataPrint(\"male\", \"Jarvis\", 28); //you can omit the params with default values! //Notice that the params with default values must be continous from the last param // void func(int a = 0, int b, int c ,int d = 0) is INCORRECT! return 0; } ","date":"2021-12-25","objectID":"/c-review/:1:4","series":[],"tags":["C++"],"title":"C++ Review","uri":"/c-review/#default-parameter-values"},{"categories":["Note"],"content":"Random numbers #include \u003ciostream\u003e#include \u003ccstdlib\u003e#include \u003ctime\u003eusing namespace std; int main(){ cout \u003c\u003c rand() \u003c\u003c endl; cout \u003c\u003c RAND_MAX \u003c\u003c endl; srand(time(0)); } ","date":"2021-12-25","objectID":"/c-review/:1:5","series":[],"tags":["C++"],"title":"C++ Review","uri":"/c-review/#random-numbers"},{"categories":["Note"],"content":"Stream ","date":"2021-12-25","objectID":"/c-review/:2:0","series":[],"tags":["C++"],"title":"C++ Review","uri":"/c-review/#stream"},{"categories":["Note"],"content":"Input string stream #include \u003ciostream\u003e#include \u003csstream\u003e#include \u003cstring\u003eusing namespace std; int main() { string userInfo = \"Amy Smith 19\"; // Input string istringstream inSS(userInfo); // Input string stream string firstName; // First name string lastName; // Last name int userAge; // Age // Parse name and age values from input string inSS \u003e\u003e firstName; inSS \u003e\u003e lastName; inSS \u003e\u003e userAge; // Output parsed values cout \u003c\u003c \"First name: \" \u003c\u003c firstName \u003c\u003c endl; cout \u003c\u003c \"Last name: \" \u003c\u003c lastName \u003c\u003c endl; cout \u003c\u003c \"Age: \" \u003c\u003c userAge \u003c\u003c endl; return 0; } Using getline() with string streams /* A common use of string streams is to process user input line-by-line. The program below reads in a line as a string and then extracts individual data items from the string. The getline() function reads an input line into a string, and inSS.str(lineString); uses the str() function to initialize the stream's buffer to string lineString. Afterwards, the program extracts input from inSS using \u003e\u003e. The statement inSS.clear(); is necessary to reset the state of the stream so that subsequent extractions start from the beginning of the input strings. */ #include \u003ciostream\u003e#include \u003cstring\u003e#include \u003csstream\u003eusing namespace std; int main() { istringstream inSS; // Input string stream string lineString; // Holds line of text string firstName; // First name string lastName; // Last name int userAge; // Age bool inputDone; // Flag to indicate next iteration inputDone = false; // Prompt user for input cout \u003c\u003c \"Enter \\\"firstname lastname age\\\"on each line\" \u003c\u003c endl; cout \u003c\u003c \"(\\\"Exit\\\"as firstname exits).\" \u003c\u003c endl \u003c\u003c endl; // Grab data as long as \"Exit\" is not entered while (!inputDone) { // Entire line into lineString getline(cin, lineString); // Copies to inSS's string buffer inSS.clear(); inSS.str(lineString); // Now process the line inSS \u003e\u003e firstName; // Output parsed values if (firstName == \"Exit\") { cout \u003c\u003c \" Exiting.\" \u003c\u003c endl; inputDone = true; } else { inSS \u003e\u003e lastName; inSS \u003e\u003e userAge; cout \u003c\u003c \" First name: \" \u003c\u003c firstName \u003c\u003c endl; cout \u003c\u003c \" Last name: \" \u003c\u003c lastName \u003c\u003c endl; cout \u003c\u003c \" Age: \" \u003c\u003c userAge \u003c\u003c endl; cout \u003c\u003c endl; } } return 0; } Reaching the end of a string stream /* A programmer will not always know how much data exists in a user input string, so using multiple individual extractions (Ex: inSS \u003e\u003e data1; inSS \u003e\u003e data2;) is not useful for reading all of the input data. Input streams have a Boolean function called eof() or end of file that returns true or false depending on whether or not the end of the stream has been reached. An if statement or while loop can check if the end of input string stream has been reached by using the extraction operator. Ex: In the code while (inSS \u003e\u003e data) { ... } the while statement implicitly calls inSS's eof() function, which returns false if more data exists in the string stream to be read and true if the end of string stream has been reached. When eof() returns false, inSS \u003e\u003e data resolves to true, causing the loop to continue. Conversely, when eof() returns true, inSS \u003e\u003e data resolves to false, meaning the end of the string stream has been reached, and the loop exits. */ #include \u003ciostream\u003e#include \u003csstream\u003e#include \u003cstring\u003eusing namespace std; int main() { istringstream inSS; // Input string stream string lineString; // Holds input string string data; cout \u003c\u003c \"Enter a list of names separated by spaces: \"; // Entire line into lineString getline(cin, lineString); inSS.str(lineString); while (inSS \u003e\u003e data) { cout \u003c\u003c data \u003c\u003c endl; } return 0; } Example: Phone number formats /* The example below reads in phone numbers in two different formats and then presents the phone numbers in a standard 10-digit format. American phone numbers include an area code (3 digits), central office code (3 digits), and station number (4 digits). The program uses an input string stream to read each portion of the phone number, the ios good() function to determine if the area code entered consists solely of integers, and two dummy char","date":"2021-12-25","objectID":"/c-review/:2:1","series":[],"tags":["C++"],"title":"C++ Review","uri":"/c-review/#input-string-stream"},{"categories":["Note"],"content":"Input string stream #include #include #include using namespace std; int main() { string userInfo = \"Amy Smith 19\"; // Input string istringstream inSS(userInfo); // Input string stream string firstName; // First name string lastName; // Last name int userAge; // Age // Parse name and age values from input string inSS firstName; inSS lastName; inSS userAge; // Output parsed values cout . The statement inSS.clear(); is necessary to reset the state of the stream so that subsequent extractions start from the beginning of the input strings. */ #include #include #include using namespace std; int main() { istringstream inSS; // Input string stream string lineString; // Holds line of text string firstName; // First name string lastName; // Last name int userAge; // Age bool inputDone; // Flag to indicate next iteration inputDone = false; // Prompt user for input cout firstName; // Output parsed values if (firstName == \"Exit\") { cout lastName; inSS userAge; cout data1; inSS data2;) is not useful for reading all of the input data. Input streams have a Boolean function called eof() or end of file that returns true or false depending on whether or not the end of the stream has been reached. An if statement or while loop can check if the end of input string stream has been reached by using the extraction operator. Ex: In the code while (inSS data) { ... } the while statement implicitly calls inSS's eof() function, which returns false if more data exists in the string stream to be read and true if the end of string stream has been reached. When eof() returns false, inSS data resolves to true, causing the loop to continue. Conversely, when eof() returns true, inSS data resolves to false, meaning the end of the string stream has been reached, and the loop exits. */ #include #include #include using namespace std; int main() { istringstream inSS; // Input string stream string lineString; // Holds input string string data; cout data) { cout ","date":"2021-12-25","objectID":"/c-review/:2:1","series":[],"tags":["C++"],"title":"C++ Review","uri":"/c-review/#using-getline-with-string-streams"},{"categories":["Note"],"content":"Input string stream #include #include #include using namespace std; int main() { string userInfo = \"Amy Smith 19\"; // Input string istringstream inSS(userInfo); // Input string stream string firstName; // First name string lastName; // Last name int userAge; // Age // Parse name and age values from input string inSS firstName; inSS lastName; inSS userAge; // Output parsed values cout . The statement inSS.clear(); is necessary to reset the state of the stream so that subsequent extractions start from the beginning of the input strings. */ #include #include #include using namespace std; int main() { istringstream inSS; // Input string stream string lineString; // Holds line of text string firstName; // First name string lastName; // Last name int userAge; // Age bool inputDone; // Flag to indicate next iteration inputDone = false; // Prompt user for input cout firstName; // Output parsed values if (firstName == \"Exit\") { cout lastName; inSS userAge; cout data1; inSS data2;) is not useful for reading all of the input data. Input streams have a Boolean function called eof() or end of file that returns true or false depending on whether or not the end of the stream has been reached. An if statement or while loop can check if the end of input string stream has been reached by using the extraction operator. Ex: In the code while (inSS data) { ... } the while statement implicitly calls inSS's eof() function, which returns false if more data exists in the string stream to be read and true if the end of string stream has been reached. When eof() returns false, inSS data resolves to true, causing the loop to continue. Conversely, when eof() returns true, inSS data resolves to false, meaning the end of the string stream has been reached, and the loop exits. */ #include #include #include using namespace std; int main() { istringstream inSS; // Input string stream string lineString; // Holds input string string data; cout data) { cout ","date":"2021-12-25","objectID":"/c-review/:2:1","series":[],"tags":["C++"],"title":"C++ Review","uri":"/c-review/#reaching-the-end-of-a-string-stream"},{"categories":["Note"],"content":"Input string stream #include #include #include using namespace std; int main() { string userInfo = \"Amy Smith 19\"; // Input string istringstream inSS(userInfo); // Input string stream string firstName; // First name string lastName; // Last name int userAge; // Age // Parse name and age values from input string inSS firstName; inSS lastName; inSS userAge; // Output parsed values cout . The statement inSS.clear(); is necessary to reset the state of the stream so that subsequent extractions start from the beginning of the input strings. */ #include #include #include using namespace std; int main() { istringstream inSS; // Input string stream string lineString; // Holds line of text string firstName; // First name string lastName; // Last name int userAge; // Age bool inputDone; // Flag to indicate next iteration inputDone = false; // Prompt user for input cout firstName; // Output parsed values if (firstName == \"Exit\") { cout lastName; inSS userAge; cout data1; inSS data2;) is not useful for reading all of the input data. Input streams have a Boolean function called eof() or end of file that returns true or false depending on whether or not the end of the stream has been reached. An if statement or while loop can check if the end of input string stream has been reached by using the extraction operator. Ex: In the code while (inSS data) { ... } the while statement implicitly calls inSS's eof() function, which returns false if more data exists in the string stream to be read and true if the end of string stream has been reached. When eof() returns false, inSS data resolves to true, causing the loop to continue. Conversely, when eof() returns true, inSS data resolves to false, meaning the end of the string stream has been reached, and the loop exits. */ #include #include #include using namespace std; int main() { istringstream inSS; // Input string stream string lineString; // Holds input string string data; cout data) { cout ","date":"2021-12-25","objectID":"/c-review/:2:1","series":[],"tags":["C++"],"title":"C++ Review","uri":"/c-review/#example-phone-number-formats"},{"categories":["Note"],"content":"Output string stream #include \u003ciostream\u003e#include \u003cstring\u003e#include \u003csstream\u003eusing namespace std; int main() { ostringstream infoOSS; // Output string stream string infoStr; // Information string string firstName; // First name string lastName; // Last name int userAge; // Age // Prompt user for input cout \u003c\u003c \"Enter \\\"firstname lastname age\\\": \" \u003c\u003c endl; cin \u003e\u003e firstName; cin \u003e\u003e lastName; cin \u003e\u003e userAge; // Write user input to string stream infoOSS \u003c\u003c lastName \u003c\u003c \", \" \u003c\u003c firstName; infoOSS \u003c\u003c \" \" \u003c\u003c userAge; // Appends (minor) to string stream if less than 21 if (userAge \u003c 21) { infoOSS \u003c\u003c \" (minor)\"; } // Extract string stream buffer as a single string infoStr = infoOSS.str(); cout \u003c\u003c \"Information: \" \u003c\u003c infoStr \u003c\u003c endl; return 0; } Example: Savings table /* The example below uses an output string stream to create a savings table. The ProduceSavingsTable() function has 3 parameters: the starting amount, the annual percentage rate, and number of years. ProduceSavingsTable() uses several manipulators like fixed, setprecision, and setw to create a table with an ostringstream and returns the table as a single string. */ #include \u003ciostream\u003e#include \u003ciomanip\u003e#include \u003cstring\u003e#include \u003csstream\u003eusing namespace std; string ProduceSavingsTable(double startAmount, double apr, int numYears) { // Column widths const int YEAR_COL_WIDTH = 5; const int BALANCE_COL_WIDTH = 10; ostringstream outSS; double interest; double balance = startAmount; int month; int totalMonths = numYears * 12; // Convert APR to monthly percentage rate and decimal number double mpr = apr / 12 * 0.01; // Display 2 decimal places outSS \u003c\u003c fixed \u003c\u003c setprecision(2); // Table heading outSS \u003c\u003c setw(YEAR_COL_WIDTH) \u003c\u003c \"Year\" \u003c\u003c setw(BALANCE_COL_WIDTH) \u003c\u003c \"Balance\" \u003c\u003c endl; // Calculate interest and ending balance for each month for (month = 1; month \u003c= totalMonths; ++month) { interest = balance * mpr; balance += interest; // Only output year number and balance at the end of the year if (month % 12 == 0) { outSS \u003c\u003c setw(YEAR_COL_WIDTH) \u003c\u003c month / 12 \u003c\u003c setw(BALANCE_COL_WIDTH) \u003c\u003c balance \u003c\u003c endl; } } // Return the table as a string return outSS.str(); } int main() { string table; double startAmount; double apr; int years; // Get input values cout \u003c\u003c \"Starting amount?\" \u003c\u003c endl; cin \u003e\u003e startAmount; cout \u003c\u003c \"Annual Percentage Rate?\" \u003c\u003c endl; cin \u003e\u003e apr; cout \u003c\u003c \"Number of years?\" \u003c\u003c endl; cin \u003e\u003e years; cout \u003c\u003c endl \u003c\u003c \"Savings over time:\" \u003c\u003c endl; table = ProduceSavingsTable(startAmount, apr, years); cout \u003c\u003c table \u003c\u003c endl; return 0; } here we have fixed, setw, setprecision(int n), setfill('-') ","date":"2021-12-25","objectID":"/c-review/:2:2","series":[],"tags":["C++"],"title":"C++ Review","uri":"/c-review/#output-string-stream"},{"categories":["Note"],"content":"Output string stream #include #include #include using namespace std; int main() { ostringstream infoOSS; // Output string stream string infoStr; // Information string string firstName; // First name string lastName; // Last name int userAge; // Age // Prompt user for input cout firstName; cin lastName; cin userAge; // Write user input to string stream infoOSS #include #include #include using namespace std; string ProduceSavingsTable(double startAmount, double apr, int numYears) { // Column widths const int YEAR_COL_WIDTH = 5; const int BALANCE_COL_WIDTH = 10; ostringstream outSS; double interest; double balance = startAmount; int month; int totalMonths = numYears * 12; // Convert APR to monthly percentage rate and decimal number double mpr = apr / 12 * 0.01; // Display 2 decimal places outSS startAmount; cout apr; cout years; cout ","date":"2021-12-25","objectID":"/c-review/:2:2","series":[],"tags":["C++"],"title":"C++ Review","uri":"/c-review/#example-savings-table"},{"categories":["Note"],"content":"File input Opening and reading from a file /* Sometimes a program should get input from a file rather than from a user typing on a keyboard. To read file input, a programmer can create a new input stream that comes from a file, rather than the predefined input stream cin that comes from the standard input (keyboard). An input stream can then be used just like cin. The inFS.open(str) function has a string parameter str that specifies the name of the file to open. The filename parameter can be a C++ string or a null-terminated C string. A program can also use a user-entered string as the filename, such as using cin \u003e\u003e filename;. */ #include \u003ciostream\u003e#include \u003cfstream\u003eusing namespace std; int main() { ifstream inFS; // Input file stream int fileNum1; // Data value from file int fileNum2; // Data value from file // Try to open file cout \u003c\u003c \"Opening file numFile.txt.\" \u003c\u003c endl; inFS.open(\"numFile.txt\"); if (!inFS.is_open()) { cout \u003c\u003c \"Could not open file numFile.txt.\" \u003c\u003c endl; return 1; // 1 indicates error } // Can now use inFS stream like cin stream // numFile.txt should contain two integers, else problems cout \u003c\u003c \"Reading two integers.\" \u003c\u003c endl; inFS \u003e\u003e fileNum1; inFS \u003e\u003e fileNum2; cout \u003c\u003c \"Closing file numFile.txt.\" \u003c\u003c endl; inFS.close(); // Done with file, so close it // Output values read from file cout \u003c\u003c \"num1: \" \u003c\u003c fileNum1 \u003c\u003c endl; cout \u003c\u003c \"num2: \" \u003c\u003c fileNum2 \u003c\u003c endl; cout \u003c\u003c \"num1 + num2: \" \u003c\u003c (fileNum1 + fileNum2) \u003c\u003c endl; return 0; } Reading until the end of the file /* A program can read varying amounts of data in a file by using a loop that reads until the end of the file has been reached. The eof() function returns true if the previous stream operation reached the end of the file. Errors may be encountered while attempting to read from a file, like the inability to read the file, reading corrupt data, etc. So, a program should check that each read was successful before using the variable to which the read data was assigned. The fail() function returns true if the previous stream operation had an error. */ Program Example input file and output #include \u003ciostream\u003e#include \u003cfstream\u003eusing namespace std; int main() { ifstream inFS; // Input file stream int fileNum; // File data // Open file cout \u003c\u003c \"Opening file myfile.txt.\" \u003c\u003c endl; inFS.open(\"myfile.txt\"); if (!inFS.is_open()) { cout \u003c\u003c \"Could not open file myfile.txt.\" \u003c\u003c endl; return 1; } // Print read numbers to output cout \u003c\u003c \"Reading and printing numbers.\" \u003c\u003c endl; while (!inFS.eof()) { inFS \u003e\u003e fileNum; if (!inFS.fail()) { cout \u003c\u003c \"num: \" \u003c\u003c fileNum \u003c\u003c endl; } } cout \u003c\u003c \"Closing file myfile.txt.\" \u003c\u003c endl; // Done with file, so close it inFS.close(); return 0; } notice inputFile.eof() and inputFile.fail() Example: Counting instances of a specific word /* The following program uses both the extraction operator, eof(), and fail() to determine how many times a user entered word appears in a file. The number of words in the file is unknown, so the program extracts words until the end of the file is reached. The program exits if the stream extraction causes an error or after the word's frequency in the file is output. */ #include \u003ciostream\u003e#include \u003cfstream\u003e#include \u003cstring\u003eusing namespace std; int main() { ifstream inFS; // Input file stream string userWord; int wordFreq = 0; string currWord; // Open file cout \u003c\u003c \"Opening file wordFile.txt.\" \u003c\u003c endl; inFS.open(\"wordFile.txt\"); if (!inFS.is_open()) { cout \u003c\u003c \"Could not open file wordFile.txt.\" \u003c\u003c endl; return 1; } // Word to be found cout \u003c\u003c \"Enter a word: \"; cin \u003e\u003e userWord; // Identify when a word matches the userWord // and increase wordFreq while (!inFS.eof()) { inFS \u003e\u003e currWord; if (!inFS.fail()) { if(currWord == userWord) { ++wordFreq; } } } cout \u003c\u003c userWord \u003c\u003c \" appears in the file \" \u003c\u003c wordFreq \u003c\u003c \" times.\" \u003c\u003c endl; // Done with file, so close it inFS.close(); return 0; } Example: Business reviews /* The following example reads a file with business reviews as the program starts and outputs data from the file at ","date":"2021-12-25","objectID":"/c-review/:2:3","series":[],"tags":["C++"],"title":"C++ Review","uri":"/c-review/#file-input"},{"categories":["Note"],"content":"File input Opening and reading from a file /* Sometimes a program should get input from a file rather than from a user typing on a keyboard. To read file input, a programmer can create a new input stream that comes from a file, rather than the predefined input stream cin that comes from the standard input (keyboard). An input stream can then be used just like cin. The inFS.open(str) function has a string parameter str that specifies the name of the file to open. The filename parameter can be a C++ string or a null-terminated C string. A program can also use a user-entered string as the filename, such as using cin filename;. */ #include #include using namespace std; int main() { ifstream inFS; // Input file stream int fileNum1; // Data value from file int fileNum2; // Data value from file // Try to open file cout fileNum1; inFS fileNum2; cout #include using namespace std; int main() { ifstream inFS; // Input file stream int fileNum; // File data // Open file cout fileNum; if (!inFS.fail()) { cout #include #include using namespace std; int main() { ifstream inFS; // Input file stream string userWord; int wordFreq = 0; string currWord; // Open file cout userWord; // Identify when a word matches the userWord // and increase wordFreq while (!inFS.eof()) { inFS currWord; if (!inFS.fail()) { if(currWord == userWord) { ++wordFreq; } } } cout ","date":"2021-12-25","objectID":"/c-review/:2:3","series":[],"tags":["C++"],"title":"C++ Review","uri":"/c-review/#opening-and-reading-from-a-file"},{"categories":["Note"],"content":"File input Opening and reading from a file /* Sometimes a program should get input from a file rather than from a user typing on a keyboard. To read file input, a programmer can create a new input stream that comes from a file, rather than the predefined input stream cin that comes from the standard input (keyboard). An input stream can then be used just like cin. The inFS.open(str) function has a string parameter str that specifies the name of the file to open. The filename parameter can be a C++ string or a null-terminated C string. A program can also use a user-entered string as the filename, such as using cin filename;. */ #include #include using namespace std; int main() { ifstream inFS; // Input file stream int fileNum1; // Data value from file int fileNum2; // Data value from file // Try to open file cout fileNum1; inFS fileNum2; cout #include using namespace std; int main() { ifstream inFS; // Input file stream int fileNum; // File data // Open file cout fileNum; if (!inFS.fail()) { cout #include #include using namespace std; int main() { ifstream inFS; // Input file stream string userWord; int wordFreq = 0; string currWord; // Open file cout userWord; // Identify when a word matches the userWord // and increase wordFreq while (!inFS.eof()) { inFS currWord; if (!inFS.fail()) { if(currWord == userWord) { ++wordFreq; } } } cout ","date":"2021-12-25","objectID":"/c-review/:2:3","series":[],"tags":["C++"],"title":"C++ Review","uri":"/c-review/#reading-until-the-end-of-the-file"},{"categories":["Note"],"content":"File input Opening and reading from a file /* Sometimes a program should get input from a file rather than from a user typing on a keyboard. To read file input, a programmer can create a new input stream that comes from a file, rather than the predefined input stream cin that comes from the standard input (keyboard). An input stream can then be used just like cin. The inFS.open(str) function has a string parameter str that specifies the name of the file to open. The filename parameter can be a C++ string or a null-terminated C string. A program can also use a user-entered string as the filename, such as using cin filename;. */ #include #include using namespace std; int main() { ifstream inFS; // Input file stream int fileNum1; // Data value from file int fileNum2; // Data value from file // Try to open file cout fileNum1; inFS fileNum2; cout #include using namespace std; int main() { ifstream inFS; // Input file stream int fileNum; // File data // Open file cout fileNum; if (!inFS.fail()) { cout #include #include using namespace std; int main() { ifstream inFS; // Input file stream string userWord; int wordFreq = 0; string currWord; // Open file cout userWord; // Identify when a word matches the userWord // and increase wordFreq while (!inFS.eof()) { inFS currWord; if (!inFS.fail()) { if(currWord == userWord) { ++wordFreq; } } } cout ","date":"2021-12-25","objectID":"/c-review/:2:3","series":[],"tags":["C++"],"title":"C++ Review","uri":"/c-review/#example-counting-instances-of-a-specific-word"},{"categories":["Note"],"content":"File input Opening and reading from a file /* Sometimes a program should get input from a file rather than from a user typing on a keyboard. To read file input, a programmer can create a new input stream that comes from a file, rather than the predefined input stream cin that comes from the standard input (keyboard). An input stream can then be used just like cin. The inFS.open(str) function has a string parameter str that specifies the name of the file to open. The filename parameter can be a C++ string or a null-terminated C string. A program can also use a user-entered string as the filename, such as using cin filename;. */ #include #include using namespace std; int main() { ifstream inFS; // Input file stream int fileNum1; // Data value from file int fileNum2; // Data value from file // Try to open file cout fileNum1; inFS fileNum2; cout #include using namespace std; int main() { ifstream inFS; // Input file stream int fileNum; // File data // Open file cout fileNum; if (!inFS.fail()) { cout #include #include using namespace std; int main() { ifstream inFS; // Input file stream string userWord; int wordFreq = 0; string currWord; // Open file cout userWord; // Identify when a word matches the userWord // and increase wordFreq while (!inFS.eof()) { inFS currWord; if (!inFS.fail()) { if(currWord == userWord) { ++wordFreq; } } } cout ","date":"2021-12-25","objectID":"/c-review/:2:3","series":[],"tags":["C++"],"title":"C++ Review","uri":"/c-review/#example-business-reviews"},{"categories":["Note"],"content":"File input Opening and reading from a file /* Sometimes a program should get input from a file rather than from a user typing on a keyboard. To read file input, a programmer can create a new input stream that comes from a file, rather than the predefined input stream cin that comes from the standard input (keyboard). An input stream can then be used just like cin. The inFS.open(str) function has a string parameter str that specifies the name of the file to open. The filename parameter can be a C++ string or a null-terminated C string. A program can also use a user-entered string as the filename, such as using cin filename;. */ #include #include using namespace std; int main() { ifstream inFS; // Input file stream int fileNum1; // Data value from file int fileNum2; // Data value from file // Try to open file cout fileNum1; inFS fileNum2; cout #include using namespace std; int main() { ifstream inFS; // Input file stream int fileNum; // File data // Open file cout fileNum; if (!inFS.fail()) { cout #include #include using namespace std; int main() { ifstream inFS; // Input file stream string userWord; int wordFreq = 0; string currWord; // Open file cout userWord; // Identify when a word matches the userWord // and increase wordFreq while (!inFS.eof()) { inFS currWord; if (!inFS.fail()) { if(currWord == userWord) { ++wordFreq; } } } cout ","date":"2021-12-25","objectID":"/c-review/:2:3","series":[],"tags":["C++"],"title":"C++ Review","uri":"/c-review/#input-stream-errors"},{"categories":["Note"],"content":"C++ example: Parsing and validating input files /* The following program reads input from the teams.txt file, which contains a baseball team name on one line followed by an optional line with the number of wins and losses for the season. Some win/loss lines only have a single number representing the number of wins. The file may have any number of team name and win/loss lines. */ #include \u003ciostream\u003e#include \u003cfstream\u003e#include \u003cstring\u003eusing namespace std; int main() { ifstream teamFS; string teamName; int numWins; int numLosses; teamFS.open(\"teams.txt\"); if (!teamFS.is_open()) { cout \u003c\u003c \"Could not open file teams.txt.\" \u003c\u003c endl; return 1; } // Read first team name getline(teamFS, teamName); // Read until end-of-file while (!teamFS.fail()) { // Attempt to read wins teamFS \u003e\u003e numWins; if (teamFS.fail()) { // Win/loss line missing cout \u003c\u003c teamName \u003c\u003c \" has no wins or losses\" \u003c\u003c endl; } else { // Attempt to read losses teamFS \u003e\u003e numLosses; if (teamFS.fail()) { // No losses provided cout \u003c\u003c teamName \u003c\u003c \" has \" \u003c\u003c numWins \u003c\u003c \" wins\" \u003c\u003c endl; } else { // Win and losses provided cout \u003c\u003c teamName \u003c\u003c \" win average is \" \u003c\u003c static_cast\u003cdouble\u003e(numWins) / (numWins + numLosses) \u003c\u003c endl; } // Remove newline teamFS.ignore(); } // Clear the error state teamFS.clear(); // Attempt to read next team getline(teamFS, teamName); } teamFS.close(); return 0; } ","date":"2021-12-25","objectID":"/c-review/:2:4","series":[],"tags":["C++"],"title":"C++ Review","uri":"/c-review/#c-example-parsing-and-validating-input-files"},{"categories":["Note"],"content":"Vector ","date":"2021-12-25","objectID":"/c-review/:3:0","series":[],"tags":["C++"],"title":"C++ Review","uri":"/c-review/#vector"},{"categories":["Note"],"content":"Vectors declaration vector\u003cdataType\u003e vectorName(numElements); #include \u003ciostream\u003e#include \u003cvector\u003eusing namespace std; int main() { vector\u003cint\u003e itemCounts(3); itemCounts.at(0) = 122; itemCounts.at(1) = 119; itemCounts.at(2) = 117; cout \u003c\u003c itemCounts.at(1); return 0; } Using an expression for a vector index /* A powerful aspect of vectors is that the index is an expression. Ex: userNums.at(i) uses the value held in the int variable i as the index. As such, a vector is useful to easily lookup the Nth item in a list. A vector's index must be an unsigned integer type. The vector index cannot be a floating-point type, even if the value is 0.0, 1.0, etc. The program below allows a user to print the age of the Nth oldest known person to have ever lived. The program quickly accesses the Nth oldest person's age using oldestPeople.at(nthPerson - 1). Note that the index is nthPerson - 1 rather than just nthPerson because a vector's indices start at 0, so the 1st age is at index 0, the 2nd at index 1, etc. */ #include \u003ciostream\u003e#include \u003cvector\u003eusing namespace std; int main() { vector\u003cint\u003e oldestPeople(5); int nthPerson; // User input, Nth oldest person oldestPeople.at(0) = 122; // Died 1997 in France oldestPeople.at(1) = 119; // Died 1999 in U.S. oldestPeople.at(2) = 117; // Died 1993 in U.S. oldestPeople.at(3) = 117; // Died 1998 in Canada oldestPeople.at(4) = 116; // Died 2006 in Ecuador cout \u003c\u003c \"Enter N (1..5): \"; cin \u003e\u003e nthPerson; if ((nthPerson \u003e= 1) \u0026\u0026 (nthPerson \u003c= 5)) { cout \u003c\u003c \"The \" \u003c\u003c nthPerson \u003c\u003c \"th oldest person lived \"; cout \u003c\u003c oldestPeople.at(nthPerson - 1) \u003c\u003c \" years.\" \u003c\u003c endl; } return 0; } Loops and vectors /* A key advantage of vectors becomes evident when used in conjunction with loops. The program below uses a loop to allow a user to enter 8 integer values, storing those values in a vector, and then printing those 8 values. A vector's size() function returns the number of vector elements. Ex: In the program below, userVals.size() is 8 because the vector was declared with 8 elements. */ #include \u003ciostream\u003e#include \u003cvector\u003eusing namespace std; int main() { const int NUM_VALS = 8; // Number of elements in vector vector\u003cint\u003e userVals(NUM_VALS); // User values unsigned int i; // Loop index cout \u003c\u003c \"Enter \" \u003c\u003c NUM_VALS \u003c\u003c \" integer values...\" \u003c\u003c endl; for (i = 0; i \u003c userVals.size(); ++i) { cout \u003c\u003c \"Value: \"; cin \u003e\u003e userVals.at(i); } cout \u003c\u003c \"You entered: \"; for (i = 0; i \u003c userVals.size(); ++i) { cout \u003c\u003c userVals.at(i) \u003c\u003c \" \"; } cout \u003c\u003c endl; return 0; } Vector initialization /* A vector's elements are automatically initialized to 0s during the vector declaration. All of a vector's elements may be initialized to another single value. Ex: vector\u003cint\u003e myVector(3, -1); creates a vector named myVector with three elements, each with value -1. A programmer may initialize each vector element with different values by specifying the initial values in braces {} separated by commas. Ex: vector\u003cint\u003e carSales = {5, 7, 11}; creates a vector of three integer elements initialized with values 5, 7, and 11. Such vector declaration and initialization does not require specifying the vector size, because the vector's size is automatically set to the number of elements within the braces. For a larger vector, initialization may be done by first declaring the vector, and then using a loop to assign vector elements. */ ","date":"2021-12-25","objectID":"/c-review/:3:1","series":[],"tags":["C++"],"title":"C++ Review","uri":"/c-review/#vectors"},{"categories":["Note"],"content":"Vectors declaration vector vectorName(numElements); #include #include using namespace std; int main() { vector itemCounts(3); itemCounts.at(0) = 122; itemCounts.at(1) = 119; itemCounts.at(2) = 117; cout #include using namespace std; int main() { vector oldestPeople(5); int nthPerson; // User input, Nth oldest person oldestPeople.at(0) = 122; // Died 1997 in France oldestPeople.at(1) = 119; // Died 1999 in U.S. oldestPeople.at(2) = 117; // Died 1993 in U.S. oldestPeople.at(3) = 117; // Died 1998 in Canada oldestPeople.at(4) = 116; // Died 2006 in Ecuador cout nthPerson; if ((nthPerson = 1) \u0026\u0026 (nthPerson #include using namespace std; int main() { const int NUM_VALS = 8; // Number of elements in vector vector userVals(NUM_VALS); // User values unsigned int i; // Loop index cout userVals.at(i); } cout myVector(3, -1); creates a vector named myVector with three elements, each with value -1. A programmer may initialize each vector element with different values by specifying the initial values in braces {} separated by commas. Ex: vector carSales = {5, 7, 11}; creates a vector of three integer elements initialized with values 5, 7, and 11. Such vector declaration and initialization does not require specifying the vector size, because the vector's size is automatically set to the number of elements within the braces. For a larger vector, initialization may be done by first declaring the vector, and then using a loop to assign vector elements. */ ","date":"2021-12-25","objectID":"/c-review/:3:1","series":[],"tags":["C++"],"title":"C++ Review","uri":"/c-review/#using-an-expression-for-a-vector-index"},{"categories":["Note"],"content":"Vectors declaration vector vectorName(numElements); #include #include using namespace std; int main() { vector itemCounts(3); itemCounts.at(0) = 122; itemCounts.at(1) = 119; itemCounts.at(2) = 117; cout #include using namespace std; int main() { vector oldestPeople(5); int nthPerson; // User input, Nth oldest person oldestPeople.at(0) = 122; // Died 1997 in France oldestPeople.at(1) = 119; // Died 1999 in U.S. oldestPeople.at(2) = 117; // Died 1993 in U.S. oldestPeople.at(3) = 117; // Died 1998 in Canada oldestPeople.at(4) = 116; // Died 2006 in Ecuador cout nthPerson; if ((nthPerson = 1) \u0026\u0026 (nthPerson #include using namespace std; int main() { const int NUM_VALS = 8; // Number of elements in vector vector userVals(NUM_VALS); // User values unsigned int i; // Loop index cout userVals.at(i); } cout myVector(3, -1); creates a vector named myVector with three elements, each with value -1. A programmer may initialize each vector element with different values by specifying the initial values in braces {} separated by commas. Ex: vector carSales = {5, 7, 11}; creates a vector of three integer elements initialized with values 5, 7, and 11. Such vector declaration and initialization does not require specifying the vector size, because the vector's size is automatically set to the number of elements within the braces. For a larger vector, initialization may be done by first declaring the vector, and then using a loop to assign vector elements. */ ","date":"2021-12-25","objectID":"/c-review/:3:1","series":[],"tags":["C++"],"title":"C++ Review","uri":"/c-review/#loops-and-vectors"},{"categories":["Note"],"content":"Vectors declaration vector vectorName(numElements); #include #include using namespace std; int main() { vector itemCounts(3); itemCounts.at(0) = 122; itemCounts.at(1) = 119; itemCounts.at(2) = 117; cout #include using namespace std; int main() { vector oldestPeople(5); int nthPerson; // User input, Nth oldest person oldestPeople.at(0) = 122; // Died 1997 in France oldestPeople.at(1) = 119; // Died 1999 in U.S. oldestPeople.at(2) = 117; // Died 1993 in U.S. oldestPeople.at(3) = 117; // Died 1998 in Canada oldestPeople.at(4) = 116; // Died 2006 in Ecuador cout nthPerson; if ((nthPerson = 1) \u0026\u0026 (nthPerson #include using namespace std; int main() { const int NUM_VALS = 8; // Number of elements in vector vector userVals(NUM_VALS); // User values unsigned int i; // Loop index cout userVals.at(i); } cout myVector(3, -1); creates a vector named myVector with three elements, each with value -1. A programmer may initialize each vector element with different values by specifying the initial values in braces {} separated by commas. Ex: vector carSales = {5, 7, 11}; creates a vector of three integer elements initialized with values 5, 7, and 11. Such vector declaration and initialization does not require specifying the vector size, because the vector's size is automatically set to the number of elements within the braces. For a larger vector, initialization may be done by first declaring the vector, and then using a loop to assign vector elements. */ ","date":"2021-12-25","objectID":"/c-review/:3:1","series":[],"tags":["C++"],"title":"C++ Review","uri":"/c-review/#vector-initialization"},{"categories":["Note"],"content":" #!/bin/bash #Command line calculator Ver0.1 read -t 30 -p \"Please enter the first operand: \" num1 read -t 30 -p \"Please enter the operator: \" op read -t 30 -p \"Please enter the second operand: \" num2 if [ -n \"$num1\" -a -n \"$num2\" -a -n \"$op\" ] then ifInt1=$(echo $num1 | sed ' s/[0-9]//g') ifInt2=$(echo $num2 | sed ' s/[0-9]//g') if [ \"$ifInt1\" == \"\" -a -z \"$ifInt2\" ] then if [ \"$op\" == \"+\" ] then result=$(($num1 + $num2)) elif [ \"$op\" == \"-\" ] then result=$(($num1 - $num2)) elif [ \"$op\" == \"*\" ] then result=$(($num1 * $num2)) elif [ \"$op\" == \"/\" ] then result=$(($num1 / $num2)) else echo \"Please enter a valid operator\" exit 11 fi else echo \"Please enter valid operands\" exit 11 fi else echo \"Please assign all 3 variables properly\" exit 11 fi echo \"$num1$op$num2= $result\" ","date":"2021-12-25","objectID":"/calculator/:0:0","series":[],"tags":["Bash"],"title":"Calculator in Bash","uri":"/calculator/#"},{"categories":["Note"],"content":"CI Tools Bamboo run multiple builds in parallel for faster compilation built in functionality to connect with repos and has built tasks for Ant, Maven, etc. Good for deployment on diff envs. Builtbot open source written in py support distribution Apache Gump Great for java Travis CI a hosted, continuous integration service used to built and test software projs hosted at GitHub. for team of all sizes support 20 diff langs Jenkins open source written in java most popular Jenkins Easy installation Easy config Plug-ins Extensible (extend it not create a new version) Distributed Jenkins Pipline Dev–\u003ecode commit–\u003eBuild–\u003eTest–\u003eRelease–\u003eDeploy/Deliver–\u003eProduction Jenkins arch ","date":"2021-12-25","objectID":"/ci-tools/:0:0","series":[],"tags":["CI"],"title":"CI Tools","uri":"/ci-tools/#"},{"categories":["Note"],"content":"Computational Complexity P = {problems solvable in polynomial} NP = {decision problems solvable in poly time via a “lucky” algorithm, which a Nondeterministic model, algorithm makes guesses and output yes or no, guesses are guaranteed to lead to a yes if possible} or {decision problem with “solution” that can be “checked” in polynomial time, whenever the answer is yes, you can prove it and check it in poly time} EXP = {problems solvable in exponential time 2nC} R = {problems solvable in finite time} NP-hard: to the right of NP NP-complete at the excatly point of the right border of NP EXP-hard EXP-complete Examples: negative-weights cycle detect ∈ P n x n Chess (who’s gonna win from this position) EXP but not P Tetris (realistic) EXP don’t know whether P halting problem: given program, does it even halt/stop? not in R Most decision problems are uncomputable( not in R ) program ≈ binary string ≈ natural number ∈ N(natural num) decision prob: input{yes, no} ≈ {0,1} where from string to binary string decision prob ∈ R(rational num) |R| » |N| =\u003e almost every prob unsolvable by any program Tetris ∈ NP if there is a yes, the luck will lead us to the yes Reductions: A -\u003e B convert prob A that you don’t know how to solve into problem B that you know how to solve unweighted shortest paths -\u003e adding weights to 1 and use Dijstra min-product path -\u003e(take logs to convert products to sums) shortest path longest path -\u003e shortest path 3-Partition -\u003e Tetris traveling salesman problem …notes ","date":"2021-12-25","objectID":"/computational-complexity/:0:1","series":[],"tags":["Algorithm"],"title":"Complexity","uri":"/computational-complexity/#computational-complexity"},{"categories":["Note"],"content":"Depth-First Search (DFS), Topological Sort DFS recursively explore graph, backtracking as necessary parent = {s: None} DFS-Visit(Adj,s): for v in Adj[s]: if v not in parent: parent[v] = s DFS-Visit(Adj,v) DFS(V,adj): parent = {} for s in V: if s not in parent: parent[s] = None DFS-Visit(Adj,s) Analysis O(V+E) time visit each vertex once in DFS alone O(V) DFS-Visit(v) called once per vertex v pay |Adj[v]| =\u003e O(sum of all |Adj(v)| in V) = O(E) Edge classification tree edge (parent pointers) visit new vertex via edge forward edge: node -\u003e descendant in tree backward edge: node -\u003e ancestor in tree cross edge: between two non-ancestor-related subtrees Notice: in undirected graph, only tree edge and backward edge exsit Cycle detection G has a cycle \u003c=\u003e DFS has a back edge proof in both directions Topological Sort Job scheduling given directed acyclic graph(DAG), order vertices so that all edges point from low order to high order topological sort: using DFS output reverse of finishing times of vertices Correctness: we wanna make sure, for any edge e:(u,v) v finishes before u finishes Case 1: u starts before v visit v before finishing u Case 2: v starts before u cannot happen since if v finishes first before finish u, that means there would be a backward edge (they may be disconnected, but that’s fine because there is not order issue) ","date":"2021-12-25","objectID":"/depth-first-search-dfs-topological-sort/:0:1","series":[],"tags":["Algorithm"],"title":"DFS","uri":"/depth-first-search-dfs-topological-sort/#depth-first-search-dfs-topological-sort"},{"categories":["Note"],"content":"Depth-First Search (DFS), Topological Sort DFS recursively explore graph, backtracking as necessary parent = {s: None} DFS-Visit(Adj,s): for v in Adj[s]: if v not in parent: parent[v] = s DFS-Visit(Adj,v) DFS(V,adj): parent = {} for s in V: if s not in parent: parent[s] = None DFS-Visit(Adj,s) Analysis O(V+E) time visit each vertex once in DFS alone O(V) DFS-Visit(v) called once per vertex v pay |Adj[v]| = O(sum of all |Adj(v)| in V) = O(E) Edge classification tree edge (parent pointers) visit new vertex via edge forward edge: node - descendant in tree backward edge: node - ancestor in tree cross edge: between two non-ancestor-related subtrees Notice: in undirected graph, only tree edge and backward edge exsit Cycle detection G has a cycle DFS has a back edge proof in both directions Topological Sort Job scheduling given directed acyclic graph(DAG), order vertices so that all edges point from low order to high order topological sort: using DFS output reverse of finishing times of vertices Correctness: we wanna make sure, for any edge e:(u,v) v finishes before u finishes Case 1: u starts before v visit v before finishing u Case 2: v starts before u cannot happen since if v finishes first before finish u, that means there would be a backward edge (they may be disconnected, but that’s fine because there is not order issue) ","date":"2021-12-25","objectID":"/depth-first-search-dfs-topological-sort/:0:1","series":[],"tags":["Algorithm"],"title":"DFS","uri":"/depth-first-search-dfs-topological-sort/#dfs"},{"categories":["Note"],"content":"Depth-First Search (DFS), Topological Sort DFS recursively explore graph, backtracking as necessary parent = {s: None} DFS-Visit(Adj,s): for v in Adj[s]: if v not in parent: parent[v] = s DFS-Visit(Adj,v) DFS(V,adj): parent = {} for s in V: if s not in parent: parent[s] = None DFS-Visit(Adj,s) Analysis O(V+E) time visit each vertex once in DFS alone O(V) DFS-Visit(v) called once per vertex v pay |Adj[v]| = O(sum of all |Adj(v)| in V) = O(E) Edge classification tree edge (parent pointers) visit new vertex via edge forward edge: node - descendant in tree backward edge: node - ancestor in tree cross edge: between two non-ancestor-related subtrees Notice: in undirected graph, only tree edge and backward edge exsit Cycle detection G has a cycle DFS has a back edge proof in both directions Topological Sort Job scheduling given directed acyclic graph(DAG), order vertices so that all edges point from low order to high order topological sort: using DFS output reverse of finishing times of vertices Correctness: we wanna make sure, for any edge e:(u,v) v finishes before u finishes Case 1: u starts before v visit v before finishing u Case 2: v starts before u cannot happen since if v finishes first before finish u, that means there would be a backward edge (they may be disconnected, but that’s fine because there is not order issue) ","date":"2021-12-25","objectID":"/depth-first-search-dfs-topological-sort/:0:1","series":[],"tags":["Algorithm"],"title":"DFS","uri":"/depth-first-search-dfs-topological-sort/#edge-classification"},{"categories":["Note"],"content":"Depth-First Search (DFS), Topological Sort DFS recursively explore graph, backtracking as necessary parent = {s: None} DFS-Visit(Adj,s): for v in Adj[s]: if v not in parent: parent[v] = s DFS-Visit(Adj,v) DFS(V,adj): parent = {} for s in V: if s not in parent: parent[s] = None DFS-Visit(Adj,s) Analysis O(V+E) time visit each vertex once in DFS alone O(V) DFS-Visit(v) called once per vertex v pay |Adj[v]| = O(sum of all |Adj(v)| in V) = O(E) Edge classification tree edge (parent pointers) visit new vertex via edge forward edge: node - descendant in tree backward edge: node - ancestor in tree cross edge: between two non-ancestor-related subtrees Notice: in undirected graph, only tree edge and backward edge exsit Cycle detection G has a cycle DFS has a back edge proof in both directions Topological Sort Job scheduling given directed acyclic graph(DAG), order vertices so that all edges point from low order to high order topological sort: using DFS output reverse of finishing times of vertices Correctness: we wanna make sure, for any edge e:(u,v) v finishes before u finishes Case 1: u starts before v visit v before finishing u Case 2: v starts before u cannot happen since if v finishes first before finish u, that means there would be a backward edge (they may be disconnected, but that’s fine because there is not order issue) ","date":"2021-12-25","objectID":"/depth-first-search-dfs-topological-sort/:0:1","series":[],"tags":["Algorithm"],"title":"DFS","uri":"/depth-first-search-dfs-topological-sort/#cycle-detection"},{"categories":["Note"],"content":"Depth-First Search (DFS), Topological Sort DFS recursively explore graph, backtracking as necessary parent = {s: None} DFS-Visit(Adj,s): for v in Adj[s]: if v not in parent: parent[v] = s DFS-Visit(Adj,v) DFS(V,adj): parent = {} for s in V: if s not in parent: parent[s] = None DFS-Visit(Adj,s) Analysis O(V+E) time visit each vertex once in DFS alone O(V) DFS-Visit(v) called once per vertex v pay |Adj[v]| = O(sum of all |Adj(v)| in V) = O(E) Edge classification tree edge (parent pointers) visit new vertex via edge forward edge: node - descendant in tree backward edge: node - ancestor in tree cross edge: between two non-ancestor-related subtrees Notice: in undirected graph, only tree edge and backward edge exsit Cycle detection G has a cycle DFS has a back edge proof in both directions Topological Sort Job scheduling given directed acyclic graph(DAG), order vertices so that all edges point from low order to high order topological sort: using DFS output reverse of finishing times of vertices Correctness: we wanna make sure, for any edge e:(u,v) v finishes before u finishes Case 1: u starts before v visit v before finishing u Case 2: v starts before u cannot happen since if v finishes first before finish u, that means there would be a backward edge (they may be disconnected, but that’s fine because there is not order issue) ","date":"2021-12-25","objectID":"/depth-first-search-dfs-topological-sort/:0:1","series":[],"tags":["Algorithm"],"title":"DFS","uri":"/depth-first-search-dfs-topological-sort/#topological-sort"},{"categories":["Note"],"content":"Depth-First Search (DFS), Topological Sort DFS recursively explore graph, backtracking as necessary parent = {s: None} DFS-Visit(Adj,s): for v in Adj[s]: if v not in parent: parent[v] = s DFS-Visit(Adj,v) DFS(V,adj): parent = {} for s in V: if s not in parent: parent[s] = None DFS-Visit(Adj,s) Analysis O(V+E) time visit each vertex once in DFS alone O(V) DFS-Visit(v) called once per vertex v pay |Adj[v]| = O(sum of all |Adj(v)| in V) = O(E) Edge classification tree edge (parent pointers) visit new vertex via edge forward edge: node - descendant in tree backward edge: node - ancestor in tree cross edge: between two non-ancestor-related subtrees Notice: in undirected graph, only tree edge and backward edge exsit Cycle detection G has a cycle DFS has a back edge proof in both directions Topological Sort Job scheduling given directed acyclic graph(DAG), order vertices so that all edges point from low order to high order topological sort: using DFS output reverse of finishing times of vertices Correctness: we wanna make sure, for any edge e:(u,v) v finishes before u finishes Case 1: u starts before v visit v before finishing u Case 2: v starts before u cannot happen since if v finishes first before finish u, that means there would be a backward edge (they may be disconnected, but that’s fine because there is not order issue) ","date":"2021-12-25","objectID":"/depth-first-search-dfs-topological-sort/:0:1","series":[],"tags":["Algorithm"],"title":"DFS","uri":"/depth-first-search-dfs-topological-sort/#job-scheduling"},{"categories":["Note"],"content":"Dijkstra (also check A* algo) Relax(u,v,w) Relax(u,v,w) if d[v] \u003e d[u] + w(u,v) d[v] = d[u] + w(u,v) 𝜋[v] = u //predecessor relationship Safety Lemma: The relaxation operation maintains the invariance that d[v] ≥ 𝛿(S,v) for all v∈V Proof: By induction on the number of steps d[u] ≥ 𝛿(S,u) 𝛿(S,v) ≤ 𝛿(S,u) + 𝛿(u,v) 𝛿(S,v) ≤ d[u] + w(u,v) DAGs (Directed Acyclic Graphs) NO -ve cycles Topological sort the DAG. Path from u to v implies that u is before v in the ordering. One pass over vertices in topological sorted order relaxing each edge that leaves each vertex. O(V+E) Demo demo Dijkstra(G,W,s) Initialize(G,s): d[s] = 0 S \u003c- φ Q \u003c- V where Q is a priority queue sorted by d value while Q ≠ φ u \u003c- EXTRACT-MIN(Q) //delete u from Q S \u003c- S U {u} for each vertex v ∈ Adj[u] relax(u,v,w) explanation A* algo Complexity Θ(V) insert into the priority queue Θ(V) extract-min ops Θ(E) decrease-key ops Array: Θ(V) Θ(V) Θ(1) Θ(V•V + E•1) = Θ(V2) Binary min-heap Θ(V) Θ(lgV) Θ(lgV) Θ(VlgV + ElgV) if we use Fibonacci heap (amortized data structure): Θ(VlgV + E) Θ(V) Θ(lgV) Θ(1) ","date":"2021-12-25","objectID":"/dijkstra-also-check-a-algo/:0:1","series":[],"tags":["Algorithm"],"title":"Dijkstra","uri":"/dijkstra-also-check-a-algo/#dijkstra-also-check-a-algo"},{"categories":["Note"],"content":"Dijkstra (also check A* algo) Relax(u,v,w) Relax(u,v,w) if d[v] d[u] + w(u,v) d[v] = d[u] + w(u,v) 𝜋[v] = u //predecessor relationship Safety Lemma: The relaxation operation maintains the invariance that d[v] ≥ 𝛿(S,v) for all v∈V Proof: By induction on the number of steps d[u] ≥ 𝛿(S,u) 𝛿(S,v) ≤ 𝛿(S,u) + 𝛿(u,v) 𝛿(S,v) ≤ d[u] + w(u,v) DAGs (Directed Acyclic Graphs) NO -ve cycles Topological sort the DAG. Path from u to v implies that u is before v in the ordering. One pass over vertices in topological sorted order relaxing each edge that leaves each vertex. O(V+E) Demo demo Dijkstra(G,W,s) Initialize(G,s): d[s] = 0 S ","date":"2021-12-25","objectID":"/dijkstra-also-check-a-algo/:0:1","series":[],"tags":["Algorithm"],"title":"Dijkstra","uri":"/dijkstra-also-check-a-algo/#relaxuvw"},{"categories":["Note"],"content":"Dijkstra (also check A* algo) Relax(u,v,w) Relax(u,v,w) if d[v] d[u] + w(u,v) d[v] = d[u] + w(u,v) 𝜋[v] = u //predecessor relationship Safety Lemma: The relaxation operation maintains the invariance that d[v] ≥ 𝛿(S,v) for all v∈V Proof: By induction on the number of steps d[u] ≥ 𝛿(S,u) 𝛿(S,v) ≤ 𝛿(S,u) + 𝛿(u,v) 𝛿(S,v) ≤ d[u] + w(u,v) DAGs (Directed Acyclic Graphs) NO -ve cycles Topological sort the DAG. Path from u to v implies that u is before v in the ordering. One pass over vertices in topological sorted order relaxing each edge that leaves each vertex. O(V+E) Demo demo Dijkstra(G,W,s) Initialize(G,s): d[s] = 0 S ","date":"2021-12-25","objectID":"/dijkstra-also-check-a-algo/:0:1","series":[],"tags":["Algorithm"],"title":"Dijkstra","uri":"/dijkstra-also-check-a-algo/#safety"},{"categories":["Note"],"content":"Dijkstra (also check A* algo) Relax(u,v,w) Relax(u,v,w) if d[v] d[u] + w(u,v) d[v] = d[u] + w(u,v) 𝜋[v] = u //predecessor relationship Safety Lemma: The relaxation operation maintains the invariance that d[v] ≥ 𝛿(S,v) for all v∈V Proof: By induction on the number of steps d[u] ≥ 𝛿(S,u) 𝛿(S,v) ≤ 𝛿(S,u) + 𝛿(u,v) 𝛿(S,v) ≤ d[u] + w(u,v) DAGs (Directed Acyclic Graphs) NO -ve cycles Topological sort the DAG. Path from u to v implies that u is before v in the ordering. One pass over vertices in topological sorted order relaxing each edge that leaves each vertex. O(V+E) Demo demo Dijkstra(G,W,s) Initialize(G,s): d[s] = 0 S ","date":"2021-12-25","objectID":"/dijkstra-also-check-a-algo/:0:1","series":[],"tags":["Algorithm"],"title":"Dijkstra","uri":"/dijkstra-also-check-a-algo/#dags-directed-acyclic-graphs"},{"categories":["Note"],"content":"Dijkstra (also check A* algo) Relax(u,v,w) Relax(u,v,w) if d[v] d[u] + w(u,v) d[v] = d[u] + w(u,v) 𝜋[v] = u //predecessor relationship Safety Lemma: The relaxation operation maintains the invariance that d[v] ≥ 𝛿(S,v) for all v∈V Proof: By induction on the number of steps d[u] ≥ 𝛿(S,u) 𝛿(S,v) ≤ 𝛿(S,u) + 𝛿(u,v) 𝛿(S,v) ≤ d[u] + w(u,v) DAGs (Directed Acyclic Graphs) NO -ve cycles Topological sort the DAG. Path from u to v implies that u is before v in the ordering. One pass over vertices in topological sorted order relaxing each edge that leaves each vertex. O(V+E) Demo demo Dijkstra(G,W,s) Initialize(G,s): d[s] = 0 S ","date":"2021-12-25","objectID":"/dijkstra-also-check-a-algo/:0:1","series":[],"tags":["Algorithm"],"title":"Dijkstra","uri":"/dijkstra-also-check-a-algo/#demo"},{"categories":["Note"],"content":"Dijkstra (also check A* algo) Relax(u,v,w) Relax(u,v,w) if d[v] d[u] + w(u,v) d[v] = d[u] + w(u,v) 𝜋[v] = u //predecessor relationship Safety Lemma: The relaxation operation maintains the invariance that d[v] ≥ 𝛿(S,v) for all v∈V Proof: By induction on the number of steps d[u] ≥ 𝛿(S,u) 𝛿(S,v) ≤ 𝛿(S,u) + 𝛿(u,v) 𝛿(S,v) ≤ d[u] + w(u,v) DAGs (Directed Acyclic Graphs) NO -ve cycles Topological sort the DAG. Path from u to v implies that u is before v in the ordering. One pass over vertices in topological sorted order relaxing each edge that leaves each vertex. O(V+E) Demo demo Dijkstra(G,W,s) Initialize(G,s): d[s] = 0 S ","date":"2021-12-25","objectID":"/dijkstra-also-check-a-algo/:0:1","series":[],"tags":["Algorithm"],"title":"Dijkstra","uri":"/dijkstra-also-check-a-algo/#dijkstragws"},{"categories":["Note"],"content":"Why Docker? Your proj can only run on your machine but not others. One or more file missing. Software version mismatch. Diff config setting. Docker can pack everything in an isolated env and make it run anywhere. And diff docker containers can run on same machine. HYPERVISORS VitualBox VMware Hyper-v (win only) Probs With Virtual Machines Each VM needs a full-blown OS Slow to start Resource intensive (it takes a slice of the hardware) Containers Allow running multiple apps in isolation Lightweight Use OS of the host (all containers share the same host OS) Start quickly Need less hardware resource (share the host resources so that we don’t need to give cores to it specifically) ","date":"2021-12-25","objectID":"/docker/:0:1","series":[],"tags":["Docker"],"title":"Docker","uri":"/docker/#why-docker"},{"categories":["Note"],"content":"Why Docker? Your proj can only run on your machine but not others. One or more file missing. Software version mismatch. Diff config setting. Docker can pack everything in an isolated env and make it run anywhere. And diff docker containers can run on same machine. HYPERVISORS VitualBox VMware Hyper-v (win only) Probs With Virtual Machines Each VM needs a full-blown OS Slow to start Resource intensive (it takes a slice of the hardware) Containers Allow running multiple apps in isolation Lightweight Use OS of the host (all containers share the same host OS) Start quickly Need less hardware resource (share the host resources so that we don’t need to give cores to it specifically) ","date":"2021-12-25","objectID":"/docker/:0:1","series":[],"tags":["Docker"],"title":"Docker","uri":"/docker/#hypervisors"},{"categories":["Note"],"content":"Why Docker? Your proj can only run on your machine but not others. One or more file missing. Software version mismatch. Diff config setting. Docker can pack everything in an isolated env and make it run anywhere. And diff docker containers can run on same machine. HYPERVISORS VitualBox VMware Hyper-v (win only) Probs With Virtual Machines Each VM needs a full-blown OS Slow to start Resource intensive (it takes a slice of the hardware) Containers Allow running multiple apps in isolation Lightweight Use OS of the host (all containers share the same host OS) Start quickly Need less hardware resource (share the host resources so that we don’t need to give cores to it specifically) ","date":"2021-12-25","objectID":"/docker/:0:1","series":[],"tags":["Docker"],"title":"Docker","uri":"/docker/#probs-with-virtual-machines"},{"categories":["Note"],"content":"Why Docker? Your proj can only run on your machine but not others. One or more file missing. Software version mismatch. Diff config setting. Docker can pack everything in an isolated env and make it run anywhere. And diff docker containers can run on same machine. HYPERVISORS VitualBox VMware Hyper-v (win only) Probs With Virtual Machines Each VM needs a full-blown OS Slow to start Resource intensive (it takes a slice of the hardware) Containers Allow running multiple apps in isolation Lightweight Use OS of the host (all containers share the same host OS) Start quickly Need less hardware resource (share the host resources so that we don’t need to give cores to it specifically) ","date":"2021-12-25","objectID":"/docker/:0:1","series":[],"tags":["Docker"],"title":"Docker","uri":"/docker/#containers"},{"categories":["Note"],"content":"Arch of Docker ","date":"2021-12-25","objectID":"/docker/:0:2","series":[],"tags":["Docker"],"title":"Docker","uri":"/docker/#arch-of-docker"},{"categories":["Note"],"content":"Installing # docs.docker.com/get-docker/ # open dockerHub docker version ","date":"2021-12-25","objectID":"/docker/:0:3","series":[],"tags":["Docker"],"title":"Docker","uri":"/docker/#installing"},{"categories":["Note"],"content":"Dev Workflow The images get loaded in a container. docker run appName to run it in a container. ","date":"2021-12-25","objectID":"/docker/:0:4","series":[],"tags":["Docker"],"title":"Docker","uri":"/docker/#dev-workflow"},{"categories":["Note"],"content":"Docker in Action mkdir hello-docker cd hello-docker code . # open in vsCode, you can use others like vim add a new file -\u003e app.js add one line -\u003e console.log(\"Hello Docker!\"); You need Node installed. node app.js then it should print Hello Docker! in terminal Instructions start with an others install Node Copy app files Run node app.js BUT NOW we can write this instructions in the dockerfile! add another file named Dockerfile with no extensions. install the docker extension for vsCode. FROMnode:alpineCOPY . /app # we gonna copy all the files in the current dir to the /app of that imageCMD node /app/app.jsor useWORKDIR/appCMD node app.js# go to dockerHub to find these image like linux or node etc.# after the : is the tag of the image, for example alpine is a specific ver of linux docker build -t hello-docker . # -t for tag that to identify the image # then the app name # then the dir to find it notice that the image is not in the app dir. docker image ls ![Docker Image(latest) with Node, Linux alpine, and the app files](/img/Docker_Image(latest)_with_Node,_Linux alpine,_and_the_app_files.png) docker run hello-docker run it using image name You can publish it on dockerhub to run it anywhere. you can also go to play with docker to have a try. docker run PceWlkr/hello-docker ","date":"2021-12-25","objectID":"/docker/:0:5","series":[],"tags":["Docker"],"title":"Docker","uri":"/docker/#docker-in-action"},{"categories":["Note"],"content":"Docker in Action mkdir hello-docker cd hello-docker code . # open in vsCode, you can use others like vim add a new file - app.js add one line - console.log(\"Hello Docker!\"); You need Node installed. node app.js then it should print Hello Docker! in terminal Instructions start with an others install Node Copy app files Run node app.js BUT NOW we can write this instructions in the dockerfile! add another file named Dockerfile with no extensions. install the docker extension for vsCode. FROMnode:alpineCOPY . /app # we gonna copy all the files in the current dir to the /app of that imageCMD node /app/app.jsor useWORKDIR/appCMD node app.js# go to dockerHub to find these image like linux or node etc.# after the : is the tag of the image, for example alpine is a specific ver of linux docker build -t hello-docker . # -t for tag that to identify the image # then the app name # then the dir to find it notice that the image is not in the app dir. docker image ls ![Docker Image(latest) with Node, Linux alpine, and the app files](/img/Docker_Image(latest)_with_Node,_Linux alpine,_and_the_app_files.png) docker run hello-docker run it using image name You can publish it on dockerhub to run it anywhere. you can also go to play with docker to have a try. docker run PceWlkr/hello-docker ","date":"2021-12-25","objectID":"/docker/:0:5","series":[],"tags":["Docker"],"title":"Docker","uri":"/docker/#instructions"},{"categories":["Note"],"content":"Docker in Action mkdir hello-docker cd hello-docker code . # open in vsCode, you can use others like vim add a new file - app.js add one line - console.log(\"Hello Docker!\"); You need Node installed. node app.js then it should print Hello Docker! in terminal Instructions start with an others install Node Copy app files Run node app.js BUT NOW we can write this instructions in the dockerfile! add another file named Dockerfile with no extensions. install the docker extension for vsCode. FROMnode:alpineCOPY . /app # we gonna copy all the files in the current dir to the /app of that imageCMD node /app/app.jsor useWORKDIR/appCMD node app.js# go to dockerHub to find these image like linux or node etc.# after the : is the tag of the image, for example alpine is a specific ver of linux docker build -t hello-docker . # -t for tag that to identify the image # then the app name # then the dir to find it notice that the image is not in the app dir. docker image ls ![Docker Image(latest) with Node, Linux alpine, and the app files](/img/Docker_Image(latest)_with_Node,_Linux alpine,_and_the_app_files.png) docker run hello-docker run it using image name You can publish it on dockerhub to run it anywhere. you can also go to play with docker to have a try. docker run PceWlkr/hello-docker ","date":"2021-12-25","objectID":"/docker/:0:5","series":[],"tags":["Docker"],"title":"Docker","uri":"/docker/#but-now-we-can-write-this-instructions-in-the-dockerfile"},{"categories":["Note"],"content":"Linux Distros Ubuntu Debian Alpine Fedora CentOS Ubuntu go to dockerhub, search for Ubuntu. we can use docker pull ubuntu but here I will use a shortcut we can use docker run ubuntu, if docker cannot find it locally then it will download it and run it in a container. However, since we didn’t interact with the container, it stopped. if we docker ps we cannot see it if we docker ps -a we can see it’s stopped We need to use docker run -it ubuntu to start it in interactive mode And then we entered its shell. root@2f856e34654e5:/# root indicates I’m having the root user mode having the highest access permission After the @ is the name of the container. The / means the dir we are at. And there is a # meaning we have the highest privilege since we are in root mode. whoami echo $0 # /bin/bash # we can see the location of shell program history !2 # will run the 2nd command in history Package Manager apt list - list oackages based on names search - search in package descriptions show - show package details install reinstall remove autoremove - remove automatically all unused packages update - update list of available packages upgrade - upgrade the sys by installing/upgrading packages full-upgrade - upgrade the sys by removing/installing/upgrading edit-sources - edit the source information file satisfy - satisfy dependency strings apt-get - look it up yourself LMAO apt install nano will give a error msg since you may not have nano in your package list apt update to update the package database apt install nano ","date":"2021-12-25","objectID":"/docker/:0:6","series":[],"tags":["Docker"],"title":"Docker","uri":"/docker/#linux-distros"},{"categories":["Note"],"content":"Linux Distros Ubuntu Debian Alpine Fedora CentOS Ubuntu go to dockerhub, search for Ubuntu. we can use docker pull ubuntu but here I will use a shortcut we can use docker run ubuntu, if docker cannot find it locally then it will download it and run it in a container. However, since we didn’t interact with the container, it stopped. if we docker ps we cannot see it if we docker ps -a we can see it’s stopped We need to use docker run -it ubuntu to start it in interactive mode And then we entered its shell. root@2f856e34654e5:/# root indicates I’m having the root user mode having the highest access permission After the @ is the name of the container. The / means the dir we are at. And there is a # meaning we have the highest privilege since we are in root mode. whoami echo $0 # /bin/bash # we can see the location of shell program history !2 # will run the 2nd command in history Package Manager apt list - list oackages based on names search - search in package descriptions show - show package details install reinstall remove autoremove - remove automatically all unused packages update - update list of available packages upgrade - upgrade the sys by installing/upgrading packages full-upgrade - upgrade the sys by removing/installing/upgrading edit-sources - edit the source information file satisfy - satisfy dependency strings apt-get - look it up yourself LMAO apt install nano will give a error msg since you may not have nano in your package list apt update to update the package database apt install nano ","date":"2021-12-25","objectID":"/docker/:0:6","series":[],"tags":["Docker"],"title":"Docker","uri":"/docker/#ubuntu"},{"categories":["Note"],"content":"Linux Distros Ubuntu Debian Alpine Fedora CentOS Ubuntu go to dockerhub, search for Ubuntu. we can use docker pull ubuntu but here I will use a shortcut we can use docker run ubuntu, if docker cannot find it locally then it will download it and run it in a container. However, since we didn’t interact with the container, it stopped. if we docker ps we cannot see it if we docker ps -a we can see it’s stopped We need to use docker run -it ubuntu to start it in interactive mode And then we entered its shell. root@2f856e34654e5:/# root indicates I’m having the root user mode having the highest access permission After the @ is the name of the container. The / means the dir we are at. And there is a # meaning we have the highest privilege since we are in root mode. whoami echo $0 # /bin/bash # we can see the location of shell program history !2 # will run the 2nd command in history Package Manager apt list - list oackages based on names search - search in package descriptions show - show package details install reinstall remove autoremove - remove automatically all unused packages update - update list of available packages upgrade - upgrade the sys by installing/upgrading packages full-upgrade - upgrade the sys by removing/installing/upgrading edit-sources - edit the source information file satisfy - satisfy dependency strings apt-get - look it up yourself LMAO apt install nano will give a error msg since you may not have nano in your package list apt update to update the package database apt install nano ","date":"2021-12-25","objectID":"/docker/:0:6","series":[],"tags":["Docker"],"title":"Docker","uri":"/docker/#package-manager"},{"categories":["Note"],"content":"File System bin: binaries boot: booting related dev: devices, in linux, everything is a file etc: editable text configuration home: the home dir of users root: the home dir of root user lib: libs, e.g. software dependencies var: varibles, updated frequently, like logs or app data proc: running processes (as files) pwd print current dir ls ls -1 one item per line ls -l full info list cd ../.. 2 level up cd ~ mv hello.txt /etc hello123.txt notice that \u003cctrl + w\u003e remove one word in shell rm file1.txt file2.txt rm file* rm -r fileDir/ touch file1.txt cat file1.txt more fileLong.txt use more if the file is long. we can use space or enter apt install less less file1.txt we can you up and down and space and enter head -n 5 file1.txt tail -n 2 file2.txt Redirectory cat file1.txt \u003e file2.txt cat file1.txt file2.txt \u003e combined.txt echo hello \u003e hello.txt ls -l /etc \u003e files.txt \u003c Redirectory for input ","date":"2021-12-25","objectID":"/docker/:0:7","series":[],"tags":["Docker"],"title":"Docker","uri":"/docker/#file-system"},{"categories":["Note"],"content":"File System bin: binaries boot: booting related dev: devices, in linux, everything is a file etc: editable text configuration home: the home dir of users root: the home dir of root user lib: libs, e.g. software dependencies var: varibles, updated frequently, like logs or app data proc: running processes (as files) pwd print current dir ls ls -1 one item per line ls -l full info list cd ../.. 2 level up cd ~ mv hello.txt /etc hello123.txt notice that remove one word in shell rm file1.txt file2.txt rm file* rm -r fileDir/ touch file1.txt cat file1.txt more fileLong.txt use more if the file is long. we can use space or enter apt install less less file1.txt we can you up and down and space and enter head -n 5 file1.txt tail -n 2 file2.txt Redirectory cat file1.txt file2.txt cat file1.txt file2.txt combined.txt echo hello hello.txt ls -l /etc files.txt ","date":"2021-12-25","objectID":"/docker/:0:7","series":[],"tags":["Docker"],"title":"Docker","uri":"/docker/#redirectory"},{"categories":["Note"],"content":"Demo Project ","date":"2021-12-25","objectID":"/docker/:1:0","series":[],"tags":["Docker"],"title":"Docker","uri":"/docker/#demo-project"},{"categories":["Note"],"content":"Dynamic Programming I: Fibonacci, Shortest Paths Dynamic programming (DP) DP ≈ careful brute force DP ≈ guessing + recurrsion + memoization time = #subprobs • time of each subprob (treating recurrsive calls as Θ(1) since we only pay it on the first call) Fibonacci numbers fib(n): if n≤2: f=1 else: f=fib(n-1)+fib(n-2) return f T(n) = T(n-1) + T(n-2) + c ≥ 2T(n-2) = Θ(2n/2) Memoized DP algo memo = {} fib(n): if n in memo: return memo[n] if n ≤ 2: f=1 else: f=fib(n-1)+fib(n-2) memo[n]=f return f fib(k) only recurses the first time it’s called, any k memoized calls cost Θ(1) num of memo is n nonrecursive work per call is Θ(1) =\u003e Θ(n) in total SO DP: memoize (remember) and re-use solutions to subproblems that help solve the problem =\u003e time = # of subprobs•time/subprobs•Θ(1) Bottom-up DP algo fib = {} for k in range(1,n+1): if k≤2: f=1 else: f=fib[k-1]+fib[k-2] fib[k]=f return fib[n] This is more efficient since there is no recursive function calls exactly same computation topological sort of subproblem dependency DAG often save some space, i.e. in this case we can keep only the latest 2 results Shortest Paths Guessing if don’t know the answer, guess try all guesses and then take the best one Guess from the last vertex for all the incoming edges traversal ẟ(s,v) = min(ẟ(s,u) + w(u,v)) this is a recursive call and it's very bad as exponential of course we will use memo to improve it a little But it might be falling in infinite time loop with cycles! =\u003e subprobs should be acyclic which may be DAG For DAGs: O(V+E) time for subprob ẟ(s,v) = indegree(v) total time = sum of indegree(v) = O(V+E) If we have +ve cycles ẟ(s,v) = shortest weight of path s-\u003ev that uses ≤k edges ẟk(s,v) = (ẟk-1(s,v) + w(u,v)) num of subprobs = V2 explanation ","date":"2021-12-25","objectID":"/dynamic-programming-i-fibonacci-shortest-paths/:0:1","series":[],"tags":["Algorithm"],"title":"DP","uri":"/dynamic-programming-i-fibonacci-shortest-paths/#dynamic-programming-i-fibonacci-shortest-paths"},{"categories":["Note"],"content":"Dynamic Programming I: Fibonacci, Shortest Paths Dynamic programming (DP) DP ≈ careful brute force DP ≈ guessing + recurrsion + memoization time = #subprobs • time of each subprob (treating recurrsive calls as Θ(1) since we only pay it on the first call) Fibonacci numbers fib(n): if n≤2: f=1 else: f=fib(n-1)+fib(n-2) return f T(n) = T(n-1) + T(n-2) + c ≥ 2T(n-2) = Θ(2n/2) Memoized DP algo memo = {} fib(n): if n in memo: return memo[n] if n ≤ 2: f=1 else: f=fib(n-1)+fib(n-2) memo[n]=f return f fib(k) only recurses the first time it’s called, any k memoized calls cost Θ(1) num of memo is n nonrecursive work per call is Θ(1) = Θ(n) in total SO DP: memoize (remember) and re-use solutions to subproblems that help solve the problem = time = # of subprobs•time/subprobs•Θ(1) Bottom-up DP algo fib = {} for k in range(1,n+1): if k≤2: f=1 else: f=fib[k-1]+fib[k-2] fib[k]=f return fib[n] This is more efficient since there is no recursive function calls exactly same computation topological sort of subproblem dependency DAG often save some space, i.e. in this case we can keep only the latest 2 results Shortest Paths Guessing if don’t know the answer, guess try all guesses and then take the best one Guess from the last vertex for all the incoming edges traversal ẟ(s,v) = min(ẟ(s,u) + w(u,v)) this is a recursive call and it's very bad as exponential of course we will use memo to improve it a little But it might be falling in infinite time loop with cycles! = subprobs should be acyclic which may be DAG For DAGs: O(V+E) time for subprob ẟ(s,v) = indegree(v) total time = sum of indegree(v) = O(V+E) If we have +ve cycles ẟ(s,v) = shortest weight of path s-v that uses ≤k edges ẟk(s,v) = (ẟk-1(s,v) + w(u,v)) num of subprobs = V2 explanation ","date":"2021-12-25","objectID":"/dynamic-programming-i-fibonacci-shortest-paths/:0:1","series":[],"tags":["Algorithm"],"title":"DP","uri":"/dynamic-programming-i-fibonacci-shortest-paths/#dynamic-programming-dp"},{"categories":["Note"],"content":"Dynamic Programming I: Fibonacci, Shortest Paths Dynamic programming (DP) DP ≈ careful brute force DP ≈ guessing + recurrsion + memoization time = #subprobs • time of each subprob (treating recurrsive calls as Θ(1) since we only pay it on the first call) Fibonacci numbers fib(n): if n≤2: f=1 else: f=fib(n-1)+fib(n-2) return f T(n) = T(n-1) + T(n-2) + c ≥ 2T(n-2) = Θ(2n/2) Memoized DP algo memo = {} fib(n): if n in memo: return memo[n] if n ≤ 2: f=1 else: f=fib(n-1)+fib(n-2) memo[n]=f return f fib(k) only recurses the first time it’s called, any k memoized calls cost Θ(1) num of memo is n nonrecursive work per call is Θ(1) = Θ(n) in total SO DP: memoize (remember) and re-use solutions to subproblems that help solve the problem = time = # of subprobs•time/subprobs•Θ(1) Bottom-up DP algo fib = {} for k in range(1,n+1): if k≤2: f=1 else: f=fib[k-1]+fib[k-2] fib[k]=f return fib[n] This is more efficient since there is no recursive function calls exactly same computation topological sort of subproblem dependency DAG often save some space, i.e. in this case we can keep only the latest 2 results Shortest Paths Guessing if don’t know the answer, guess try all guesses and then take the best one Guess from the last vertex for all the incoming edges traversal ẟ(s,v) = min(ẟ(s,u) + w(u,v)) this is a recursive call and it's very bad as exponential of course we will use memo to improve it a little But it might be falling in infinite time loop with cycles! = subprobs should be acyclic which may be DAG For DAGs: O(V+E) time for subprob ẟ(s,v) = indegree(v) total time = sum of indegree(v) = O(V+E) If we have +ve cycles ẟ(s,v) = shortest weight of path s-v that uses ≤k edges ẟk(s,v) = (ẟk-1(s,v) + w(u,v)) num of subprobs = V2 explanation ","date":"2021-12-25","objectID":"/dynamic-programming-i-fibonacci-shortest-paths/:0:1","series":[],"tags":["Algorithm"],"title":"DP","uri":"/dynamic-programming-i-fibonacci-shortest-paths/#fibonacci-numbers"},{"categories":["Note"],"content":"Dynamic Programming I: Fibonacci, Shortest Paths Dynamic programming (DP) DP ≈ careful brute force DP ≈ guessing + recurrsion + memoization time = #subprobs • time of each subprob (treating recurrsive calls as Θ(1) since we only pay it on the first call) Fibonacci numbers fib(n): if n≤2: f=1 else: f=fib(n-1)+fib(n-2) return f T(n) = T(n-1) + T(n-2) + c ≥ 2T(n-2) = Θ(2n/2) Memoized DP algo memo = {} fib(n): if n in memo: return memo[n] if n ≤ 2: f=1 else: f=fib(n-1)+fib(n-2) memo[n]=f return f fib(k) only recurses the first time it’s called, any k memoized calls cost Θ(1) num of memo is n nonrecursive work per call is Θ(1) = Θ(n) in total SO DP: memoize (remember) and re-use solutions to subproblems that help solve the problem = time = # of subprobs•time/subprobs•Θ(1) Bottom-up DP algo fib = {} for k in range(1,n+1): if k≤2: f=1 else: f=fib[k-1]+fib[k-2] fib[k]=f return fib[n] This is more efficient since there is no recursive function calls exactly same computation topological sort of subproblem dependency DAG often save some space, i.e. in this case we can keep only the latest 2 results Shortest Paths Guessing if don’t know the answer, guess try all guesses and then take the best one Guess from the last vertex for all the incoming edges traversal ẟ(s,v) = min(ẟ(s,u) + w(u,v)) this is a recursive call and it's very bad as exponential of course we will use memo to improve it a little But it might be falling in infinite time loop with cycles! = subprobs should be acyclic which may be DAG For DAGs: O(V+E) time for subprob ẟ(s,v) = indegree(v) total time = sum of indegree(v) = O(V+E) If we have +ve cycles ẟ(s,v) = shortest weight of path s-v that uses ≤k edges ẟk(s,v) = (ẟk-1(s,v) + w(u,v)) num of subprobs = V2 explanation ","date":"2021-12-25","objectID":"/dynamic-programming-i-fibonacci-shortest-paths/:0:1","series":[],"tags":["Algorithm"],"title":"DP","uri":"/dynamic-programming-i-fibonacci-shortest-paths/#memoized-dp-algo"},{"categories":["Note"],"content":"Dynamic Programming I: Fibonacci, Shortest Paths Dynamic programming (DP) DP ≈ careful brute force DP ≈ guessing + recurrsion + memoization time = #subprobs • time of each subprob (treating recurrsive calls as Θ(1) since we only pay it on the first call) Fibonacci numbers fib(n): if n≤2: f=1 else: f=fib(n-1)+fib(n-2) return f T(n) = T(n-1) + T(n-2) + c ≥ 2T(n-2) = Θ(2n/2) Memoized DP algo memo = {} fib(n): if n in memo: return memo[n] if n ≤ 2: f=1 else: f=fib(n-1)+fib(n-2) memo[n]=f return f fib(k) only recurses the first time it’s called, any k memoized calls cost Θ(1) num of memo is n nonrecursive work per call is Θ(1) = Θ(n) in total SO DP: memoize (remember) and re-use solutions to subproblems that help solve the problem = time = # of subprobs•time/subprobs•Θ(1) Bottom-up DP algo fib = {} for k in range(1,n+1): if k≤2: f=1 else: f=fib[k-1]+fib[k-2] fib[k]=f return fib[n] This is more efficient since there is no recursive function calls exactly same computation topological sort of subproblem dependency DAG often save some space, i.e. in this case we can keep only the latest 2 results Shortest Paths Guessing if don’t know the answer, guess try all guesses and then take the best one Guess from the last vertex for all the incoming edges traversal ẟ(s,v) = min(ẟ(s,u) + w(u,v)) this is a recursive call and it's very bad as exponential of course we will use memo to improve it a little But it might be falling in infinite time loop with cycles! = subprobs should be acyclic which may be DAG For DAGs: O(V+E) time for subprob ẟ(s,v) = indegree(v) total time = sum of indegree(v) = O(V+E) If we have +ve cycles ẟ(s,v) = shortest weight of path s-v that uses ≤k edges ẟk(s,v) = (ẟk-1(s,v) + w(u,v)) num of subprobs = V2 explanation ","date":"2021-12-25","objectID":"/dynamic-programming-i-fibonacci-shortest-paths/:0:1","series":[],"tags":["Algorithm"],"title":"DP","uri":"/dynamic-programming-i-fibonacci-shortest-paths/#bottom-up-dp-algo"},{"categories":["Note"],"content":"Dynamic Programming I: Fibonacci, Shortest Paths Dynamic programming (DP) DP ≈ careful brute force DP ≈ guessing + recurrsion + memoization time = #subprobs • time of each subprob (treating recurrsive calls as Θ(1) since we only pay it on the first call) Fibonacci numbers fib(n): if n≤2: f=1 else: f=fib(n-1)+fib(n-2) return f T(n) = T(n-1) + T(n-2) + c ≥ 2T(n-2) = Θ(2n/2) Memoized DP algo memo = {} fib(n): if n in memo: return memo[n] if n ≤ 2: f=1 else: f=fib(n-1)+fib(n-2) memo[n]=f return f fib(k) only recurses the first time it’s called, any k memoized calls cost Θ(1) num of memo is n nonrecursive work per call is Θ(1) = Θ(n) in total SO DP: memoize (remember) and re-use solutions to subproblems that help solve the problem = time = # of subprobs•time/subprobs•Θ(1) Bottom-up DP algo fib = {} for k in range(1,n+1): if k≤2: f=1 else: f=fib[k-1]+fib[k-2] fib[k]=f return fib[n] This is more efficient since there is no recursive function calls exactly same computation topological sort of subproblem dependency DAG often save some space, i.e. in this case we can keep only the latest 2 results Shortest Paths Guessing if don’t know the answer, guess try all guesses and then take the best one Guess from the last vertex for all the incoming edges traversal ẟ(s,v) = min(ẟ(s,u) + w(u,v)) this is a recursive call and it's very bad as exponential of course we will use memo to improve it a little But it might be falling in infinite time loop with cycles! = subprobs should be acyclic which may be DAG For DAGs: O(V+E) time for subprob ẟ(s,v) = indegree(v) total time = sum of indegree(v) = O(V+E) If we have +ve cycles ẟ(s,v) = shortest weight of path s-v that uses ≤k edges ẟk(s,v) = (ẟk-1(s,v) + w(u,v)) num of subprobs = V2 explanation ","date":"2021-12-25","objectID":"/dynamic-programming-i-fibonacci-shortest-paths/:0:1","series":[],"tags":["Algorithm"],"title":"DP","uri":"/dynamic-programming-i-fibonacci-shortest-paths/#shortest-paths"},{"categories":["Note"],"content":"Dynamic Programming I: Fibonacci, Shortest Paths Dynamic programming (DP) DP ≈ careful brute force DP ≈ guessing + recurrsion + memoization time = #subprobs • time of each subprob (treating recurrsive calls as Θ(1) since we only pay it on the first call) Fibonacci numbers fib(n): if n≤2: f=1 else: f=fib(n-1)+fib(n-2) return f T(n) = T(n-1) + T(n-2) + c ≥ 2T(n-2) = Θ(2n/2) Memoized DP algo memo = {} fib(n): if n in memo: return memo[n] if n ≤ 2: f=1 else: f=fib(n-1)+fib(n-2) memo[n]=f return f fib(k) only recurses the first time it’s called, any k memoized calls cost Θ(1) num of memo is n nonrecursive work per call is Θ(1) = Θ(n) in total SO DP: memoize (remember) and re-use solutions to subproblems that help solve the problem = time = # of subprobs•time/subprobs•Θ(1) Bottom-up DP algo fib = {} for k in range(1,n+1): if k≤2: f=1 else: f=fib[k-1]+fib[k-2] fib[k]=f return fib[n] This is more efficient since there is no recursive function calls exactly same computation topological sort of subproblem dependency DAG often save some space, i.e. in this case we can keep only the latest 2 results Shortest Paths Guessing if don’t know the answer, guess try all guesses and then take the best one Guess from the last vertex for all the incoming edges traversal ẟ(s,v) = min(ẟ(s,u) + w(u,v)) this is a recursive call and it's very bad as exponential of course we will use memo to improve it a little But it might be falling in infinite time loop with cycles! = subprobs should be acyclic which may be DAG For DAGs: O(V+E) time for subprob ẟ(s,v) = indegree(v) total time = sum of indegree(v) = O(V+E) If we have +ve cycles ẟ(s,v) = shortest weight of path s-v that uses ≤k edges ẟk(s,v) = (ẟk-1(s,v) + w(u,v)) num of subprobs = V2 explanation ","date":"2021-12-25","objectID":"/dynamic-programming-i-fibonacci-shortest-paths/:0:1","series":[],"tags":["Algorithm"],"title":"DP","uri":"/dynamic-programming-i-fibonacci-shortest-paths/#guessing"},{"categories":["Note"],"content":"Dynamic Programming II: Text Justification, Blackjack 5 “easy” steps to DP define subprob guess(part of solution) relate subprob solution (recurrence) recurse \u0026 memoize or build DP table bottom-up acyclic topo order time = #subprobs•time per subprob solve original problem? Note Text justification split text into “good” lines text = list of words badness(i-j): how bad it is as words[i:j] fit a line if don’t fit =\u003e infinity otherwise (page width - total width)3 Goal is to have a least sum of badness subprob: suffixes words[ i : ] #subprobs: n guess: where to start 2nd line #choices ≤ n-i = O(n) recurrence: DP(i) which is the solution of the subprob with suffixes of words{i:} min(DP(i) = badness(i,j) + DP(j) for j in range(i+1,n+1)) topological order i = n, n-1,…,0 total time: O(n2) if original prob solved: DP(0) Parent pointers remember which guess was best parent[i] = argmin(…) = j value 0 -\u003e parent[0] -\u003e parent(parent(0))…… Blackjack Perfect-information deck: C0,C1,…,Cn-1 player vs dealer $1 bet/hand subprob: suffix Ci: num of subprobs: n guess: how many hits are left? #choices \u003c n recurrence: BJ(i) = max( outcome∈{-1,0,1} BJ(j) where j = i + 4 + #hits + #dealerhits for #ofHits in range(0,n) if valid play ","date":"2021-12-25","objectID":"/dynamic-programming-ii-text-justification-blackjack/:0:1","series":[],"tags":["Algorithm"],"title":"DP 2","uri":"/dynamic-programming-ii-text-justification-blackjack/#dynamic-programming-ii-text-justification-blackjack"},{"categories":["Note"],"content":"Dynamic Programming II: Text Justification, Blackjack 5 “easy” steps to DP define subprob guess(part of solution) relate subprob solution (recurrence) recurse \u0026 memoize or build DP table bottom-up acyclic topo order time = #subprobs•time per subprob solve original problem? Note Text justification split text into “good” lines text = list of words badness(i-j): how bad it is as words[i:j] fit a line if don’t fit = infinity otherwise (page width - total width)3 Goal is to have a least sum of badness subprob: suffixes words[ i : ] #subprobs: n guess: where to start 2nd line #choices ≤ n-i = O(n) recurrence: DP(i) which is the solution of the subprob with suffixes of words{i:} min(DP(i) = badness(i,j) + DP(j) for j in range(i+1,n+1)) topological order i = n, n-1,…,0 total time: O(n2) if original prob solved: DP(0) Parent pointers remember which guess was best parent[i] = argmin(…) = j value 0 - parent[0] - parent(parent(0))…… Blackjack Perfect-information deck: C0,C1,…,Cn-1 player vs dealer $1 bet/hand subprob: suffix Ci: num of subprobs: n guess: how many hits are left? #choices ","date":"2021-12-25","objectID":"/dynamic-programming-ii-text-justification-blackjack/:0:1","series":[],"tags":["Algorithm"],"title":"DP 2","uri":"/dynamic-programming-ii-text-justification-blackjack/#5-easy-steps-to-dp"},{"categories":["Note"],"content":"Dynamic Programming II: Text Justification, Blackjack 5 “easy” steps to DP define subprob guess(part of solution) relate subprob solution (recurrence) recurse \u0026 memoize or build DP table bottom-up acyclic topo order time = #subprobs•time per subprob solve original problem? Note Text justification split text into “good” lines text = list of words badness(i-j): how bad it is as words[i:j] fit a line if don’t fit = infinity otherwise (page width - total width)3 Goal is to have a least sum of badness subprob: suffixes words[ i : ] #subprobs: n guess: where to start 2nd line #choices ≤ n-i = O(n) recurrence: DP(i) which is the solution of the subprob with suffixes of words{i:} min(DP(i) = badness(i,j) + DP(j) for j in range(i+1,n+1)) topological order i = n, n-1,…,0 total time: O(n2) if original prob solved: DP(0) Parent pointers remember which guess was best parent[i] = argmin(…) = j value 0 - parent[0] - parent(parent(0))…… Blackjack Perfect-information deck: C0,C1,…,Cn-1 player vs dealer $1 bet/hand subprob: suffix Ci: num of subprobs: n guess: how many hits are left? #choices ","date":"2021-12-25","objectID":"/dynamic-programming-ii-text-justification-blackjack/:0:1","series":[],"tags":["Algorithm"],"title":"DP 2","uri":"/dynamic-programming-ii-text-justification-blackjack/#text-justification"},{"categories":["Note"],"content":"Dynamic Programming II: Text Justification, Blackjack 5 “easy” steps to DP define subprob guess(part of solution) relate subprob solution (recurrence) recurse \u0026 memoize or build DP table bottom-up acyclic topo order time = #subprobs•time per subprob solve original problem? Note Text justification split text into “good” lines text = list of words badness(i-j): how bad it is as words[i:j] fit a line if don’t fit = infinity otherwise (page width - total width)3 Goal is to have a least sum of badness subprob: suffixes words[ i : ] #subprobs: n guess: where to start 2nd line #choices ≤ n-i = O(n) recurrence: DP(i) which is the solution of the subprob with suffixes of words{i:} min(DP(i) = badness(i,j) + DP(j) for j in range(i+1,n+1)) topological order i = n, n-1,…,0 total time: O(n2) if original prob solved: DP(0) Parent pointers remember which guess was best parent[i] = argmin(…) = j value 0 - parent[0] - parent(parent(0))…… Blackjack Perfect-information deck: C0,C1,…,Cn-1 player vs dealer $1 bet/hand subprob: suffix Ci: num of subprobs: n guess: how many hits are left? #choices ","date":"2021-12-25","objectID":"/dynamic-programming-ii-text-justification-blackjack/:0:1","series":[],"tags":["Algorithm"],"title":"DP 2","uri":"/dynamic-programming-ii-text-justification-blackjack/#parent-pointers"},{"categories":["Note"],"content":"Dynamic Programming II: Text Justification, Blackjack 5 “easy” steps to DP define subprob guess(part of solution) relate subprob solution (recurrence) recurse \u0026 memoize or build DP table bottom-up acyclic topo order time = #subprobs•time per subprob solve original problem? Note Text justification split text into “good” lines text = list of words badness(i-j): how bad it is as words[i:j] fit a line if don’t fit = infinity otherwise (page width - total width)3 Goal is to have a least sum of badness subprob: suffixes words[ i : ] #subprobs: n guess: where to start 2nd line #choices ≤ n-i = O(n) recurrence: DP(i) which is the solution of the subprob with suffixes of words{i:} min(DP(i) = badness(i,j) + DP(j) for j in range(i+1,n+1)) topological order i = n, n-1,…,0 total time: O(n2) if original prob solved: DP(0) Parent pointers remember which guess was best parent[i] = argmin(…) = j value 0 - parent[0] - parent(parent(0))…… Blackjack Perfect-information deck: C0,C1,…,Cn-1 player vs dealer $1 bet/hand subprob: suffix Ci: num of subprobs: n guess: how many hits are left? #choices ","date":"2021-12-25","objectID":"/dynamic-programming-ii-text-justification-blackjack/:0:1","series":[],"tags":["Algorithm"],"title":"DP 2","uri":"/dynamic-programming-ii-text-justification-blackjack/#blackjack"},{"categories":["Note"],"content":"Dynamic Programming II: Text Justification, Blackjack 5 “easy” steps to DP define subprob guess(part of solution) relate subprob solution (recurrence) recurse \u0026 memoize or build DP table bottom-up acyclic topo order time = #subprobs•time per subprob solve original problem? Note Text justification split text into “good” lines text = list of words badness(i-j): how bad it is as words[i:j] fit a line if don’t fit = infinity otherwise (page width - total width)3 Goal is to have a least sum of badness subprob: suffixes words[ i : ] #subprobs: n guess: where to start 2nd line #choices ≤ n-i = O(n) recurrence: DP(i) which is the solution of the subprob with suffixes of words{i:} min(DP(i) = badness(i,j) + DP(j) for j in range(i+1,n+1)) topological order i = n, n-1,…,0 total time: O(n2) if original prob solved: DP(0) Parent pointers remember which guess was best parent[i] = argmin(…) = j value 0 - parent[0] - parent(parent(0))…… Blackjack Perfect-information deck: C0,C1,…,Cn-1 player vs dealer $1 bet/hand subprob: suffix Ci: num of subprobs: n guess: how many hits are left? #choices ","date":"2021-12-25","objectID":"/dynamic-programming-ii-text-justification-blackjack/:0:1","series":[],"tags":["Algorithm"],"title":"DP 2","uri":"/dynamic-programming-ii-text-justification-blackjack/#perfect-information"},{"categories":["Note"],"content":"DP III: Parenthesization, Edit Distance, Knapsack Subprblem for strings/sequences suffixes x[i:] for any i Θ(n) prefixes x[:i] for any i Θ(n) substrings x[i:j] for all i ≤ j Θ(n2) Parenthesization optimal evaluation of associative expression A0•A1•…•An-1 how to put the parenthesis note subprob: the optimal evaluation of Ai to Aj-1 which is i:j #subprobs = Θ(n2) guess: outermost/last multiplication (Ai…Ak-1)•(Ak…Aj-1) #choices = O(j-i+1) = O(n) recurrence DP[i:j] = min( DP(i,k) + DP(k,j) + cost of (Ai…Ak-1)•(Ak…Aj-1) for k in range(i+1,j) ) time per subprob = O(n) time = Θ(n3) topological order: increasing substring size Edit distance given two string x\u0026y, what’s the cheapest possible sequence of character edits to turn x-\u003ey where we allow to insert, delete, replace as character edits longest common subsequence HIEROGLYPHOLOGY MICHAELANGELO cost of insert/delete = 1 cost of replace c-\u003ec' = if c=c' 𝜑 else ∞ subprob = edit distance on x[i:] \u0026 y[j:] $subprobs = Θ(|x|•|y|) guess one of 3 possibilities ∈ {insert,delete,replace} recurrence DP(i,j) = min( cost of replace x[i] -\u003e y[j] + DP(i+1,j+1), cost of insert y[j] + DP(i,j+1), cost of delete x[i] + DP(i+1,j) ) topological order for i = |x|,…,0 for j = |y|,…,0 you can see this in a form of matrix DP(0,0) Θ(1) per subprob time=Θ(|x|•|y|) Knapsack list of items each with size si -\u003e integer value vi -\u003e integer Knapsack of size S max sum of values of total size ≤ S subprob = suffix i: of items \u0026 remaining capacity X ≤ S #subprobs = (n•S) guessing: is item i in subset or not DP(i,X) = max(DP(i+1,X), DP(i+1,X-si) + vi ) time = Θ(n•S) not polynomial time since if input(size, value) is huge, the input will be Θ(nlgS) since it takes lgS bits to contain it but is S is small it’s fine pseudopolynomial time ","date":"2021-12-25","objectID":"/dp-iii-parenthesization-edit-distance-knapsack/:0:1","series":[],"tags":["Algorithm"],"title":"DP 3","uri":"/dp-iii-parenthesization-edit-distance-knapsack/#dp-iii-parenthesization-edit-distance-knapsack"},{"categories":["Note"],"content":"DP III: Parenthesization, Edit Distance, Knapsack Subprblem for strings/sequences suffixes x[i:] for any i Θ(n) prefixes x[:i] for any i Θ(n) substrings x[i:j] for all i ≤ j Θ(n2) Parenthesization optimal evaluation of associative expression A0•A1•…•An-1 how to put the parenthesis note subprob: the optimal evaluation of Ai to Aj-1 which is i:j #subprobs = Θ(n2) guess: outermost/last multiplication (Ai…Ak-1)•(Ak…Aj-1) #choices = O(j-i+1) = O(n) recurrence DP[i:j] = min( DP(i,k) + DP(k,j) + cost of (Ai…Ak-1)•(Ak…Aj-1) for k in range(i+1,j) ) time per subprob = O(n) time = Θ(n3) topological order: increasing substring size Edit distance given two string x\u0026y, what’s the cheapest possible sequence of character edits to turn x-y where we allow to insert, delete, replace as character edits longest common subsequence HIEROGLYPHOLOGY MICHAELANGELO cost of insert/delete = 1 cost of replace c-c' = if c=c' 𝜑 else ∞ subprob = edit distance on x[i:] \u0026 y[j:] $subprobs = Θ(|x|•|y|) guess one of 3 possibilities ∈ {insert,delete,replace} recurrence DP(i,j) = min( cost of replace x[i] - y[j] + DP(i+1,j+1), cost of insert y[j] + DP(i,j+1), cost of delete x[i] + DP(i+1,j) ) topological order for i = |x|,…,0 for j = |y|,…,0 you can see this in a form of matrix DP(0,0) Θ(1) per subprob time=Θ(|x|•|y|) Knapsack list of items each with size si - integer value vi - integer Knapsack of size S max sum of values of total size ≤ S subprob = suffix i: of items \u0026 remaining capacity X ≤ S #subprobs = (n•S) guessing: is item i in subset or not DP(i,X) = max(DP(i+1,X), DP(i+1,X-si) + vi ) time = Θ(n•S) not polynomial time since if input(size, value) is huge, the input will be Θ(nlgS) since it takes lgS bits to contain it but is S is small it’s fine pseudopolynomial time ","date":"2021-12-25","objectID":"/dp-iii-parenthesization-edit-distance-knapsack/:0:1","series":[],"tags":["Algorithm"],"title":"DP 3","uri":"/dp-iii-parenthesization-edit-distance-knapsack/#subprblem-for-stringssequences"},{"categories":["Note"],"content":"DP III: Parenthesization, Edit Distance, Knapsack Subprblem for strings/sequences suffixes x[i:] for any i Θ(n) prefixes x[:i] for any i Θ(n) substrings x[i:j] for all i ≤ j Θ(n2) Parenthesization optimal evaluation of associative expression A0•A1•…•An-1 how to put the parenthesis note subprob: the optimal evaluation of Ai to Aj-1 which is i:j #subprobs = Θ(n2) guess: outermost/last multiplication (Ai…Ak-1)•(Ak…Aj-1) #choices = O(j-i+1) = O(n) recurrence DP[i:j] = min( DP(i,k) + DP(k,j) + cost of (Ai…Ak-1)•(Ak…Aj-1) for k in range(i+1,j) ) time per subprob = O(n) time = Θ(n3) topological order: increasing substring size Edit distance given two string x\u0026y, what’s the cheapest possible sequence of character edits to turn x-y where we allow to insert, delete, replace as character edits longest common subsequence HIEROGLYPHOLOGY MICHAELANGELO cost of insert/delete = 1 cost of replace c-c' = if c=c' 𝜑 else ∞ subprob = edit distance on x[i:] \u0026 y[j:] $subprobs = Θ(|x|•|y|) guess one of 3 possibilities ∈ {insert,delete,replace} recurrence DP(i,j) = min( cost of replace x[i] - y[j] + DP(i+1,j+1), cost of insert y[j] + DP(i,j+1), cost of delete x[i] + DP(i+1,j) ) topological order for i = |x|,…,0 for j = |y|,…,0 you can see this in a form of matrix DP(0,0) Θ(1) per subprob time=Θ(|x|•|y|) Knapsack list of items each with size si - integer value vi - integer Knapsack of size S max sum of values of total size ≤ S subprob = suffix i: of items \u0026 remaining capacity X ≤ S #subprobs = (n•S) guessing: is item i in subset or not DP(i,X) = max(DP(i+1,X), DP(i+1,X-si) + vi ) time = Θ(n•S) not polynomial time since if input(size, value) is huge, the input will be Θ(nlgS) since it takes lgS bits to contain it but is S is small it’s fine pseudopolynomial time ","date":"2021-12-25","objectID":"/dp-iii-parenthesization-edit-distance-knapsack/:0:1","series":[],"tags":["Algorithm"],"title":"DP 3","uri":"/dp-iii-parenthesization-edit-distance-knapsack/#parenthesization"},{"categories":["Note"],"content":"DP III: Parenthesization, Edit Distance, Knapsack Subprblem for strings/sequences suffixes x[i:] for any i Θ(n) prefixes x[:i] for any i Θ(n) substrings x[i:j] for all i ≤ j Θ(n2) Parenthesization optimal evaluation of associative expression A0•A1•…•An-1 how to put the parenthesis note subprob: the optimal evaluation of Ai to Aj-1 which is i:j #subprobs = Θ(n2) guess: outermost/last multiplication (Ai…Ak-1)•(Ak…Aj-1) #choices = O(j-i+1) = O(n) recurrence DP[i:j] = min( DP(i,k) + DP(k,j) + cost of (Ai…Ak-1)•(Ak…Aj-1) for k in range(i+1,j) ) time per subprob = O(n) time = Θ(n3) topological order: increasing substring size Edit distance given two string x\u0026y, what’s the cheapest possible sequence of character edits to turn x-y where we allow to insert, delete, replace as character edits longest common subsequence HIEROGLYPHOLOGY MICHAELANGELO cost of insert/delete = 1 cost of replace c-c' = if c=c' 𝜑 else ∞ subprob = edit distance on x[i:] \u0026 y[j:] $subprobs = Θ(|x|•|y|) guess one of 3 possibilities ∈ {insert,delete,replace} recurrence DP(i,j) = min( cost of replace x[i] - y[j] + DP(i+1,j+1), cost of insert y[j] + DP(i,j+1), cost of delete x[i] + DP(i+1,j) ) topological order for i = |x|,…,0 for j = |y|,…,0 you can see this in a form of matrix DP(0,0) Θ(1) per subprob time=Θ(|x|•|y|) Knapsack list of items each with size si - integer value vi - integer Knapsack of size S max sum of values of total size ≤ S subprob = suffix i: of items \u0026 remaining capacity X ≤ S #subprobs = (n•S) guessing: is item i in subset or not DP(i,X) = max(DP(i+1,X), DP(i+1,X-si) + vi ) time = Θ(n•S) not polynomial time since if input(size, value) is huge, the input will be Θ(nlgS) since it takes lgS bits to contain it but is S is small it’s fine pseudopolynomial time ","date":"2021-12-25","objectID":"/dp-iii-parenthesization-edit-distance-knapsack/:0:1","series":[],"tags":["Algorithm"],"title":"DP 3","uri":"/dp-iii-parenthesization-edit-distance-knapsack/#edit-distance"},{"categories":["Note"],"content":"DP III: Parenthesization, Edit Distance, Knapsack Subprblem for strings/sequences suffixes x[i:] for any i Θ(n) prefixes x[:i] for any i Θ(n) substrings x[i:j] for all i ≤ j Θ(n2) Parenthesization optimal evaluation of associative expression A0•A1•…•An-1 how to put the parenthesis note subprob: the optimal evaluation of Ai to Aj-1 which is i:j #subprobs = Θ(n2) guess: outermost/last multiplication (Ai…Ak-1)•(Ak…Aj-1) #choices = O(j-i+1) = O(n) recurrence DP[i:j] = min( DP(i,k) + DP(k,j) + cost of (Ai…Ak-1)•(Ak…Aj-1) for k in range(i+1,j) ) time per subprob = O(n) time = Θ(n3) topological order: increasing substring size Edit distance given two string x\u0026y, what’s the cheapest possible sequence of character edits to turn x-y where we allow to insert, delete, replace as character edits longest common subsequence HIEROGLYPHOLOGY MICHAELANGELO cost of insert/delete = 1 cost of replace c-c' = if c=c' 𝜑 else ∞ subprob = edit distance on x[i:] \u0026 y[j:] $subprobs = Θ(|x|•|y|) guess one of 3 possibilities ∈ {insert,delete,replace} recurrence DP(i,j) = min( cost of replace x[i] - y[j] + DP(i+1,j+1), cost of insert y[j] + DP(i,j+1), cost of delete x[i] + DP(i+1,j) ) topological order for i = |x|,…,0 for j = |y|,…,0 you can see this in a form of matrix DP(0,0) Θ(1) per subprob time=Θ(|x|•|y|) Knapsack list of items each with size si - integer value vi - integer Knapsack of size S max sum of values of total size ≤ S subprob = suffix i: of items \u0026 remaining capacity X ≤ S #subprobs = (n•S) guessing: is item i in subset or not DP(i,X) = max(DP(i+1,X), DP(i+1,X-si) + vi ) time = Θ(n•S) not polynomial time since if input(size, value) is huge, the input will be Θ(nlgS) since it takes lgS bits to contain it but is S is small it’s fine pseudopolynomial time ","date":"2021-12-25","objectID":"/dp-iii-parenthesization-edit-distance-knapsack/:0:1","series":[],"tags":["Algorithm"],"title":"DP 3","uri":"/dp-iii-parenthesization-edit-distance-knapsack/#knapsack"},{"categories":["Note"],"content":"DP IV: Guitar Fingering, Tetris, Super Mario Bros. 2 kinds of guessing in step 2\u00263: guessing which subprob to use to solve bigger subprob in step 1: add more subprobs to guess(remember more features of the solution) Piano/guitar fingering given sequence of n notes, find fingering for each note(single) fingers 1,…, F difficulty measure d(p,f,q,g) some note p on finger f, and we want to transition to note q on finger g subproblem = how to play notes[i:] when use f for notes[i] guess: finger g for notes[n+1] recurrence: DP(i,f) = min (DP(i+1,g) + d(notes[i],f,notes[i+1],g) for g in 1,…,f) topo order: for i in reversed(range(n)): for f in 1,…,f: orig problem: min(DP(s,f) for f in 1,..,f) n•F•Θ(F) = Θ(nF2) if we want to make it a single-source prob just add a source node at the beginning and link it to all 5 posible starting fingers with weights of 0 Guitar generalize “finger” to finger + string time-\u003eΘ(nF2S2) Multiple notes notes[i] = list of notes ≤ F and for guitar we still have ≤ S state: we need to know about “past” is assignment of fingers to notes/null (F+1)F time -\u003e Θ(n(F+1)2F) Tetris training given seq, of n pieces to fall must drop from top full rows don’t clear can you survive? the width of the board is small board is empty subproblems = how to play suffix pieces[i:] given the board skyline n(h+1)w subprobs guess how to play piece 4w where 4 for rotations and w for choices on x axis running time = (n•w•(h+1)w) Super Mario Bros given level n small w•h screen configuration: everything on screen Cwh mario’s velocity C score S time T screen vs level w notes ","date":"2021-12-25","objectID":"/dp-iv-guitar-fingering-tetris-super-mario-bros/:0:1","series":[],"tags":["Algorithm"],"title":"DP 4","uri":"/dp-iv-guitar-fingering-tetris-super-mario-bros/#dp-iv-guitar-fingering-tetris-super-mario-bros"},{"categories":["Note"],"content":"DP IV: Guitar Fingering, Tetris, Super Mario Bros. 2 kinds of guessing in step 2\u00263: guessing which subprob to use to solve bigger subprob in step 1: add more subprobs to guess(remember more features of the solution) Piano/guitar fingering given sequence of n notes, find fingering for each note(single) fingers 1,…, F difficulty measure d(p,f,q,g) some note p on finger f, and we want to transition to note q on finger g subproblem = how to play notes[i:] when use f for notes[i] guess: finger g for notes[n+1] recurrence: DP(i,f) = min (DP(i+1,g) + d(notes[i],f,notes[i+1],g) for g in 1,…,f) topo order: for i in reversed(range(n)): for f in 1,…,f: orig problem: min(DP(s,f) for f in 1,..,f) n•F•Θ(F) = Θ(nF2) if we want to make it a single-source prob just add a source node at the beginning and link it to all 5 posible starting fingers with weights of 0 Guitar generalize “finger” to finger + string time-Θ(nF2S2) Multiple notes notes[i] = list of notes ≤ F and for guitar we still have ≤ S state: we need to know about “past” is assignment of fingers to notes/null (F+1)F time - Θ(n(F+1)2F) Tetris training given seq, of n pieces to fall must drop from top full rows don’t clear can you survive? the width of the board is small board is empty subproblems = how to play suffix pieces[i:] given the board skyline n(h+1)w subprobs guess how to play piece 4w where 4 for rotations and w for choices on x axis running time = (n•w•(h+1)w) Super Mario Bros given level n small w•h screen configuration: everything on screen Cwh mario’s velocity C score S time T screen vs level w notes ","date":"2021-12-25","objectID":"/dp-iv-guitar-fingering-tetris-super-mario-bros/:0:1","series":[],"tags":["Algorithm"],"title":"DP 4","uri":"/dp-iv-guitar-fingering-tetris-super-mario-bros/#2-kinds-of-guessing"},{"categories":["Note"],"content":"DP IV: Guitar Fingering, Tetris, Super Mario Bros. 2 kinds of guessing in step 2\u00263: guessing which subprob to use to solve bigger subprob in step 1: add more subprobs to guess(remember more features of the solution) Piano/guitar fingering given sequence of n notes, find fingering for each note(single) fingers 1,…, F difficulty measure d(p,f,q,g) some note p on finger f, and we want to transition to note q on finger g subproblem = how to play notes[i:] when use f for notes[i] guess: finger g for notes[n+1] recurrence: DP(i,f) = min (DP(i+1,g) + d(notes[i],f,notes[i+1],g) for g in 1,…,f) topo order: for i in reversed(range(n)): for f in 1,…,f: orig problem: min(DP(s,f) for f in 1,..,f) n•F•Θ(F) = Θ(nF2) if we want to make it a single-source prob just add a source node at the beginning and link it to all 5 posible starting fingers with weights of 0 Guitar generalize “finger” to finger + string time-Θ(nF2S2) Multiple notes notes[i] = list of notes ≤ F and for guitar we still have ≤ S state: we need to know about “past” is assignment of fingers to notes/null (F+1)F time - Θ(n(F+1)2F) Tetris training given seq, of n pieces to fall must drop from top full rows don’t clear can you survive? the width of the board is small board is empty subproblems = how to play suffix pieces[i:] given the board skyline n(h+1)w subprobs guess how to play piece 4w where 4 for rotations and w for choices on x axis running time = (n•w•(h+1)w) Super Mario Bros given level n small w•h screen configuration: everything on screen Cwh mario’s velocity C score S time T screen vs level w notes ","date":"2021-12-25","objectID":"/dp-iv-guitar-fingering-tetris-super-mario-bros/:0:1","series":[],"tags":["Algorithm"],"title":"DP 4","uri":"/dp-iv-guitar-fingering-tetris-super-mario-bros/#pianoguitar-fingering"},{"categories":["Note"],"content":"DP IV: Guitar Fingering, Tetris, Super Mario Bros. 2 kinds of guessing in step 2\u00263: guessing which subprob to use to solve bigger subprob in step 1: add more subprobs to guess(remember more features of the solution) Piano/guitar fingering given sequence of n notes, find fingering for each note(single) fingers 1,…, F difficulty measure d(p,f,q,g) some note p on finger f, and we want to transition to note q on finger g subproblem = how to play notes[i:] when use f for notes[i] guess: finger g for notes[n+1] recurrence: DP(i,f) = min (DP(i+1,g) + d(notes[i],f,notes[i+1],g) for g in 1,…,f) topo order: for i in reversed(range(n)): for f in 1,…,f: orig problem: min(DP(s,f) for f in 1,..,f) n•F•Θ(F) = Θ(nF2) if we want to make it a single-source prob just add a source node at the beginning and link it to all 5 posible starting fingers with weights of 0 Guitar generalize “finger” to finger + string time-Θ(nF2S2) Multiple notes notes[i] = list of notes ≤ F and for guitar we still have ≤ S state: we need to know about “past” is assignment of fingers to notes/null (F+1)F time - Θ(n(F+1)2F) Tetris training given seq, of n pieces to fall must drop from top full rows don’t clear can you survive? the width of the board is small board is empty subproblems = how to play suffix pieces[i:] given the board skyline n(h+1)w subprobs guess how to play piece 4w where 4 for rotations and w for choices on x axis running time = (n•w•(h+1)w) Super Mario Bros given level n small w•h screen configuration: everything on screen Cwh mario’s velocity C score S time T screen vs level w notes ","date":"2021-12-25","objectID":"/dp-iv-guitar-fingering-tetris-super-mario-bros/:0:1","series":[],"tags":["Algorithm"],"title":"DP 4","uri":"/dp-iv-guitar-fingering-tetris-super-mario-bros/#guitar"},{"categories":["Note"],"content":"DP IV: Guitar Fingering, Tetris, Super Mario Bros. 2 kinds of guessing in step 2\u00263: guessing which subprob to use to solve bigger subprob in step 1: add more subprobs to guess(remember more features of the solution) Piano/guitar fingering given sequence of n notes, find fingering for each note(single) fingers 1,…, F difficulty measure d(p,f,q,g) some note p on finger f, and we want to transition to note q on finger g subproblem = how to play notes[i:] when use f for notes[i] guess: finger g for notes[n+1] recurrence: DP(i,f) = min (DP(i+1,g) + d(notes[i],f,notes[i+1],g) for g in 1,…,f) topo order: for i in reversed(range(n)): for f in 1,…,f: orig problem: min(DP(s,f) for f in 1,..,f) n•F•Θ(F) = Θ(nF2) if we want to make it a single-source prob just add a source node at the beginning and link it to all 5 posible starting fingers with weights of 0 Guitar generalize “finger” to finger + string time-Θ(nF2S2) Multiple notes notes[i] = list of notes ≤ F and for guitar we still have ≤ S state: we need to know about “past” is assignment of fingers to notes/null (F+1)F time - Θ(n(F+1)2F) Tetris training given seq, of n pieces to fall must drop from top full rows don’t clear can you survive? the width of the board is small board is empty subproblems = how to play suffix pieces[i:] given the board skyline n(h+1)w subprobs guess how to play piece 4w where 4 for rotations and w for choices on x axis running time = (n•w•(h+1)w) Super Mario Bros given level n small w•h screen configuration: everything on screen Cwh mario’s velocity C score S time T screen vs level w notes ","date":"2021-12-25","objectID":"/dp-iv-guitar-fingering-tetris-super-mario-bros/:0:1","series":[],"tags":["Algorithm"],"title":"DP 4","uri":"/dp-iv-guitar-fingering-tetris-super-mario-bros/#multiple-notes"},{"categories":["Note"],"content":"DP IV: Guitar Fingering, Tetris, Super Mario Bros. 2 kinds of guessing in step 2\u00263: guessing which subprob to use to solve bigger subprob in step 1: add more subprobs to guess(remember more features of the solution) Piano/guitar fingering given sequence of n notes, find fingering for each note(single) fingers 1,…, F difficulty measure d(p,f,q,g) some note p on finger f, and we want to transition to note q on finger g subproblem = how to play notes[i:] when use f for notes[i] guess: finger g for notes[n+1] recurrence: DP(i,f) = min (DP(i+1,g) + d(notes[i],f,notes[i+1],g) for g in 1,…,f) topo order: for i in reversed(range(n)): for f in 1,…,f: orig problem: min(DP(s,f) for f in 1,..,f) n•F•Θ(F) = Θ(nF2) if we want to make it a single-source prob just add a source node at the beginning and link it to all 5 posible starting fingers with weights of 0 Guitar generalize “finger” to finger + string time-Θ(nF2S2) Multiple notes notes[i] = list of notes ≤ F and for guitar we still have ≤ S state: we need to know about “past” is assignment of fingers to notes/null (F+1)F time - Θ(n(F+1)2F) Tetris training given seq, of n pieces to fall must drop from top full rows don’t clear can you survive? the width of the board is small board is empty subproblems = how to play suffix pieces[i:] given the board skyline n(h+1)w subprobs guess how to play piece 4w where 4 for rotations and w for choices on x axis running time = (n•w•(h+1)w) Super Mario Bros given level n small w•h screen configuration: everything on screen Cwh mario’s velocity C score S time T screen vs level w notes ","date":"2021-12-25","objectID":"/dp-iv-guitar-fingering-tetris-super-mario-bros/:0:1","series":[],"tags":["Algorithm"],"title":"DP 4","uri":"/dp-iv-guitar-fingering-tetris-super-mario-bros/#tetris-training"},{"categories":["Note"],"content":"DP IV: Guitar Fingering, Tetris, Super Mario Bros. 2 kinds of guessing in step 2\u00263: guessing which subprob to use to solve bigger subprob in step 1: add more subprobs to guess(remember more features of the solution) Piano/guitar fingering given sequence of n notes, find fingering for each note(single) fingers 1,…, F difficulty measure d(p,f,q,g) some note p on finger f, and we want to transition to note q on finger g subproblem = how to play notes[i:] when use f for notes[i] guess: finger g for notes[n+1] recurrence: DP(i,f) = min (DP(i+1,g) + d(notes[i],f,notes[i+1],g) for g in 1,…,f) topo order: for i in reversed(range(n)): for f in 1,…,f: orig problem: min(DP(s,f) for f in 1,..,f) n•F•Θ(F) = Θ(nF2) if we want to make it a single-source prob just add a source node at the beginning and link it to all 5 posible starting fingers with weights of 0 Guitar generalize “finger” to finger + string time-Θ(nF2S2) Multiple notes notes[i] = list of notes ≤ F and for guitar we still have ≤ S state: we need to know about “past” is assignment of fingers to notes/null (F+1)F time - Θ(n(F+1)2F) Tetris training given seq, of n pieces to fall must drop from top full rows don’t clear can you survive? the width of the board is small board is empty subproblems = how to play suffix pieces[i:] given the board skyline n(h+1)w subprobs guess how to play piece 4w where 4 for rotations and w for choices on x axis running time = (n•w•(h+1)w) Super Mario Bros given level n small w•h screen configuration: everything on screen Cwh mario’s velocity C score S time T screen vs level w notes ","date":"2021-12-25","objectID":"/dp-iv-guitar-fingering-tetris-super-mario-bros/:0:1","series":[],"tags":["Algorithm"],"title":"DP 4","uri":"/dp-iv-guitar-fingering-tetris-super-mario-bros/#super-mario-bros"},{"categories":["Note"],"content":"Tips About Dual Boot If you are using MBR for dual boot… When you are installing the Linux sys, git the make a partition with a size of 1 or 2 GB to mount /boot, where saves several kernels and the booting info. This action ensures the booting of your Linux don’t affect that of your Windows sys. After you install the Linux sys, in my case, the Pop OS, don’t forget to install os-prober sudo os-prober sudo update-grub ","date":"2021-12-25","objectID":"/dual-boot/:0:0","series":[],"tags":["Dual Boot"],"title":"Dual Boot Tips","uri":"/dual-boot/#tips-about-dual-boot"},{"categories":["Note"],"content":"FTP, SFTP, TFTP ","date":"2021-12-25","objectID":"/ftp-sftp-tftp/:0:0","series":[],"tags":["Network"],"title":"FTP","uri":"/ftp-sftp-tftp/#ftp-sftp-tftp"},{"categories":["Note"],"content":"FTP (File Transfer Protocol) FTP is the lang that computers use to transfer files over a TCP/IP network. You can use web browser to upload and download files. For example, you can go to ftp.example.com and browse the files. ","date":"2021-12-25","objectID":"/ftp-sftp-tftp/:1:0","series":[],"tags":["Network"],"title":"FTP","uri":"/ftp-sftp-tftp/#ftp-file-transfer-protocol"},{"categories":["Note"],"content":"SFTP FTP with a secure layer added. Notice FTP\u0026SFTP are based on TCP so the delivery is secured. ","date":"2021-12-25","objectID":"/ftp-sftp-tftp/:2:0","series":[],"tags":["Network"],"title":"FTP","uri":"/ftp-sftp-tftp/#sftp"},{"categories":["Note"],"content":"TFTP (Trivial) It mainly used to transfer file in local network. It uses UDP! ","date":"2021-12-25","objectID":"/ftp-sftp-tftp/:3:0","series":[],"tags":["Network"],"title":"FTP","uri":"/ftp-sftp-tftp/#tftp-trivial"},{"categories":["Note"],"content":"Setup an SFTP Server on Ubuntu https://www.pcwdld.com/setup-sftp-server-on-ubuntu#wbounce-modal ","date":"2021-12-25","objectID":"/ftp-sftp-tftp/:4:0","series":[],"tags":["Network"],"title":"FTP","uri":"/ftp-sftp-tftp/#setup-an-sftp-server-on-ubuntu"},{"categories":["Note"],"content":"Git ","date":"2021-12-25","objectID":"/gitreview/:0:0","series":[],"tags":["Git"],"title":"Git Review","uri":"/gitreview/#git"},{"categories":["Note"],"content":"First Run #need sudo /etc/gitconfig git config --system #work on all git repos of the current user, ~/.gitconfig 或 ~/.config/git/config git config --global #this is by default. If you are at a git repo, this r/w .git/config for this repo git config --local #每一个级别会覆盖上一级别的配置 #check all the config and their paths git config --list --show-origin 首先设置用户名和邮件地址，每一次commit都会写入信息，且无法更改。 git config --global user.name \"John Doe\" git config --global user.email johndoe@example.com 设置编辑器 $ git config --global core.editor emacs # or $ git config --global core.editor \"'C:/Program Files/Notepad++/notepad++.exe' -multiInst -notabbar -nosession -noPlugin\" 检查配置 git config --list 输入 git config \u003ckey\u003e： 来检查 Git 的某一项配置 $ git config user.name John Doe git \u003cverb\u003e --help man git-\u003cverb\u003e ","date":"2021-12-25","objectID":"/gitreview/:1:0","series":[],"tags":["Git"],"title":"Git Review","uri":"/gitreview/#first-run"},{"categories":["Note"],"content":"Init ","date":"2021-12-25","objectID":"/gitreview/:2:0","series":[],"tags":["Git"],"title":"Git Review","uri":"/gitreview/#init"},{"categories":["Note"],"content":"For an Existing Dir for Linux: $ cd /home/user/my_project for macOS: $ cd /Users/user/my_project for Windows: $ cd C:/Users/user/my_project and type: $ git init 如果在一个已存在文件的文件夹（而非空文件夹）中进行版本控制，你应该开始追踪这些文件并进行初始提交。 可以通过 git add 命令来指定所需的文件来进行追踪，然后执行 git commit ： $ git add *.c $ git add LICENSE $ git commit -m 'initial project version' ","date":"2021-12-25","objectID":"/gitreview/:2:1","series":[],"tags":["Git"],"title":"Git Review","uri":"/gitreview/#for-an-existing-dir"},{"categories":["Note"],"content":"Clone 克隆仓库的命令是 git clone \u003curl\u003e 。 比如，要克隆 Git 的链接库 libgit2，可以用下面的命令： $ git clone https://github.com/libgit2/libgit2 如果你想在克隆远程仓库的时候，自定义本地仓库的名字，你可以通过额外的参数指定新的目录名： $ git clone https://github.com/libgit2/libgit2 mylibgit 这会执行与上一条命令相同的操作，但目标目录名变为了 mylibgit。 Git 支持多种数据传输协议。 上面的例子使用的是 https:// 协议，不过你也可以使用 git:// 协议或者使用 SSH 传输协议，比如 user@server:path/to/repo.git 。 在服务器上搭建 Git 将会介绍所有这些协议在服务器端如何配置使用，以及各种方式之间的利弊。 ","date":"2021-12-25","objectID":"/gitreview/:2:2","series":[],"tags":["Git"],"title":"Git Review","uri":"/gitreview/#clone"},{"categories":["Note"],"content":"Recording Changes to the Repository ![The lifecycle of the status of your files](https://git-scm.com/book/en/v2/images/lifecycle.png) ","date":"2021-12-25","objectID":"/gitreview/:3:0","series":[],"tags":["Git"],"title":"Git Review","uri":"/gitreview/#recording-changes-to-the-repository"},{"categories":["Note"],"content":"检查当前文件状态 可以用 git status 命令查看哪些文件处于什么状态。 如果在克隆仓库后立即使用此命令，会看到类似这样的输出： $ git status On branch master Your branch is up-to-date with 'origin/master'. nothing to commit, working directory clean 现在，让我们在项目下创建一个新的 README 文件。 如果之前并不存在这个文件，使用 git status 命令，你将看到一个新的未跟踪文件： $ echo 'My Project' \u003e README $ git status On branch master Your branch is up-to-date with 'origin/master'. Untracked files: (use \"git add \u003cfile\u003e...\" to include in what will be committed) README nothing added to commit but untracked files present (use \"git add\" to track) 使用命令 git add 开始跟踪一个文件。 所以，要跟踪 README 文件，运行： $ git add README ","date":"2021-12-25","objectID":"/gitreview/:3:1","series":[],"tags":["Git"],"title":"Git Review","uri":"/gitreview/#检查当前文件状态"},{"categories":["Note"],"content":"暂存已修改的文件 git add CONTRIBUTING.md ","date":"2021-12-25","objectID":"/gitreview/:3:2","series":[],"tags":["Git"],"title":"Git Review","uri":"/gitreview/#暂存已修改的文件"},{"categories":["Note"],"content":"状态简览 git status 命令的输出十分详细，但其用语有些繁琐。 Git 有一个选项可以帮你缩短状态命令的输出，这样可以以简洁的方式查看更改。 如果你使用 git status -s 命令或 git status --short 命令，你将得到一种格式更为紧凑的输出。 $ git status -s M README MM Rakefile A lib/git.rb M lib/simplegit.rb ?? LICENSE.txt ","date":"2021-12-25","objectID":"/gitreview/:3:3","series":[],"tags":["Git"],"title":"Git Review","uri":"/gitreview/#状态简览"},{"categories":["Note"],"content":"忽略文件 一般我们总会有些文件无需纳入 Git 的管理，也不希望它们总出现在未跟踪文件列表。 通常都是些自动生成的文件，比如日志文件，或者编译过程中创建的临时文件等。 在这种情况下，我们可以创建一个名为 .gitignore 的文件，列出要忽略的文件的模式。 来看一个实际的 .gitignore 例子： $ cat .gitignore *.[oa] *~ 第一行告诉 Git 忽略所有以 .o 或 .a 结尾的文件。一般这类对象文件和存档文件都是编译过程中出现的。 第二行告诉 Git 忽略所有名字以波浪符（~）结尾的文件，许多文本编辑软件（比如 Emacs）都用这样的文件名保存副本。 此外，你可能还需要忽略 log，tmp 或者 pid 目录，以及自动生成的文档等等。 要养成一开始就为你的新仓库设置好 .gitignore 文件的习惯，以免将来误提交这类无用的文件。 文件 .gitignore 的格式规范如下： 所有空行或者以 # 开头的行都会被 Git 忽略。 可以使用标准的 glob 模式匹配，它会递归地应用在整个工作区中。 匹配模式可以以（/）开头防止递归。 匹配模式可以以（/）结尾指定目录。 要忽略指定模式以外的文件或目录，可以在模式前加上叹号（!）取反。 所谓的 glob 模式是指 shell 所使用的简化了的正则表达式。 星号（*）匹配零个或多个任意字符；[abc] 匹配任何一个列在方括号中的字符 （这个例子要么匹配一个 a，要么匹配一个 b，要么匹配一个 c）； 问号（?）只匹配一个任意字符；如果在方括号中使用短划线分隔两个字符， 表示所有在这两个字符范围内的都可以匹配（比如 [0-9] 表示匹配所有 0 到 9 的数字）。 使用两个星号（**）表示匹配任意中间目录，比如 a/**/z 可以匹配 a/z 、 a/b/z 或 a/b/c/z 等。 我们再看一个 .gitignore 文件的例子： # 忽略所有的 .a 文件 *.a # 但跟踪所有的 lib.a，即便你在前面忽略了 .a 文件 !lib.a # 只忽略当前目录下的 TODO 文件，而不忽略 subdir/TODO /TODO # 忽略任何目录下名为 build 的文件夹 build/ # 忽略 doc/notes.txt，但不忽略 doc/server/arch.txt doc/*.txt # 忽略 doc/ 目录及其所有子目录下的 .pdf 文件 doc/**/*.pdf ","date":"2021-12-25","objectID":"/gitreview/:3:4","series":[],"tags":["Git"],"title":"Git Review","uri":"/gitreview/#忽略文件"},{"categories":["Note"],"content":"查看已暂存和未暂存的修改 如果 git status 命令的输出对于你来说过于简略，而你想知道具体修改了什么地方，可以用 git diff 命令。 要查看尚未暂存的文件更新了哪些部分，不加参数直接输入 git diff 此命令比较的是工作目录中当前文件和暂存区域快照之间的差异。 也就是修改之后还没有暂存起来的变化内容。 若要查看已暂存的将要添加到下次提交里的内容，可以用 git diff --staged 命令。 这条命令将比对已暂存文件与最后一次提交的文件差异： 请注意，git diff 本身只显示尚未暂存的改动，而不是自上次提交以来所做的所有改动。 所以有时候你一下子暂存了所有更新过的文件，运行 git diff 后却什么也没有，就是这个原因。 ","date":"2021-12-25","objectID":"/gitreview/:3:5","series":[],"tags":["Git"],"title":"Git Review","uri":"/gitreview/#查看已暂存和未暂存的修改"},{"categories":["Note"],"content":"提交更新 git commit 另外，你也可以在 commit 命令后添加 -m 选项，将提交信息与命令放在同一行，如下所示： $ git commit -m \"Story 182: Fix benchmarks for speed\" [master 463dc4f] Story 182: Fix benchmarks for speed 2 files changed, 2 insertions(+) create mode 100644 README 好，现在你已经创建了第一个提交！ 可以看到，提交后它会告诉你，当前是在哪个分支（master）提交的，本次提交的完整 SHA-1 校验和是什么（463dc4f），以及在本次提交中，有多少文件修订过，多少行添加和删改过。 请记住，提交时记录的是放在暂存区域的快照。 任何还未暂存文件的仍然保持已修改状态，可以在下次提交时纳入版本管理。 每一次运行提交操作，都是对你项目作一次快照，以后可以回到这个状态，或者进行比较。 ","date":"2021-12-25","objectID":"/gitreview/:3:6","series":[],"tags":["Git"],"title":"Git Review","uri":"/gitreview/#提交更新"},{"categories":["Note"],"content":"跳过使用暂存区域 尽管使用暂存区域的方式可以精心准备要提交的细节，但有时候这么做略显繁琐。 Git 提供了一个跳过使用暂存区域的方式， 只要在提交的时候，给 git commit 加上 -a 选项，Git 就会自动把所有已经跟踪过的文件暂存起来一并提交，从而跳过 git add 步骤 ","date":"2021-12-25","objectID":"/gitreview/:3:7","series":[],"tags":["Git"],"title":"Git Review","uri":"/gitreview/#跳过使用暂存区域"},{"categories":["Note"],"content":"移除文件 要从 Git 中移除某个文件，就必须要从已跟踪文件清单中移除（确切地说，是从暂存区域移除），然后提交。 可以用 git rm 命令完成此项工作，并连带从工作目录中删除指定的文件，这样以后就不会出现在未跟踪文件清单中了。 如果要删除之前修改过或已经放到暂存区的文件，则必须使用强制删除选项 -f（译注：即 force 的首字母）。 这是一种安全特性，用于防止误删尚未添加到快照的数据，这样的数据不能被 Git 恢复。 另外一种情况是，我们想把文件从 Git 仓库中删除（亦即从暂存区域移除），但仍然希望保留在当前工作目录中。 换句话说，你想让文件保留在磁盘，但是并不想让 Git 继续跟踪。 当你忘记添加 .gitignore 文件，不小心把一个很大的日志文件或一堆 .a 这样的编译生成文件添加到暂存区时，这一做法尤其有用。 为达到这一目的，使用 --cached 选项： $ git rm --cached README git rm 命令后面可以列出文件或者目录的名字，也可以使用 glob 模式。比如： $ git rm log/\\*.log 注意到星号 * 之前的反斜杠 \\， 因为 Git 有它自己的文件模式扩展匹配方式，所以我们不用 shell 来帮忙展开。 此命令删除 log/ 目录下扩展名为 .log 的所有文件。 类似的比如： $ git rm \\*~ 该命令会删除所有名字以 ~ 结尾的文件。 ","date":"2021-12-25","objectID":"/gitreview/:3:8","series":[],"tags":["Git"],"title":"Git Review","uri":"/gitreview/#移除文件"},{"categories":["Note"],"content":"移动文件 不像其它的 VCS 系统，Git 并不显式跟踪文件移动操作。 如果在 Git 中重命名了某个文件，仓库中存储的元数据并不会体现出这是一次改名操作。 不过 Git 非常聪明，它会推断出究竟发生了什么，至于具体是如何做到的，我们稍后再谈。 既然如此，当你看到 Git 的 mv 命令时一定会困惑不已。 要在 Git 中对文件改名，可以这么做： $ git mv file_from file_to 其实，运行 git mv 就相当于运行了下面三条命令： $ mv README.md README $ git rm README.md $ git add README 如此分开操作，Git 也会意识到这是一次重命名，所以不管何种方式结果都一样。 两者唯一的区别在于，git mv 是一条命令而非三条命令，直接使用 git mv 方便得多。 不过在使用其他工具重命名文件时，记得在提交前 git rm 删除旧文件名，再 git add 添加新文件名。 ","date":"2021-12-25","objectID":"/gitreview/:3:9","series":[],"tags":["Git"],"title":"Git Review","uri":"/gitreview/#移动文件"},{"categories":["Note"],"content":"查看提交历史 ","date":"2021-12-25","objectID":"/gitreview/:0:0","series":[],"tags":["Git"],"title":"Git Review","uri":"/gitreview/#查看提交历史"},{"categories":["Note"],"content":"查看提交历史 在提交了若干更新，又或者克隆了某个项目之后，你也许想回顾下提交历史。 完成这个任务最简单而又有效的工具是 git log 命令。 git log 有许多选项可以帮助你搜寻你所要找的提交， 下面我们会介绍几个最常用的选项。 其中一个比较有用的选项是 -p 或 --patch ，它会显示每次提交所引入的差异（按 补丁 的格式输出）。 你也可以限制显示的日志条目数量，例如使用 -2 选项来只显示最近的两次提交 该选项除了显示基本信息之外，还附带了每次提交的变化。 当进行代码审查，或者快速浏览某个搭档的提交所带来的变化的时候，这个参数就非常有用了。 你也可以为 git log 附带一系列的总结性选项。 比如你想看到每次提交的简略统计信息，可以使用 --stat 选项： --stat 选项在每次提交的下面列出所有被修改过的文件、有多少文件被修改了以及被修改过的文件的哪些行被移除或是添加了。 在每次提交的最后还有一个总结。 另一个非常有用的选项是 --pretty。 这个选项可以使用不同于默认格式的方式展示提交历史。 这个选项有一些内建的子选项供你使用。 比如 oneline 会将每个提交放在一行显示，在浏览大量的提交时非常有用。 另外还有 short，full 和 fuller 选项，它们展示信息的格式基本一致，但是详尽程度不一 $ git log --pretty=oneline ca82a6dff817ec66f44342007202690a93763949 changed the version number 085bb3bcb608e1e8451d4b2432f8ecbe6306e7e7 removed unnecessary test a11bef06a3f659402fe7563abf99ad00de2209e6 first commit 最有意思的是 format ，可以定制记录的显示格式。 这样的输出对后期提取分析格外有用——因为你知道输出的格式不会随着 Git 的更新而发生改变： $ git log --pretty=format:\"%h - %an, %ar : %s\" ca82a6d - Scott Chacon, 6 years ago : changed the version number 085bb3b - Scott Chacon, 6 years ago : removed unnecessary test a11bef0 - Scott Chacon, 6 years ago : first commit git log --pretty=format 常用的选项 列出了 format 接受的常用格式占位符的写法及其代表的意义。 选项 说明 %H 提交的完整哈希值 %h 提交的简写哈希值 %T 树的完整哈希值 %t 树的简写哈希值 %P 父提交的完整哈希值 %p 父提交的简写哈希值 %an 作者名字 %ae 作者的电子邮件地址 %ad 作者修订日期（可以用 –date=选项 来定制格式） %ar 作者修订日期，按多久以前的方式显示 %cn 提交者的名字 %ce 提交者的电子邮件地址 %cd 提交日期 %cr 提交日期（距今多长时间） %s 提交说明 你一定奇怪 作者 和 提交者 之间究竟有何差别， 其实作者指的是实际作出修改的人，提交者指的是最后将此工作成果提交到仓库的人。 所以，当你为某个项目发布补丁，然后某个核心成员将你的补丁并入项目时，你就是作者，而那个核心成员就是提交者。 我们会在 分布式 Git 再详细介绍两者之间的细微差别。 当 oneline 或 format 与另一个 log 选项 --graph 结合使用时尤其有用。 这个选项添加了一些 ASCII 字符串来形象地展示你的分支、合并历史 选项 说明 -p 按补丁格式显示每个提交引入的差异。 --stat 显示每次提交的文件修改统计信息。 --shortstat 只显示 –stat 中最后的行数修改添加移除统计。 --name-only 仅在提交信息后显示已修改的文件清单。 --name-status 显示新增、修改、删除的文件清单。 --abbrev-commit 仅显示 SHA-1 校验和所有 40 个字符中的前几个字符。 --relative-date 使用较短的相对时间而不是完整格式显示日期（比如“2 weeks ago”）。 --graph 在日志旁以 ASCII 图形显示分支与合并历史。 --pretty 使用其他格式显示历史提交信息。可用的选项包括 oneline、short、full、fuller 和 format（用来定义自己的格式）。 --oneline --pretty=oneline --abbrev-commit 合用的简写。 ","date":"2021-12-25","objectID":"/gitreview/:1:0","series":[],"tags":["Git"],"title":"Git Review","uri":"/gitreview/#查看提交历史-1"},{"categories":["Note"],"content":"限制输出长度 除了定制输出格式的选项之外，git log 还有许多非常实用的限制输出长度的选项，也就是只输出一部分的提交。 之前你已经看到过 -2 选项了，它只会显示最近的两条提交， 实际上，你可以使用类似 -\u003cn\u003e 的选项，其中的 n 可以是任何整数，表示仅显示最近的 n 条提交。 不过实践中这个选项不是很常用，因为 Git 默认会将所有的输出传送到分页程序中，所以你一次只会看到一页的内容。 但是，类似 --since 和 --until 这种按照时间作限制的选项很有用。 例如，下面的命令会列出最近两周的所有提交： $ git log --since=2.weeks 该命令可用的格式十分丰富——可以是类似 \"2008-01-15\" 的具体的某一天，也可以是类似 \"2 years 1 day 3 minutes ago\" 的相对日期。 还可以过滤出匹配指定条件的提交。 用 --author 选项显示指定作者的提交，用 --grep 选项搜索提交说明中的关键字。 另一个非常有用的过滤器是 -S（俗称“pickaxe”选项，取“用鹤嘴锄在土里捡石头”之意）， 它接受一个字符串参数，并且只会显示那些添加或删除了该字符串的提交。 假设你想找出添加或删除了对某一个特定函数的引用的提交，可以调用： $ git log -S function_name 最后一个很实用的 git log 选项是路径（path）， 如果只关心某些文件或者目录的历史提交，可以在 git log 选项的最后指定它们的路径。 因为是放在最后位置上的选项，所以用两个短划线（–）隔开之前的选项和后面限定的路径名。 在 限制 git log 输出的选项 中列出了常用的选项 选项 说明 -\u003cn\u003e 仅显示最近的 n 条提交。 --since, --after 仅显示指定时间之后的提交。 --until, --before 仅显示指定时间之前的提交。 --author 仅显示作者匹配指定字符串的提交。 --committer 仅显示提交者匹配指定字符串的提交。 --grep 仅显示提交说明中包含指定字符串的提交。 -S 仅显示添加或删除内容匹配指定字符串的提交。 来看一个实际的例子，如果要在 Git 源码库中查看 Junio Hamano 在 2008 年 10 月其间， 除了合并提交之外的哪一个提交修改了测试文件，可以使用下面的命令： $ git log --pretty=\"%h - %s\" --author='Junio C Hamano' --since=\"2008-10-01\" \\ --before=\"2008-11-01\" --no-merges -- t/ 5610e3b - Fix testcase failure when extended attributes are in use acd3b9e - Enhance hold_lock_file_for_{update,append}() API f563754 - demonstrate breakage of detached checkout with symbolic link HEAD d1a43f2 - reset --hard/read-tree --reset -u: remove unmerged new paths 51a94af - Fix \"checkout --track -b newbranch\" on detached HEAD b0ad11e - pull: allow \"git pull origin $something:$current_branch\" into an unborn branch 在近 40000 条提交中，上面的输出仅列出了符合条件的 6 条记录。 git log --all --decorate --oneline --graph ","date":"2021-12-25","objectID":"/gitreview/:1:1","series":[],"tags":["Git"],"title":"Git Review","uri":"/gitreview/#限制输出长度"},{"categories":["Note"],"content":"撤消操作 ","date":"2021-12-25","objectID":"/gitreview/:0:0","series":[],"tags":["Git"],"title":"Git Review","uri":"/gitreview/#撤消操作"},{"categories":["Note"],"content":"远程仓库的使用 ","date":"2021-12-25","objectID":"/gitreview/:0:0","series":[],"tags":["Git"],"title":"Git Review","uri":"/gitreview/#远程仓库的使用"},{"categories":["Note"],"content":"打标签 ","date":"2021-12-25","objectID":"/gitreview/:0:0","series":[],"tags":["Git"],"title":"Git Review","uri":"/gitreview/#打标签"},{"categories":["Note"],"content":"Git 别名 ","date":"2021-12-25","objectID":"/gitreview/:0:0","series":[],"tags":["Git"],"title":"Git Review","uri":"/gitreview/#git-别名"},{"categories":["Note"],"content":"https://www.hacksplaining.com/lessons ","date":"2021-12-25","objectID":"/hackspaining/:0:0","series":[],"tags":["Security"],"title":"Hacking Defense Note","uri":"/hackspaining/#"},{"categories":["Note"],"content":"SQL Injection ","date":"2021-12-25","objectID":"/hackspaining/:1:0","series":[],"tags":["Security"],"title":"Hacking Defense Note","uri":"/hackspaining/#sql-injection"},{"categories":["Note"],"content":"Harm Extract sensitive information, like Social Security numbers, or credit card details. Enumerate the authentication details of users registered on a website, so these logins can be used in attacks on other sites. Delete data or drop tables, corrupting the database, and making the website unusable. Inject further malicious code to be executed when users visit the site. Parameterized Statements Make sure that the parameters passed into SQL statements are treated in a safe manner. Object Relational Mapping ORM makes the translation of SQL result sets into code objects more seamless. Using an ORM does not automatically make you immune to SQL injection, however. As a general rule of thumb: if you find yourself writing SQL statements by concatenating strings, think very carefully about what you are doing. Escaping Inputs Programming languages have standard ways to describe strings containing quotes within them – SQL is no different in this respect. Typically, doubling up the quote character – replacing ' with '' – means “treat this quote as part of the string, not the end of the string”. Sanitizing Inputs Client-side validation (i.e. in JavaScript) is useful for giving the user immediate feedback when filling out a form, but is no defense against a serious hacker. Most hack attempts are performed using scripts, rather than the browser itself. ","date":"2021-12-25","objectID":"/hackspaining/:1:1","series":[],"tags":["Security"],"title":"Hacking Defense Note","uri":"/hackspaining/#harm"},{"categories":["Note"],"content":"Harm Extract sensitive information, like Social Security numbers, or credit card details. Enumerate the authentication details of users registered on a website, so these logins can be used in attacks on other sites. Delete data or drop tables, corrupting the database, and making the website unusable. Inject further malicious code to be executed when users visit the site. Parameterized Statements Make sure that the parameters passed into SQL statements are treated in a safe manner. Object Relational Mapping ORM makes the translation of SQL result sets into code objects more seamless. Using an ORM does not automatically make you immune to SQL injection, however. As a general rule of thumb: if you find yourself writing SQL statements by concatenating strings, think very carefully about what you are doing. Escaping Inputs Programming languages have standard ways to describe strings containing quotes within them – SQL is no different in this respect. Typically, doubling up the quote character – replacing ' with '' – means “treat this quote as part of the string, not the end of the string”. Sanitizing Inputs Client-side validation (i.e. in JavaScript) is useful for giving the user immediate feedback when filling out a form, but is no defense against a serious hacker. Most hack attempts are performed using scripts, rather than the browser itself. ","date":"2021-12-25","objectID":"/hackspaining/:1:1","series":[],"tags":["Security"],"title":"Hacking Defense Note","uri":"/hackspaining/#parameterized-statements"},{"categories":["Note"],"content":"Harm Extract sensitive information, like Social Security numbers, or credit card details. Enumerate the authentication details of users registered on a website, so these logins can be used in attacks on other sites. Delete data or drop tables, corrupting the database, and making the website unusable. Inject further malicious code to be executed when users visit the site. Parameterized Statements Make sure that the parameters passed into SQL statements are treated in a safe manner. Object Relational Mapping ORM makes the translation of SQL result sets into code objects more seamless. Using an ORM does not automatically make you immune to SQL injection, however. As a general rule of thumb: if you find yourself writing SQL statements by concatenating strings, think very carefully about what you are doing. Escaping Inputs Programming languages have standard ways to describe strings containing quotes within them – SQL is no different in this respect. Typically, doubling up the quote character – replacing ' with '' – means “treat this quote as part of the string, not the end of the string”. Sanitizing Inputs Client-side validation (i.e. in JavaScript) is useful for giving the user immediate feedback when filling out a form, but is no defense against a serious hacker. Most hack attempts are performed using scripts, rather than the browser itself. ","date":"2021-12-25","objectID":"/hackspaining/:1:1","series":[],"tags":["Security"],"title":"Hacking Defense Note","uri":"/hackspaining/#object-relational-mapping"},{"categories":["Note"],"content":"Harm Extract sensitive information, like Social Security numbers, or credit card details. Enumerate the authentication details of users registered on a website, so these logins can be used in attacks on other sites. Delete data or drop tables, corrupting the database, and making the website unusable. Inject further malicious code to be executed when users visit the site. Parameterized Statements Make sure that the parameters passed into SQL statements are treated in a safe manner. Object Relational Mapping ORM makes the translation of SQL result sets into code objects more seamless. Using an ORM does not automatically make you immune to SQL injection, however. As a general rule of thumb: if you find yourself writing SQL statements by concatenating strings, think very carefully about what you are doing. Escaping Inputs Programming languages have standard ways to describe strings containing quotes within them – SQL is no different in this respect. Typically, doubling up the quote character – replacing ' with '' – means “treat this quote as part of the string, not the end of the string”. Sanitizing Inputs Client-side validation (i.e. in JavaScript) is useful for giving the user immediate feedback when filling out a form, but is no defense against a serious hacker. Most hack attempts are performed using scripts, rather than the browser itself. ","date":"2021-12-25","objectID":"/hackspaining/:1:1","series":[],"tags":["Security"],"title":"Hacking Defense Note","uri":"/hackspaining/#escaping-inputs"},{"categories":["Note"],"content":"Harm Extract sensitive information, like Social Security numbers, or credit card details. Enumerate the authentication details of users registered on a website, so these logins can be used in attacks on other sites. Delete data or drop tables, corrupting the database, and making the website unusable. Inject further malicious code to be executed when users visit the site. Parameterized Statements Make sure that the parameters passed into SQL statements are treated in a safe manner. Object Relational Mapping ORM makes the translation of SQL result sets into code objects more seamless. Using an ORM does not automatically make you immune to SQL injection, however. As a general rule of thumb: if you find yourself writing SQL statements by concatenating strings, think very carefully about what you are doing. Escaping Inputs Programming languages have standard ways to describe strings containing quotes within them – SQL is no different in this respect. Typically, doubling up the quote character – replacing ' with '' – means “treat this quote as part of the string, not the end of the string”. Sanitizing Inputs Client-side validation (i.e. in JavaScript) is useful for giving the user immediate feedback when filling out a form, but is no defense against a serious hacker. Most hack attempts are performed using scripts, rather than the browser itself. ","date":"2021-12-25","objectID":"/hackspaining/:1:1","series":[],"tags":["Security"],"title":"Hacking Defense Note","uri":"/hackspaining/#sanitizing-inputs"},{"categories":["Note"],"content":"Cross-Site Scripting (XSS) Spreading worms on social media sites. Facebook, Twitter and YouTube have all been successfully attacked in this way. Session hijacking. Malicious JavaScript may be able to send the session ID to a remote site under the hacker’s control, allowing the hacker to impersonate that user by hijacking a session in progress. Identity theft. If the user enters confidential information such as credit card numbers into a compromised website, these details can be stolen using malicious JavaScript. Denial of service attacks and website vandalism. Theft of sensitive data, like passwords. Financial fraud on banking sites. Escape Dynamic Content you should escape all dynamic content coming from a data store, so the browser knows it is to be treated as the contents of HTML tags, as opposed to raw HTML. Escaping dynamic content generally consists of replacing significant characters with the HTML entity encoding: \" \u0026#34 # \u0026#35 \u0026 \u0026#38 ' \u0026#39 ( \u0026#40 ) \u0026#41 / \u0026#47 ; \u0026#59 \u003c \u0026#60 \u003e \u0026#62 Whitelist Values instead of asking a user to type in their country of residence, have them select from a drop-down list. Implement a Content-Security Policy allow the author of a web-page to control where JavaScript (and other resources) can be loaded and executed from. The content security policy can also be set in a tag in the element of the page: \u003cmeta http-equiv=\"Content-Security-Policy\" content=\"script-src 'self' https://apis.google.com\"\u003e This approach will protect your users very effectively! Sanitize HTML Some sites have a legitimate need to store and render raw HTML, especially now that contentEditable has become part of the HTML5 standard. If your site stores and renders rich content, you need to use a HTML sanitization library to ensure malicious users cannot inject scripts in their HTML submissions. ","date":"2021-12-25","objectID":"/hackspaining/:2:0","series":[],"tags":["Security"],"title":"Hacking Defense Note","uri":"/hackspaining/#cross-site-scripting-xss"},{"categories":["Note"],"content":"Cross-Site Scripting (XSS) Spreading worms on social media sites. Facebook, Twitter and YouTube have all been successfully attacked in this way. Session hijacking. Malicious JavaScript may be able to send the session ID to a remote site under the hacker’s control, allowing the hacker to impersonate that user by hijacking a session in progress. Identity theft. If the user enters confidential information such as credit card numbers into a compromised website, these details can be stolen using malicious JavaScript. Denial of service attacks and website vandalism. Theft of sensitive data, like passwords. Financial fraud on banking sites. Escape Dynamic Content you should escape all dynamic content coming from a data store, so the browser knows it is to be treated as the contents of HTML tags, as opposed to raw HTML. Escaping dynamic content generally consists of replacing significant characters with the HTML entity encoding: \" \" # # \u0026 \u0026 ' ' ( ( ) ) / / ; ; \u003e Whitelist Values instead of asking a user to type in their country of residence, have them select from a drop-down list. Implement a Content-Security Policy allow the author of a web-page to control where JavaScript (and other resources) can be loaded and executed from. The content security policy can also be set in a tag in the element of the page: This approach will protect your users very effectively! Sanitize HTML Some sites have a legitimate need to store and render raw HTML, especially now that contentEditable has become part of the HTML5 standard. If your site stores and renders rich content, you need to use a HTML sanitization library to ensure malicious users cannot inject scripts in their HTML submissions. ","date":"2021-12-25","objectID":"/hackspaining/:2:0","series":[],"tags":["Security"],"title":"Hacking Defense Note","uri":"/hackspaining/#escape-dynamic-content"},{"categories":["Note"],"content":"Cross-Site Scripting (XSS) Spreading worms on social media sites. Facebook, Twitter and YouTube have all been successfully attacked in this way. Session hijacking. Malicious JavaScript may be able to send the session ID to a remote site under the hacker’s control, allowing the hacker to impersonate that user by hijacking a session in progress. Identity theft. If the user enters confidential information such as credit card numbers into a compromised website, these details can be stolen using malicious JavaScript. Denial of service attacks and website vandalism. Theft of sensitive data, like passwords. Financial fraud on banking sites. Escape Dynamic Content you should escape all dynamic content coming from a data store, so the browser knows it is to be treated as the contents of HTML tags, as opposed to raw HTML. Escaping dynamic content generally consists of replacing significant characters with the HTML entity encoding: \" \" # # \u0026 \u0026 ' ' ( ( ) ) / / ; ; Whitelist Values instead of asking a user to type in their country of residence, have them select from a drop-down list. Implement a Content-Security Policy allow the author of a web-page to control where JavaScript (and other resources) can be loaded and executed from. The content security policy can also be set in a tag in the element of the page: This approach will protect your users very effectively! Sanitize HTML Some sites have a legitimate need to store and render raw HTML, especially now that contentEditable has become part of the HTML5 standard. If your site stores and renders rich content, you need to use a HTML sanitization library to ensure malicious users cannot inject scripts in their HTML submissions. ","date":"2021-12-25","objectID":"/hackspaining/:2:0","series":[],"tags":["Security"],"title":"Hacking Defense Note","uri":"/hackspaining/#whitelist-values"},{"categories":["Note"],"content":"Cross-Site Scripting (XSS) Spreading worms on social media sites. Facebook, Twitter and YouTube have all been successfully attacked in this way. Session hijacking. Malicious JavaScript may be able to send the session ID to a remote site under the hacker’s control, allowing the hacker to impersonate that user by hijacking a session in progress. Identity theft. If the user enters confidential information such as credit card numbers into a compromised website, these details can be stolen using malicious JavaScript. Denial of service attacks and website vandalism. Theft of sensitive data, like passwords. Financial fraud on banking sites. Escape Dynamic Content you should escape all dynamic content coming from a data store, so the browser knows it is to be treated as the contents of HTML tags, as opposed to raw HTML. Escaping dynamic content generally consists of replacing significant characters with the HTML entity encoding: \" \" # # \u0026 \u0026 ' ' ( ( ) ) / / ; ; Whitelist Values instead of asking a user to type in their country of residence, have them select from a drop-down list. Implement a Content-Security Policy allow the author of a web-page to control where JavaScript (and other resources) can be loaded and executed from. The content security policy can also be set in a tag in the element of the page: This approach will protect your users very effectively! Sanitize HTML Some sites have a legitimate need to store and render raw HTML, especially now that contentEditable has become part of the HTML5 standard. If your site stores and renders rich content, you need to use a HTML sanitization library to ensure malicious users cannot inject scripts in their HTML submissions. ","date":"2021-12-25","objectID":"/hackspaining/:2:0","series":[],"tags":["Security"],"title":"Hacking Defense Note","uri":"/hackspaining/#implement-a-content-security-policy"},{"categories":["Note"],"content":"Cross-Site Scripting (XSS) Spreading worms on social media sites. Facebook, Twitter and YouTube have all been successfully attacked in this way. Session hijacking. Malicious JavaScript may be able to send the session ID to a remote site under the hacker’s control, allowing the hacker to impersonate that user by hijacking a session in progress. Identity theft. If the user enters confidential information such as credit card numbers into a compromised website, these details can be stolen using malicious JavaScript. Denial of service attacks and website vandalism. Theft of sensitive data, like passwords. Financial fraud on banking sites. Escape Dynamic Content you should escape all dynamic content coming from a data store, so the browser knows it is to be treated as the contents of HTML tags, as opposed to raw HTML. Escaping dynamic content generally consists of replacing significant characters with the HTML entity encoding: \" \" # # \u0026 \u0026 ' ' ( ( ) ) / / ; ; Whitelist Values instead of asking a user to type in their country of residence, have them select from a drop-down list. Implement a Content-Security Policy allow the author of a web-page to control where JavaScript (and other resources) can be loaded and executed from. The content security policy can also be set in a tag in the element of the page: This approach will protect your users very effectively! Sanitize HTML Some sites have a legitimate need to store and render raw HTML, especially now that contentEditable has become part of the HTML5 standard. If your site stores and renders rich content, you need to use a HTML sanitization library to ensure malicious users cannot inject scripts in their HTML submissions. ","date":"2021-12-25","objectID":"/hackspaining/:2:0","series":[],"tags":["Security"],"title":"Hacking Defense Note","uri":"/hackspaining/#sanitize-html"},{"categories":["Note"],"content":"Command Execution Remote code execution is a major security lapse, and the last step along the road to complete system takeover. After gaining access, an attacker will attempt to escalate their privileges on the server, install malicious scripts, or make your server part of a botnet to be used at a later date. Command injection vulnerabilities often occur in older, legacy code, such as CGI scripts. Try to Avoid Command Line Calls Altogether Use APIs wherever possible – only use shell commands where absolutely necessary. Escape Inputs Correctly Injection vulnerabilities occur when untrusted input is not sanitized correctly. If you use shell commands, be sure to scrub input values for potentially malicious characters: ; \u0026 | ` Even better, restrict input by testing it against a regular expression of known safe characters. (For example, alphanumeric characters.) Restrict the Permitted Commands Perform Thorough Code Reviews Run with Restricted Permissions ","date":"2021-12-25","objectID":"/hackspaining/:3:0","series":[],"tags":["Security"],"title":"Hacking Defense Note","uri":"/hackspaining/#command-execution"},{"categories":["Note"],"content":"Command Execution Remote code execution is a major security lapse, and the last step along the road to complete system takeover. After gaining access, an attacker will attempt to escalate their privileges on the server, install malicious scripts, or make your server part of a botnet to be used at a later date. Command injection vulnerabilities often occur in older, legacy code, such as CGI scripts. Try to Avoid Command Line Calls Altogether Use APIs wherever possible – only use shell commands where absolutely necessary. Escape Inputs Correctly Injection vulnerabilities occur when untrusted input is not sanitized correctly. If you use shell commands, be sure to scrub input values for potentially malicious characters: ; \u0026 | ` Even better, restrict input by testing it against a regular expression of known safe characters. (For example, alphanumeric characters.) Restrict the Permitted Commands Perform Thorough Code Reviews Run with Restricted Permissions ","date":"2021-12-25","objectID":"/hackspaining/:3:0","series":[],"tags":["Security"],"title":"Hacking Defense Note","uri":"/hackspaining/#try-to-avoid-command-line-calls-altogether"},{"categories":["Note"],"content":"Command Execution Remote code execution is a major security lapse, and the last step along the road to complete system takeover. After gaining access, an attacker will attempt to escalate their privileges on the server, install malicious scripts, or make your server part of a botnet to be used at a later date. Command injection vulnerabilities often occur in older, legacy code, such as CGI scripts. Try to Avoid Command Line Calls Altogether Use APIs wherever possible – only use shell commands where absolutely necessary. Escape Inputs Correctly Injection vulnerabilities occur when untrusted input is not sanitized correctly. If you use shell commands, be sure to scrub input values for potentially malicious characters: ; \u0026 | ` Even better, restrict input by testing it against a regular expression of known safe characters. (For example, alphanumeric characters.) Restrict the Permitted Commands Perform Thorough Code Reviews Run with Restricted Permissions ","date":"2021-12-25","objectID":"/hackspaining/:3:0","series":[],"tags":["Security"],"title":"Hacking Defense Note","uri":"/hackspaining/#escape-inputs-correctly"},{"categories":["Note"],"content":"Command Execution Remote code execution is a major security lapse, and the last step along the road to complete system takeover. After gaining access, an attacker will attempt to escalate their privileges on the server, install malicious scripts, or make your server part of a botnet to be used at a later date. Command injection vulnerabilities often occur in older, legacy code, such as CGI scripts. Try to Avoid Command Line Calls Altogether Use APIs wherever possible – only use shell commands where absolutely necessary. Escape Inputs Correctly Injection vulnerabilities occur when untrusted input is not sanitized correctly. If you use shell commands, be sure to scrub input values for potentially malicious characters: ; \u0026 | ` Even better, restrict input by testing it against a regular expression of known safe characters. (For example, alphanumeric characters.) Restrict the Permitted Commands Perform Thorough Code Reviews Run with Restricted Permissions ","date":"2021-12-25","objectID":"/hackspaining/:3:0","series":[],"tags":["Security"],"title":"Hacking Defense Note","uri":"/hackspaining/#restrict-the-permitted-commands"},{"categories":["Note"],"content":"Command Execution Remote code execution is a major security lapse, and the last step along the road to complete system takeover. After gaining access, an attacker will attempt to escalate their privileges on the server, install malicious scripts, or make your server part of a botnet to be used at a later date. Command injection vulnerabilities often occur in older, legacy code, such as CGI scripts. Try to Avoid Command Line Calls Altogether Use APIs wherever possible – only use shell commands where absolutely necessary. Escape Inputs Correctly Injection vulnerabilities occur when untrusted input is not sanitized correctly. If you use shell commands, be sure to scrub input values for potentially malicious characters: ; \u0026 | ` Even better, restrict input by testing it against a regular expression of known safe characters. (For example, alphanumeric characters.) Restrict the Permitted Commands Perform Thorough Code Reviews Run with Restricted Permissions ","date":"2021-12-25","objectID":"/hackspaining/:3:0","series":[],"tags":["Security"],"title":"Hacking Defense Note","uri":"/hackspaining/#perform-thorough-code-reviews"},{"categories":["Note"],"content":"Command Execution Remote code execution is a major security lapse, and the last step along the road to complete system takeover. After gaining access, an attacker will attempt to escalate their privileges on the server, install malicious scripts, or make your server part of a botnet to be used at a later date. Command injection vulnerabilities often occur in older, legacy code, such as CGI scripts. Try to Avoid Command Line Calls Altogether Use APIs wherever possible – only use shell commands where absolutely necessary. Escape Inputs Correctly Injection vulnerabilities occur when untrusted input is not sanitized correctly. If you use shell commands, be sure to scrub input values for potentially malicious characters: ; \u0026 | ` Even better, restrict input by testing it against a regular expression of known safe characters. (For example, alphanumeric characters.) Restrict the Permitted Commands Perform Thorough Code Reviews Run with Restricted Permissions ","date":"2021-12-25","objectID":"/hackspaining/:3:0","series":[],"tags":["Security"],"title":"Hacking Defense Note","uri":"/hackspaining/#run-with-restricted-permissions"},{"categories":["Note"],"content":"Clickjacking Harvest login credentials, by rendering a fake login box on top of the real one. Trick users into turning on their web-cam or microphone, by rendering invisible elements over the Adobe Flash settings page. Spread worms on social media sites like Twitter and MySpace. Promote online scams by tricking people into clicking on things they otherwise would not. Spread malware by diverting users to malicious download links. X-Frame-Options The X-Frame-Options HTTP header can be used to indicate whether or not a browser should be allowed to render a page in a \u003cframe\u003e, \u003ciframe\u003e or \u003cobject\u003e tag. It was designed specifically to help protect against clickjacking. There are three permitted values for the header: DENY The page cannot be displayed in a frame, regardless of the site attempting to do so. SAMEORIGIN The page can only be displayed in a frame on the same origin as the page itself. ALLOW-FROM uri The page can only be displayed in a frame on the specified origins. Content Security Policy Frame-Killing In older browsers, the most common way to protect users against clickjacking was to include a frame-killing JavaScript snippet in pages to prevent them being included in foreign iframes. Frame-killing offers a large degree of protection against clickjacking, but it can be error-prone. Be sure to set appropriate HTTP headers as the first recourse in protecting your site. ","date":"2021-12-25","objectID":"/hackspaining/:4:0","series":[],"tags":["Security"],"title":"Hacking Defense Note","uri":"/hackspaining/#clickjacking"},{"categories":["Note"],"content":"Clickjacking Harvest login credentials, by rendering a fake login box on top of the real one. Trick users into turning on their web-cam or microphone, by rendering invisible elements over the Adobe Flash settings page. Spread worms on social media sites like Twitter and MySpace. Promote online scams by tricking people into clicking on things they otherwise would not. Spread malware by diverting users to malicious download links. X-Frame-Options The X-Frame-Options HTTP header can be used to indicate whether or not a browser should be allowed to render a page in a , or tag. It was designed specifically to help protect against clickjacking. There are three permitted values for the header: DENY The page cannot be displayed in a frame, regardless of the site attempting to do so. SAMEORIGIN The page can only be displayed in a frame on the same origin as the page itself. ALLOW-FROM uri The page can only be displayed in a frame on the specified origins. Content Security Policy Frame-Killing In older browsers, the most common way to protect users against clickjacking was to include a frame-killing JavaScript snippet in pages to prevent them being included in foreign iframes. Frame-killing offers a large degree of protection against clickjacking, but it can be error-prone. Be sure to set appropriate HTTP headers as the first recourse in protecting your site. ","date":"2021-12-25","objectID":"/hackspaining/:4:0","series":[],"tags":["Security"],"title":"Hacking Defense Note","uri":"/hackspaining/#x-frame-options"},{"categories":["Note"],"content":"Clickjacking Harvest login credentials, by rendering a fake login box on top of the real one. Trick users into turning on their web-cam or microphone, by rendering invisible elements over the Adobe Flash settings page. Spread worms on social media sites like Twitter and MySpace. Promote online scams by tricking people into clicking on things they otherwise would not. Spread malware by diverting users to malicious download links. X-Frame-Options The X-Frame-Options HTTP header can be used to indicate whether or not a browser should be allowed to render a page in a , or tag. It was designed specifically to help protect against clickjacking. There are three permitted values for the header: DENY The page cannot be displayed in a frame, regardless of the site attempting to do so. SAMEORIGIN The page can only be displayed in a frame on the same origin as the page itself. ALLOW-FROM uri The page can only be displayed in a frame on the specified origins. Content Security Policy Frame-Killing In older browsers, the most common way to protect users against clickjacking was to include a frame-killing JavaScript snippet in pages to prevent them being included in foreign iframes. Frame-killing offers a large degree of protection against clickjacking, but it can be error-prone. Be sure to set appropriate HTTP headers as the first recourse in protecting your site. ","date":"2021-12-25","objectID":"/hackspaining/:4:0","series":[],"tags":["Security"],"title":"Hacking Defense Note","uri":"/hackspaining/#content-security-policy"},{"categories":["Note"],"content":"Clickjacking Harvest login credentials, by rendering a fake login box on top of the real one. Trick users into turning on their web-cam or microphone, by rendering invisible elements over the Adobe Flash settings page. Spread worms on social media sites like Twitter and MySpace. Promote online scams by tricking people into clicking on things they otherwise would not. Spread malware by diverting users to malicious download links. X-Frame-Options The X-Frame-Options HTTP header can be used to indicate whether or not a browser should be allowed to render a page in a , or tag. It was designed specifically to help protect against clickjacking. There are three permitted values for the header: DENY The page cannot be displayed in a frame, regardless of the site attempting to do so. SAMEORIGIN The page can only be displayed in a frame on the same origin as the page itself. ALLOW-FROM uri The page can only be displayed in a frame on the specified origins. Content Security Policy Frame-Killing In older browsers, the most common way to protect users against clickjacking was to include a frame-killing JavaScript snippet in pages to prevent them being included in foreign iframes. Frame-killing offers a large degree of protection against clickjacking, but it can be error-prone. Be sure to set appropriate HTTP headers as the first recourse in protecting your site. ","date":"2021-12-25","objectID":"/hackspaining/:4:0","series":[],"tags":["Security"],"title":"Hacking Defense Note","uri":"/hackspaining/#frame-killing"},{"categories":["Note"],"content":"Cross-Site Request Forgery (CSRF) Steal confidential data. Spread worms on social media. Install malware on mobile phones. REST Representation State Transfer (REST) is a series of design principles that assign certain types of action (view, create, delete, update) to different HTTP verbs. Following REST-ful designs will keep your code clean and help your site scale. Moreover, REST insists that GET requests are used only to view resources. Keeping your GET requests side-effect free will limit the harm that can be done by maliciously crafted URLs–an attacker will have to work much harder to generate harmful POST requests. Anti-Forgery Tokens This is called an anti-forgery token. Each time your server renders a page that performs sensitive actions, it should write out an anti-forgery token in a hidden HTML form field. This token must be included with form submissions, or AJAX calls. The server should validate the token when it is returned in subsequent requests, and reject any calls with missing or invalid tokens. Ensure Cookies are sent with the SameSite Cookie Attribute A value of Strict will mean than any request initiated by a third-party domain to your domain will have any cookies stripped by the browser. This is the most secure setting, since it prevents malicious sites attempting to perform harmful actions under a user’s session. A value of Lax permits GET request from a third-party domain to your domain to have cookies attached - but only GET requests. With this setting a user will not have to sign in again to your site if the follow a link from another site (say, Google search results). This makes for a friendlier user-experience - but make sure your GET requests are side-effect free! Include Addition Authentication for Sensitive Actions ","date":"2021-12-25","objectID":"/hackspaining/:5:0","series":[],"tags":["Security"],"title":"Hacking Defense Note","uri":"/hackspaining/#cross-site-request-forgery-csrf"},{"categories":["Note"],"content":"Cross-Site Request Forgery (CSRF) Steal confidential data. Spread worms on social media. Install malware on mobile phones. REST Representation State Transfer (REST) is a series of design principles that assign certain types of action (view, create, delete, update) to different HTTP verbs. Following REST-ful designs will keep your code clean and help your site scale. Moreover, REST insists that GET requests are used only to view resources. Keeping your GET requests side-effect free will limit the harm that can be done by maliciously crafted URLs–an attacker will have to work much harder to generate harmful POST requests. Anti-Forgery Tokens This is called an anti-forgery token. Each time your server renders a page that performs sensitive actions, it should write out an anti-forgery token in a hidden HTML form field. This token must be included with form submissions, or AJAX calls. The server should validate the token when it is returned in subsequent requests, and reject any calls with missing or invalid tokens. Ensure Cookies are sent with the SameSite Cookie Attribute A value of Strict will mean than any request initiated by a third-party domain to your domain will have any cookies stripped by the browser. This is the most secure setting, since it prevents malicious sites attempting to perform harmful actions under a user’s session. A value of Lax permits GET request from a third-party domain to your domain to have cookies attached - but only GET requests. With this setting a user will not have to sign in again to your site if the follow a link from another site (say, Google search results). This makes for a friendlier user-experience - but make sure your GET requests are side-effect free! Include Addition Authentication for Sensitive Actions ","date":"2021-12-25","objectID":"/hackspaining/:5:0","series":[],"tags":["Security"],"title":"Hacking Defense Note","uri":"/hackspaining/#rest"},{"categories":["Note"],"content":"Cross-Site Request Forgery (CSRF) Steal confidential data. Spread worms on social media. Install malware on mobile phones. REST Representation State Transfer (REST) is a series of design principles that assign certain types of action (view, create, delete, update) to different HTTP verbs. Following REST-ful designs will keep your code clean and help your site scale. Moreover, REST insists that GET requests are used only to view resources. Keeping your GET requests side-effect free will limit the harm that can be done by maliciously crafted URLs–an attacker will have to work much harder to generate harmful POST requests. Anti-Forgery Tokens This is called an anti-forgery token. Each time your server renders a page that performs sensitive actions, it should write out an anti-forgery token in a hidden HTML form field. This token must be included with form submissions, or AJAX calls. The server should validate the token when it is returned in subsequent requests, and reject any calls with missing or invalid tokens. Ensure Cookies are sent with the SameSite Cookie Attribute A value of Strict will mean than any request initiated by a third-party domain to your domain will have any cookies stripped by the browser. This is the most secure setting, since it prevents malicious sites attempting to perform harmful actions under a user’s session. A value of Lax permits GET request from a third-party domain to your domain to have cookies attached - but only GET requests. With this setting a user will not have to sign in again to your site if the follow a link from another site (say, Google search results). This makes for a friendlier user-experience - but make sure your GET requests are side-effect free! Include Addition Authentication for Sensitive Actions ","date":"2021-12-25","objectID":"/hackspaining/:5:0","series":[],"tags":["Security"],"title":"Hacking Defense Note","uri":"/hackspaining/#anti-forgery-tokens"},{"categories":["Note"],"content":"Cross-Site Request Forgery (CSRF) Steal confidential data. Spread worms on social media. Install malware on mobile phones. REST Representation State Transfer (REST) is a series of design principles that assign certain types of action (view, create, delete, update) to different HTTP verbs. Following REST-ful designs will keep your code clean and help your site scale. Moreover, REST insists that GET requests are used only to view resources. Keeping your GET requests side-effect free will limit the harm that can be done by maliciously crafted URLs–an attacker will have to work much harder to generate harmful POST requests. Anti-Forgery Tokens This is called an anti-forgery token. Each time your server renders a page that performs sensitive actions, it should write out an anti-forgery token in a hidden HTML form field. This token must be included with form submissions, or AJAX calls. The server should validate the token when it is returned in subsequent requests, and reject any calls with missing or invalid tokens. Ensure Cookies are sent with the SameSite Cookie Attribute A value of Strict will mean than any request initiated by a third-party domain to your domain will have any cookies stripped by the browser. This is the most secure setting, since it prevents malicious sites attempting to perform harmful actions under a user’s session. A value of Lax permits GET request from a third-party domain to your domain to have cookies attached - but only GET requests. With this setting a user will not have to sign in again to your site if the follow a link from another site (say, Google search results). This makes for a friendlier user-experience - but make sure your GET requests are side-effect free! Include Addition Authentication for Sensitive Actions ","date":"2021-12-25","objectID":"/hackspaining/:5:0","series":[],"tags":["Security"],"title":"Hacking Defense Note","uri":"/hackspaining/#ensure-cookies-are-sent-with-the-samesite-cookie-attribute"},{"categories":["Note"],"content":"Cross-Site Request Forgery (CSRF) Steal confidential data. Spread worms on social media. Install malware on mobile phones. REST Representation State Transfer (REST) is a series of design principles that assign certain types of action (view, create, delete, update) to different HTTP verbs. Following REST-ful designs will keep your code clean and help your site scale. Moreover, REST insists that GET requests are used only to view resources. Keeping your GET requests side-effect free will limit the harm that can be done by maliciously crafted URLs–an attacker will have to work much harder to generate harmful POST requests. Anti-Forgery Tokens This is called an anti-forgery token. Each time your server renders a page that performs sensitive actions, it should write out an anti-forgery token in a hidden HTML form field. This token must be included with form submissions, or AJAX calls. The server should validate the token when it is returned in subsequent requests, and reject any calls with missing or invalid tokens. Ensure Cookies are sent with the SameSite Cookie Attribute A value of Strict will mean than any request initiated by a third-party domain to your domain will have any cookies stripped by the browser. This is the most secure setting, since it prevents malicious sites attempting to perform harmful actions under a user’s session. A value of Lax permits GET request from a third-party domain to your domain to have cookies attached - but only GET requests. With this setting a user will not have to sign in again to your site if the follow a link from another site (say, Google search results). This makes for a friendlier user-experience - but make sure your GET requests are side-effect free! Include Addition Authentication for Sensitive Actions ","date":"2021-12-25","objectID":"/hackspaining/:5:0","series":[],"tags":["Security"],"title":"Hacking Defense Note","uri":"/hackspaining/#include-addition-authentication-for-sensitive-actions"},{"categories":["Note"],"content":"Reflected XSS Search results - does the search criteria get displayed back to the user? Is it written out in the page title? Are you sure it is being escaped properly? Error pages - if you have error messages that complain about invalid inputs, does the input get escaped properly when it is displayed back to the user? Does your 404 page mention the path being searched for? Form submissions - if a page POSTs data, does any part of the data being submitted by the form get displayed back to the user? What if the form submission is rejected – does the error page allow injection of malicious code? Does an erroneously submitted form get pre-populated with the values previously submitted? Escape Dynamic Content Whitelist Values Implement a Content-Security Policy ","date":"2021-12-25","objectID":"/hackspaining/:6:0","series":[],"tags":["Security"],"title":"Hacking Defense Note","uri":"/hackspaining/#reflected-xss"},{"categories":["Note"],"content":"Reflected XSS Search results - does the search criteria get displayed back to the user? Is it written out in the page title? Are you sure it is being escaped properly? Error pages - if you have error messages that complain about invalid inputs, does the input get escaped properly when it is displayed back to the user? Does your 404 page mention the path being searched for? Form submissions - if a page POSTs data, does any part of the data being submitted by the form get displayed back to the user? What if the form submission is rejected – does the error page allow injection of malicious code? Does an erroneously submitted form get pre-populated with the values previously submitted? Escape Dynamic Content Whitelist Values Implement a Content-Security Policy ","date":"2021-12-25","objectID":"/hackspaining/:6:0","series":[],"tags":["Security"],"title":"Hacking Defense Note","uri":"/hackspaining/#escape-dynamic-content-1"},{"categories":["Note"],"content":"Reflected XSS Search results - does the search criteria get displayed back to the user? Is it written out in the page title? Are you sure it is being escaped properly? Error pages - if you have error messages that complain about invalid inputs, does the input get escaped properly when it is displayed back to the user? Does your 404 page mention the path being searched for? Form submissions - if a page POSTs data, does any part of the data being submitted by the form get displayed back to the user? What if the form submission is rejected – does the error page allow injection of malicious code? Does an erroneously submitted form get pre-populated with the values previously submitted? Escape Dynamic Content Whitelist Values Implement a Content-Security Policy ","date":"2021-12-25","objectID":"/hackspaining/:6:0","series":[],"tags":["Security"],"title":"Hacking Defense Note","uri":"/hackspaining/#whitelist-values-1"},{"categories":["Note"],"content":"Reflected XSS Search results - does the search criteria get displayed back to the user? Is it written out in the page title? Are you sure it is being escaped properly? Error pages - if you have error messages that complain about invalid inputs, does the input get escaped properly when it is displayed back to the user? Does your 404 page mention the path being searched for? Form submissions - if a page POSTs data, does any part of the data being submitted by the form get displayed back to the user? What if the form submission is rejected – does the error page allow injection of malicious code? Does an erroneously submitted form get pre-populated with the values previously submitted? Escape Dynamic Content Whitelist Values Implement a Content-Security Policy ","date":"2021-12-25","objectID":"/hackspaining/:6:0","series":[],"tags":["Security"],"title":"Hacking Defense Note","uri":"/hackspaining/#implement-a-content-security-policy-1"},{"categories":["Note"],"content":"File Upload Vulnerabilities Sophisticated hackers typically exploit a combination of vulnerabilities when attacking your site – uploading malicious code to a server is step one in the hacker playbook. The next step is finding a way to execute the malicious code. Even big companies fall foul to this vulnerability, particularly if they are running complex, legacy code bases. Segregate Your Uploads File uploads are generally intended to be inert. Unless you are building a very particular type of website, you are typically expecting images, videos, or document files, rather than executable code. If this is the case, making sure uploaded files are kept separate from application code is a key security consideration. Consider using cloud-based storage or a content management system to store uploaded files. Alternatively, if you are sure of your ability to scale your backend, you could write uploaded files to your database. Both of these approaches prevent accidental execution of an executable file. Ensure Upload Files Cannot Be Executed Rename Files on Upload Validate File Formats and Extensions Validate the Content-Type Header Use a Virus Scanner ","date":"2021-12-25","objectID":"/hackspaining/:7:0","series":[],"tags":["Security"],"title":"Hacking Defense Note","uri":"/hackspaining/#file-upload-vulnerabilities"},{"categories":["Note"],"content":"File Upload Vulnerabilities Sophisticated hackers typically exploit a combination of vulnerabilities when attacking your site – uploading malicious code to a server is step one in the hacker playbook. The next step is finding a way to execute the malicious code. Even big companies fall foul to this vulnerability, particularly if they are running complex, legacy code bases. Segregate Your Uploads File uploads are generally intended to be inert. Unless you are building a very particular type of website, you are typically expecting images, videos, or document files, rather than executable code. If this is the case, making sure uploaded files are kept separate from application code is a key security consideration. Consider using cloud-based storage or a content management system to store uploaded files. Alternatively, if you are sure of your ability to scale your backend, you could write uploaded files to your database. Both of these approaches prevent accidental execution of an executable file. Ensure Upload Files Cannot Be Executed Rename Files on Upload Validate File Formats and Extensions Validate the Content-Type Header Use a Virus Scanner ","date":"2021-12-25","objectID":"/hackspaining/:7:0","series":[],"tags":["Security"],"title":"Hacking Defense Note","uri":"/hackspaining/#segregate-your-uploads"},{"categories":["Note"],"content":"File Upload Vulnerabilities Sophisticated hackers typically exploit a combination of vulnerabilities when attacking your site – uploading malicious code to a server is step one in the hacker playbook. The next step is finding a way to execute the malicious code. Even big companies fall foul to this vulnerability, particularly if they are running complex, legacy code bases. Segregate Your Uploads File uploads are generally intended to be inert. Unless you are building a very particular type of website, you are typically expecting images, videos, or document files, rather than executable code. If this is the case, making sure uploaded files are kept separate from application code is a key security consideration. Consider using cloud-based storage or a content management system to store uploaded files. Alternatively, if you are sure of your ability to scale your backend, you could write uploaded files to your database. Both of these approaches prevent accidental execution of an executable file. Ensure Upload Files Cannot Be Executed Rename Files on Upload Validate File Formats and Extensions Validate the Content-Type Header Use a Virus Scanner ","date":"2021-12-25","objectID":"/hackspaining/:7:0","series":[],"tags":["Security"],"title":"Hacking Defense Note","uri":"/hackspaining/#ensure-upload-files-cannot-be-executed"},{"categories":["Note"],"content":"File Upload Vulnerabilities Sophisticated hackers typically exploit a combination of vulnerabilities when attacking your site – uploading malicious code to a server is step one in the hacker playbook. The next step is finding a way to execute the malicious code. Even big companies fall foul to this vulnerability, particularly if they are running complex, legacy code bases. Segregate Your Uploads File uploads are generally intended to be inert. Unless you are building a very particular type of website, you are typically expecting images, videos, or document files, rather than executable code. If this is the case, making sure uploaded files are kept separate from application code is a key security consideration. Consider using cloud-based storage or a content management system to store uploaded files. Alternatively, if you are sure of your ability to scale your backend, you could write uploaded files to your database. Both of these approaches prevent accidental execution of an executable file. Ensure Upload Files Cannot Be Executed Rename Files on Upload Validate File Formats and Extensions Validate the Content-Type Header Use a Virus Scanner ","date":"2021-12-25","objectID":"/hackspaining/:7:0","series":[],"tags":["Security"],"title":"Hacking Defense Note","uri":"/hackspaining/#rename-files-on-upload"},{"categories":["Note"],"content":"File Upload Vulnerabilities Sophisticated hackers typically exploit a combination of vulnerabilities when attacking your site – uploading malicious code to a server is step one in the hacker playbook. The next step is finding a way to execute the malicious code. Even big companies fall foul to this vulnerability, particularly if they are running complex, legacy code bases. Segregate Your Uploads File uploads are generally intended to be inert. Unless you are building a very particular type of website, you are typically expecting images, videos, or document files, rather than executable code. If this is the case, making sure uploaded files are kept separate from application code is a key security consideration. Consider using cloud-based storage or a content management system to store uploaded files. Alternatively, if you are sure of your ability to scale your backend, you could write uploaded files to your database. Both of these approaches prevent accidental execution of an executable file. Ensure Upload Files Cannot Be Executed Rename Files on Upload Validate File Formats and Extensions Validate the Content-Type Header Use a Virus Scanner ","date":"2021-12-25","objectID":"/hackspaining/:7:0","series":[],"tags":["Security"],"title":"Hacking Defense Note","uri":"/hackspaining/#validate-file-formats-and-extensions"},{"categories":["Note"],"content":"File Upload Vulnerabilities Sophisticated hackers typically exploit a combination of vulnerabilities when attacking your site – uploading malicious code to a server is step one in the hacker playbook. The next step is finding a way to execute the malicious code. Even big companies fall foul to this vulnerability, particularly if they are running complex, legacy code bases. Segregate Your Uploads File uploads are generally intended to be inert. Unless you are building a very particular type of website, you are typically expecting images, videos, or document files, rather than executable code. If this is the case, making sure uploaded files are kept separate from application code is a key security consideration. Consider using cloud-based storage or a content management system to store uploaded files. Alternatively, if you are sure of your ability to scale your backend, you could write uploaded files to your database. Both of these approaches prevent accidental execution of an executable file. Ensure Upload Files Cannot Be Executed Rename Files on Upload Validate File Formats and Extensions Validate the Content-Type Header Use a Virus Scanner ","date":"2021-12-25","objectID":"/hackspaining/:7:0","series":[],"tags":["Security"],"title":"Hacking Defense Note","uri":"/hackspaining/#validate-the-content-type-header"},{"categories":["Note"],"content":"File Upload Vulnerabilities Sophisticated hackers typically exploit a combination of vulnerabilities when attacking your site – uploading malicious code to a server is step one in the hacker playbook. The next step is finding a way to execute the malicious code. Even big companies fall foul to this vulnerability, particularly if they are running complex, legacy code bases. Segregate Your Uploads File uploads are generally intended to be inert. Unless you are building a very particular type of website, you are typically expecting images, videos, or document files, rather than executable code. If this is the case, making sure uploaded files are kept separate from application code is a key security consideration. Consider using cloud-based storage or a content management system to store uploaded files. Alternatively, if you are sure of your ability to scale your backend, you could write uploaded files to your database. Both of these approaches prevent accidental execution of an executable file. Ensure Upload Files Cannot Be Executed Rename Files on Upload Validate File Formats and Extensions Validate the Content-Type Header Use a Virus Scanner ","date":"2021-12-25","objectID":"/hackspaining/:7:0","series":[],"tags":["Security"],"title":"Hacking Defense Note","uri":"/hackspaining/#use-a-virus-scanner"},{"categories":["Note"],"content":"Open Redirects Redirects are a useful function to have when building a website. If a user attempts to access a resource before they are logged in, it is conventional to redirect them to the login page, put the original URL in a query parameter, and after they have logged in, automatically redirect them to their original destination. This type of functionality shows you are putting thought into the user experience, and is to be encouraged. However, you need to be sure anywhere you do redirects, they are done safely – otherwise you are putting your users in harm’s way by enabling phishing attacks. Disallow Offsite Redirects Make sure all redirect URLs are relative paths – i.e. they start with a single / character. (Note that URLs starting with // will be interpreted by the browser as a protocol agnostic, absolute URL – so they should be rejected too.) If you do need to perform external redirects, consider whitelisting the individual sites that you permit redirects to. Check the Referrer When Doing Redirects Redirects to URLs passed in query parameters should only be triggered by pages on your site. As a second layer of defense, check that the Referer in the HTTP request matches your domain whenever you perform a redirect. ","date":"2021-12-25","objectID":"/hackspaining/:8:0","series":[],"tags":["Security"],"title":"Hacking Defense Note","uri":"/hackspaining/#open-redirects"},{"categories":["Note"],"content":"Open Redirects Redirects are a useful function to have when building a website. If a user attempts to access a resource before they are logged in, it is conventional to redirect them to the login page, put the original URL in a query parameter, and after they have logged in, automatically redirect them to their original destination. This type of functionality shows you are putting thought into the user experience, and is to be encouraged. However, you need to be sure anywhere you do redirects, they are done safely – otherwise you are putting your users in harm’s way by enabling phishing attacks. Disallow Offsite Redirects Make sure all redirect URLs are relative paths – i.e. they start with a single / character. (Note that URLs starting with // will be interpreted by the browser as a protocol agnostic, absolute URL – so they should be rejected too.) If you do need to perform external redirects, consider whitelisting the individual sites that you permit redirects to. Check the Referrer When Doing Redirects Redirects to URLs passed in query parameters should only be triggered by pages on your site. As a second layer of defense, check that the Referer in the HTTP request matches your domain whenever you perform a redirect. ","date":"2021-12-25","objectID":"/hackspaining/:8:0","series":[],"tags":["Security"],"title":"Hacking Defense Note","uri":"/hackspaining/#disallow-offsite-redirects"},{"categories":["Note"],"content":"Open Redirects Redirects are a useful function to have when building a website. If a user attempts to access a resource before they are logged in, it is conventional to redirect them to the login page, put the original URL in a query parameter, and after they have logged in, automatically redirect them to their original destination. This type of functionality shows you are putting thought into the user experience, and is to be encouraged. However, you need to be sure anywhere you do redirects, they are done safely – otherwise you are putting your users in harm’s way by enabling phishing attacks. Disallow Offsite Redirects Make sure all redirect URLs are relative paths – i.e. they start with a single / character. (Note that URLs starting with // will be interpreted by the browser as a protocol agnostic, absolute URL – so they should be rejected too.) If you do need to perform external redirects, consider whitelisting the individual sites that you permit redirects to. Check the Referrer When Doing Redirects Redirects to URLs passed in query parameters should only be triggered by pages on your site. As a second layer of defense, check that the Referer in the HTTP request matches your domain whenever you perform a redirect. ","date":"2021-12-25","objectID":"/hackspaining/:8:0","series":[],"tags":["Security"],"title":"Hacking Defense Note","uri":"/hackspaining/#check-the-referrer-when-doing-redirects"},{"categories":["Note"],"content":"Unencrypted Communication Insecure Wi-Fi hotspots, as illustrated in our exercise, are just one way enterprising hackers have found to take advantage of unencrypted communication. They may also try to sniff traffic within your network, and if they get access, inspect traffic going through compromised edge devices. Buy a certificate, install it, and configure your web server to use it. It’s really as simple as that. Web servers are typically able to serve the same content over HTTP (on port 80) and HTTPS (on port 443). Any non-trivial website should use HTTPS. Facebook and Twitter use HTTPS by default, and this a good example to follow. But make sure you know how to force your web server to elevate to a secure connection, and do so whenever a user is authenticating or establishing a session. A common way of enforcing this is to make sure that cookies are set to secure – that way, sessions can only be established over HTTPS. ","date":"2021-12-25","objectID":"/hackspaining/:9:0","series":[],"tags":["Security"],"title":"Hacking Defense Note","uri":"/hackspaining/#unencrypted-communication"},{"categories":["Note"],"content":"Unencrypted Communication Insecure Wi-Fi hotspots, as illustrated in our exercise, are just one way enterprising hackers have found to take advantage of unencrypted communication. They may also try to sniff traffic within your network, and if they get access, inspect traffic going through compromised edge devices. Buy a certificate, install it, and configure your web server to use it. It’s really as simple as that. Web servers are typically able to serve the same content over HTTP (on port 80) and HTTPS (on port 443). Any non-trivial website should use HTTPS. Facebook and Twitter use HTTPS by default, and this a good example to follow. But make sure you know how to force your web server to elevate to a secure connection, and do so whenever a user is authenticating or establishing a session. A common way of enforcing this is to make sure that cookies are set to secure – that way, sessions can only be established over HTTPS. ","date":"2021-12-25","objectID":"/hackspaining/:9:0","series":[],"tags":["Security"],"title":"Hacking Defense Note","uri":"/hackspaining/#buy-a-certificate-install-it-and-configure-your-web-server-to-use-it"},{"categories":["Note"],"content":"User Enumeration Login Make sure to return a generic “No such username or password” message when a login failure occurs. Make sure the HTTP response, and the time taken to respond are no different when a username does not exist, and an incorrect password is entered. Password Reset Make sure your “forgotten password” page does not reveal usernames. If your password reset process involves sending an email, have the user enter their email address. Then send an email with a password reset link if the account exists. Registration Avoid having your site tell people that a supplied username is already taken. If your usernames are email addresses, send a password reset email if a user tries to sign-up with an existing address. If usernames are not email addresses, protect your sign-up page with a CAPTCHA. Profile Pages If your users have profile pages, make sure they are only visible to other users who are already logged in. If you hide a profile page, ensure a hidden profile is indistinguishable from a non-existent profile. ","date":"2021-12-25","objectID":"/hackspaining/:10:0","series":[],"tags":["Security"],"title":"Hacking Defense Note","uri":"/hackspaining/#user-enumeration"},{"categories":["Note"],"content":"User Enumeration Login Make sure to return a generic “No such username or password” message when a login failure occurs. Make sure the HTTP response, and the time taken to respond are no different when a username does not exist, and an incorrect password is entered. Password Reset Make sure your “forgotten password” page does not reveal usernames. If your password reset process involves sending an email, have the user enter their email address. Then send an email with a password reset link if the account exists. Registration Avoid having your site tell people that a supplied username is already taken. If your usernames are email addresses, send a password reset email if a user tries to sign-up with an existing address. If usernames are not email addresses, protect your sign-up page with a CAPTCHA. Profile Pages If your users have profile pages, make sure they are only visible to other users who are already logged in. If you hide a profile page, ensure a hidden profile is indistinguishable from a non-existent profile. ","date":"2021-12-25","objectID":"/hackspaining/:10:0","series":[],"tags":["Security"],"title":"Hacking Defense Note","uri":"/hackspaining/#login"},{"categories":["Note"],"content":"User Enumeration Login Make sure to return a generic “No such username or password” message when a login failure occurs. Make sure the HTTP response, and the time taken to respond are no different when a username does not exist, and an incorrect password is entered. Password Reset Make sure your “forgotten password” page does not reveal usernames. If your password reset process involves sending an email, have the user enter their email address. Then send an email with a password reset link if the account exists. Registration Avoid having your site tell people that a supplied username is already taken. If your usernames are email addresses, send a password reset email if a user tries to sign-up with an existing address. If usernames are not email addresses, protect your sign-up page with a CAPTCHA. Profile Pages If your users have profile pages, make sure they are only visible to other users who are already logged in. If you hide a profile page, ensure a hidden profile is indistinguishable from a non-existent profile. ","date":"2021-12-25","objectID":"/hackspaining/:10:0","series":[],"tags":["Security"],"title":"Hacking Defense Note","uri":"/hackspaining/#password-reset"},{"categories":["Note"],"content":"User Enumeration Login Make sure to return a generic “No such username or password” message when a login failure occurs. Make sure the HTTP response, and the time taken to respond are no different when a username does not exist, and an incorrect password is entered. Password Reset Make sure your “forgotten password” page does not reveal usernames. If your password reset process involves sending an email, have the user enter their email address. Then send an email with a password reset link if the account exists. Registration Avoid having your site tell people that a supplied username is already taken. If your usernames are email addresses, send a password reset email if a user tries to sign-up with an existing address. If usernames are not email addresses, protect your sign-up page with a CAPTCHA. Profile Pages If your users have profile pages, make sure they are only visible to other users who are already logged in. If you hide a profile page, ensure a hidden profile is indistinguishable from a non-existent profile. ","date":"2021-12-25","objectID":"/hackspaining/:10:0","series":[],"tags":["Security"],"title":"Hacking Defense Note","uri":"/hackspaining/#registration"},{"categories":["Note"],"content":"User Enumeration Login Make sure to return a generic “No such username or password” message when a login failure occurs. Make sure the HTTP response, and the time taken to respond are no different when a username does not exist, and an incorrect password is entered. Password Reset Make sure your “forgotten password” page does not reveal usernames. If your password reset process involves sending an email, have the user enter their email address. Then send an email with a password reset link if the account exists. Registration Avoid having your site tell people that a supplied username is already taken. If your usernames are email addresses, send a password reset email if a user tries to sign-up with an existing address. If usernames are not email addresses, protect your sign-up page with a CAPTCHA. Profile Pages If your users have profile pages, make sure they are only visible to other users who are already logged in. If you hide a profile page, ensure a hidden profile is indistinguishable from a non-existent profile. ","date":"2021-12-25","objectID":"/hackspaining/:10:0","series":[],"tags":["Security"],"title":"Hacking Defense Note","uri":"/hackspaining/#profile-pages"},{"categories":["Note"],"content":"Password Mismanagement Use Third-Party Authentication if Possible Ensure Password Complexity Allow Password Resets via Email Confirm Old Password On Reset Prevent Brute-Forcing Store Passwords With A Strong Hash, Salted Passwords should always be stored as salted hashes. Timeout Sessions After Inactivity, and Provide a Logout Function Use HTTPS for Secure Communication ","date":"2021-12-25","objectID":"/hackspaining/:11:0","series":[],"tags":["Security"],"title":"Hacking Defense Note","uri":"/hackspaining/#password-mismanagement"},{"categories":["Note"],"content":"Password Mismanagement Use Third-Party Authentication if Possible Ensure Password Complexity Allow Password Resets via Email Confirm Old Password On Reset Prevent Brute-Forcing Store Passwords With A Strong Hash, Salted Passwords should always be stored as salted hashes. Timeout Sessions After Inactivity, and Provide a Logout Function Use HTTPS for Secure Communication ","date":"2021-12-25","objectID":"/hackspaining/:11:0","series":[],"tags":["Security"],"title":"Hacking Defense Note","uri":"/hackspaining/#use-third-party-authentication-if-possible"},{"categories":["Note"],"content":"Password Mismanagement Use Third-Party Authentication if Possible Ensure Password Complexity Allow Password Resets via Email Confirm Old Password On Reset Prevent Brute-Forcing Store Passwords With A Strong Hash, Salted Passwords should always be stored as salted hashes. Timeout Sessions After Inactivity, and Provide a Logout Function Use HTTPS for Secure Communication ","date":"2021-12-25","objectID":"/hackspaining/:11:0","series":[],"tags":["Security"],"title":"Hacking Defense Note","uri":"/hackspaining/#ensure-password-complexity"},{"categories":["Note"],"content":"Password Mismanagement Use Third-Party Authentication if Possible Ensure Password Complexity Allow Password Resets via Email Confirm Old Password On Reset Prevent Brute-Forcing Store Passwords With A Strong Hash, Salted Passwords should always be stored as salted hashes. Timeout Sessions After Inactivity, and Provide a Logout Function Use HTTPS for Secure Communication ","date":"2021-12-25","objectID":"/hackspaining/:11:0","series":[],"tags":["Security"],"title":"Hacking Defense Note","uri":"/hackspaining/#allow-password-resets-via-email"},{"categories":["Note"],"content":"Password Mismanagement Use Third-Party Authentication if Possible Ensure Password Complexity Allow Password Resets via Email Confirm Old Password On Reset Prevent Brute-Forcing Store Passwords With A Strong Hash, Salted Passwords should always be stored as salted hashes. Timeout Sessions After Inactivity, and Provide a Logout Function Use HTTPS for Secure Communication ","date":"2021-12-25","objectID":"/hackspaining/:11:0","series":[],"tags":["Security"],"title":"Hacking Defense Note","uri":"/hackspaining/#confirm-old-password-on-reset"},{"categories":["Note"],"content":"Password Mismanagement Use Third-Party Authentication if Possible Ensure Password Complexity Allow Password Resets via Email Confirm Old Password On Reset Prevent Brute-Forcing Store Passwords With A Strong Hash, Salted Passwords should always be stored as salted hashes. Timeout Sessions After Inactivity, and Provide a Logout Function Use HTTPS for Secure Communication ","date":"2021-12-25","objectID":"/hackspaining/:11:0","series":[],"tags":["Security"],"title":"Hacking Defense Note","uri":"/hackspaining/#prevent-brute-forcing"},{"categories":["Note"],"content":"Password Mismanagement Use Third-Party Authentication if Possible Ensure Password Complexity Allow Password Resets via Email Confirm Old Password On Reset Prevent Brute-Forcing Store Passwords With A Strong Hash, Salted Passwords should always be stored as salted hashes. Timeout Sessions After Inactivity, and Provide a Logout Function Use HTTPS for Secure Communication ","date":"2021-12-25","objectID":"/hackspaining/:11:0","series":[],"tags":["Security"],"title":"Hacking Defense Note","uri":"/hackspaining/#store-passwords-with-a-strong-hash-salted"},{"categories":["Note"],"content":"Password Mismanagement Use Third-Party Authentication if Possible Ensure Password Complexity Allow Password Resets via Email Confirm Old Password On Reset Prevent Brute-Forcing Store Passwords With A Strong Hash, Salted Passwords should always be stored as salted hashes. Timeout Sessions After Inactivity, and Provide a Logout Function Use HTTPS for Secure Communication ","date":"2021-12-25","objectID":"/hackspaining/:11:0","series":[],"tags":["Security"],"title":"Hacking Defense Note","uri":"/hackspaining/#timeout-sessions-after-inactivity-and-provide-a-logout-function"},{"categories":["Note"],"content":"Password Mismanagement Use Third-Party Authentication if Possible Ensure Password Complexity Allow Password Resets via Email Confirm Old Password On Reset Prevent Brute-Forcing Store Passwords With A Strong Hash, Salted Passwords should always be stored as salted hashes. Timeout Sessions After Inactivity, and Provide a Logout Function Use HTTPS for Secure Communication ","date":"2021-12-25","objectID":"/hackspaining/:11:0","series":[],"tags":["Security"],"title":"Hacking Defense Note","uri":"/hackspaining/#use-https-for-secure-communication"},{"categories":["Note"],"content":"Email Spoofing Steal their credentials by sending “phishing” messages. Trick them into falling for online scams by abusing the trust they have in your site. Spread malware by sharing malicious attachments. SPF Implement the Sender Policy Framework (SPF): publish a DNS record to explicitly state which servers are allowed to send email from your domain. Implement Domain Key Identified Mail (DKIM): use a digital signature to prove that outgoing email was legitimately sent from your domain, and that it wasn’t modified in transit. DMARC There is also an emerging umbrella standard called DMARC (“Domain-based Message Authentication, Reporting \u0026 Conformance”) that you should be aware of. Read more about DMARC here. ","date":"2021-12-25","objectID":"/hackspaining/:12:0","series":[],"tags":["Security"],"title":"Hacking Defense Note","uri":"/hackspaining/#email-spoofing"},{"categories":["Note"],"content":"Email Spoofing Steal their credentials by sending “phishing” messages. Trick them into falling for online scams by abusing the trust they have in your site. Spread malware by sharing malicious attachments. SPF Implement the Sender Policy Framework (SPF): publish a DNS record to explicitly state which servers are allowed to send email from your domain. Implement Domain Key Identified Mail (DKIM): use a digital signature to prove that outgoing email was legitimately sent from your domain, and that it wasn’t modified in transit. DMARC There is also an emerging umbrella standard called DMARC (“Domain-based Message Authentication, Reporting \u0026 Conformance”) that you should be aware of. Read more about DMARC here. ","date":"2021-12-25","objectID":"/hackspaining/:12:0","series":[],"tags":["Security"],"title":"Hacking Defense Note","uri":"/hackspaining/#spf"},{"categories":["Note"],"content":"Email Spoofing Steal their credentials by sending “phishing” messages. Trick them into falling for online scams by abusing the trust they have in your site. Spread malware by sharing malicious attachments. SPF Implement the Sender Policy Framework (SPF): publish a DNS record to explicitly state which servers are allowed to send email from your domain. Implement Domain Key Identified Mail (DKIM): use a digital signature to prove that outgoing email was legitimately sent from your domain, and that it wasn’t modified in transit. DMARC There is also an emerging umbrella standard called DMARC (“Domain-based Message Authentication, Reporting \u0026 Conformance”) that you should be aware of. Read more about DMARC here. ","date":"2021-12-25","objectID":"/hackspaining/:12:0","series":[],"tags":["Security"],"title":"Hacking Defense Note","uri":"/hackspaining/#dmarc"},{"categories":["Note"],"content":"configuration mplementing SPF and DKIM requires publishing new DNS records and making configuration changes to your technology stack - consult the documentation for your email sending service or software for details. Here are the relevant documentation links for some of the more common methods of sending email. Transactional Email Services Email Marketing Services Mail Transfer Agents ","date":"2021-12-25","objectID":"/hackspaining/:12:1","series":[],"tags":["Security"],"title":"Hacking Defense Note","uri":"/hackspaining/#configuration"},{"categories":["Note"],"content":"configuration mplementing SPF and DKIM requires publishing new DNS records and making configuration changes to your technology stack - consult the documentation for your email sending service or software for details. Here are the relevant documentation links for some of the more common methods of sending email. Transactional Email Services Email Marketing Services Mail Transfer Agents ","date":"2021-12-25","objectID":"/hackspaining/:12:1","series":[],"tags":["Security"],"title":"Hacking Defense Note","uri":"/hackspaining/#transactional-email-services"},{"categories":["Note"],"content":"configuration mplementing SPF and DKIM requires publishing new DNS records and making configuration changes to your technology stack - consult the documentation for your email sending service or software for details. Here are the relevant documentation links for some of the more common methods of sending email. Transactional Email Services Email Marketing Services Mail Transfer Agents ","date":"2021-12-25","objectID":"/hackspaining/:12:1","series":[],"tags":["Security"],"title":"Hacking Defense Note","uri":"/hackspaining/#email-marketing-services"},{"categories":["Note"],"content":"configuration mplementing SPF and DKIM requires publishing new DNS records and making configuration changes to your technology stack - consult the documentation for your email sending service or software for details. Here are the relevant documentation links for some of the more common methods of sending email. Transactional Email Services Email Marketing Services Mail Transfer Agents ","date":"2021-12-25","objectID":"/hackspaining/:12:1","series":[],"tags":["Security"],"title":"Hacking Defense Note","uri":"/hackspaining/#mail-transfer-agents"},{"categories":["Note"],"content":"Malvertising Malicious downloads, including ransomware. “Drive-by” downloads don’t even require the user to click on an advert - simply viewing the page may be enough to deliver the payload. Malware is usually delivered through vulnerable versions of Flash or Adobe Acrobat. Redirects to phishing sites that attempt to steal a user’s credentials. Scareware - adverts designed to trick a user into downloading unnecessary and potentially dangerous software, such as fake antivirus protection. Browser lockers - malware that locks up the browser, often posing as a security alert. ","date":"2021-12-25","objectID":"/hackspaining/:13:0","series":[],"tags":["Security"],"title":"Hacking Defense Note","uri":"/hackspaining/#malvertising"},{"categories":["Note"],"content":"Protection Working with reputable ad networks. Choose networks that are certified by e.g. Google. If you are evaluating a new ad network, see if they have any existing big-name clients. Avoid advertising networks that use deceptive practices pop-ups and pop-under windows. Performing due diligence on agencies and advertisers. Restrict your advertising to relevant market segments, and if your ad networks permits it, consider individually whitelisting advertisers. Implementing a content security policy. Implementing a Content-Security Policy will help control what domains can host content used in your web-pages. Unfortunately, many advertising toolkits (e.g. Google Adsense) cannot be restricted in this fashion - so you may have to create a “soft” whitelist using the Content-Security-Policy-Report-Only header, and monitor unexpected domains. Using client-side error reporting tools. Tools for recording errors in the browser - like Sentry, TrackJS, Rollbar and Airbrake - will help you detect unexpected and anomalous behavior that could indicate a malvertising infection. Logging out-going URLs. Capturing click-strings for adverts will help with forensic analysis in the case of a malvertising outbreak. ","date":"2021-12-25","objectID":"/hackspaining/:13:1","series":[],"tags":["Security"],"title":"Hacking Defense Note","uri":"/hackspaining/#protection"},{"categories":["Note"],"content":"Logging And Monitoring https://www.hacksplaining.com/prevention/logging-and-monitoring ","date":"2021-12-25","objectID":"/hackspaining/:14:0","series":[],"tags":["Security"],"title":"Hacking Defense Note","uri":"/hackspaining/#logging-and-monitoring"},{"categories":["Note"],"content":"Buffer Overflows Insecure Function Secure Alternative gets() fgets() strcpy() strncpy() strcat() strncat() sprintf() snprintf() It’s pretty rare for web-developers to write low-level code in languages like C or C++, so the biggest risk of buffer overflows for must of us in the applications we use. Web Servers Most websites are deployed using a web server to serve static content. (This is distinct from the application server that executes dynamic content.) The three most common web-servers are: Apache HTTP Server Microsoft Internet Information Services (IIS) Nginx Each of these has been found to be vulnerable to buffer overflows at different times. Web-server vendors are very quick to patch vulnerabilities, so the key to keeping yourself secure is deploying security patches as soon as they become available. Operating Systems and Language Runtimes Buffer overflow attacks have been launched against websites by taking advantage of vulnerabilities in operating systems and language runtimes. The Heartbleed attack took advantage of a serious vulnerability in the OpenSSL cryptographic software library that Linux-based web-servers use to encrypt SSL/TLS traffic. Similarly, security researchers have discovered vulnerabilities in various functions in the PHP runtime which allow attackers to launch buffer overflow attacks remotely by crafting malicious input. Remediation To avoid being exposed to buffer overflow vulnerabilities in the applications you use, you need to keep them up-to-date with the latest security patches. These are the key things to need to do: Automate your build and deployment process. You need to know which versions of each application your are running on each server. This means writing deployment scripts for web-servers and language runtimes, and retaining copies of deployment logs. Keep on top of security bulletins. Make sure your team is on the lookout for security announcements for the applications you use. Sign up for mailing lists, join forums, and follow software vendors on social media. Deploy security patches as soon as they become available! Hackers will find ways to take advantage of security vulnerabilities as soon as they are made public, so make sure you are not amongst the target audience. ","date":"2021-12-25","objectID":"/hackspaining/:15:0","series":[],"tags":["Security"],"title":"Hacking Defense Note","uri":"/hackspaining/#buffer-overflows"},{"categories":["Note"],"content":"Buffer Overflows Insecure Function Secure Alternative gets() fgets() strcpy() strncpy() strcat() strncat() sprintf() snprintf() It’s pretty rare for web-developers to write low-level code in languages like C or C++, so the biggest risk of buffer overflows for must of us in the applications we use. Web Servers Most websites are deployed using a web server to serve static content. (This is distinct from the application server that executes dynamic content.) The three most common web-servers are: Apache HTTP Server Microsoft Internet Information Services (IIS) Nginx Each of these has been found to be vulnerable to buffer overflows at different times. Web-server vendors are very quick to patch vulnerabilities, so the key to keeping yourself secure is deploying security patches as soon as they become available. Operating Systems and Language Runtimes Buffer overflow attacks have been launched against websites by taking advantage of vulnerabilities in operating systems and language runtimes. The Heartbleed attack took advantage of a serious vulnerability in the OpenSSL cryptographic software library that Linux-based web-servers use to encrypt SSL/TLS traffic. Similarly, security researchers have discovered vulnerabilities in various functions in the PHP runtime which allow attackers to launch buffer overflow attacks remotely by crafting malicious input. Remediation To avoid being exposed to buffer overflow vulnerabilities in the applications you use, you need to keep them up-to-date with the latest security patches. These are the key things to need to do: Automate your build and deployment process. You need to know which versions of each application your are running on each server. This means writing deployment scripts for web-servers and language runtimes, and retaining copies of deployment logs. Keep on top of security bulletins. Make sure your team is on the lookout for security announcements for the applications you use. Sign up for mailing lists, join forums, and follow software vendors on social media. Deploy security patches as soon as they become available! Hackers will find ways to take advantage of security vulnerabilities as soon as they are made public, so make sure you are not amongst the target audience. ","date":"2021-12-25","objectID":"/hackspaining/:15:0","series":[],"tags":["Security"],"title":"Hacking Defense Note","uri":"/hackspaining/#web-servers"},{"categories":["Note"],"content":"Buffer Overflows Insecure Function Secure Alternative gets() fgets() strcpy() strncpy() strcat() strncat() sprintf() snprintf() It’s pretty rare for web-developers to write low-level code in languages like C or C++, so the biggest risk of buffer overflows for must of us in the applications we use. Web Servers Most websites are deployed using a web server to serve static content. (This is distinct from the application server that executes dynamic content.) The three most common web-servers are: Apache HTTP Server Microsoft Internet Information Services (IIS) Nginx Each of these has been found to be vulnerable to buffer overflows at different times. Web-server vendors are very quick to patch vulnerabilities, so the key to keeping yourself secure is deploying security patches as soon as they become available. Operating Systems and Language Runtimes Buffer overflow attacks have been launched against websites by taking advantage of vulnerabilities in operating systems and language runtimes. The Heartbleed attack took advantage of a serious vulnerability in the OpenSSL cryptographic software library that Linux-based web-servers use to encrypt SSL/TLS traffic. Similarly, security researchers have discovered vulnerabilities in various functions in the PHP runtime which allow attackers to launch buffer overflow attacks remotely by crafting malicious input. Remediation To avoid being exposed to buffer overflow vulnerabilities in the applications you use, you need to keep them up-to-date with the latest security patches. These are the key things to need to do: Automate your build and deployment process. You need to know which versions of each application your are running on each server. This means writing deployment scripts for web-servers and language runtimes, and retaining copies of deployment logs. Keep on top of security bulletins. Make sure your team is on the lookout for security announcements for the applications you use. Sign up for mailing lists, join forums, and follow software vendors on social media. Deploy security patches as soon as they become available! Hackers will find ways to take advantage of security vulnerabilities as soon as they are made public, so make sure you are not amongst the target audience. ","date":"2021-12-25","objectID":"/hackspaining/:15:0","series":[],"tags":["Security"],"title":"Hacking Defense Note","uri":"/hackspaining/#operating-systems-and-language-runtimes"},{"categories":["Note"],"content":"Buffer Overflows Insecure Function Secure Alternative gets() fgets() strcpy() strncpy() strcat() strncat() sprintf() snprintf() It’s pretty rare for web-developers to write low-level code in languages like C or C++, so the biggest risk of buffer overflows for must of us in the applications we use. Web Servers Most websites are deployed using a web server to serve static content. (This is distinct from the application server that executes dynamic content.) The three most common web-servers are: Apache HTTP Server Microsoft Internet Information Services (IIS) Nginx Each of these has been found to be vulnerable to buffer overflows at different times. Web-server vendors are very quick to patch vulnerabilities, so the key to keeping yourself secure is deploying security patches as soon as they become available. Operating Systems and Language Runtimes Buffer overflow attacks have been launched against websites by taking advantage of vulnerabilities in operating systems and language runtimes. The Heartbleed attack took advantage of a serious vulnerability in the OpenSSL cryptographic software library that Linux-based web-servers use to encrypt SSL/TLS traffic. Similarly, security researchers have discovered vulnerabilities in various functions in the PHP runtime which allow attackers to launch buffer overflow attacks remotely by crafting malicious input. Remediation To avoid being exposed to buffer overflow vulnerabilities in the applications you use, you need to keep them up-to-date with the latest security patches. These are the key things to need to do: Automate your build and deployment process. You need to know which versions of each application your are running on each server. This means writing deployment scripts for web-servers and language runtimes, and retaining copies of deployment logs. Keep on top of security bulletins. Make sure your team is on the lookout for security announcements for the applications you use. Sign up for mailing lists, join forums, and follow software vendors on social media. Deploy security patches as soon as they become available! Hackers will find ways to take advantage of security vulnerabilities as soon as they are made public, so make sure you are not amongst the target audience. ","date":"2021-12-25","objectID":"/hackspaining/:15:0","series":[],"tags":["Security"],"title":"Hacking Defense Note","uri":"/hackspaining/#remediation"},{"categories":["Note"],"content":"Report: Setup Hadoop Cluster on MS Azure https://klasserom.azurewebsites.net/Lessons/Binder/2410 Notice: In this report, the ssh .pem is named SSH_keypair.pem, and the user name in Linux by default is set to PceWlkr. ","date":"2021-12-25","objectID":"/setup-hadoop-cluster-on-ms-azure/:0:0","series":[],"tags":["Hadoop"],"title":"Hadoop Setup","uri":"/setup-hadoop-cluster-on-ms-azure/#report-setup-hadoop-cluster-on-ms-azure"},{"categories":["Note"],"content":"set up virtual machine ","date":"2021-12-25","objectID":"/setup-hadoop-cluster-on-ms-azure/:1:0","series":[],"tags":["Hadoop"],"title":"Hadoop Setup","uri":"/setup-hadoop-cluster-on-ms-azure/#set-up-virtual-machine"},{"categories":["Note"],"content":"Basics use the B1s as the bare bone std The first vm set in the group will need to generate a new key pair of SSH public key, and give it a name. Others can just use the SSH we had already. Set the public inbound ports. (we set this up for testing purpose only, so the fact that all IP addrs will be allowed to access my vms doesn’t bother.) ","date":"2021-12-25","objectID":"/setup-hadoop-cluster-on-ms-azure/:1:1","series":[],"tags":["Hadoop"],"title":"Hadoop Setup","uri":"/setup-hadoop-cluster-on-ms-azure/#basics"},{"categories":["Note"],"content":"Disks go with standard SSD encryption type: default ","date":"2021-12-25","objectID":"/setup-hadoop-cluster-on-ms-azure/:1:2","series":[],"tags":["Hadoop"],"title":"Hadoop Setup","uri":"/setup-hadoop-cluster-on-ms-azure/#disks"},{"categories":["Note"],"content":"Networking virtual network: default subnet: default public IP: use the namenode ip NIC network security group: Basic Public inbound ports: allow selected ports inbound ports ","date":"2021-12-25","objectID":"/setup-hadoop-cluster-on-ms-azure/:1:3","series":[],"tags":["Hadoop"],"title":"Hadoop Setup","uri":"/setup-hadoop-cluster-on-ms-azure/#networking"},{"categories":["Note"],"content":"Management auto-shutdown: do this since we may forgot shut then down and lose money for that ","date":"2021-12-25","objectID":"/setup-hadoop-cluster-on-ms-azure/:1:4","series":[],"tags":["Hadoop"],"title":"Hadoop Setup","uri":"/setup-hadoop-cluster-on-ms-azure/#management"},{"categories":["Note"],"content":"Advanced ","date":"2021-12-25","objectID":"/setup-hadoop-cluster-on-ms-azure/:1:5","series":[],"tags":["Hadoop"],"title":"Hadoop Setup","uri":"/setup-hadoop-cluster-on-ms-azure/#advanced"},{"categories":["Note"],"content":"Tags ","date":"2021-12-25","objectID":"/setup-hadoop-cluster-on-ms-azure/:1:6","series":[],"tags":["Hadoop"],"title":"Hadoop Setup","uri":"/setup-hadoop-cluster-on-ms-azure/#tags"},{"categories":["Note"],"content":"Review and create review the price with extra cautions ","date":"2021-12-25","objectID":"/setup-hadoop-cluster-on-ms-azure/:1:7","series":[],"tags":["Hadoop"],"title":"Hadoop Setup","uri":"/setup-hadoop-cluster-on-ms-azure/#review-and-create"},{"categories":["Note"],"content":"Additional info it takes some time to create/ Download the private SSH key pair and store it carefully Better to have WinSCP available SFTP host name is the public ip port num is what we set before input the .pem file, which is the OpenSSH private key WinSCP will convert it to .ppk call this node namenode when connected, you can see the /home/PceWlkr/ Putty use putty to login the server sudo apt-get update //update the linux sys and everything installed ","date":"2021-12-25","objectID":"/setup-hadoop-cluster-on-ms-azure/:1:8","series":[],"tags":["Hadoop"],"title":"Hadoop Setup","uri":"/setup-hadoop-cluster-on-ms-azure/#additional-info"},{"categories":["Note"],"content":"Additional info it takes some time to create/ Download the private SSH key pair and store it carefully Better to have WinSCP available SFTP host name is the public ip port num is what we set before input the .pem file, which is the OpenSSH private key WinSCP will convert it to .ppk call this node namenode when connected, you can see the /home/PceWlkr/ Putty use putty to login the server sudo apt-get update //update the linux sys and everything installed ","date":"2021-12-25","objectID":"/setup-hadoop-cluster-on-ms-azure/:1:8","series":[],"tags":["Hadoop"],"title":"Hadoop Setup","uri":"/setup-hadoop-cluster-on-ms-azure/#better-to-have-winscp-available"},{"categories":["Note"],"content":"Additional info it takes some time to create/ Download the private SSH key pair and store it carefully Better to have WinSCP available SFTP host name is the public ip port num is what we set before input the .pem file, which is the OpenSSH private key WinSCP will convert it to .ppk call this node namenode when connected, you can see the /home/PceWlkr/ Putty use putty to login the server sudo apt-get update //update the linux sys and everything installed ","date":"2021-12-25","objectID":"/setup-hadoop-cluster-on-ms-azure/:1:8","series":[],"tags":["Hadoop"],"title":"Hadoop Setup","uri":"/setup-hadoop-cluster-on-ms-azure/#putty"},{"categories":["Note"],"content":"Add VMI to your Virtual Network Now we should have a public IP addr Everytime you restart the VM, it will give you a new public IP. Remember to update the IP you used for WinSCP. We are going to create more VMs as the DataNodes. Resource group: VirtualMachines name: DataNode001 image: Ubuntu Server 20.04 LTS Gen 1 Size: Std B1s Username: PceWlkr SSH: SSH_keypair inbound ports: SSH(22) OS disk type: std subnet: make it on the same network as last time security group: Basic (will adjust later) enable the auto-shutdown like before Go to Virtual Machines on the dash board, check if everything is there. Go to the namenode and copy the IP addr and then go the WinSCP to change the host. Clone it to a new site. Edit the newsite to register the datanode001 on WinSCP like before. Go the terminal to check if things are there. ","date":"2021-12-25","objectID":"/setup-hadoop-cluster-on-ms-azure/:2:0","series":[],"tags":["Hadoop"],"title":"Hadoop Setup","uri":"/setup-hadoop-cluster-on-ms-azure/#add-vmi-to-your-virtual-network"},{"categories":["Note"],"content":"Add a DNS to your VMI Go to the namenode and click the DNS name. Enter a DNS name label which must be unique that nobody else has reserved. Now we can use the DNS in the WinSCP instead of IP. ","date":"2021-12-25","objectID":"/setup-hadoop-cluster-on-ms-azure/:3:0","series":[],"tags":["Hadoop"],"title":"Hadoop Setup","uri":"/setup-hadoop-cluster-on-ms-azure/#add-a-dns-to-your-vmi"},{"categories":["Note"],"content":"Network Security Ports Go to the VM and then go to the Networking setting. Add inbound port rule. Service shoule be changed to SSH. Priority: 100 Name: SSH_22 Then add another inbound port for the remote desktop. Service:RDP Priority: 110 (lower then SSH) Name: RDP_3389 Also set up a PPK SSH for the namenode. Go to Advanced and Authentication, and go for the .pub in the private key file. Convert it and then save and login. ","date":"2021-12-25","objectID":"/setup-hadoop-cluster-on-ms-azure/:4:0","series":[],"tags":["Hadoop"],"title":"Hadoop Setup","uri":"/setup-hadoop-cluster-on-ms-azure/#network-security-ports"},{"categories":["Note"],"content":"Update/Upgrade Packages ","date":"2021-12-25","objectID":"/setup-hadoop-cluster-on-ms-azure/:5:0","series":[],"tags":["Hadoop"],"title":"Hadoop Setup","uri":"/setup-hadoop-cluster-on-ms-azure/#updateupgrade-packages"},{"categories":["Note"],"content":"Disable Unattended Upgrades sudo apt -y remove unattended-upgrades or if you do not want to remove Unattended-Upgrades, use sudo dpkg-reconfigure unattended-upgrades to turn on or off the features. ","date":"2021-12-25","objectID":"/setup-hadoop-cluster-on-ms-azure/:5:1","series":[],"tags":["Hadoop"],"title":"Hadoop Setup","uri":"/setup-hadoop-cluster-on-ms-azure/#disable-unattended-upgrades"},{"categories":["Note"],"content":"Update and Upgrade Packages sudo apt-get update -y \u0026\u0026 sudo apt-get upgrade -y ","date":"2021-12-25","objectID":"/setup-hadoop-cluster-on-ms-azure/:5:2","series":[],"tags":["Hadoop"],"title":"Hadoop Setup","uri":"/setup-hadoop-cluster-on-ms-azure/#update-and-upgrade-packages"},{"categories":["Note"],"content":"Hadoop Installation and Configuration You will learn the following: Administrate users in Ubuntu Manage environment variables in Ubuntu Use Secure Shell (SSH) to communicate with Virtual Machines Hadoop Prerequistes Java Developers Kit (JDK) pdsh rsync Install and Configure Hadoop Administrate Hadoop configuration files Test HDFS commands Test MapReduce using sample applications ","date":"2021-12-25","objectID":"/setup-hadoop-cluster-on-ms-azure/:6:0","series":[],"tags":["Hadoop"],"title":"Hadoop Setup","uri":"/setup-hadoop-cluster-on-ms-azure/#hadoop-installation-and-configuration"},{"categories":["Note"],"content":"Cluster Environment Setup We have done this: sudo apt -y remove unattended-upgrades \u0026\u0026 sudo apt-get update -y \u0026\u0026 sudo apt-get upgrade -y Secure Admin Account In this case, my admin account’s name is PceWlkr. sudo passwd PceWlkr Common Environment Variables for Hadoop Clusters In general, these include: Java - JAVA_HOME Hadoop - HADOOP_HOME Hive - HIVE_HOME Pig - PIG_HOME The etc/profile.d dir holding shell script will be run at start-up and install fuatures for all users. So we’ll create a file bigdata.sh for later installations. sudo touch /etc/profile.d/bigdata.sh export BigDataSH=/etc/profile.d/bigdata.sh export IdentityFile=\"/.ssh/SSH_keypair.pem\" export SSHConfigFile=\"/.ssh/config\" sudo rm $BigDataSH echo -e '#!/bin/bash \\n' | sudo tee --append $BigDataSH \u003e /dev/null echo -e \"# Environment Variables for Big Data tools\\n\" | sudo tee --append $BigDataSH \u003e /dev/null echo -e \"export BigDataSH=${BigDataSH}\" | sudo tee --append $BigDataSH \u003e /dev/null echo -e \"export IdentityFile=~${IdentityFile}\" | sudo tee --append $BigDataSH \u003e /dev/null echo -e \"export SSHConfigFile=~${SSHConfigFile}\\n\" | sudo tee --append $BigDataSH \u003e /dev/null sudo chmod 644 $BigDataSH cat $BigDataSH The result should be: #!/bin/bash # Environment Variables for Big Data tools export BigDataSH=/etc/profile.d/bigdata.sh export IdentityFile=~/.ssh/SSH_keypair.pem export SSHConfigFile=~/.ssh/config sudo reboot After rebooting, confirm the vars exist. echo $BigDataSH $IdentityFile $SSHConfigFile The result should be: /etc/profile.d/bigdata.sh /home/PceWlkr/.ssh/SSH_keypair.pem /home/PceWlkr/.ssh/config Map Virtual Machine Cluster Environment Variables Collect the Public DNS and “Internal” IP addresses from your Virtual Machine Instances Copy and paste the following commands into a text editor: export NameNodeDNS=\"Namenode\" export DataNode001DNS=\"Datanode001\" export DataNode002DNS=\"Datanode002\" export DataNode003DNS=\"Datanode003\" export DataNode004DNS=\"Datanode004\" export NameNodeIP=\"10.0.0.4\" export DataNode001IP=\"10.0.0.5\" export DataNode002IP=\"10.0.0.6\" export DataNode003IP=\"10.0.0.7\" Notice: you can use hostname and hostname -I to find the hostname and private IP Copy all of the commands above from the text editor Paste the commands into the SSH session at the command line for your Virtual Machine Instance When you pasted the commands, they were executed automatically. Try to use one of the variables we set: echo $DataNode001DNS The result should look something like this: Datanode001 Execute the following to add the schema to the bigdata.sh file: echo -e \"# Cluster Variables START\" | sudo tee --append $BigDataSH \u003e /dev/null echo -e \"export NameNodeDNS=\\\"${NameNodeDNS}\\\"\" | sudo tee --append $BigDataSH \u003e /dev/null echo -e \"export DataNode001DNS=\\\"${DataNode001DNS}\\\"\" | sudo tee --append $BigDataSH \u003e /dev/null echo -e \"export DataNode002DNS=\\\"${DataNode002DNS}\\\"\" | sudo tee --append $BigDataSH \u003e /dev/null echo -e \"export DataNode003DNS=\\\"${DataNode003DNS}\\\"\" | sudo tee --append $BigDataSH \u003e /dev/null echo -e \"export DataNode004DNS=\\\"${DataNode004DNS}\\\"\" | sudo tee --append $BigDataSH \u003e /dev/null echo -e \"\" | sudo tee --append $BigDataSH \u003e /dev/null echo -e \"export NameNodeIP=\\\"${NameNodeIP}\\\"\" | sudo tee --append $BigDataSH \u003e /dev/null echo -e \"export DataNode001IP=\\\"${DataNode001IP}\\\"\" | sudo tee --append $BigDataSH \u003e /dev/null echo -e \"export DataNode002IP=\\\"${DataNode002IP}\\\"\" | sudo tee --append $BigDataSH \u003e /dev/null echo -e \"export DataNode003IP=\\\"${DataNode003IP}\\\"\" | sudo tee --append $BigDataSH \u003e /dev/null echo -e \"export DataNode004IP=\\\"${DataNode004IP}\\\"\" | sudo tee --append $BigDataSH \u003e /dev/null echo -e \"# Cluster Variables END\" | sudo tee --append $BigDataSH \u003e /dev/null Then Display the contents of the $BigDataSh file: cat $BigDataSH result should be like: #!/bin/bash # Environment Variables for Big Data tools export BigDataSH=/etc/profile.d/bigdata.sh export IdentityFile=~/.ssh/SSH_keypair.pem export SSHConfigFile=~/.ssh/config # Cluster Variable","date":"2021-12-25","objectID":"/setup-hadoop-cluster-on-ms-azure/:6:1","series":[],"tags":["Hadoop"],"title":"Hadoop Setup","uri":"/setup-hadoop-cluster-on-ms-azure/#cluster-environment-setup"},{"categories":["Note"],"content":"Cluster Environment Setup We have done this: sudo apt -y remove unattended-upgrades \u0026\u0026 sudo apt-get update -y \u0026\u0026 sudo apt-get upgrade -y Secure Admin Account In this case, my admin account’s name is PceWlkr. sudo passwd PceWlkr Common Environment Variables for Hadoop Clusters In general, these include: Java - JAVA_HOME Hadoop - HADOOP_HOME Hive - HIVE_HOME Pig - PIG_HOME The etc/profile.d dir holding shell script will be run at start-up and install fuatures for all users. So we’ll create a file bigdata.sh for later installations. sudo touch /etc/profile.d/bigdata.sh export BigDataSH=/etc/profile.d/bigdata.sh export IdentityFile=\"/.ssh/SSH_keypair.pem\" export SSHConfigFile=\"/.ssh/config\" sudo rm $BigDataSH echo -e '#!/bin/bash \\n' | sudo tee --append $BigDataSH /dev/null echo -e \"# Environment Variables for Big Data tools\\n\" | sudo tee --append $BigDataSH /dev/null echo -e \"export BigDataSH=${BigDataSH}\" | sudo tee --append $BigDataSH /dev/null echo -e \"export IdentityFile=~${IdentityFile}\" | sudo tee --append $BigDataSH /dev/null echo -e \"export SSHConfigFile=~${SSHConfigFile}\\n\" | sudo tee --append $BigDataSH /dev/null sudo chmod 644 $BigDataSH cat $BigDataSH The result should be: #!/bin/bash # Environment Variables for Big Data tools export BigDataSH=/etc/profile.d/bigdata.sh export IdentityFile=~/.ssh/SSH_keypair.pem export SSHConfigFile=~/.ssh/config sudo reboot After rebooting, confirm the vars exist. echo $BigDataSH $IdentityFile $SSHConfigFile The result should be: /etc/profile.d/bigdata.sh /home/PceWlkr/.ssh/SSH_keypair.pem /home/PceWlkr/.ssh/config Map Virtual Machine Cluster Environment Variables Collect the Public DNS and “Internal” IP addresses from your Virtual Machine Instances Copy and paste the following commands into a text editor: export NameNodeDNS=\"Namenode\" export DataNode001DNS=\"Datanode001\" export DataNode002DNS=\"Datanode002\" export DataNode003DNS=\"Datanode003\" export DataNode004DNS=\"Datanode004\" export NameNodeIP=\"10.0.0.4\" export DataNode001IP=\"10.0.0.5\" export DataNode002IP=\"10.0.0.6\" export DataNode003IP=\"10.0.0.7\" Notice: you can use hostname and hostname -I to find the hostname and private IP Copy all of the commands above from the text editor Paste the commands into the SSH session at the command line for your Virtual Machine Instance When you pasted the commands, they were executed automatically. Try to use one of the variables we set: echo $DataNode001DNS The result should look something like this: Datanode001 Execute the following to add the schema to the bigdata.sh file: echo -e \"# Cluster Variables START\" | sudo tee --append $BigDataSH /dev/null echo -e \"export NameNodeDNS=\\\"${NameNodeDNS}\\\"\" | sudo tee --append $BigDataSH /dev/null echo -e \"export DataNode001DNS=\\\"${DataNode001DNS}\\\"\" | sudo tee --append $BigDataSH /dev/null echo -e \"export DataNode002DNS=\\\"${DataNode002DNS}\\\"\" | sudo tee --append $BigDataSH /dev/null echo -e \"export DataNode003DNS=\\\"${DataNode003DNS}\\\"\" | sudo tee --append $BigDataSH /dev/null echo -e \"export DataNode004DNS=\\\"${DataNode004DNS}\\\"\" | sudo tee --append $BigDataSH /dev/null echo -e \"\" | sudo tee --append $BigDataSH /dev/null echo -e \"export NameNodeIP=\\\"${NameNodeIP}\\\"\" | sudo tee --append $BigDataSH /dev/null echo -e \"export DataNode001IP=\\\"${DataNode001IP}\\\"\" | sudo tee --append $BigDataSH /dev/null echo -e \"export DataNode002IP=\\\"${DataNode002IP}\\\"\" | sudo tee --append $BigDataSH /dev/null echo -e \"export DataNode003IP=\\\"${DataNode003IP}\\\"\" | sudo tee --append $BigDataSH /dev/null echo -e \"export DataNode004IP=\\\"${DataNode004IP}\\\"\" | sudo tee --append $BigDataSH /dev/null echo -e \"# Cluster Variables END\" | sudo tee --append $BigDataSH /dev/null Then Display the contents of the $BigDataSh file: cat $BigDataSH result should be like: #!/bin/bash # Environment Variables for Big Data tools export BigDataSH=/etc/profile.d/bigdata.sh export IdentityFile=~/.ssh/SSH_keypair.pem export SSHConfigFile=~/.ssh/config # Cluster Variable","date":"2021-12-25","objectID":"/setup-hadoop-cluster-on-ms-azure/:6:1","series":[],"tags":["Hadoop"],"title":"Hadoop Setup","uri":"/setup-hadoop-cluster-on-ms-azure/#secure-admin-account"},{"categories":["Note"],"content":"Cluster Environment Setup We have done this: sudo apt -y remove unattended-upgrades \u0026\u0026 sudo apt-get update -y \u0026\u0026 sudo apt-get upgrade -y Secure Admin Account In this case, my admin account’s name is PceWlkr. sudo passwd PceWlkr Common Environment Variables for Hadoop Clusters In general, these include: Java - JAVA_HOME Hadoop - HADOOP_HOME Hive - HIVE_HOME Pig - PIG_HOME The etc/profile.d dir holding shell script will be run at start-up and install fuatures for all users. So we’ll create a file bigdata.sh for later installations. sudo touch /etc/profile.d/bigdata.sh export BigDataSH=/etc/profile.d/bigdata.sh export IdentityFile=\"/.ssh/SSH_keypair.pem\" export SSHConfigFile=\"/.ssh/config\" sudo rm $BigDataSH echo -e '#!/bin/bash \\n' | sudo tee --append $BigDataSH /dev/null echo -e \"# Environment Variables for Big Data tools\\n\" | sudo tee --append $BigDataSH /dev/null echo -e \"export BigDataSH=${BigDataSH}\" | sudo tee --append $BigDataSH /dev/null echo -e \"export IdentityFile=~${IdentityFile}\" | sudo tee --append $BigDataSH /dev/null echo -e \"export SSHConfigFile=~${SSHConfigFile}\\n\" | sudo tee --append $BigDataSH /dev/null sudo chmod 644 $BigDataSH cat $BigDataSH The result should be: #!/bin/bash # Environment Variables for Big Data tools export BigDataSH=/etc/profile.d/bigdata.sh export IdentityFile=~/.ssh/SSH_keypair.pem export SSHConfigFile=~/.ssh/config sudo reboot After rebooting, confirm the vars exist. echo $BigDataSH $IdentityFile $SSHConfigFile The result should be: /etc/profile.d/bigdata.sh /home/PceWlkr/.ssh/SSH_keypair.pem /home/PceWlkr/.ssh/config Map Virtual Machine Cluster Environment Variables Collect the Public DNS and “Internal” IP addresses from your Virtual Machine Instances Copy and paste the following commands into a text editor: export NameNodeDNS=\"Namenode\" export DataNode001DNS=\"Datanode001\" export DataNode002DNS=\"Datanode002\" export DataNode003DNS=\"Datanode003\" export DataNode004DNS=\"Datanode004\" export NameNodeIP=\"10.0.0.4\" export DataNode001IP=\"10.0.0.5\" export DataNode002IP=\"10.0.0.6\" export DataNode003IP=\"10.0.0.7\" Notice: you can use hostname and hostname -I to find the hostname and private IP Copy all of the commands above from the text editor Paste the commands into the SSH session at the command line for your Virtual Machine Instance When you pasted the commands, they were executed automatically. Try to use one of the variables we set: echo $DataNode001DNS The result should look something like this: Datanode001 Execute the following to add the schema to the bigdata.sh file: echo -e \"# Cluster Variables START\" | sudo tee --append $BigDataSH /dev/null echo -e \"export NameNodeDNS=\\\"${NameNodeDNS}\\\"\" | sudo tee --append $BigDataSH /dev/null echo -e \"export DataNode001DNS=\\\"${DataNode001DNS}\\\"\" | sudo tee --append $BigDataSH /dev/null echo -e \"export DataNode002DNS=\\\"${DataNode002DNS}\\\"\" | sudo tee --append $BigDataSH /dev/null echo -e \"export DataNode003DNS=\\\"${DataNode003DNS}\\\"\" | sudo tee --append $BigDataSH /dev/null echo -e \"export DataNode004DNS=\\\"${DataNode004DNS}\\\"\" | sudo tee --append $BigDataSH /dev/null echo -e \"\" | sudo tee --append $BigDataSH /dev/null echo -e \"export NameNodeIP=\\\"${NameNodeIP}\\\"\" | sudo tee --append $BigDataSH /dev/null echo -e \"export DataNode001IP=\\\"${DataNode001IP}\\\"\" | sudo tee --append $BigDataSH /dev/null echo -e \"export DataNode002IP=\\\"${DataNode002IP}\\\"\" | sudo tee --append $BigDataSH /dev/null echo -e \"export DataNode003IP=\\\"${DataNode003IP}\\\"\" | sudo tee --append $BigDataSH /dev/null echo -e \"export DataNode004IP=\\\"${DataNode004IP}\\\"\" | sudo tee --append $BigDataSH /dev/null echo -e \"# Cluster Variables END\" | sudo tee --append $BigDataSH /dev/null Then Display the contents of the $BigDataSh file: cat $BigDataSH result should be like: #!/bin/bash # Environment Variables for Big Data tools export BigDataSH=/etc/profile.d/bigdata.sh export IdentityFile=~/.ssh/SSH_keypair.pem export SSHConfigFile=~/.ssh/config # Cluster Variable","date":"2021-12-25","objectID":"/setup-hadoop-cluster-on-ms-azure/:6:1","series":[],"tags":["Hadoop"],"title":"Hadoop Setup","uri":"/setup-hadoop-cluster-on-ms-azure/#common-environment-variables-for-hadoop-clusters"},{"categories":["Note"],"content":"Cluster Environment Setup We have done this: sudo apt -y remove unattended-upgrades \u0026\u0026 sudo apt-get update -y \u0026\u0026 sudo apt-get upgrade -y Secure Admin Account In this case, my admin account’s name is PceWlkr. sudo passwd PceWlkr Common Environment Variables for Hadoop Clusters In general, these include: Java - JAVA_HOME Hadoop - HADOOP_HOME Hive - HIVE_HOME Pig - PIG_HOME The etc/profile.d dir holding shell script will be run at start-up and install fuatures for all users. So we’ll create a file bigdata.sh for later installations. sudo touch /etc/profile.d/bigdata.sh export BigDataSH=/etc/profile.d/bigdata.sh export IdentityFile=\"/.ssh/SSH_keypair.pem\" export SSHConfigFile=\"/.ssh/config\" sudo rm $BigDataSH echo -e '#!/bin/bash \\n' | sudo tee --append $BigDataSH /dev/null echo -e \"# Environment Variables for Big Data tools\\n\" | sudo tee --append $BigDataSH /dev/null echo -e \"export BigDataSH=${BigDataSH}\" | sudo tee --append $BigDataSH /dev/null echo -e \"export IdentityFile=~${IdentityFile}\" | sudo tee --append $BigDataSH /dev/null echo -e \"export SSHConfigFile=~${SSHConfigFile}\\n\" | sudo tee --append $BigDataSH /dev/null sudo chmod 644 $BigDataSH cat $BigDataSH The result should be: #!/bin/bash # Environment Variables for Big Data tools export BigDataSH=/etc/profile.d/bigdata.sh export IdentityFile=~/.ssh/SSH_keypair.pem export SSHConfigFile=~/.ssh/config sudo reboot After rebooting, confirm the vars exist. echo $BigDataSH $IdentityFile $SSHConfigFile The result should be: /etc/profile.d/bigdata.sh /home/PceWlkr/.ssh/SSH_keypair.pem /home/PceWlkr/.ssh/config Map Virtual Machine Cluster Environment Variables Collect the Public DNS and “Internal” IP addresses from your Virtual Machine Instances Copy and paste the following commands into a text editor: export NameNodeDNS=\"Namenode\" export DataNode001DNS=\"Datanode001\" export DataNode002DNS=\"Datanode002\" export DataNode003DNS=\"Datanode003\" export DataNode004DNS=\"Datanode004\" export NameNodeIP=\"10.0.0.4\" export DataNode001IP=\"10.0.0.5\" export DataNode002IP=\"10.0.0.6\" export DataNode003IP=\"10.0.0.7\" Notice: you can use hostname and hostname -I to find the hostname and private IP Copy all of the commands above from the text editor Paste the commands into the SSH session at the command line for your Virtual Machine Instance When you pasted the commands, they were executed automatically. Try to use one of the variables we set: echo $DataNode001DNS The result should look something like this: Datanode001 Execute the following to add the schema to the bigdata.sh file: echo -e \"# Cluster Variables START\" | sudo tee --append $BigDataSH /dev/null echo -e \"export NameNodeDNS=\\\"${NameNodeDNS}\\\"\" | sudo tee --append $BigDataSH /dev/null echo -e \"export DataNode001DNS=\\\"${DataNode001DNS}\\\"\" | sudo tee --append $BigDataSH /dev/null echo -e \"export DataNode002DNS=\\\"${DataNode002DNS}\\\"\" | sudo tee --append $BigDataSH /dev/null echo -e \"export DataNode003DNS=\\\"${DataNode003DNS}\\\"\" | sudo tee --append $BigDataSH /dev/null echo -e \"export DataNode004DNS=\\\"${DataNode004DNS}\\\"\" | sudo tee --append $BigDataSH /dev/null echo -e \"\" | sudo tee --append $BigDataSH /dev/null echo -e \"export NameNodeIP=\\\"${NameNodeIP}\\\"\" | sudo tee --append $BigDataSH /dev/null echo -e \"export DataNode001IP=\\\"${DataNode001IP}\\\"\" | sudo tee --append $BigDataSH /dev/null echo -e \"export DataNode002IP=\\\"${DataNode002IP}\\\"\" | sudo tee --append $BigDataSH /dev/null echo -e \"export DataNode003IP=\\\"${DataNode003IP}\\\"\" | sudo tee --append $BigDataSH /dev/null echo -e \"export DataNode004IP=\\\"${DataNode004IP}\\\"\" | sudo tee --append $BigDataSH /dev/null echo -e \"# Cluster Variables END\" | sudo tee --append $BigDataSH /dev/null Then Display the contents of the $BigDataSh file: cat $BigDataSH result should be like: #!/bin/bash # Environment Variables for Big Data tools export BigDataSH=/etc/profile.d/bigdata.sh export IdentityFile=~/.ssh/SSH_keypair.pem export SSHConfigFile=~/.ssh/config # Cluster Variable","date":"2021-12-25","objectID":"/setup-hadoop-cluster-on-ms-azure/:6:1","series":[],"tags":["Hadoop"],"title":"Hadoop Setup","uri":"/setup-hadoop-cluster-on-ms-azure/#map-virtual-machine-cluster-environment-variables"},{"categories":["Note"],"content":"Cluster Environment Setup We have done this: sudo apt -y remove unattended-upgrades \u0026\u0026 sudo apt-get update -y \u0026\u0026 sudo apt-get upgrade -y Secure Admin Account In this case, my admin account’s name is PceWlkr. sudo passwd PceWlkr Common Environment Variables for Hadoop Clusters In general, these include: Java - JAVA_HOME Hadoop - HADOOP_HOME Hive - HIVE_HOME Pig - PIG_HOME The etc/profile.d dir holding shell script will be run at start-up and install fuatures for all users. So we’ll create a file bigdata.sh for later installations. sudo touch /etc/profile.d/bigdata.sh export BigDataSH=/etc/profile.d/bigdata.sh export IdentityFile=\"/.ssh/SSH_keypair.pem\" export SSHConfigFile=\"/.ssh/config\" sudo rm $BigDataSH echo -e '#!/bin/bash \\n' | sudo tee --append $BigDataSH /dev/null echo -e \"# Environment Variables for Big Data tools\\n\" | sudo tee --append $BigDataSH /dev/null echo -e \"export BigDataSH=${BigDataSH}\" | sudo tee --append $BigDataSH /dev/null echo -e \"export IdentityFile=~${IdentityFile}\" | sudo tee --append $BigDataSH /dev/null echo -e \"export SSHConfigFile=~${SSHConfigFile}\\n\" | sudo tee --append $BigDataSH /dev/null sudo chmod 644 $BigDataSH cat $BigDataSH The result should be: #!/bin/bash # Environment Variables for Big Data tools export BigDataSH=/etc/profile.d/bigdata.sh export IdentityFile=~/.ssh/SSH_keypair.pem export SSHConfigFile=~/.ssh/config sudo reboot After rebooting, confirm the vars exist. echo $BigDataSH $IdentityFile $SSHConfigFile The result should be: /etc/profile.d/bigdata.sh /home/PceWlkr/.ssh/SSH_keypair.pem /home/PceWlkr/.ssh/config Map Virtual Machine Cluster Environment Variables Collect the Public DNS and “Internal” IP addresses from your Virtual Machine Instances Copy and paste the following commands into a text editor: export NameNodeDNS=\"Namenode\" export DataNode001DNS=\"Datanode001\" export DataNode002DNS=\"Datanode002\" export DataNode003DNS=\"Datanode003\" export DataNode004DNS=\"Datanode004\" export NameNodeIP=\"10.0.0.4\" export DataNode001IP=\"10.0.0.5\" export DataNode002IP=\"10.0.0.6\" export DataNode003IP=\"10.0.0.7\" Notice: you can use hostname and hostname -I to find the hostname and private IP Copy all of the commands above from the text editor Paste the commands into the SSH session at the command line for your Virtual Machine Instance When you pasted the commands, they were executed automatically. Try to use one of the variables we set: echo $DataNode001DNS The result should look something like this: Datanode001 Execute the following to add the schema to the bigdata.sh file: echo -e \"# Cluster Variables START\" | sudo tee --append $BigDataSH /dev/null echo -e \"export NameNodeDNS=\\\"${NameNodeDNS}\\\"\" | sudo tee --append $BigDataSH /dev/null echo -e \"export DataNode001DNS=\\\"${DataNode001DNS}\\\"\" | sudo tee --append $BigDataSH /dev/null echo -e \"export DataNode002DNS=\\\"${DataNode002DNS}\\\"\" | sudo tee --append $BigDataSH /dev/null echo -e \"export DataNode003DNS=\\\"${DataNode003DNS}\\\"\" | sudo tee --append $BigDataSH /dev/null echo -e \"export DataNode004DNS=\\\"${DataNode004DNS}\\\"\" | sudo tee --append $BigDataSH /dev/null echo -e \"\" | sudo tee --append $BigDataSH /dev/null echo -e \"export NameNodeIP=\\\"${NameNodeIP}\\\"\" | sudo tee --append $BigDataSH /dev/null echo -e \"export DataNode001IP=\\\"${DataNode001IP}\\\"\" | sudo tee --append $BigDataSH /dev/null echo -e \"export DataNode002IP=\\\"${DataNode002IP}\\\"\" | sudo tee --append $BigDataSH /dev/null echo -e \"export DataNode003IP=\\\"${DataNode003IP}\\\"\" | sudo tee --append $BigDataSH /dev/null echo -e \"export DataNode004IP=\\\"${DataNode004IP}\\\"\" | sudo tee --append $BigDataSH /dev/null echo -e \"# Cluster Variables END\" | sudo tee --append $BigDataSH /dev/null Then Display the contents of the $BigDataSh file: cat $BigDataSH result should be like: #!/bin/bash # Environment Variables for Big Data tools export BigDataSH=/etc/profile.d/bigdata.sh export IdentityFile=~/.ssh/SSH_keypair.pem export SSHConfigFile=~/.ssh/config # Cluster Variable","date":"2021-12-25","objectID":"/setup-hadoop-cluster-on-ms-azure/:6:1","series":[],"tags":["Hadoop"],"title":"Hadoop Setup","uri":"/setup-hadoop-cluster-on-ms-azure/#passwordless-ssh-for-cluster-using-config-and-pem-files"},{"categories":["Note"],"content":"Java Developers Kit (JDK) sudo apt-get -y update sudo apt-get -y install default-jdk confirm you have it: cd /usr/lib/jvm/ \u0026\u0026 ls result should be like: default-java java-1.11.0-openjdk-amd64 java-11-openjdk-amd64 openjdk-11 Add Environment Variables to /etc/profile.d/bigdata.sh Open the file /etc/profile.d/bigdata.sh sudo nano $BigDataSH Add these lines to the end of the bigdata.sh file: export JAVA_HOME=/usr/lib/jvm/default-java PATH=$PATH:$JAVA_HOME/bin Or, copy the following code and paste it at the command line. This will echo the entries into the bigdata.sh file echo \"# JAVA Variables START\" | sudo tee --append $BigDataSH \u003e /dev/null echo \"export JAVA_HOME=/usr/lib/jvm/default-java\" | sudo tee --append $BigDataSH \u003e /dev/null echo \"PATH=\\$PATH:\\$JAVA_HOME/bin\" | sudo tee --append $BigDataSH \u003e /dev/null echo \"# JAVA Variables END\" | sudo tee --append $BigDataSH \u003e /dev/null Confirm that your Java variables were added, open the /etc/profile.d/bigdata.sh file: cat $BigDataSH Your bigdata.sh file output should look like this now: #!/bin/bash # Environment Variables for Big Data tools export BigDataSH=/etc/profile.d/bigdata.sh export IdentityFile=/etc/ssh/ssh_config.d/SSH_keypair.pem export SSHConfigFile=/etc/ssh/ssh_config.d/config.conf # JAVA Variables START export JAVA_HOME=/usr/lib/jvm/default-java PATH=$PATH:$JAVA_HOME/bin # JAVA Variables END sudo reboot Confirm the Java Version and Environment Variables java -version result should be like: openjdk version \"11.0.11\" 2021-04-20 OpenJDK Runtime Environment (build 11.0.11+9-Ubuntu-0ubuntu2.18.04) OpenJDK 64-Bit Server VM (build 11.0.11+9-Ubuntu-0ubuntu2.18.04, mixed mode, sharing) confirm you have it: echo $JAVA_HOME result should be like: /usr/lib/jvm/default-java Java Developers Kit (JDK) for DataNodes in a Cluster To send a command to a DateNode using SSH, we wrap the command with quotes \"\" and ssh into the Node: ssh DataNode001 \"{command}\" Update packages on the server ssh Datanode001 \"sudo apt-get -y update\" ssh Datanode001 \"sudo apt-get -y install default-jdk\" Notice: You will synchronize your DataNodes with the NameNode later, so you do not need to set up environment variables yet. pdsh pdsh is a variant of the rsh(1) command. Unlike rsh(1), which runs commands on a single remote host, pdsh can run multiple remote commands in parallel. pdsh uses a \"sliding window\" (or fanout) of threads to conserve resources on the initiating host while allowing some connections to time out. sudo apt-get -y install pdsh Add the following variable to your bigdata.sh file: export PDSH_RCMD_TYPE=ssh or run this commands: echo -e \"# PDSH Variables START\" | sudo tee --append $BigDataSH \u003e /dev/null echo -e \"export PDSH_RCMD_TYPE=ssh\" | sudo tee --append $BigDataSH \u003e /dev/null echo -e \"# PDSH Variables END\" | sudo tee --append $BigDataSH \u003e /dev/null sudo reboot rsync rsync is a utility for efficiently transferring and synchronizing files across computer systems by checking the timestamp and size of files. It is commonly found on Unix-like systems and functions as both a file synchronization and file transfer program. The rsync algorithm is a type of delta encoding and is used for minimizing network usage. Zlib may be used for additional compression, and SSH or stunnel can be used for data security. rsync(1) - Linux man page sudo apt-get -y install rsync sudo reboot ","date":"2021-12-25","objectID":"/setup-hadoop-cluster-on-ms-azure/:6:2","series":[],"tags":["Hadoop"],"title":"Hadoop Setup","uri":"/setup-hadoop-cluster-on-ms-azure/#java-developers-kit-jdk"},{"categories":["Note"],"content":"Java Developers Kit (JDK) sudo apt-get -y update sudo apt-get -y install default-jdk confirm you have it: cd /usr/lib/jvm/ \u0026\u0026 ls result should be like: default-java java-1.11.0-openjdk-amd64 java-11-openjdk-amd64 openjdk-11 Add Environment Variables to /etc/profile.d/bigdata.sh Open the file /etc/profile.d/bigdata.sh sudo nano $BigDataSH Add these lines to the end of the bigdata.sh file: export JAVA_HOME=/usr/lib/jvm/default-java PATH=$PATH:$JAVA_HOME/bin Or, copy the following code and paste it at the command line. This will echo the entries into the bigdata.sh file echo \"# JAVA Variables START\" | sudo tee --append $BigDataSH /dev/null echo \"export JAVA_HOME=/usr/lib/jvm/default-java\" | sudo tee --append $BigDataSH /dev/null echo \"PATH=\\$PATH:\\$JAVA_HOME/bin\" | sudo tee --append $BigDataSH /dev/null echo \"# JAVA Variables END\" | sudo tee --append $BigDataSH /dev/null Confirm that your Java variables were added, open the /etc/profile.d/bigdata.sh file: cat $BigDataSH Your bigdata.sh file output should look like this now: #!/bin/bash # Environment Variables for Big Data tools export BigDataSH=/etc/profile.d/bigdata.sh export IdentityFile=/etc/ssh/ssh_config.d/SSH_keypair.pem export SSHConfigFile=/etc/ssh/ssh_config.d/config.conf # JAVA Variables START export JAVA_HOME=/usr/lib/jvm/default-java PATH=$PATH:$JAVA_HOME/bin # JAVA Variables END sudo reboot Confirm the Java Version and Environment Variables java -version result should be like: openjdk version \"11.0.11\" 2021-04-20 OpenJDK Runtime Environment (build 11.0.11+9-Ubuntu-0ubuntu2.18.04) OpenJDK 64-Bit Server VM (build 11.0.11+9-Ubuntu-0ubuntu2.18.04, mixed mode, sharing) confirm you have it: echo $JAVA_HOME result should be like: /usr/lib/jvm/default-java Java Developers Kit (JDK) for DataNodes in a Cluster To send a command to a DateNode using SSH, we wrap the command with quotes \"\" and ssh into the Node: ssh DataNode001 \"{command}\" Update packages on the server ssh Datanode001 \"sudo apt-get -y update\" ssh Datanode001 \"sudo apt-get -y install default-jdk\" Notice: You will synchronize your DataNodes with the NameNode later, so you do not need to set up environment variables yet. pdsh pdsh is a variant of the rsh(1) command. Unlike rsh(1), which runs commands on a single remote host, pdsh can run multiple remote commands in parallel. pdsh uses a \"sliding window\" (or fanout) of threads to conserve resources on the initiating host while allowing some connections to time out. sudo apt-get -y install pdsh Add the following variable to your bigdata.sh file: export PDSH_RCMD_TYPE=ssh or run this commands: echo -e \"# PDSH Variables START\" | sudo tee --append $BigDataSH /dev/null echo -e \"export PDSH_RCMD_TYPE=ssh\" | sudo tee --append $BigDataSH /dev/null echo -e \"# PDSH Variables END\" | sudo tee --append $BigDataSH /dev/null sudo reboot rsync rsync is a utility for efficiently transferring and synchronizing files across computer systems by checking the timestamp and size of files. It is commonly found on Unix-like systems and functions as both a file synchronization and file transfer program. The rsync algorithm is a type of delta encoding and is used for minimizing network usage. Zlib may be used for additional compression, and SSH or stunnel can be used for data security. rsync(1) - Linux man page sudo apt-get -y install rsync sudo reboot ","date":"2021-12-25","objectID":"/setup-hadoop-cluster-on-ms-azure/:6:2","series":[],"tags":["Hadoop"],"title":"Hadoop Setup","uri":"/setup-hadoop-cluster-on-ms-azure/#add-environment-variables-to-etcprofiledbigdatash"},{"categories":["Note"],"content":"Java Developers Kit (JDK) sudo apt-get -y update sudo apt-get -y install default-jdk confirm you have it: cd /usr/lib/jvm/ \u0026\u0026 ls result should be like: default-java java-1.11.0-openjdk-amd64 java-11-openjdk-amd64 openjdk-11 Add Environment Variables to /etc/profile.d/bigdata.sh Open the file /etc/profile.d/bigdata.sh sudo nano $BigDataSH Add these lines to the end of the bigdata.sh file: export JAVA_HOME=/usr/lib/jvm/default-java PATH=$PATH:$JAVA_HOME/bin Or, copy the following code and paste it at the command line. This will echo the entries into the bigdata.sh file echo \"# JAVA Variables START\" | sudo tee --append $BigDataSH /dev/null echo \"export JAVA_HOME=/usr/lib/jvm/default-java\" | sudo tee --append $BigDataSH /dev/null echo \"PATH=\\$PATH:\\$JAVA_HOME/bin\" | sudo tee --append $BigDataSH /dev/null echo \"# JAVA Variables END\" | sudo tee --append $BigDataSH /dev/null Confirm that your Java variables were added, open the /etc/profile.d/bigdata.sh file: cat $BigDataSH Your bigdata.sh file output should look like this now: #!/bin/bash # Environment Variables for Big Data tools export BigDataSH=/etc/profile.d/bigdata.sh export IdentityFile=/etc/ssh/ssh_config.d/SSH_keypair.pem export SSHConfigFile=/etc/ssh/ssh_config.d/config.conf # JAVA Variables START export JAVA_HOME=/usr/lib/jvm/default-java PATH=$PATH:$JAVA_HOME/bin # JAVA Variables END sudo reboot Confirm the Java Version and Environment Variables java -version result should be like: openjdk version \"11.0.11\" 2021-04-20 OpenJDK Runtime Environment (build 11.0.11+9-Ubuntu-0ubuntu2.18.04) OpenJDK 64-Bit Server VM (build 11.0.11+9-Ubuntu-0ubuntu2.18.04, mixed mode, sharing) confirm you have it: echo $JAVA_HOME result should be like: /usr/lib/jvm/default-java Java Developers Kit (JDK) for DataNodes in a Cluster To send a command to a DateNode using SSH, we wrap the command with quotes \"\" and ssh into the Node: ssh DataNode001 \"{command}\" Update packages on the server ssh Datanode001 \"sudo apt-get -y update\" ssh Datanode001 \"sudo apt-get -y install default-jdk\" Notice: You will synchronize your DataNodes with the NameNode later, so you do not need to set up environment variables yet. pdsh pdsh is a variant of the rsh(1) command. Unlike rsh(1), which runs commands on a single remote host, pdsh can run multiple remote commands in parallel. pdsh uses a \"sliding window\" (or fanout) of threads to conserve resources on the initiating host while allowing some connections to time out. sudo apt-get -y install pdsh Add the following variable to your bigdata.sh file: export PDSH_RCMD_TYPE=ssh or run this commands: echo -e \"# PDSH Variables START\" | sudo tee --append $BigDataSH /dev/null echo -e \"export PDSH_RCMD_TYPE=ssh\" | sudo tee --append $BigDataSH /dev/null echo -e \"# PDSH Variables END\" | sudo tee --append $BigDataSH /dev/null sudo reboot rsync rsync is a utility for efficiently transferring and synchronizing files across computer systems by checking the timestamp and size of files. It is commonly found on Unix-like systems and functions as both a file synchronization and file transfer program. The rsync algorithm is a type of delta encoding and is used for minimizing network usage. Zlib may be used for additional compression, and SSH or stunnel can be used for data security. rsync(1) - Linux man page sudo apt-get -y install rsync sudo reboot ","date":"2021-12-25","objectID":"/setup-hadoop-cluster-on-ms-azure/:6:2","series":[],"tags":["Hadoop"],"title":"Hadoop Setup","uri":"/setup-hadoop-cluster-on-ms-azure/#confirm-the-java-version-and-environment-variables"},{"categories":["Note"],"content":"Java Developers Kit (JDK) sudo apt-get -y update sudo apt-get -y install default-jdk confirm you have it: cd /usr/lib/jvm/ \u0026\u0026 ls result should be like: default-java java-1.11.0-openjdk-amd64 java-11-openjdk-amd64 openjdk-11 Add Environment Variables to /etc/profile.d/bigdata.sh Open the file /etc/profile.d/bigdata.sh sudo nano $BigDataSH Add these lines to the end of the bigdata.sh file: export JAVA_HOME=/usr/lib/jvm/default-java PATH=$PATH:$JAVA_HOME/bin Or, copy the following code and paste it at the command line. This will echo the entries into the bigdata.sh file echo \"# JAVA Variables START\" | sudo tee --append $BigDataSH /dev/null echo \"export JAVA_HOME=/usr/lib/jvm/default-java\" | sudo tee --append $BigDataSH /dev/null echo \"PATH=\\$PATH:\\$JAVA_HOME/bin\" | sudo tee --append $BigDataSH /dev/null echo \"# JAVA Variables END\" | sudo tee --append $BigDataSH /dev/null Confirm that your Java variables were added, open the /etc/profile.d/bigdata.sh file: cat $BigDataSH Your bigdata.sh file output should look like this now: #!/bin/bash # Environment Variables for Big Data tools export BigDataSH=/etc/profile.d/bigdata.sh export IdentityFile=/etc/ssh/ssh_config.d/SSH_keypair.pem export SSHConfigFile=/etc/ssh/ssh_config.d/config.conf # JAVA Variables START export JAVA_HOME=/usr/lib/jvm/default-java PATH=$PATH:$JAVA_HOME/bin # JAVA Variables END sudo reboot Confirm the Java Version and Environment Variables java -version result should be like: openjdk version \"11.0.11\" 2021-04-20 OpenJDK Runtime Environment (build 11.0.11+9-Ubuntu-0ubuntu2.18.04) OpenJDK 64-Bit Server VM (build 11.0.11+9-Ubuntu-0ubuntu2.18.04, mixed mode, sharing) confirm you have it: echo $JAVA_HOME result should be like: /usr/lib/jvm/default-java Java Developers Kit (JDK) for DataNodes in a Cluster To send a command to a DateNode using SSH, we wrap the command with quotes \"\" and ssh into the Node: ssh DataNode001 \"{command}\" Update packages on the server ssh Datanode001 \"sudo apt-get -y update\" ssh Datanode001 \"sudo apt-get -y install default-jdk\" Notice: You will synchronize your DataNodes with the NameNode later, so you do not need to set up environment variables yet. pdsh pdsh is a variant of the rsh(1) command. Unlike rsh(1), which runs commands on a single remote host, pdsh can run multiple remote commands in parallel. pdsh uses a \"sliding window\" (or fanout) of threads to conserve resources on the initiating host while allowing some connections to time out. sudo apt-get -y install pdsh Add the following variable to your bigdata.sh file: export PDSH_RCMD_TYPE=ssh or run this commands: echo -e \"# PDSH Variables START\" | sudo tee --append $BigDataSH /dev/null echo -e \"export PDSH_RCMD_TYPE=ssh\" | sudo tee --append $BigDataSH /dev/null echo -e \"# PDSH Variables END\" | sudo tee --append $BigDataSH /dev/null sudo reboot rsync rsync is a utility for efficiently transferring and synchronizing files across computer systems by checking the timestamp and size of files. It is commonly found on Unix-like systems and functions as both a file synchronization and file transfer program. The rsync algorithm is a type of delta encoding and is used for minimizing network usage. Zlib may be used for additional compression, and SSH or stunnel can be used for data security. rsync(1) - Linux man page sudo apt-get -y install rsync sudo reboot ","date":"2021-12-25","objectID":"/setup-hadoop-cluster-on-ms-azure/:6:2","series":[],"tags":["Hadoop"],"title":"Hadoop Setup","uri":"/setup-hadoop-cluster-on-ms-azure/#java-developers-kit-jdk-for-datanodes-in-a-cluster"},{"categories":["Note"],"content":"Java Developers Kit (JDK) sudo apt-get -y update sudo apt-get -y install default-jdk confirm you have it: cd /usr/lib/jvm/ \u0026\u0026 ls result should be like: default-java java-1.11.0-openjdk-amd64 java-11-openjdk-amd64 openjdk-11 Add Environment Variables to /etc/profile.d/bigdata.sh Open the file /etc/profile.d/bigdata.sh sudo nano $BigDataSH Add these lines to the end of the bigdata.sh file: export JAVA_HOME=/usr/lib/jvm/default-java PATH=$PATH:$JAVA_HOME/bin Or, copy the following code and paste it at the command line. This will echo the entries into the bigdata.sh file echo \"# JAVA Variables START\" | sudo tee --append $BigDataSH /dev/null echo \"export JAVA_HOME=/usr/lib/jvm/default-java\" | sudo tee --append $BigDataSH /dev/null echo \"PATH=\\$PATH:\\$JAVA_HOME/bin\" | sudo tee --append $BigDataSH /dev/null echo \"# JAVA Variables END\" | sudo tee --append $BigDataSH /dev/null Confirm that your Java variables were added, open the /etc/profile.d/bigdata.sh file: cat $BigDataSH Your bigdata.sh file output should look like this now: #!/bin/bash # Environment Variables for Big Data tools export BigDataSH=/etc/profile.d/bigdata.sh export IdentityFile=/etc/ssh/ssh_config.d/SSH_keypair.pem export SSHConfigFile=/etc/ssh/ssh_config.d/config.conf # JAVA Variables START export JAVA_HOME=/usr/lib/jvm/default-java PATH=$PATH:$JAVA_HOME/bin # JAVA Variables END sudo reboot Confirm the Java Version and Environment Variables java -version result should be like: openjdk version \"11.0.11\" 2021-04-20 OpenJDK Runtime Environment (build 11.0.11+9-Ubuntu-0ubuntu2.18.04) OpenJDK 64-Bit Server VM (build 11.0.11+9-Ubuntu-0ubuntu2.18.04, mixed mode, sharing) confirm you have it: echo $JAVA_HOME result should be like: /usr/lib/jvm/default-java Java Developers Kit (JDK) for DataNodes in a Cluster To send a command to a DateNode using SSH, we wrap the command with quotes \"\" and ssh into the Node: ssh DataNode001 \"{command}\" Update packages on the server ssh Datanode001 \"sudo apt-get -y update\" ssh Datanode001 \"sudo apt-get -y install default-jdk\" Notice: You will synchronize your DataNodes with the NameNode later, so you do not need to set up environment variables yet. pdsh pdsh is a variant of the rsh(1) command. Unlike rsh(1), which runs commands on a single remote host, pdsh can run multiple remote commands in parallel. pdsh uses a \"sliding window\" (or fanout) of threads to conserve resources on the initiating host while allowing some connections to time out. sudo apt-get -y install pdsh Add the following variable to your bigdata.sh file: export PDSH_RCMD_TYPE=ssh or run this commands: echo -e \"# PDSH Variables START\" | sudo tee --append $BigDataSH /dev/null echo -e \"export PDSH_RCMD_TYPE=ssh\" | sudo tee --append $BigDataSH /dev/null echo -e \"# PDSH Variables END\" | sudo tee --append $BigDataSH /dev/null sudo reboot rsync rsync is a utility for efficiently transferring and synchronizing files across computer systems by checking the timestamp and size of files. It is commonly found on Unix-like systems and functions as both a file synchronization and file transfer program. The rsync algorithm is a type of delta encoding and is used for minimizing network usage. Zlib may be used for additional compression, and SSH or stunnel can be used for data security. rsync(1) - Linux man page sudo apt-get -y install rsync sudo reboot ","date":"2021-12-25","objectID":"/setup-hadoop-cluster-on-ms-azure/:6:2","series":[],"tags":["Hadoop"],"title":"Hadoop Setup","uri":"/setup-hadoop-cluster-on-ms-azure/#update-packages-on-the-server"},{"categories":["Note"],"content":"Java Developers Kit (JDK) sudo apt-get -y update sudo apt-get -y install default-jdk confirm you have it: cd /usr/lib/jvm/ \u0026\u0026 ls result should be like: default-java java-1.11.0-openjdk-amd64 java-11-openjdk-amd64 openjdk-11 Add Environment Variables to /etc/profile.d/bigdata.sh Open the file /etc/profile.d/bigdata.sh sudo nano $BigDataSH Add these lines to the end of the bigdata.sh file: export JAVA_HOME=/usr/lib/jvm/default-java PATH=$PATH:$JAVA_HOME/bin Or, copy the following code and paste it at the command line. This will echo the entries into the bigdata.sh file echo \"# JAVA Variables START\" | sudo tee --append $BigDataSH /dev/null echo \"export JAVA_HOME=/usr/lib/jvm/default-java\" | sudo tee --append $BigDataSH /dev/null echo \"PATH=\\$PATH:\\$JAVA_HOME/bin\" | sudo tee --append $BigDataSH /dev/null echo \"# JAVA Variables END\" | sudo tee --append $BigDataSH /dev/null Confirm that your Java variables were added, open the /etc/profile.d/bigdata.sh file: cat $BigDataSH Your bigdata.sh file output should look like this now: #!/bin/bash # Environment Variables for Big Data tools export BigDataSH=/etc/profile.d/bigdata.sh export IdentityFile=/etc/ssh/ssh_config.d/SSH_keypair.pem export SSHConfigFile=/etc/ssh/ssh_config.d/config.conf # JAVA Variables START export JAVA_HOME=/usr/lib/jvm/default-java PATH=$PATH:$JAVA_HOME/bin # JAVA Variables END sudo reboot Confirm the Java Version and Environment Variables java -version result should be like: openjdk version \"11.0.11\" 2021-04-20 OpenJDK Runtime Environment (build 11.0.11+9-Ubuntu-0ubuntu2.18.04) OpenJDK 64-Bit Server VM (build 11.0.11+9-Ubuntu-0ubuntu2.18.04, mixed mode, sharing) confirm you have it: echo $JAVA_HOME result should be like: /usr/lib/jvm/default-java Java Developers Kit (JDK) for DataNodes in a Cluster To send a command to a DateNode using SSH, we wrap the command with quotes \"\" and ssh into the Node: ssh DataNode001 \"{command}\" Update packages on the server ssh Datanode001 \"sudo apt-get -y update\" ssh Datanode001 \"sudo apt-get -y install default-jdk\" Notice: You will synchronize your DataNodes with the NameNode later, so you do not need to set up environment variables yet. pdsh pdsh is a variant of the rsh(1) command. Unlike rsh(1), which runs commands on a single remote host, pdsh can run multiple remote commands in parallel. pdsh uses a \"sliding window\" (or fanout) of threads to conserve resources on the initiating host while allowing some connections to time out. sudo apt-get -y install pdsh Add the following variable to your bigdata.sh file: export PDSH_RCMD_TYPE=ssh or run this commands: echo -e \"# PDSH Variables START\" | sudo tee --append $BigDataSH /dev/null echo -e \"export PDSH_RCMD_TYPE=ssh\" | sudo tee --append $BigDataSH /dev/null echo -e \"# PDSH Variables END\" | sudo tee --append $BigDataSH /dev/null sudo reboot rsync rsync is a utility for efficiently transferring and synchronizing files across computer systems by checking the timestamp and size of files. It is commonly found on Unix-like systems and functions as both a file synchronization and file transfer program. The rsync algorithm is a type of delta encoding and is used for minimizing network usage. Zlib may be used for additional compression, and SSH or stunnel can be used for data security. rsync(1) - Linux man page sudo apt-get -y install rsync sudo reboot ","date":"2021-12-25","objectID":"/setup-hadoop-cluster-on-ms-azure/:6:2","series":[],"tags":["Hadoop"],"title":"Hadoop Setup","uri":"/setup-hadoop-cluster-on-ms-azure/#pdsh"},{"categories":["Note"],"content":"Java Developers Kit (JDK) sudo apt-get -y update sudo apt-get -y install default-jdk confirm you have it: cd /usr/lib/jvm/ \u0026\u0026 ls result should be like: default-java java-1.11.0-openjdk-amd64 java-11-openjdk-amd64 openjdk-11 Add Environment Variables to /etc/profile.d/bigdata.sh Open the file /etc/profile.d/bigdata.sh sudo nano $BigDataSH Add these lines to the end of the bigdata.sh file: export JAVA_HOME=/usr/lib/jvm/default-java PATH=$PATH:$JAVA_HOME/bin Or, copy the following code and paste it at the command line. This will echo the entries into the bigdata.sh file echo \"# JAVA Variables START\" | sudo tee --append $BigDataSH /dev/null echo \"export JAVA_HOME=/usr/lib/jvm/default-java\" | sudo tee --append $BigDataSH /dev/null echo \"PATH=\\$PATH:\\$JAVA_HOME/bin\" | sudo tee --append $BigDataSH /dev/null echo \"# JAVA Variables END\" | sudo tee --append $BigDataSH /dev/null Confirm that your Java variables were added, open the /etc/profile.d/bigdata.sh file: cat $BigDataSH Your bigdata.sh file output should look like this now: #!/bin/bash # Environment Variables for Big Data tools export BigDataSH=/etc/profile.d/bigdata.sh export IdentityFile=/etc/ssh/ssh_config.d/SSH_keypair.pem export SSHConfigFile=/etc/ssh/ssh_config.d/config.conf # JAVA Variables START export JAVA_HOME=/usr/lib/jvm/default-java PATH=$PATH:$JAVA_HOME/bin # JAVA Variables END sudo reboot Confirm the Java Version and Environment Variables java -version result should be like: openjdk version \"11.0.11\" 2021-04-20 OpenJDK Runtime Environment (build 11.0.11+9-Ubuntu-0ubuntu2.18.04) OpenJDK 64-Bit Server VM (build 11.0.11+9-Ubuntu-0ubuntu2.18.04, mixed mode, sharing) confirm you have it: echo $JAVA_HOME result should be like: /usr/lib/jvm/default-java Java Developers Kit (JDK) for DataNodes in a Cluster To send a command to a DateNode using SSH, we wrap the command with quotes \"\" and ssh into the Node: ssh DataNode001 \"{command}\" Update packages on the server ssh Datanode001 \"sudo apt-get -y update\" ssh Datanode001 \"sudo apt-get -y install default-jdk\" Notice: You will synchronize your DataNodes with the NameNode later, so you do not need to set up environment variables yet. pdsh pdsh is a variant of the rsh(1) command. Unlike rsh(1), which runs commands on a single remote host, pdsh can run multiple remote commands in parallel. pdsh uses a \"sliding window\" (or fanout) of threads to conserve resources on the initiating host while allowing some connections to time out. sudo apt-get -y install pdsh Add the following variable to your bigdata.sh file: export PDSH_RCMD_TYPE=ssh or run this commands: echo -e \"# PDSH Variables START\" | sudo tee --append $BigDataSH /dev/null echo -e \"export PDSH_RCMD_TYPE=ssh\" | sudo tee --append $BigDataSH /dev/null echo -e \"# PDSH Variables END\" | sudo tee --append $BigDataSH /dev/null sudo reboot rsync rsync is a utility for efficiently transferring and synchronizing files across computer systems by checking the timestamp and size of files. It is commonly found on Unix-like systems and functions as both a file synchronization and file transfer program. The rsync algorithm is a type of delta encoding and is used for minimizing network usage. Zlib may be used for additional compression, and SSH or stunnel can be used for data security. rsync(1) - Linux man page sudo apt-get -y install rsync sudo reboot ","date":"2021-12-25","objectID":"/setup-hadoop-cluster-on-ms-azure/:6:2","series":[],"tags":["Hadoop"],"title":"Hadoop Setup","uri":"/setup-hadoop-cluster-on-ms-azure/#rsync"},{"categories":["Note"],"content":"Install and Configure Hadoop as a Single Node Cluster ","date":"2021-12-25","objectID":"/setup-hadoop-cluster-on-ms-azure/:7:0","series":[],"tags":["Hadoop"],"title":"Hadoop Setup","uri":"/setup-hadoop-cluster-on-ms-azure/#install-and-configure-hadoop-as-a-single-node-cluster"},{"categories":["Note"],"content":"Download Hadoop from Apache wget http://apache.forsale.plus/hadoop/common/hadoop-3.3.1/hadoop-3.3.1.tar.gz -P ~/Downloads/Hadoop ","date":"2021-12-25","objectID":"/setup-hadoop-cluster-on-ms-azure/:7:1","series":[],"tags":["Hadoop"],"title":"Hadoop Setup","uri":"/setup-hadoop-cluster-on-ms-azure/#download-hadoop-from-apache"},{"categories":["Note"],"content":"Uncompress the Hadoop tar file into the /usr/local folder sudo tar -zxvf ~/Downloads/Hadoop/hadoop-*.tar.gz -C /usr/local ","date":"2021-12-25","objectID":"/setup-hadoop-cluster-on-ms-azure/:7:2","series":[],"tags":["Hadoop"],"title":"Hadoop Setup","uri":"/setup-hadoop-cluster-on-ms-azure/#uncompress-the-hadoop-tar-file-into-the-usrlocal-folder"},{"categories":["Note"],"content":"Rename the hadoop-* directory to /usr/local/hadoop sudo mv /usr/local/hadoop-* /usr/local/hadoop/ ","date":"2021-12-25","objectID":"/setup-hadoop-cluster-on-ms-azure/:7:3","series":[],"tags":["Hadoop"],"title":"Hadoop Setup","uri":"/setup-hadoop-cluster-on-ms-azure/#rename-the-hadoop--directory-to-usrlocalhadoop"},{"categories":["Note"],"content":"Modify permissions on /usr/local/hadoop/ Allow read+write on the /usr/local/hadoop/ directory for anyone in the hadoop user group. Double Check! Before you run this command, confirm that you have created a hadoop user group. See Hadoop User and Group Hadoop User named (hduser) and User Group named (hadoop) Add the hadoop User Group sudo addgroup hadoop sudo adduser hduser Add hduser to User Groups Run this command to add hduser to the hadoop user group: sudo usermod -a -G hadoop hduser Run this command to add hduser to the sudo (superuser) user group: sudo usermod -a -G sudo hduser We will also add the user to the hadoop user group. sudo usermod -a -G hadoop PceWlkr Now you can switch to hduser when you type this command: su - hduser Confirm which groups hduser is a member of: groups hduser The result should look something like this: hduser : hduser sudo hadoop sudo reboot su - hduser Back to Topic This command will set ownership of all files and directories in the /usr/local/hadoop/ directory: sudo chown PceWlkr:PceWlkr -R /usr/local/hadoop/ Set the permissions on the /usr/local/hadoop/ directory to rwxrwxr–: rwxrwxr– User and Group: Read + Write + Execute Other users: read sudo chmod -R 774 /usr/local/hadoop/ Set Environment Variables Use this command to edit the /etc/profile.d/bigdata.sh file: sudo nano $BigDataSH export HADOOP_HOME=\"/usr/local/hadoop\" export HADOOP_CONF_DIR=\"${HADOOP_HOME}/etc/hadoop\" export YARN_EXAMPLES=\"${HADOOP_HOME}/share/hadoop/mapreduce\" PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin or run these: echo -e \"# HADOOP Variables START\" | sudo tee --append $BigDataSH \u003e /dev/null echo -e \"export HADOOP_HOME=\\\"/usr/local/hadoop\\\"\" | sudo tee --append $BigDataSH \u003e /dev/null echo -e \"export HADOOP_CONF_DIR=\\\"\\${HADOOP_HOME}/etc/hadoop\\\"\" | sudo tee --append $BigDataSH \u003e /dev/null echo -e \"export YARN_EXAMPLES=\\\"\\${HADOOP_HOME}/share/hadoop/mapreduce\\\"\" | sudo tee --append $BigDataSH \u003e /dev/null echo -e \"PATH=\\$PATH:\\$HADOOP_HOME/bin:\\$HADOOP_HOME/sbin\" | sudo tee --append $BigDataSH \u003e /dev/null echo -e \"# HADOOP Variables END\" | sudo tee --append $BigDataSH \u003e /dev/null Instantiate Environment Variables The following command will instantiate the new variables available immediately. You can use this method to instantiate variables in any of the modified shell scripts .sh files: source $BigDataSH test if it’s there: echo $HADOOP_HOME result should be: /usr/local/hadoop sudo reboot Test Environment Variables echo $HADOOP_HOME Test Hadoop Version hadoop version ","date":"2021-12-25","objectID":"/setup-hadoop-cluster-on-ms-azure/:7:4","series":[],"tags":["Hadoop"],"title":"Hadoop Setup","uri":"/setup-hadoop-cluster-on-ms-azure/#modify-permissions-on-usrlocalhadoop"},{"categories":["Note"],"content":"Modify permissions on /usr/local/hadoop/ Allow read+write on the /usr/local/hadoop/ directory for anyone in the hadoop user group. Double Check! Before you run this command, confirm that you have created a hadoop user group. See Hadoop User and Group Hadoop User named (hduser) and User Group named (hadoop) Add the hadoop User Group sudo addgroup hadoop sudo adduser hduser Add hduser to User Groups Run this command to add hduser to the hadoop user group: sudo usermod -a -G hadoop hduser Run this command to add hduser to the sudo (superuser) user group: sudo usermod -a -G sudo hduser We will also add the user to the hadoop user group. sudo usermod -a -G hadoop PceWlkr Now you can switch to hduser when you type this command: su - hduser Confirm which groups hduser is a member of: groups hduser The result should look something like this: hduser : hduser sudo hadoop sudo reboot su - hduser Back to Topic This command will set ownership of all files and directories in the /usr/local/hadoop/ directory: sudo chown PceWlkr:PceWlkr -R /usr/local/hadoop/ Set the permissions on the /usr/local/hadoop/ directory to rwxrwxr–: rwxrwxr– User and Group: Read + Write + Execute Other users: read sudo chmod -R 774 /usr/local/hadoop/ Set Environment Variables Use this command to edit the /etc/profile.d/bigdata.sh file: sudo nano $BigDataSH export HADOOP_HOME=\"/usr/local/hadoop\" export HADOOP_CONF_DIR=\"${HADOOP_HOME}/etc/hadoop\" export YARN_EXAMPLES=\"${HADOOP_HOME}/share/hadoop/mapreduce\" PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin or run these: echo -e \"# HADOOP Variables START\" | sudo tee --append $BigDataSH /dev/null echo -e \"export HADOOP_HOME=\\\"/usr/local/hadoop\\\"\" | sudo tee --append $BigDataSH /dev/null echo -e \"export HADOOP_CONF_DIR=\\\"\\${HADOOP_HOME}/etc/hadoop\\\"\" | sudo tee --append $BigDataSH /dev/null echo -e \"export YARN_EXAMPLES=\\\"\\${HADOOP_HOME}/share/hadoop/mapreduce\\\"\" | sudo tee --append $BigDataSH /dev/null echo -e \"PATH=\\$PATH:\\$HADOOP_HOME/bin:\\$HADOOP_HOME/sbin\" | sudo tee --append $BigDataSH /dev/null echo -e \"# HADOOP Variables END\" | sudo tee --append $BigDataSH /dev/null Instantiate Environment Variables The following command will instantiate the new variables available immediately. You can use this method to instantiate variables in any of the modified shell scripts .sh files: source $BigDataSH test if it’s there: echo $HADOOP_HOME result should be: /usr/local/hadoop sudo reboot Test Environment Variables echo $HADOOP_HOME Test Hadoop Version hadoop version ","date":"2021-12-25","objectID":"/setup-hadoop-cluster-on-ms-azure/:7:4","series":[],"tags":["Hadoop"],"title":"Hadoop Setup","uri":"/setup-hadoop-cluster-on-ms-azure/#double-check"},{"categories":["Note"],"content":"Modify permissions on /usr/local/hadoop/ Allow read+write on the /usr/local/hadoop/ directory for anyone in the hadoop user group. Double Check! Before you run this command, confirm that you have created a hadoop user group. See Hadoop User and Group Hadoop User named (hduser) and User Group named (hadoop) Add the hadoop User Group sudo addgroup hadoop sudo adduser hduser Add hduser to User Groups Run this command to add hduser to the hadoop user group: sudo usermod -a -G hadoop hduser Run this command to add hduser to the sudo (superuser) user group: sudo usermod -a -G sudo hduser We will also add the user to the hadoop user group. sudo usermod -a -G hadoop PceWlkr Now you can switch to hduser when you type this command: su - hduser Confirm which groups hduser is a member of: groups hduser The result should look something like this: hduser : hduser sudo hadoop sudo reboot su - hduser Back to Topic This command will set ownership of all files and directories in the /usr/local/hadoop/ directory: sudo chown PceWlkr:PceWlkr -R /usr/local/hadoop/ Set the permissions on the /usr/local/hadoop/ directory to rwxrwxr–: rwxrwxr– User and Group: Read + Write + Execute Other users: read sudo chmod -R 774 /usr/local/hadoop/ Set Environment Variables Use this command to edit the /etc/profile.d/bigdata.sh file: sudo nano $BigDataSH export HADOOP_HOME=\"/usr/local/hadoop\" export HADOOP_CONF_DIR=\"${HADOOP_HOME}/etc/hadoop\" export YARN_EXAMPLES=\"${HADOOP_HOME}/share/hadoop/mapreduce\" PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin or run these: echo -e \"# HADOOP Variables START\" | sudo tee --append $BigDataSH /dev/null echo -e \"export HADOOP_HOME=\\\"/usr/local/hadoop\\\"\" | sudo tee --append $BigDataSH /dev/null echo -e \"export HADOOP_CONF_DIR=\\\"\\${HADOOP_HOME}/etc/hadoop\\\"\" | sudo tee --append $BigDataSH /dev/null echo -e \"export YARN_EXAMPLES=\\\"\\${HADOOP_HOME}/share/hadoop/mapreduce\\\"\" | sudo tee --append $BigDataSH /dev/null echo -e \"PATH=\\$PATH:\\$HADOOP_HOME/bin:\\$HADOOP_HOME/sbin\" | sudo tee --append $BigDataSH /dev/null echo -e \"# HADOOP Variables END\" | sudo tee --append $BigDataSH /dev/null Instantiate Environment Variables The following command will instantiate the new variables available immediately. You can use this method to instantiate variables in any of the modified shell scripts .sh files: source $BigDataSH test if it’s there: echo $HADOOP_HOME result should be: /usr/local/hadoop sudo reboot Test Environment Variables echo $HADOOP_HOME Test Hadoop Version hadoop version ","date":"2021-12-25","objectID":"/setup-hadoop-cluster-on-ms-azure/:7:4","series":[],"tags":["Hadoop"],"title":"Hadoop Setup","uri":"/setup-hadoop-cluster-on-ms-azure/#hadoop-user-named-hduser-and-user-group-named-hadoop"},{"categories":["Note"],"content":"Modify permissions on /usr/local/hadoop/ Allow read+write on the /usr/local/hadoop/ directory for anyone in the hadoop user group. Double Check! Before you run this command, confirm that you have created a hadoop user group. See Hadoop User and Group Hadoop User named (hduser) and User Group named (hadoop) Add the hadoop User Group sudo addgroup hadoop sudo adduser hduser Add hduser to User Groups Run this command to add hduser to the hadoop user group: sudo usermod -a -G hadoop hduser Run this command to add hduser to the sudo (superuser) user group: sudo usermod -a -G sudo hduser We will also add the user to the hadoop user group. sudo usermod -a -G hadoop PceWlkr Now you can switch to hduser when you type this command: su - hduser Confirm which groups hduser is a member of: groups hduser The result should look something like this: hduser : hduser sudo hadoop sudo reboot su - hduser Back to Topic This command will set ownership of all files and directories in the /usr/local/hadoop/ directory: sudo chown PceWlkr:PceWlkr -R /usr/local/hadoop/ Set the permissions on the /usr/local/hadoop/ directory to rwxrwxr–: rwxrwxr– User and Group: Read + Write + Execute Other users: read sudo chmod -R 774 /usr/local/hadoop/ Set Environment Variables Use this command to edit the /etc/profile.d/bigdata.sh file: sudo nano $BigDataSH export HADOOP_HOME=\"/usr/local/hadoop\" export HADOOP_CONF_DIR=\"${HADOOP_HOME}/etc/hadoop\" export YARN_EXAMPLES=\"${HADOOP_HOME}/share/hadoop/mapreduce\" PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin or run these: echo -e \"# HADOOP Variables START\" | sudo tee --append $BigDataSH /dev/null echo -e \"export HADOOP_HOME=\\\"/usr/local/hadoop\\\"\" | sudo tee --append $BigDataSH /dev/null echo -e \"export HADOOP_CONF_DIR=\\\"\\${HADOOP_HOME}/etc/hadoop\\\"\" | sudo tee --append $BigDataSH /dev/null echo -e \"export YARN_EXAMPLES=\\\"\\${HADOOP_HOME}/share/hadoop/mapreduce\\\"\" | sudo tee --append $BigDataSH /dev/null echo -e \"PATH=\\$PATH:\\$HADOOP_HOME/bin:\\$HADOOP_HOME/sbin\" | sudo tee --append $BigDataSH /dev/null echo -e \"# HADOOP Variables END\" | sudo tee --append $BigDataSH /dev/null Instantiate Environment Variables The following command will instantiate the new variables available immediately. You can use this method to instantiate variables in any of the modified shell scripts .sh files: source $BigDataSH test if it’s there: echo $HADOOP_HOME result should be: /usr/local/hadoop sudo reboot Test Environment Variables echo $HADOOP_HOME Test Hadoop Version hadoop version ","date":"2021-12-25","objectID":"/setup-hadoop-cluster-on-ms-azure/:7:4","series":[],"tags":["Hadoop"],"title":"Hadoop Setup","uri":"/setup-hadoop-cluster-on-ms-azure/#add-the-hadoop-user-group"},{"categories":["Note"],"content":"Modify permissions on /usr/local/hadoop/ Allow read+write on the /usr/local/hadoop/ directory for anyone in the hadoop user group. Double Check! Before you run this command, confirm that you have created a hadoop user group. See Hadoop User and Group Hadoop User named (hduser) and User Group named (hadoop) Add the hadoop User Group sudo addgroup hadoop sudo adduser hduser Add hduser to User Groups Run this command to add hduser to the hadoop user group: sudo usermod -a -G hadoop hduser Run this command to add hduser to the sudo (superuser) user group: sudo usermod -a -G sudo hduser We will also add the user to the hadoop user group. sudo usermod -a -G hadoop PceWlkr Now you can switch to hduser when you type this command: su - hduser Confirm which groups hduser is a member of: groups hduser The result should look something like this: hduser : hduser sudo hadoop sudo reboot su - hduser Back to Topic This command will set ownership of all files and directories in the /usr/local/hadoop/ directory: sudo chown PceWlkr:PceWlkr -R /usr/local/hadoop/ Set the permissions on the /usr/local/hadoop/ directory to rwxrwxr–: rwxrwxr– User and Group: Read + Write + Execute Other users: read sudo chmod -R 774 /usr/local/hadoop/ Set Environment Variables Use this command to edit the /etc/profile.d/bigdata.sh file: sudo nano $BigDataSH export HADOOP_HOME=\"/usr/local/hadoop\" export HADOOP_CONF_DIR=\"${HADOOP_HOME}/etc/hadoop\" export YARN_EXAMPLES=\"${HADOOP_HOME}/share/hadoop/mapreduce\" PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin or run these: echo -e \"# HADOOP Variables START\" | sudo tee --append $BigDataSH /dev/null echo -e \"export HADOOP_HOME=\\\"/usr/local/hadoop\\\"\" | sudo tee --append $BigDataSH /dev/null echo -e \"export HADOOP_CONF_DIR=\\\"\\${HADOOP_HOME}/etc/hadoop\\\"\" | sudo tee --append $BigDataSH /dev/null echo -e \"export YARN_EXAMPLES=\\\"\\${HADOOP_HOME}/share/hadoop/mapreduce\\\"\" | sudo tee --append $BigDataSH /dev/null echo -e \"PATH=\\$PATH:\\$HADOOP_HOME/bin:\\$HADOOP_HOME/sbin\" | sudo tee --append $BigDataSH /dev/null echo -e \"# HADOOP Variables END\" | sudo tee --append $BigDataSH /dev/null Instantiate Environment Variables The following command will instantiate the new variables available immediately. You can use this method to instantiate variables in any of the modified shell scripts .sh files: source $BigDataSH test if it’s there: echo $HADOOP_HOME result should be: /usr/local/hadoop sudo reboot Test Environment Variables echo $HADOOP_HOME Test Hadoop Version hadoop version ","date":"2021-12-25","objectID":"/setup-hadoop-cluster-on-ms-azure/:7:4","series":[],"tags":["Hadoop"],"title":"Hadoop Setup","uri":"/setup-hadoop-cluster-on-ms-azure/#add-hduser-to-user-groups"},{"categories":["Note"],"content":"Modify permissions on /usr/local/hadoop/ Allow read+write on the /usr/local/hadoop/ directory for anyone in the hadoop user group. Double Check! Before you run this command, confirm that you have created a hadoop user group. See Hadoop User and Group Hadoop User named (hduser) and User Group named (hadoop) Add the hadoop User Group sudo addgroup hadoop sudo adduser hduser Add hduser to User Groups Run this command to add hduser to the hadoop user group: sudo usermod -a -G hadoop hduser Run this command to add hduser to the sudo (superuser) user group: sudo usermod -a -G sudo hduser We will also add the user to the hadoop user group. sudo usermod -a -G hadoop PceWlkr Now you can switch to hduser when you type this command: su - hduser Confirm which groups hduser is a member of: groups hduser The result should look something like this: hduser : hduser sudo hadoop sudo reboot su - hduser Back to Topic This command will set ownership of all files and directories in the /usr/local/hadoop/ directory: sudo chown PceWlkr:PceWlkr -R /usr/local/hadoop/ Set the permissions on the /usr/local/hadoop/ directory to rwxrwxr–: rwxrwxr– User and Group: Read + Write + Execute Other users: read sudo chmod -R 774 /usr/local/hadoop/ Set Environment Variables Use this command to edit the /etc/profile.d/bigdata.sh file: sudo nano $BigDataSH export HADOOP_HOME=\"/usr/local/hadoop\" export HADOOP_CONF_DIR=\"${HADOOP_HOME}/etc/hadoop\" export YARN_EXAMPLES=\"${HADOOP_HOME}/share/hadoop/mapreduce\" PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin or run these: echo -e \"# HADOOP Variables START\" | sudo tee --append $BigDataSH /dev/null echo -e \"export HADOOP_HOME=\\\"/usr/local/hadoop\\\"\" | sudo tee --append $BigDataSH /dev/null echo -e \"export HADOOP_CONF_DIR=\\\"\\${HADOOP_HOME}/etc/hadoop\\\"\" | sudo tee --append $BigDataSH /dev/null echo -e \"export YARN_EXAMPLES=\\\"\\${HADOOP_HOME}/share/hadoop/mapreduce\\\"\" | sudo tee --append $BigDataSH /dev/null echo -e \"PATH=\\$PATH:\\$HADOOP_HOME/bin:\\$HADOOP_HOME/sbin\" | sudo tee --append $BigDataSH /dev/null echo -e \"# HADOOP Variables END\" | sudo tee --append $BigDataSH /dev/null Instantiate Environment Variables The following command will instantiate the new variables available immediately. You can use this method to instantiate variables in any of the modified shell scripts .sh files: source $BigDataSH test if it’s there: echo $HADOOP_HOME result should be: /usr/local/hadoop sudo reboot Test Environment Variables echo $HADOOP_HOME Test Hadoop Version hadoop version ","date":"2021-12-25","objectID":"/setup-hadoop-cluster-on-ms-azure/:7:4","series":[],"tags":["Hadoop"],"title":"Hadoop Setup","uri":"/setup-hadoop-cluster-on-ms-azure/#back-to-topic"},{"categories":["Note"],"content":"Modify permissions on /usr/local/hadoop/ Allow read+write on the /usr/local/hadoop/ directory for anyone in the hadoop user group. Double Check! Before you run this command, confirm that you have created a hadoop user group. See Hadoop User and Group Hadoop User named (hduser) and User Group named (hadoop) Add the hadoop User Group sudo addgroup hadoop sudo adduser hduser Add hduser to User Groups Run this command to add hduser to the hadoop user group: sudo usermod -a -G hadoop hduser Run this command to add hduser to the sudo (superuser) user group: sudo usermod -a -G sudo hduser We will also add the user to the hadoop user group. sudo usermod -a -G hadoop PceWlkr Now you can switch to hduser when you type this command: su - hduser Confirm which groups hduser is a member of: groups hduser The result should look something like this: hduser : hduser sudo hadoop sudo reboot su - hduser Back to Topic This command will set ownership of all files and directories in the /usr/local/hadoop/ directory: sudo chown PceWlkr:PceWlkr -R /usr/local/hadoop/ Set the permissions on the /usr/local/hadoop/ directory to rwxrwxr–: rwxrwxr– User and Group: Read + Write + Execute Other users: read sudo chmod -R 774 /usr/local/hadoop/ Set Environment Variables Use this command to edit the /etc/profile.d/bigdata.sh file: sudo nano $BigDataSH export HADOOP_HOME=\"/usr/local/hadoop\" export HADOOP_CONF_DIR=\"${HADOOP_HOME}/etc/hadoop\" export YARN_EXAMPLES=\"${HADOOP_HOME}/share/hadoop/mapreduce\" PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin or run these: echo -e \"# HADOOP Variables START\" | sudo tee --append $BigDataSH /dev/null echo -e \"export HADOOP_HOME=\\\"/usr/local/hadoop\\\"\" | sudo tee --append $BigDataSH /dev/null echo -e \"export HADOOP_CONF_DIR=\\\"\\${HADOOP_HOME}/etc/hadoop\\\"\" | sudo tee --append $BigDataSH /dev/null echo -e \"export YARN_EXAMPLES=\\\"\\${HADOOP_HOME}/share/hadoop/mapreduce\\\"\" | sudo tee --append $BigDataSH /dev/null echo -e \"PATH=\\$PATH:\\$HADOOP_HOME/bin:\\$HADOOP_HOME/sbin\" | sudo tee --append $BigDataSH /dev/null echo -e \"# HADOOP Variables END\" | sudo tee --append $BigDataSH /dev/null Instantiate Environment Variables The following command will instantiate the new variables available immediately. You can use this method to instantiate variables in any of the modified shell scripts .sh files: source $BigDataSH test if it’s there: echo $HADOOP_HOME result should be: /usr/local/hadoop sudo reboot Test Environment Variables echo $HADOOP_HOME Test Hadoop Version hadoop version ","date":"2021-12-25","objectID":"/setup-hadoop-cluster-on-ms-azure/:7:4","series":[],"tags":["Hadoop"],"title":"Hadoop Setup","uri":"/setup-hadoop-cluster-on-ms-azure/#set-environment-variables"},{"categories":["Note"],"content":"Modify permissions on /usr/local/hadoop/ Allow read+write on the /usr/local/hadoop/ directory for anyone in the hadoop user group. Double Check! Before you run this command, confirm that you have created a hadoop user group. See Hadoop User and Group Hadoop User named (hduser) and User Group named (hadoop) Add the hadoop User Group sudo addgroup hadoop sudo adduser hduser Add hduser to User Groups Run this command to add hduser to the hadoop user group: sudo usermod -a -G hadoop hduser Run this command to add hduser to the sudo (superuser) user group: sudo usermod -a -G sudo hduser We will also add the user to the hadoop user group. sudo usermod -a -G hadoop PceWlkr Now you can switch to hduser when you type this command: su - hduser Confirm which groups hduser is a member of: groups hduser The result should look something like this: hduser : hduser sudo hadoop sudo reboot su - hduser Back to Topic This command will set ownership of all files and directories in the /usr/local/hadoop/ directory: sudo chown PceWlkr:PceWlkr -R /usr/local/hadoop/ Set the permissions on the /usr/local/hadoop/ directory to rwxrwxr–: rwxrwxr– User and Group: Read + Write + Execute Other users: read sudo chmod -R 774 /usr/local/hadoop/ Set Environment Variables Use this command to edit the /etc/profile.d/bigdata.sh file: sudo nano $BigDataSH export HADOOP_HOME=\"/usr/local/hadoop\" export HADOOP_CONF_DIR=\"${HADOOP_HOME}/etc/hadoop\" export YARN_EXAMPLES=\"${HADOOP_HOME}/share/hadoop/mapreduce\" PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin or run these: echo -e \"# HADOOP Variables START\" | sudo tee --append $BigDataSH /dev/null echo -e \"export HADOOP_HOME=\\\"/usr/local/hadoop\\\"\" | sudo tee --append $BigDataSH /dev/null echo -e \"export HADOOP_CONF_DIR=\\\"\\${HADOOP_HOME}/etc/hadoop\\\"\" | sudo tee --append $BigDataSH /dev/null echo -e \"export YARN_EXAMPLES=\\\"\\${HADOOP_HOME}/share/hadoop/mapreduce\\\"\" | sudo tee --append $BigDataSH /dev/null echo -e \"PATH=\\$PATH:\\$HADOOP_HOME/bin:\\$HADOOP_HOME/sbin\" | sudo tee --append $BigDataSH /dev/null echo -e \"# HADOOP Variables END\" | sudo tee --append $BigDataSH /dev/null Instantiate Environment Variables The following command will instantiate the new variables available immediately. You can use this method to instantiate variables in any of the modified shell scripts .sh files: source $BigDataSH test if it’s there: echo $HADOOP_HOME result should be: /usr/local/hadoop sudo reboot Test Environment Variables echo $HADOOP_HOME Test Hadoop Version hadoop version ","date":"2021-12-25","objectID":"/setup-hadoop-cluster-on-ms-azure/:7:4","series":[],"tags":["Hadoop"],"title":"Hadoop Setup","uri":"/setup-hadoop-cluster-on-ms-azure/#instantiate-environment-variables"},{"categories":["Note"],"content":"Modify permissions on /usr/local/hadoop/ Allow read+write on the /usr/local/hadoop/ directory for anyone in the hadoop user group. Double Check! Before you run this command, confirm that you have created a hadoop user group. See Hadoop User and Group Hadoop User named (hduser) and User Group named (hadoop) Add the hadoop User Group sudo addgroup hadoop sudo adduser hduser Add hduser to User Groups Run this command to add hduser to the hadoop user group: sudo usermod -a -G hadoop hduser Run this command to add hduser to the sudo (superuser) user group: sudo usermod -a -G sudo hduser We will also add the user to the hadoop user group. sudo usermod -a -G hadoop PceWlkr Now you can switch to hduser when you type this command: su - hduser Confirm which groups hduser is a member of: groups hduser The result should look something like this: hduser : hduser sudo hadoop sudo reboot su - hduser Back to Topic This command will set ownership of all files and directories in the /usr/local/hadoop/ directory: sudo chown PceWlkr:PceWlkr -R /usr/local/hadoop/ Set the permissions on the /usr/local/hadoop/ directory to rwxrwxr–: rwxrwxr– User and Group: Read + Write + Execute Other users: read sudo chmod -R 774 /usr/local/hadoop/ Set Environment Variables Use this command to edit the /etc/profile.d/bigdata.sh file: sudo nano $BigDataSH export HADOOP_HOME=\"/usr/local/hadoop\" export HADOOP_CONF_DIR=\"${HADOOP_HOME}/etc/hadoop\" export YARN_EXAMPLES=\"${HADOOP_HOME}/share/hadoop/mapreduce\" PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin or run these: echo -e \"# HADOOP Variables START\" | sudo tee --append $BigDataSH /dev/null echo -e \"export HADOOP_HOME=\\\"/usr/local/hadoop\\\"\" | sudo tee --append $BigDataSH /dev/null echo -e \"export HADOOP_CONF_DIR=\\\"\\${HADOOP_HOME}/etc/hadoop\\\"\" | sudo tee --append $BigDataSH /dev/null echo -e \"export YARN_EXAMPLES=\\\"\\${HADOOP_HOME}/share/hadoop/mapreduce\\\"\" | sudo tee --append $BigDataSH /dev/null echo -e \"PATH=\\$PATH:\\$HADOOP_HOME/bin:\\$HADOOP_HOME/sbin\" | sudo tee --append $BigDataSH /dev/null echo -e \"# HADOOP Variables END\" | sudo tee --append $BigDataSH /dev/null Instantiate Environment Variables The following command will instantiate the new variables available immediately. You can use this method to instantiate variables in any of the modified shell scripts .sh files: source $BigDataSH test if it’s there: echo $HADOOP_HOME result should be: /usr/local/hadoop sudo reboot Test Environment Variables echo $HADOOP_HOME Test Hadoop Version hadoop version ","date":"2021-12-25","objectID":"/setup-hadoop-cluster-on-ms-azure/:7:4","series":[],"tags":["Hadoop"],"title":"Hadoop Setup","uri":"/setup-hadoop-cluster-on-ms-azure/#test-environment-variables"},{"categories":["Note"],"content":"Modify permissions on /usr/local/hadoop/ Allow read+write on the /usr/local/hadoop/ directory for anyone in the hadoop user group. Double Check! Before you run this command, confirm that you have created a hadoop user group. See Hadoop User and Group Hadoop User named (hduser) and User Group named (hadoop) Add the hadoop User Group sudo addgroup hadoop sudo adduser hduser Add hduser to User Groups Run this command to add hduser to the hadoop user group: sudo usermod -a -G hadoop hduser Run this command to add hduser to the sudo (superuser) user group: sudo usermod -a -G sudo hduser We will also add the user to the hadoop user group. sudo usermod -a -G hadoop PceWlkr Now you can switch to hduser when you type this command: su - hduser Confirm which groups hduser is a member of: groups hduser The result should look something like this: hduser : hduser sudo hadoop sudo reboot su - hduser Back to Topic This command will set ownership of all files and directories in the /usr/local/hadoop/ directory: sudo chown PceWlkr:PceWlkr -R /usr/local/hadoop/ Set the permissions on the /usr/local/hadoop/ directory to rwxrwxr–: rwxrwxr– User and Group: Read + Write + Execute Other users: read sudo chmod -R 774 /usr/local/hadoop/ Set Environment Variables Use this command to edit the /etc/profile.d/bigdata.sh file: sudo nano $BigDataSH export HADOOP_HOME=\"/usr/local/hadoop\" export HADOOP_CONF_DIR=\"${HADOOP_HOME}/etc/hadoop\" export YARN_EXAMPLES=\"${HADOOP_HOME}/share/hadoop/mapreduce\" PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin or run these: echo -e \"# HADOOP Variables START\" | sudo tee --append $BigDataSH /dev/null echo -e \"export HADOOP_HOME=\\\"/usr/local/hadoop\\\"\" | sudo tee --append $BigDataSH /dev/null echo -e \"export HADOOP_CONF_DIR=\\\"\\${HADOOP_HOME}/etc/hadoop\\\"\" | sudo tee --append $BigDataSH /dev/null echo -e \"export YARN_EXAMPLES=\\\"\\${HADOOP_HOME}/share/hadoop/mapreduce\\\"\" | sudo tee --append $BigDataSH /dev/null echo -e \"PATH=\\$PATH:\\$HADOOP_HOME/bin:\\$HADOOP_HOME/sbin\" | sudo tee --append $BigDataSH /dev/null echo -e \"# HADOOP Variables END\" | sudo tee --append $BigDataSH /dev/null Instantiate Environment Variables The following command will instantiate the new variables available immediately. You can use this method to instantiate variables in any of the modified shell scripts .sh files: source $BigDataSH test if it’s there: echo $HADOOP_HOME result should be: /usr/local/hadoop sudo reboot Test Environment Variables echo $HADOOP_HOME Test Hadoop Version hadoop version ","date":"2021-12-25","objectID":"/setup-hadoop-cluster-on-ms-azure/:7:4","series":[],"tags":["Hadoop"],"title":"Hadoop Setup","uri":"/setup-hadoop-cluster-on-ms-azure/#test-hadoop-version"},{"categories":["Note"],"content":"Hadoop Configuration Files Add JAVA_HOME Variable to $HADOOP_CONF_DIR/hadoop-env.sh echo $JAVA_HOME sudo nano $HADOOP_CONF_DIR/hadoop-env.sh Locate the area in the hadoop-env.sh file that indicates the JAVA_HOME variable. For Hadoop 3.3.1, this is on line 54. The line should look something like this: # export JAVA_HOME= Change the line entry to look like this statement; this value should be the same as your JAVA_HOME environment variable: export JAVA_HOME=/usr/lib/jvm/default-java sed -i 's/# export JAVA_HOME=/export JAVA_HOME=\\/usr\\/lib\\/jvm\\/default-java # export JAVA_HOME=/g' $HADOOP_CONF_DIR/hadoop-env.sh cat $BigDataSH result should be: # The java implementation to use. By default, this environment # variable is REQUIRED on ALL platforms except OS X! export JAVA_HOME=/usr/lib/jvm/default-java Modify $HADOOP_CONF_DIR/core-site.xml sudo nano $HADOOP_CONF_DIR/core-site.xml Replace the contents of the core-site.xml file section with the following lines: \u003cconfiguration\u003e \u003c!--Custom Properties--\u003e \u003cproperty\u003e \u003cname\u003ethisnamenode\u003c/name\u003e \u003cvalue\u003elocalhost\u003c/value\u003e \u003cdescription\u003eThis used as a variable throughout the configuration files. localhost may be replaced with a DNS that points to the NameNode. \u003c/description\u003e \u003c/property\u003e \u003cproperty\u003e \u003cname\u003ehomefolder\u003c/name\u003e \u003cvalue\u003e/home/${user.name}\u003c/value\u003e \u003c/property\u003e \u003cproperty\u003e \u003cname\u003efs.defaultFS\u003c/name\u003e \u003cvalue\u003ehdfs://${thisnamenode}:9000\u003c/value\u003e \u003cdescription\u003elocalhost may be replaced with a DNS that points to the NameNode.\u003c/description\u003e \u003c/property\u003e \u003c!-- Do not enable permission check --\u003e \u003cproperty\u003e \u003cname\u003edfs.permissions.enabled\u003c/name\u003e \u003cvalue\u003efalse\u003c/value\u003e \u003cdescription\u003eIf \"true\", enable permission checking in HDFS. If \"false\", permission checking is turned off, but all other behavior is unchanged. Switching from one parameter value to the other does not change the mode, owner or group of files or directories. \u003c/description\u003e \u003c/property\u003e \u003c!-- The current user is all set to root --\u003e \u003cproperty\u003e \u003cname\u003ehadoop.http.staticuser.user\u003c/name\u003e \u003c!-- For Virtual Machine Instances in the Cloud, use ubuntu --\u003e \u003c!-- \u003cvalue\u003ePcewlkr\u003c/value\u003e --\u003e \u003cvalue\u003ePcewlkr\u003c/value\u003e \u003cdescription\u003ePcewlkr is the default user for our NameNode. This property sets the WebUI user for file browsing. For Virtual Machine Instances in the Cloud, use Pcewlkr \u003c/description\u003e \u003c/property\u003e \u003c/configuration\u003e Modify $HADOOP_CONF_DIR/yarn-site.xml sudo nano $HADOOP_CONF_DIR/yarn-site.xml \u003cconfiguration\u003e \u003cproperty\u003e \u003cname\u003eyarn.nodemanager.aux-services\u003c/name\u003e \u003cvalue\u003emapreduce_shuffle\u003c/value\u003e \u003c/property\u003e \u003cproperty\u003e \u003cname\u003emapred.job.tracker\u003c/name\u003e \u003cvalue\u003e${thisnamenode}:9001\u003c/value\u003e \u003c/property\u003e \u003cproperty\u003e \u003cname\u003eyarn.nodemanager.env-whitelist\u003c/name\u003e \u003cvalue\u003eJAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_MAPRED_HOME\u003c/value\u003e \u003c/property\u003e \u003c/configuration\u003e Modify $HADOOP_CONF_DIR/mapred-site.xml sudo nano $HADOOP_CONF_DIR/mapred-site.xml \u003cconfiguration\u003e \u003cproperty\u003e \u003cname\u003emapreduce.jobtracker.address\u003c/name\u003e \u003cvalue\u003elocal\u003c/value\u003e \u003c/property\u003e \u003cproperty\u003e \u003cname\u003emapreduce.framework.name\u003c/name\u003e \u003cvalue\u003eyarn\u003c/value\u003e \u003c/property\u003e \u003c/configuration\u003e Modify $HADOOP_CONF_DIR/hdfs-site.xml sudo nano $HADOOP_CONF_DIR/hdfs-site.xml \u003cconfiguration\u003e \u003cproperty\u003e \u003cname\u003edfs.replication\u003c/name\u003e \u003c!--\u003cvalue\u003e3\u003c/value\u003e--\u003e \u003cvalue\u003e1\u003c/value\u003e \u003cdescription\u003eDefault block replication. The actual number of replications can be specified when the file is created. The default is used if replication is not specified in create time. When migrating your cluster to a Fully Distributed Cluster, change this to 3. \u003c/description\u003e \u003c/property\u003e \u003cproperty\u003e \u003cname\u003edfs.permissions.enabled\u003c/name\u003e \u003cvalue\u003efalse\u003c/value\u003e \u003cdescription\u003eIf \"true\", enable permission checking in HDFS. If \"false\", permission checking is turned off, but all other behavior is unchanged. Switching from one parameter value to the other does not change the mode, owner or group of files or directories. \u003c/description\u003e \u003c/property\u003e \u003cproperty\u003e \u003cname\u003edfs.namenode.name.dir\u003c/name\u003e \u003cvalue\u003efile:///","date":"2021-12-25","objectID":"/setup-hadoop-cluster-on-ms-azure/:7:5","series":[],"tags":["Hadoop"],"title":"Hadoop Setup","uri":"/setup-hadoop-cluster-on-ms-azure/#hadoop-configuration-files"},{"categories":["Note"],"content":"Hadoop Configuration Files Add JAVA_HOME Variable to $HADOOP_CONF_DIR/hadoop-env.sh echo $JAVA_HOME sudo nano $HADOOP_CONF_DIR/hadoop-env.sh Locate the area in the hadoop-env.sh file that indicates the JAVA_HOME variable. For Hadoop 3.3.1, this is on line 54. The line should look something like this: # export JAVA_HOME= Change the line entry to look like this statement; this value should be the same as your JAVA_HOME environment variable: export JAVA_HOME=/usr/lib/jvm/default-java sed -i 's/# export JAVA_HOME=/export JAVA_HOME=\\/usr\\/lib\\/jvm\\/default-java # export JAVA_HOME=/g' $HADOOP_CONF_DIR/hadoop-env.sh cat $BigDataSH result should be: # The java implementation to use. By default, this environment # variable is REQUIRED on ALL platforms except OS X! export JAVA_HOME=/usr/lib/jvm/default-java Modify $HADOOP_CONF_DIR/core-site.xml sudo nano $HADOOP_CONF_DIR/core-site.xml Replace the contents of the core-site.xml file section with the following lines: thisnamenode localhost This used as a variable throughout the configuration files. localhost may be replaced with a DNS that points to the NameNode. homefolder /home/${user.name} fs.defaultFS hdfs://${thisnamenode}:9000 localhost may be replaced with a DNS that points to the NameNode. dfs.permissions.enabled false If \"true\", enable permission checking in HDFS. If \"false\", permission checking is turned off, but all other behavior is unchanged. Switching from one parameter value to the other does not change the mode, owner or group of files or directories. hadoop.http.staticuser.user Pcewlkr -- Pcewlkr Pcewlkr is the default user for our NameNode. This property sets the WebUI user for file browsing. For Virtual Machine Instances in the Cloud, use Pcewlkr Modify $HADOOP_CONF_DIR/yarn-site.xml sudo nano $HADOOP_CONF_DIR/yarn-site.xml yarn.nodemanager.aux-services mapreduce_shuffle mapred.job.tracker ${thisnamenode}:9001 yarn.nodemanager.env-whitelist JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_MAPRED_HOME Modify $HADOOP_CONF_DIR/mapred-site.xml sudo nano $HADOOP_CONF_DIR/mapred-site.xml mapreduce.jobtracker.address local mapreduce.framework.name yarn Modify $HADOOP_CONF_DIR/hdfs-site.xml sudo nano $HADOOP_CONF_DIR/hdfs-site.xml dfs.replication 3-- 1 Default block replication. The actual number of replications can be specified when the file is created. The default is used if replication is not specified in create time. When migrating your cluster to a Fully Distributed Cluster, change this to 3. dfs.permissions.enabled false If \"true\", enable permission checking in HDFS. If \"false\", permission checking is turned off, but all other behavior is unchanged. Switching from one parameter value to the other does not change the mode, owner or group of files or directories. dfs.namenode.name.dir file:///","date":"2021-12-25","objectID":"/setup-hadoop-cluster-on-ms-azure/:7:5","series":[],"tags":["Hadoop"],"title":"Hadoop Setup","uri":"/setup-hadoop-cluster-on-ms-azure/#add-java_home-variable-to-hadoop_conf_dirhadoop-envsh"},{"categories":["Note"],"content":"Hadoop Configuration Files Add JAVA_HOME Variable to $HADOOP_CONF_DIR/hadoop-env.sh echo $JAVA_HOME sudo nano $HADOOP_CONF_DIR/hadoop-env.sh Locate the area in the hadoop-env.sh file that indicates the JAVA_HOME variable. For Hadoop 3.3.1, this is on line 54. The line should look something like this: # export JAVA_HOME= Change the line entry to look like this statement; this value should be the same as your JAVA_HOME environment variable: export JAVA_HOME=/usr/lib/jvm/default-java sed -i 's/# export JAVA_HOME=/export JAVA_HOME=\\/usr\\/lib\\/jvm\\/default-java # export JAVA_HOME=/g' $HADOOP_CONF_DIR/hadoop-env.sh cat $BigDataSH result should be: # The java implementation to use. By default, this environment # variable is REQUIRED on ALL platforms except OS X! export JAVA_HOME=/usr/lib/jvm/default-java Modify $HADOOP_CONF_DIR/core-site.xml sudo nano $HADOOP_CONF_DIR/core-site.xml Replace the contents of the core-site.xml file section with the following lines: thisnamenode localhost This used as a variable throughout the configuration files. localhost may be replaced with a DNS that points to the NameNode. homefolder /home/${user.name} fs.defaultFS hdfs://${thisnamenode}:9000 localhost may be replaced with a DNS that points to the NameNode. dfs.permissions.enabled false If \"true\", enable permission checking in HDFS. If \"false\", permission checking is turned off, but all other behavior is unchanged. Switching from one parameter value to the other does not change the mode, owner or group of files or directories. hadoop.http.staticuser.user Pcewlkr -- Pcewlkr Pcewlkr is the default user for our NameNode. This property sets the WebUI user for file browsing. For Virtual Machine Instances in the Cloud, use Pcewlkr Modify $HADOOP_CONF_DIR/yarn-site.xml sudo nano $HADOOP_CONF_DIR/yarn-site.xml yarn.nodemanager.aux-services mapreduce_shuffle mapred.job.tracker ${thisnamenode}:9001 yarn.nodemanager.env-whitelist JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_MAPRED_HOME Modify $HADOOP_CONF_DIR/mapred-site.xml sudo nano $HADOOP_CONF_DIR/mapred-site.xml mapreduce.jobtracker.address local mapreduce.framework.name yarn Modify $HADOOP_CONF_DIR/hdfs-site.xml sudo nano $HADOOP_CONF_DIR/hdfs-site.xml dfs.replication 3-- 1 Default block replication. The actual number of replications can be specified when the file is created. The default is used if replication is not specified in create time. When migrating your cluster to a Fully Distributed Cluster, change this to 3. dfs.permissions.enabled false If \"true\", enable permission checking in HDFS. If \"false\", permission checking is turned off, but all other behavior is unchanged. Switching from one parameter value to the other does not change the mode, owner or group of files or directories. dfs.namenode.name.dir file:///","date":"2021-12-25","objectID":"/setup-hadoop-cluster-on-ms-azure/:7:5","series":[],"tags":["Hadoop"],"title":"Hadoop Setup","uri":"/setup-hadoop-cluster-on-ms-azure/#modify-hadoop_conf_dircore-sitexml"},{"categories":["Note"],"content":"Hadoop Configuration Files Add JAVA_HOME Variable to $HADOOP_CONF_DIR/hadoop-env.sh echo $JAVA_HOME sudo nano $HADOOP_CONF_DIR/hadoop-env.sh Locate the area in the hadoop-env.sh file that indicates the JAVA_HOME variable. For Hadoop 3.3.1, this is on line 54. The line should look something like this: # export JAVA_HOME= Change the line entry to look like this statement; this value should be the same as your JAVA_HOME environment variable: export JAVA_HOME=/usr/lib/jvm/default-java sed -i 's/# export JAVA_HOME=/export JAVA_HOME=\\/usr\\/lib\\/jvm\\/default-java # export JAVA_HOME=/g' $HADOOP_CONF_DIR/hadoop-env.sh cat $BigDataSH result should be: # The java implementation to use. By default, this environment # variable is REQUIRED on ALL platforms except OS X! export JAVA_HOME=/usr/lib/jvm/default-java Modify $HADOOP_CONF_DIR/core-site.xml sudo nano $HADOOP_CONF_DIR/core-site.xml Replace the contents of the core-site.xml file section with the following lines: thisnamenode localhost This used as a variable throughout the configuration files. localhost may be replaced with a DNS that points to the NameNode. homefolder /home/${user.name} fs.defaultFS hdfs://${thisnamenode}:9000 localhost may be replaced with a DNS that points to the NameNode. dfs.permissions.enabled false If \"true\", enable permission checking in HDFS. If \"false\", permission checking is turned off, but all other behavior is unchanged. Switching from one parameter value to the other does not change the mode, owner or group of files or directories. hadoop.http.staticuser.user Pcewlkr -- Pcewlkr Pcewlkr is the default user for our NameNode. This property sets the WebUI user for file browsing. For Virtual Machine Instances in the Cloud, use Pcewlkr Modify $HADOOP_CONF_DIR/yarn-site.xml sudo nano $HADOOP_CONF_DIR/yarn-site.xml yarn.nodemanager.aux-services mapreduce_shuffle mapred.job.tracker ${thisnamenode}:9001 yarn.nodemanager.env-whitelist JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_MAPRED_HOME Modify $HADOOP_CONF_DIR/mapred-site.xml sudo nano $HADOOP_CONF_DIR/mapred-site.xml mapreduce.jobtracker.address local mapreduce.framework.name yarn Modify $HADOOP_CONF_DIR/hdfs-site.xml sudo nano $HADOOP_CONF_DIR/hdfs-site.xml dfs.replication 3-- 1 Default block replication. The actual number of replications can be specified when the file is created. The default is used if replication is not specified in create time. When migrating your cluster to a Fully Distributed Cluster, change this to 3. dfs.permissions.enabled false If \"true\", enable permission checking in HDFS. If \"false\", permission checking is turned off, but all other behavior is unchanged. Switching from one parameter value to the other does not change the mode, owner or group of files or directories. dfs.namenode.name.dir file:///","date":"2021-12-25","objectID":"/setup-hadoop-cluster-on-ms-azure/:7:5","series":[],"tags":["Hadoop"],"title":"Hadoop Setup","uri":"/setup-hadoop-cluster-on-ms-azure/#modify-hadoop_conf_diryarn-sitexml"},{"categories":["Note"],"content":"Hadoop Configuration Files Add JAVA_HOME Variable to $HADOOP_CONF_DIR/hadoop-env.sh echo $JAVA_HOME sudo nano $HADOOP_CONF_DIR/hadoop-env.sh Locate the area in the hadoop-env.sh file that indicates the JAVA_HOME variable. For Hadoop 3.3.1, this is on line 54. The line should look something like this: # export JAVA_HOME= Change the line entry to look like this statement; this value should be the same as your JAVA_HOME environment variable: export JAVA_HOME=/usr/lib/jvm/default-java sed -i 's/# export JAVA_HOME=/export JAVA_HOME=\\/usr\\/lib\\/jvm\\/default-java # export JAVA_HOME=/g' $HADOOP_CONF_DIR/hadoop-env.sh cat $BigDataSH result should be: # The java implementation to use. By default, this environment # variable is REQUIRED on ALL platforms except OS X! export JAVA_HOME=/usr/lib/jvm/default-java Modify $HADOOP_CONF_DIR/core-site.xml sudo nano $HADOOP_CONF_DIR/core-site.xml Replace the contents of the core-site.xml file section with the following lines: thisnamenode localhost This used as a variable throughout the configuration files. localhost may be replaced with a DNS that points to the NameNode. homefolder /home/${user.name} fs.defaultFS hdfs://${thisnamenode}:9000 localhost may be replaced with a DNS that points to the NameNode. dfs.permissions.enabled false If \"true\", enable permission checking in HDFS. If \"false\", permission checking is turned off, but all other behavior is unchanged. Switching from one parameter value to the other does not change the mode, owner or group of files or directories. hadoop.http.staticuser.user Pcewlkr -- Pcewlkr Pcewlkr is the default user for our NameNode. This property sets the WebUI user for file browsing. For Virtual Machine Instances in the Cloud, use Pcewlkr Modify $HADOOP_CONF_DIR/yarn-site.xml sudo nano $HADOOP_CONF_DIR/yarn-site.xml yarn.nodemanager.aux-services mapreduce_shuffle mapred.job.tracker ${thisnamenode}:9001 yarn.nodemanager.env-whitelist JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_MAPRED_HOME Modify $HADOOP_CONF_DIR/mapred-site.xml sudo nano $HADOOP_CONF_DIR/mapred-site.xml mapreduce.jobtracker.address local mapreduce.framework.name yarn Modify $HADOOP_CONF_DIR/hdfs-site.xml sudo nano $HADOOP_CONF_DIR/hdfs-site.xml dfs.replication 3-- 1 Default block replication. The actual number of replications can be specified when the file is created. The default is used if replication is not specified in create time. When migrating your cluster to a Fully Distributed Cluster, change this to 3. dfs.permissions.enabled false If \"true\", enable permission checking in HDFS. If \"false\", permission checking is turned off, but all other behavior is unchanged. Switching from one parameter value to the other does not change the mode, owner or group of files or directories. dfs.namenode.name.dir file:///","date":"2021-12-25","objectID":"/setup-hadoop-cluster-on-ms-azure/:7:5","series":[],"tags":["Hadoop"],"title":"Hadoop Setup","uri":"/setup-hadoop-cluster-on-ms-azure/#modify-hadoop_conf_dirmapred-sitexml"},{"categories":["Note"],"content":"Hadoop Configuration Files Add JAVA_HOME Variable to $HADOOP_CONF_DIR/hadoop-env.sh echo $JAVA_HOME sudo nano $HADOOP_CONF_DIR/hadoop-env.sh Locate the area in the hadoop-env.sh file that indicates the JAVA_HOME variable. For Hadoop 3.3.1, this is on line 54. The line should look something like this: # export JAVA_HOME= Change the line entry to look like this statement; this value should be the same as your JAVA_HOME environment variable: export JAVA_HOME=/usr/lib/jvm/default-java sed -i 's/# export JAVA_HOME=/export JAVA_HOME=\\/usr\\/lib\\/jvm\\/default-java # export JAVA_HOME=/g' $HADOOP_CONF_DIR/hadoop-env.sh cat $BigDataSH result should be: # The java implementation to use. By default, this environment # variable is REQUIRED on ALL platforms except OS X! export JAVA_HOME=/usr/lib/jvm/default-java Modify $HADOOP_CONF_DIR/core-site.xml sudo nano $HADOOP_CONF_DIR/core-site.xml Replace the contents of the core-site.xml file section with the following lines: thisnamenode localhost This used as a variable throughout the configuration files. localhost may be replaced with a DNS that points to the NameNode. homefolder /home/${user.name} fs.defaultFS hdfs://${thisnamenode}:9000 localhost may be replaced with a DNS that points to the NameNode. dfs.permissions.enabled false If \"true\", enable permission checking in HDFS. If \"false\", permission checking is turned off, but all other behavior is unchanged. Switching from one parameter value to the other does not change the mode, owner or group of files or directories. hadoop.http.staticuser.user Pcewlkr -- Pcewlkr Pcewlkr is the default user for our NameNode. This property sets the WebUI user for file browsing. For Virtual Machine Instances in the Cloud, use Pcewlkr Modify $HADOOP_CONF_DIR/yarn-site.xml sudo nano $HADOOP_CONF_DIR/yarn-site.xml yarn.nodemanager.aux-services mapreduce_shuffle mapred.job.tracker ${thisnamenode}:9001 yarn.nodemanager.env-whitelist JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_MAPRED_HOME Modify $HADOOP_CONF_DIR/mapred-site.xml sudo nano $HADOOP_CONF_DIR/mapred-site.xml mapreduce.jobtracker.address local mapreduce.framework.name yarn Modify $HADOOP_CONF_DIR/hdfs-site.xml sudo nano $HADOOP_CONF_DIR/hdfs-site.xml dfs.replication 3-- 1 Default block replication. The actual number of replications can be specified when the file is created. The default is used if replication is not specified in create time. When migrating your cluster to a Fully Distributed Cluster, change this to 3. dfs.permissions.enabled false If \"true\", enable permission checking in HDFS. If \"false\", permission checking is turned off, but all other behavior is unchanged. Switching from one parameter value to the other does not change the mode, owner or group of files or directories. dfs.namenode.name.dir file:///","date":"2021-12-25","objectID":"/setup-hadoop-cluster-on-ms-azure/:7:5","series":[],"tags":["Hadoop"],"title":"Hadoop Setup","uri":"/setup-hadoop-cluster-on-ms-azure/#modify-hadoop_conf_dirhdfs-sitexml"},{"categories":["Note"],"content":"Format the HDFS hdfs namenode -format ","date":"2021-12-25","objectID":"/setup-hadoop-cluster-on-ms-azure/:7:6","series":[],"tags":["Hadoop"],"title":"Hadoop Setup","uri":"/setup-hadoop-cluster-on-ms-azure/#format-the-hdfs"},{"categories":["Note"],"content":"Start up your Hadoop Cluster start-dfs.sh check the namenode http://DNSofNameNode:9870 start-yarn.sh mapred --daemon start historyserver check the history website http://DNSofNameNode:19888 check the resource manager website http://DNSofNameNode:8088 jps will show you the running java processes On windows, edit C:\\Windows\\System32\\drivers\\etc\\hosts, add xxx.xxx.xxx.xxx namenode.internal.cloudapp.net namenode xxx.xxx.xxx.xxx datanode001.internal.cloudapp.net datanode001 xxx.xxx.xxx.xxx datanode002.internal.cloudapp.net datanode002 So that Windows can find the interal website http://namenode:9870 or http://namenode.internal.cloudapp.net:9870 ","date":"2021-12-25","objectID":"/setup-hadoop-cluster-on-ms-azure/:7:7","series":[],"tags":["Hadoop"],"title":"Hadoop Setup","uri":"/setup-hadoop-cluster-on-ms-azure/#start-up-your-hadoop-cluster"},{"categories":["Note"],"content":"Test the HDFS hdfs dfsadmin -report hdfs dfs -mkdir -p /user/PceWlkr/hdfs/tests mkdir -p ~/Documents/HDFS/Tests touch ~/Documents/HDFS/Tests/test.txt hdfs dfs -put ~/Documents/HDFS/Tests/test.txt /user/PceWlkr/hdfs/tests hdfs dfs -ls /user/PceWlkr/hdfs/tests ","date":"2021-12-25","objectID":"/setup-hadoop-cluster-on-ms-azure/:7:8","series":[],"tags":["Hadoop"],"title":"Hadoop Setup","uri":"/setup-hadoop-cluster-on-ms-azure/#test-the-hdfs"},{"categories":["Note"],"content":"Fully Distributed Hadoop Cluster on a Cloud Provider These configuration files include: SSH config SSH_keypair.pem Environment Variables bigdata.sh Environment Setup Java JDK pdsh rsync Hadoop Configuration - the Hadoop entire directory is usually copied directly to the new DataNodes hadoop-env.sh hdfs.site.xml core-site.xml yarn-site.xml mapred-site.xml masters workers ","date":"2021-12-25","objectID":"/setup-hadoop-cluster-on-ms-azure/:8:0","series":[],"tags":["Hadoop"],"title":"Hadoop Setup","uri":"/setup-hadoop-cluster-on-ms-azure/#fully-distributed-hadoop-cluster-on-a-cloud-provider"},{"categories":["Note"],"content":"Configure .masters File sudo touch $HADOOP_CONF_DIR/masters Add the DNS of your Master Node: Namenode Datanode001 Datanode002 sudo chown ubuntu $HADOOP_CONF_DIR/masters sudo chmod 0644 $HADOOP_CONF_DIR/masters ","date":"2021-12-25","objectID":"/setup-hadoop-cluster-on-ms-azure/:8:1","series":[],"tags":["Hadoop"],"title":"Hadoop Setup","uri":"/setup-hadoop-cluster-on-ms-azure/#configure-masters-file"},{"categories":["Note"],"content":"Configure .workers File ‘sudo nano $HADOOP_CONF_DIR/workers’ Add the entries for the Data Nodes: Datanode001 Datanode002 sudo chown ubuntu $HADOOP_CONF_DIR/workers sudo chmod 0644 $HADOOP_CONF_DIR/workers ","date":"2021-12-25","objectID":"/setup-hadoop-cluster-on-ms-azure/:8:2","series":[],"tags":["Hadoop"],"title":"Hadoop Setup","uri":"/setup-hadoop-cluster-on-ms-azure/#configure-workers-file"},{"categories":["Note"],"content":"Modify configuration files for Fully Distributed Cluster sudo nano $HADOOP_CONF_DIR/core-site.xml Change the thisnamenode property value to NameNode in the core-site.xml file. \u003cproperty\u003e \u003cname\u003ethisnamenode\u003c/name\u003e \u003cvalue\u003eNameNode\u003c/value\u003e \u003cdescription\u003eNameNode is the hostname specified in the config file and etc/hosts file. It may be replaced with a DNS that points to your NameNode.\u003c/description\u003e \u003c/property\u003e sudo nano $HADOOP_CONF_DIR/hdfs-site.xml Edit the dfs.replication property in hdfs-site.xml. \u003cproperty\u003e \u003cname\u003edfs.replication\u003c/name\u003e \u003cvalue\u003e3\u003c/value\u003e \u003cdescription\u003eDefault block replication. The actual number of replications can be specified when the file is created. The default is used if replication is not specified in create time. \u003c/description\u003e \u003c/property\u003e ","date":"2021-12-25","objectID":"/setup-hadoop-cluster-on-ms-azure/:8:3","series":[],"tags":["Hadoop"],"title":"Hadoop Setup","uri":"/setup-hadoop-cluster-on-ms-azure/#modify-configuration-files-for-fully-distributed-cluster"},{"categories":["Note"],"content":"Add a DataNode to your Hadoop Cluster stop-dfs.sh scp -p $SSHConfigFile $IdentityFile PceWlkr@Datanode001:~/.ssh/ scp -p $SSHConfigFile $IdentityFile PceWlkr@Datanode002:~/.ssh/ ssh Datanode001 sudo apt -y remove unattended-upgrades \u0026\u0026\rsudo apt-get -y update \u0026\u0026\rsudo apt-get -y upgrade \u0026\u0026\rsudo apt-get -y install default-jdk pdsh rsync exit ssh Datanode002 sudo apt -y remove unattended-upgrades \u0026\u0026\rsudo apt-get -y update \u0026\u0026\rsudo apt-get -y upgrade \u0026\u0026\rsudo apt-get -y install default-jdk pdsh rsync exit If the hadoop directory does not exist on the DataNode, you must first create it. Do this for each DataNode in your Cluster. Create the hadoop directory: ssh PceWlkr@Datanode001 \"sudo mkdir -p ${HADOOP_HOME}/\" ssh PceWlkr@Datanode001 \"sudo chown -R PceWlkr:PceWlkr ${HADOOP_HOME}/\" ssh PceWlkr@Datanode001 \"sudo chmod -R 774 ${HADOOP_HOME}/\" ssh PceWlkr@Datanode002 \"sudo mkdir -p ${HADOOP_HOME}/\" ssh PceWlkr@Datanode002 \"sudo chown -R PceWlkr:PceWlkr ${HADOOP_HOME}/\" ssh PceWlkr@Datanode002 \"sudo chmod -R 774 ${HADOOP_HOME}/\" cat $BigDataSH | ssh PceWlkr@Datanode001 \"sudo tee ${BigDataSH}\" cat $BigDataSH | ssh PceWlkr@Datanode002 \"sudo tee ${BigDataSH}\" sudo rm $HADOOP_HOME/logs/*.* rsync -ravl $HADOOP_HOME PceWlkr@Datanode001:/usr/local/ rsync -ravl $HADOOP_HOME PceWlkr@Datanode002:/usr/local/ Then reboot the Datanode001 and Datanode002 ","date":"2021-12-25","objectID":"/setup-hadoop-cluster-on-ms-azure/:8:4","series":[],"tags":["Hadoop"],"title":"Hadoop Setup","uri":"/setup-hadoop-cluster-on-ms-azure/#add-a-datanode-to-your-hadoop-cluster"},{"categories":["Note"],"content":"Test the HDFS Again ","date":"2021-12-25","objectID":"/setup-hadoop-cluster-on-ms-azure/:8:5","series":[],"tags":["Hadoop"],"title":"Hadoop Setup","uri":"/setup-hadoop-cluster-on-ms-azure/#test-the-hdfs-again"},{"categories":["Note"],"content":"Test MapReduce hadoop jar $YARN_EXAMPLES/hadoop-mapreduce-examples-3.3.1.jar hdfs dfs -mkdir -p /user/PceWlkr/wordcount/input hdfs dfs -chmod -R 777 /user hdfs dfs -put $HADOOP_HOME/*.txt /user/PceWlkr/wordcount/input hadoop jar $YARN_EXAMPLES/hadoop-mapreduce-examples-3.3.1.jar wordcount /user/ubPceWlkrntu/wordcount/input /user/PceWlkr/wordcount/output hdfs dfs -cat /user/PceWlkr/wordcount/output/* ","date":"2021-12-25","objectID":"/setup-hadoop-cluster-on-ms-azure/:8:6","series":[],"tags":["Hadoop"],"title":"Hadoop Setup","uri":"/setup-hadoop-cluster-on-ms-azure/#test-mapreduce"},{"categories":["Note"],"content":"Env Vars The hadoop config directory HADOOP_CONF_DIR The directory of the progtram JAVA_HOME HADOOP_HOME HIVE_HOME PIG_HOME HADOOP_YARN_HOME HADOOP_MAPRED_HOME The path of the files under ~/.ssh/ BigDataSH=/etc/profile.d/bigdata.sh IdentityFile=~/.ssh/SSH_keypair.pem SSHConfigFile=~/.ssh/config The following are DNS and IP for all nodes NameNodeDNS=“Namenode” DataNode001DNS=“Datanode001” DataNode002DNS=“Datanode002” NameNodeIP=“10.0.0.4” DataNode001IP=“10.0.0.5” DataNode002IP=“10.0.0.6” ","date":"2021-12-25","objectID":"/setup-hadoop-cluster-on-ms-azure/:0:0","series":[],"tags":["Hadoop"],"title":"Hadoop Setup","uri":"/setup-hadoop-cluster-on-ms-azure/#env-vars"},{"categories":["Note"],"content":"Env Vars The hadoop config directory HADOOP_CONF_DIR The directory of the progtram JAVA_HOME HADOOP_HOME HIVE_HOME PIG_HOME HADOOP_YARN_HOME HADOOP_MAPRED_HOME The path of the files under ~/.ssh/ BigDataSH=/etc/profile.d/bigdata.sh IdentityFile=~/.ssh/SSH_keypair.pem SSHConfigFile=~/.ssh/config The following are DNS and IP for all nodes NameNodeDNS=“Namenode” DataNode001DNS=“Datanode001” DataNode002DNS=“Datanode002” NameNodeIP=“10.0.0.4” DataNode001IP=“10.0.0.5” DataNode002IP=“10.0.0.6” ","date":"2021-12-25","objectID":"/setup-hadoop-cluster-on-ms-azure/:0:0","series":[],"tags":["Hadoop"],"title":"Hadoop Setup","uri":"/setup-hadoop-cluster-on-ms-azure/#the-hadoop-config-directory"},{"categories":["Note"],"content":"Env Vars The hadoop config directory HADOOP_CONF_DIR The directory of the progtram JAVA_HOME HADOOP_HOME HIVE_HOME PIG_HOME HADOOP_YARN_HOME HADOOP_MAPRED_HOME The path of the files under ~/.ssh/ BigDataSH=/etc/profile.d/bigdata.sh IdentityFile=~/.ssh/SSH_keypair.pem SSHConfigFile=~/.ssh/config The following are DNS and IP for all nodes NameNodeDNS=“Namenode” DataNode001DNS=“Datanode001” DataNode002DNS=“Datanode002” NameNodeIP=“10.0.0.4” DataNode001IP=“10.0.0.5” DataNode002IP=“10.0.0.6” ","date":"2021-12-25","objectID":"/setup-hadoop-cluster-on-ms-azure/:0:0","series":[],"tags":["Hadoop"],"title":"Hadoop Setup","uri":"/setup-hadoop-cluster-on-ms-azure/#the-directory-of-the-progtram"},{"categories":["Note"],"content":"Env Vars The hadoop config directory HADOOP_CONF_DIR The directory of the progtram JAVA_HOME HADOOP_HOME HIVE_HOME PIG_HOME HADOOP_YARN_HOME HADOOP_MAPRED_HOME The path of the files under ~/.ssh/ BigDataSH=/etc/profile.d/bigdata.sh IdentityFile=~/.ssh/SSH_keypair.pem SSHConfigFile=~/.ssh/config The following are DNS and IP for all nodes NameNodeDNS=“Namenode” DataNode001DNS=“Datanode001” DataNode002DNS=“Datanode002” NameNodeIP=“10.0.0.4” DataNode001IP=“10.0.0.5” DataNode002IP=“10.0.0.6” ","date":"2021-12-25","objectID":"/setup-hadoop-cluster-on-ms-azure/:0:0","series":[],"tags":["Hadoop"],"title":"Hadoop Setup","uri":"/setup-hadoop-cluster-on-ms-azure/#the-path-of-the-files-under-ssh"},{"categories":["Note"],"content":"Env Vars The hadoop config directory HADOOP_CONF_DIR The directory of the progtram JAVA_HOME HADOOP_HOME HIVE_HOME PIG_HOME HADOOP_YARN_HOME HADOOP_MAPRED_HOME The path of the files under ~/.ssh/ BigDataSH=/etc/profile.d/bigdata.sh IdentityFile=~/.ssh/SSH_keypair.pem SSHConfigFile=~/.ssh/config The following are DNS and IP for all nodes NameNodeDNS=“Namenode” DataNode001DNS=“Datanode001” DataNode002DNS=“Datanode002” NameNodeIP=“10.0.0.4” DataNode001IP=“10.0.0.5” DataNode002IP=“10.0.0.6” ","date":"2021-12-25","objectID":"/setup-hadoop-cluster-on-ms-azure/:0:0","series":[],"tags":["Hadoop"],"title":"Hadoop Setup","uri":"/setup-hadoop-cluster-on-ms-azure/#the-following-are-dns-and-ip-for-all-nodes"},{"categories":["Note"],"content":"Configs SSH config –\u003e give a identity to anyone enter through ssh, and give all host a IP and DNS so that ssh can recognize them SSH_keypair.pem –\u003e The ssh key Environment Variables bigdata.sh –\u003e storing env vars for ssh config and files, java vars, pdsh vars, and other vars Hadoop Configuration - the Hadoop entire directory is usually copied directly to the new DataNodes hadoop-env.sh –\u003e some env vars hdfs.site.xml –\u003e config for HDFS core-site.xml –\u003e config for Hadoop and Namenode yarn-site.xml –\u003e config for yarn mapred-site.xml –\u003e config for MapReduce masters –\u003e specify the master nodes workers –\u003e specify the slave nodes ","date":"2021-12-25","objectID":"/setup-hadoop-cluster-on-ms-azure/:0:0","series":[],"tags":["Hadoop"],"title":"Hadoop Setup","uri":"/setup-hadoop-cluster-on-ms-azure/#configs"},{"categories":["Note"],"content":"Daemons HDFS Daemons: They are configured by masters and workers and hdfs.site.xml and core-site.xml Name Node Secondary Name Node Data Node YARN Daemons: They are configured by yarn-site.xml Resource Manager Node Manager MapReduce Daemon: They are configured by mapred-site.xml Job History Server ","date":"2021-12-25","objectID":"/setup-hadoop-cluster-on-ms-azure/:0:0","series":[],"tags":["Hadoop"],"title":"Hadoop Setup","uri":"/setup-hadoop-cluster-on-ms-azure/#daemons"},{"categories":["Note"],"content":"Cluster Tests ","date":"2021-12-25","objectID":"/setup-hadoop-cluster-on-ms-azure/:0:0","series":[],"tags":["Hadoop"],"title":"Hadoop Setup","uri":"/setup-hadoop-cluster-on-ms-azure/#cluster-tests"},{"categories":["Note"],"content":"HDFS Test Result ","date":"2021-12-25","objectID":"/setup-hadoop-cluster-on-ms-azure/:1:0","series":[],"tags":["Hadoop"],"title":"Hadoop Setup","uri":"/setup-hadoop-cluster-on-ms-azure/#hdfs-test-result"},{"categories":["Note"],"content":"MapReduce Test Result ","date":"2021-12-25","objectID":"/setup-hadoop-cluster-on-ms-azure/:2:0","series":[],"tags":["Hadoop"],"title":"Hadoop Setup","uri":"/setup-hadoop-cluster-on-ms-azure/#mapreduce-test-result"},{"categories":["Note"],"content":"Hashing with Chaining ADT: Dictionary Python: Dict Motivation docdist database login system compilers \u0026 interpreters network router for looking up local machines server virtual memory substring search file and directory synchronization cryptography Simple approach Direct-access table store items in array indexed by key it may end up wasting spaces since many indices of array are unused keys may not be integers gigantic memory hog Solutions prehash map keys to nonneg. integers in theory: keys are finite and discrete (string of bits) in python hash(x) is the prehash of x ideally: hash(x) == hash(y) \u003c=\u003e x == y but hash(\\0B) == hash(\\0\\0C)== 64 Notice that the prehash function should not be mutable since you may not find the thing afterwards hashing reduce universe 𝜇 of all keys (integers) down to reasonable size m for table idea: m = Θ(n) where n is the # of keys collision: h(ki) == h(kj) but i ≠ j the solution is hashing with chaining, which means the linked list so we can search anything in Θ(1), but what if a linked list is too long so that the search time increses to Θ(n) so we have to ensure our hash function can well distributing all the keys randomly for the convenience, we’ll apply a false assumption called Simple Uniform Hashing, which assumes each key is equally likely to be hashed to any slot of the table, indepentent of where other keys hashing uniformity independence Analysis of Hashing with Chaining: expected length of chain for n keys, m slots is n/m, which is the load factor of the table 𝛼 for instance, it will be Θ(1) if m == Θ(n) running time == O(1 + the length of 1 chain) == O(1 + 𝛼) Hash functions division method (not good) h(k) = k mod m if m is a prime, it’s gonna be better since you do not have those common factors between k and m and it’s not very close to power of 2 and 10 multiplication method (not good but better) h(k) = [(a•k) mod 2w)] » (w-r) where k has w bits explanation m = 2r Universal hashing (GOOD!) h(k) = [(ak + b) mod p] mod m a,b,k is a random num in [0 - (p-1)] p is a prime \u003e |µ| for worst case, keys k1 ≠ k2, P(h(k1) == h(k2)) == 1/m for the reason ","date":"2021-12-25","objectID":"/hashing-with-chaining/:0:1","series":[],"tags":["Algorithm"],"title":"Hashing","uri":"/hashing-with-chaining/#hashing-with-chaining"},{"categories":["Note"],"content":"Hashing with Chaining ADT: Dictionary Python: Dict Motivation docdist database login system compilers \u0026 interpreters network router for looking up local machines server virtual memory substring search file and directory synchronization cryptography Simple approach Direct-access table store items in array indexed by key it may end up wasting spaces since many indices of array are unused keys may not be integers gigantic memory hog Solutions prehash map keys to nonneg. integers in theory: keys are finite and discrete (string of bits) in python hash(x) is the prehash of x ideally: hash(x) == hash(y) x == y but hash(\\0B) == hash(\\0\\0C)== 64 Notice that the prehash function should not be mutable since you may not find the thing afterwards hashing reduce universe 𝜇 of all keys (integers) down to reasonable size m for table idea: m = Θ(n) where n is the # of keys collision: h(ki) == h(kj) but i ≠ j the solution is hashing with chaining, which means the linked list so we can search anything in Θ(1), but what if a linked list is too long so that the search time increses to Θ(n) so we have to ensure our hash function can well distributing all the keys randomly for the convenience, we’ll apply a false assumption called Simple Uniform Hashing, which assumes each key is equally likely to be hashed to any slot of the table, indepentent of where other keys hashing uniformity independence Analysis of Hashing with Chaining: expected length of chain for n keys, m slots is n/m, which is the load factor of the table 𝛼 for instance, it will be Θ(1) if m == Θ(n) running time == O(1 + the length of 1 chain) == O(1 + 𝛼) Hash functions division method (not good) h(k) = k mod m if m is a prime, it’s gonna be better since you do not have those common factors between k and m and it’s not very close to power of 2 and 10 multiplication method (not good but better) h(k) = [(a•k) mod 2w)] » (w-r) where k has w bits explanation m = 2r Universal hashing (GOOD!) h(k) = [(ak + b) mod p] mod m a,b,k is a random num in [0 - (p-1)] p is a prime |µ| for worst case, keys k1 ≠ k2, P(h(k1) == h(k2)) == 1/m for the reason ","date":"2021-12-25","objectID":"/hashing-with-chaining/:0:1","series":[],"tags":["Algorithm"],"title":"Hashing","uri":"/hashing-with-chaining/#adt-dictionary"},{"categories":["Note"],"content":"Open Addressing, Cryptographic Hashing Open Addressing no chaining one item per slot =\u003e m ≥ n where m is the # of slot and n is the # of keys Probing Hash function specifies order of slots to probe for a key (for insert/search/delete) h: U x {0,1,…,m-1} -\u003e {0,1,…,m-1} U is universe of keys first {} is the trial count the latter {} is the slot in table we want to design a function h, with the property that for all k in U: h(k,1), h(k,2),…,h(k,m-1) k is an arbitrary key to be permutation of 0,1,…,m-1 i.e. if we keep trying h(k,i) for increasing i, I will eventually hit all slots of the table /* Insert(k,v) keep probing until an empty slot is found, treating DeleteMe as None Search(k) as long as the slots encountered are occupied by keys ≠ k, keep probing until you either encounter k or find an empty slot(which mean fail to find the key), and if we encounter DeleteMe, ignore it and continue //notice we search it using the same sequence of inserting the key, so if the key is in the table, we'll never encounter an empty slot Delete(k) //the issue is that if we want to delete a key k, and replace it with None. //When I search another key k', I may find this empty slot since there was a collision in this slot while inserting k' //We fail incorrectly! //we need to replace deleted item with DeleteMe flag (diff from None) keep probing until we find the key. While finding the key, ignore DeleteMe. If found the key, replace it with DeleteMe flag. */ Probing Strategies Linear probing (not good) h(k,i) = (h'(k) + i) mod m why it’s bad : clustering: you end up getting conecutive groups of occupied slots assuming 0-99 have been occupied, and the hashing function maps the key to 2 where a collision happens. Then it will try one by one until reaching 100. Then the load factor will not be attractive. 0.01 \u003c 𝛼 = n/m \u003c 0.99 we see cluster of size Θ(logn) even the k in h'(k) is a prime Double hashing (solved the pain above) h(k,i) = (h1(k) + i•h2(k)) mod m where h2(k) and m are relatively prime =\u003e permutation so you will roll around in the indices we can simply set m = 2r, h2(k) for all k is odd. Uniform Hashing Assumption Each key is equally likely to have any one of the m! permutations as its probe sequence (double hashing almost did this) 𝛼 = n/m cost of operations insert ≤ 1/(1-𝛼) where we want to keep 𝛼 small (proof in notes: p = (m-n)/n = 1 - 𝛼) keep 𝛼 around 0.5 Cryptographic Hashing Password Storage hashed psw stored in a file like /etc/password h(input) == h(psw) how do we deal with collisions, what properties should the hash function has? read notes and wikipedia ","date":"2021-12-25","objectID":"/open-addressing-cryptographic-hashing/:0:1","series":[],"tags":["Algorithm"],"title":"Hashing 2","uri":"/open-addressing-cryptographic-hashing/#open-addressing-cryptographic-hashing"},{"categories":["Note"],"content":"Open Addressing, Cryptographic Hashing Open Addressing no chaining one item per slot = m ≥ n where m is the # of slot and n is the # of keys Probing Hash function specifies order of slots to probe for a key (for insert/search/delete) h: U x {0,1,…,m-1} - {0,1,…,m-1} U is universe of keys first {} is the trial count the latter {} is the slot in table we want to design a function h, with the property that for all k in U: h(k,1), h(k,2),…,h(k,m-1) k is an arbitrary key to be permutation of 0,1,…,m-1 i.e. if we keep trying h(k,i) for increasing i, I will eventually hit all slots of the table /* Insert(k,v) keep probing until an empty slot is found, treating DeleteMe as None Search(k) as long as the slots encountered are occupied by keys ≠ k, keep probing until you either encounter k or find an empty slot(which mean fail to find the key), and if we encounter DeleteMe, ignore it and continue //notice we search it using the same sequence of inserting the key, so if the key is in the table, we'll never encounter an empty slot Delete(k) //the issue is that if we want to delete a key k, and replace it with None. //When I search another key k', I may find this empty slot since there was a collision in this slot while inserting k' //We fail incorrectly! //we need to replace deleted item with DeleteMe flag (diff from None) keep probing until we find the key. While finding the key, ignore DeleteMe. If found the key, replace it with DeleteMe flag. */ Probing Strategies Linear probing (not good) h(k,i) = (h'(k) + i) mod m why it’s bad : clustering: you end up getting conecutive groups of occupied slots assuming 0-99 have been occupied, and the hashing function maps the key to 2 where a collision happens. Then it will try one by one until reaching 100. Then the load factor will not be attractive. 0.01 permutation so you will roll around in the indices we can simply set m = 2r, h2(k) for all k is odd. Uniform Hashing Assumption Each key is equally likely to have any one of the m! permutations as its probe sequence (double hashing almost did this) 𝛼 = n/m cost of operations insert ≤ 1/(1-𝛼) where we want to keep 𝛼 small (proof in notes: p = (m-n)/n = 1 - 𝛼) keep 𝛼 around 0.5 Cryptographic Hashing Password Storage hashed psw stored in a file like /etc/password h(input) == h(psw) how do we deal with collisions, what properties should the hash function has? read notes and wikipedia ","date":"2021-12-25","objectID":"/open-addressing-cryptographic-hashing/:0:1","series":[],"tags":["Algorithm"],"title":"Hashing 2","uri":"/open-addressing-cryptographic-hashing/#open-addressing"},{"categories":["Note"],"content":"Open Addressing, Cryptographic Hashing Open Addressing no chaining one item per slot = m ≥ n where m is the # of slot and n is the # of keys Probing Hash function specifies order of slots to probe for a key (for insert/search/delete) h: U x {0,1,…,m-1} - {0,1,…,m-1} U is universe of keys first {} is the trial count the latter {} is the slot in table we want to design a function h, with the property that for all k in U: h(k,1), h(k,2),…,h(k,m-1) k is an arbitrary key to be permutation of 0,1,…,m-1 i.e. if we keep trying h(k,i) for increasing i, I will eventually hit all slots of the table /* Insert(k,v) keep probing until an empty slot is found, treating DeleteMe as None Search(k) as long as the slots encountered are occupied by keys ≠ k, keep probing until you either encounter k or find an empty slot(which mean fail to find the key), and if we encounter DeleteMe, ignore it and continue //notice we search it using the same sequence of inserting the key, so if the key is in the table, we'll never encounter an empty slot Delete(k) //the issue is that if we want to delete a key k, and replace it with None. //When I search another key k', I may find this empty slot since there was a collision in this slot while inserting k' //We fail incorrectly! //we need to replace deleted item with DeleteMe flag (diff from None) keep probing until we find the key. While finding the key, ignore DeleteMe. If found the key, replace it with DeleteMe flag. */ Probing Strategies Linear probing (not good) h(k,i) = (h'(k) + i) mod m why it’s bad : clustering: you end up getting conecutive groups of occupied slots assuming 0-99 have been occupied, and the hashing function maps the key to 2 where a collision happens. Then it will try one by one until reaching 100. Then the load factor will not be attractive. 0.01 permutation so you will roll around in the indices we can simply set m = 2r, h2(k) for all k is odd. Uniform Hashing Assumption Each key is equally likely to have any one of the m! permutations as its probe sequence (double hashing almost did this) 𝛼 = n/m cost of operations insert ≤ 1/(1-𝛼) where we want to keep 𝛼 small (proof in notes: p = (m-n)/n = 1 - 𝛼) keep 𝛼 around 0.5 Cryptographic Hashing Password Storage hashed psw stored in a file like /etc/password h(input) == h(psw) how do we deal with collisions, what properties should the hash function has? read notes and wikipedia ","date":"2021-12-25","objectID":"/open-addressing-cryptographic-hashing/:0:1","series":[],"tags":["Algorithm"],"title":"Hashing 2","uri":"/open-addressing-cryptographic-hashing/#probing"},{"categories":["Note"],"content":"Open Addressing, Cryptographic Hashing Open Addressing no chaining one item per slot = m ≥ n where m is the # of slot and n is the # of keys Probing Hash function specifies order of slots to probe for a key (for insert/search/delete) h: U x {0,1,…,m-1} - {0,1,…,m-1} U is universe of keys first {} is the trial count the latter {} is the slot in table we want to design a function h, with the property that for all k in U: h(k,1), h(k,2),…,h(k,m-1) k is an arbitrary key to be permutation of 0,1,…,m-1 i.e. if we keep trying h(k,i) for increasing i, I will eventually hit all slots of the table /* Insert(k,v) keep probing until an empty slot is found, treating DeleteMe as None Search(k) as long as the slots encountered are occupied by keys ≠ k, keep probing until you either encounter k or find an empty slot(which mean fail to find the key), and if we encounter DeleteMe, ignore it and continue //notice we search it using the same sequence of inserting the key, so if the key is in the table, we'll never encounter an empty slot Delete(k) //the issue is that if we want to delete a key k, and replace it with None. //When I search another key k', I may find this empty slot since there was a collision in this slot while inserting k' //We fail incorrectly! //we need to replace deleted item with DeleteMe flag (diff from None) keep probing until we find the key. While finding the key, ignore DeleteMe. If found the key, replace it with DeleteMe flag. */ Probing Strategies Linear probing (not good) h(k,i) = (h'(k) + i) mod m why it’s bad : clustering: you end up getting conecutive groups of occupied slots assuming 0-99 have been occupied, and the hashing function maps the key to 2 where a collision happens. Then it will try one by one until reaching 100. Then the load factor will not be attractive. 0.01 permutation so you will roll around in the indices we can simply set m = 2r, h2(k) for all k is odd. Uniform Hashing Assumption Each key is equally likely to have any one of the m! permutations as its probe sequence (double hashing almost did this) 𝛼 = n/m cost of operations insert ≤ 1/(1-𝛼) where we want to keep 𝛼 small (proof in notes: p = (m-n)/n = 1 - 𝛼) keep 𝛼 around 0.5 Cryptographic Hashing Password Storage hashed psw stored in a file like /etc/password h(input) == h(psw) how do we deal with collisions, what properties should the hash function has? read notes and wikipedia ","date":"2021-12-25","objectID":"/open-addressing-cryptographic-hashing/:0:1","series":[],"tags":["Algorithm"],"title":"Hashing 2","uri":"/open-addressing-cryptographic-hashing/#cryptographic-hashing"},{"categories":["Note"],"content":"Open Addressing, Cryptographic Hashing Open Addressing no chaining one item per slot = m ≥ n where m is the # of slot and n is the # of keys Probing Hash function specifies order of slots to probe for a key (for insert/search/delete) h: U x {0,1,…,m-1} - {0,1,…,m-1} U is universe of keys first {} is the trial count the latter {} is the slot in table we want to design a function h, with the property that for all k in U: h(k,1), h(k,2),…,h(k,m-1) k is an arbitrary key to be permutation of 0,1,…,m-1 i.e. if we keep trying h(k,i) for increasing i, I will eventually hit all slots of the table /* Insert(k,v) keep probing until an empty slot is found, treating DeleteMe as None Search(k) as long as the slots encountered are occupied by keys ≠ k, keep probing until you either encounter k or find an empty slot(which mean fail to find the key), and if we encounter DeleteMe, ignore it and continue //notice we search it using the same sequence of inserting the key, so if the key is in the table, we'll never encounter an empty slot Delete(k) //the issue is that if we want to delete a key k, and replace it with None. //When I search another key k', I may find this empty slot since there was a collision in this slot while inserting k' //We fail incorrectly! //we need to replace deleted item with DeleteMe flag (diff from None) keep probing until we find the key. While finding the key, ignore DeleteMe. If found the key, replace it with DeleteMe flag. */ Probing Strategies Linear probing (not good) h(k,i) = (h'(k) + i) mod m why it’s bad : clustering: you end up getting conecutive groups of occupied slots assuming 0-99 have been occupied, and the hashing function maps the key to 2 where a collision happens. Then it will try one by one until reaching 100. Then the load factor will not be attractive. 0.01 permutation so you will roll around in the indices we can simply set m = 2r, h2(k) for all k is odd. Uniform Hashing Assumption Each key is equally likely to have any one of the m! permutations as its probe sequence (double hashing almost did this) 𝛼 = n/m cost of operations insert ≤ 1/(1-𝛼) where we want to keep 𝛼 small (proof in notes: p = (m-n)/n = 1 - 𝛼) keep 𝛼 around 0.5 Cryptographic Hashing Password Storage hashed psw stored in a file like /etc/password h(input) == h(psw) how do we deal with collisions, what properties should the hash function has? read notes and wikipedia ","date":"2021-12-25","objectID":"/open-addressing-cryptographic-hashing/:0:1","series":[],"tags":["Algorithm"],"title":"Hashing 2","uri":"/open-addressing-cryptographic-hashing/#password-storage"},{"categories":["Note"],"content":"Java ","date":"2021-12-25","objectID":"/java-2/:0:0","series":[],"tags":["Java"],"title":"Java 2","uri":"/java-2/#java"},{"categories":["Note"],"content":"可变参数 public void show(String ... strs){ System.out.println(\"sths\"); } public void show(String str){ System.out.println(\"sth\"); } //public void show(String[] strs){} 冲突 /* Test test = new Test(); test.show(\"hey\"); 此时调用的是后者 因为它更加确定 */ 可变个数形参的格式 数据类型 … 变量名 当调用可变个数形参的方法时，传入的参数个数可以是0个，1个……多个 可变个数形参的方法与本类中方法名相同，形参不同的方法构成重载 可变个数形参的方法与本类中方法名相同，形参是类型相同的数组的方法不构成重载，也就是说，不能共存 它们本质上是相同的 以前数组作为参数时：test.show(new String[] {“这里是参数”, “另一个参数”})； 现在可以：test.show(“aa”, “bb”); 本质上是数组，因为在方法内部循环遍历时，跟数组完全一样用 可变个数形参在方法的形参中，必须声明在末尾（类似于parma in C#） 主要是为了编译器了解实参的归属问题 可变个数形参在方法的形参中，最多只能声明一个可变形参（原因为5.） ","date":"2021-12-25","objectID":"/java-2/:0:1","series":[],"tags":["Java"],"title":"Java 2","uri":"/java-2/#可变参数"},{"categories":["Note"],"content":"Scanner 从键盘获取不同类型的变量，需要使用Scanner类 导入：import java.util.Scanner; 实例化：Scanner scan = new Scanner(System.in); 方法 nextInt() 具体方法看文档 没有返回char的方法 可用字符串的代替 next(), 或者用char变量接收一个返回字符串的第一个位置 String gender = scan.next(); char genderChar = gender.charAt(0); - charAt(int index)获取索引位置上的char 注意：需要根据相应的方法，来输入制定类型的值，如果输入的数据类型与要求不匹配时，报错 注意 ：不一定非得一样，因为有些匹配规则可以自行转换类型 ","date":"2021-12-25","objectID":"/java-2/:0:2","series":[],"tags":["Java"],"title":"Java 2","uri":"/java-2/#scanner"},{"categories":["Note"],"content":"Arrays工具类 java.util.Arrays 常用方法 bool equals(int a, int b) String toString(int[] a) 遍历并输出数组信息 void fill(int[] a, int val) 将指定的值替换进a的所有位置 void sort(int[] a) 双pivot快排 int binarySearch(int[] a, int key) 前提是有序 然后二分查找 返回值小于0说明没找到 其他看文档 ","date":"2021-12-25","objectID":"/java-2/:0:3","series":[],"tags":["Java"],"title":"Java 2","uri":"/java-2/#arrays工具类"},{"categories":["Note"],"content":"对象的内存解析（初级） 对象的创建和使用：内存解析 Heap: 存放对象实例 VM Stack：储存局部变量 Method Area：储存已被虚拟机加载的类信息，常量，静态变量，即时编译器编译后的代码等 Person p1 = new Person(); //首地址值 0x12ab 在栈上 指向堆中的实例 p1.name = \"Tom\"; p1.isMale = true; //更改堆中的成员 Person p2 = new Person(); //首地址值 0x7788 sysout(p2.name); Person p3 = p1; //首地址值 0x12ab 此时实际上就是p1 p3.age = 10; //修改了p3，p1改变 ","date":"2021-12-25","objectID":"/java-2/:0:4","series":[],"tags":["Java"],"title":"Java 2","uri":"/java-2/#对象的内存解析初级"},{"categories":["Note"],"content":"方法参数的值传递机制 目前进度 ","date":"2021-12-25","objectID":"/java-2/:0:5","series":[],"tags":["Java"],"title":"Java 2","uri":"/java-2/#方法参数的值传递机制"},{"categories":["Note"],"content":"JAVA ","date":"2021-12-25","objectID":"/java-3/:0:0","series":[],"tags":["Java"],"title":"Java 3","uri":"/java-3/#java"},{"categories":["Note"],"content":"Java_Ternary Conditional Operator String name = \"Jessie\"; int i = name.equals(\"Jessie\") ? 1 : 3; //If true, i = 1. If false, i = 3. ","date":"2021-12-25","objectID":"/java-3/:1:0","series":[],"tags":["Java"],"title":"Java 3","uri":"/java-3/#java_ternary-conditional-operator"},{"categories":["Note"],"content":"Java_Continue //Different from break that let the program jump out of a loop, continue will skip the code after it in the current loop and then enter the next time of the loop. ","date":"2021-12-25","objectID":"/java-3/:2:0","series":[],"tags":["Java"],"title":"Java 3","uri":"/java-3/#java_continue"},{"categories":["Note"],"content":"Java_toString() and deepToString() Array a = {1,2,3,4,4,5,6,7,4,3,2,3}; System.out.println(a); //You'll get the address of a. System.out.println(Array.toString(a)); //{1,2,3,4,4,5,6,7,4,3,2,3} Array b = { {1,2,3,4},{4,5,6,7,4,3,2,3/\\}\\}/; System.out.println(Array.deepToString(b)); System.out.println(Array.toString(b)); //{1,2,3,4},{4,5,6,7,4,3,2,3} //You'll get two addresses of the inner arraies. ","date":"2021-12-25","objectID":"/java-3/:3:0","series":[],"tags":["Java"],"title":"Java 3","uri":"/java-3/#java_tostring-and-deeptostring"},{"categories":["Note"],"content":"Java_sort() and parallelSort() int[] grades = {4,3,7,6,1,5,2}; Array.sort(grades); System.out.println(Array.toString(grades)); //{1,2,3,4,5,6,7} ","date":"2021-12-25","objectID":"/java-3/:4:0","series":[],"tags":["Java"],"title":"Java 3","uri":"/java-3/#java_sort-and-parallelsort"},{"categories":["Note"],"content":"Java_Array.equals(a, b) .fill(a, value) .asList(a) int[] grades1 = {1,2,3,4,123}; int[] grades2 = {1,2,3,4,123}; System.out.println(grades1 + \" \" + grades2); if(grades1 == grades2) { System.out.println(\"1\"); } if(grades1.equals(grades2)) { System.out.println(\"2\"); } if(Array.equals(grades1, grades2)) { System.out.println(\"3\"); } // [I@3764951d [I@4b1210ee //3 //The first two are comparing the addresses, seeing if they are the same array. //Also we have Array.deepEquals() to deal with the nested array. //.fill(a, val) fill every index of the array a with the val. //.asList(a) returns a list. ","date":"2021-12-25","objectID":"/java-3/:5:0","series":[],"tags":["Java"],"title":"Java 3","uri":"/java-3/#java_arrayequalsa-b-filla-value-aslista"},{"categories":["Note"],"content":"Notice Do not create a temp object to carry data from one array to another since the temp will point to the same object in the heap, and you are just changing the instances in the same object. So you’ll get an array with elements that are all the same. Create a Helper.tempLoader() to create the intermediate because it will create different objects in the heap, and the temporary intermediate will pass these different objects to the pointers in the array. Plz see “Issue of moving data from one array to another” // Why every element in the array list is the last one, which is the card object when i = 0. public static ArrayList initialization() { String[] firstName = {\"Kyle\",\"Cory\",\"Tanner\",\"Jordan\",\"Jesse\"}; String[] lastName = {\"Bustami\",\"Chambers\",\"Douglas\",\"Jones\",\"Pecar\"}; String[] cardNum = {\"123456789\",\"135792468\",\"019283746\",\"675849302\",\"347821904\"}; String[] pin = {\"1111\",\"2097\",\"6194\",\"0071\",\"9871\"}; float[] checking = {500,100,1500,50,150}; float[] saving = {200,700,2500,-1,250}; int[] counter = {2,3,5,0,1}; System.out.print(\"The size of database is: \"); Card.setTotalCards(Integer.parseInt(Helper.input())); ArrayList cardDB = new ArrayList\u003c\u003e(); Card tempCard = new Card(); for (int i = 0; i \u003c Card.getTotalCards(); i++) { tempCard.setFirstName(firstName[i]); tempCard.setLastName(lastName[i]); tempCard.setCardNum(cardNum[i]); tempCard.setPin(pin[i]); tempCard.setChecking(checking[i]); tempCard.setSaving(saving[i]); tempCard.setCounter(counter[i]); cardDB.add(tempCard); } return cardDB; } ","date":"2021-12-25","objectID":"/java-3/:5:1","series":[],"tags":["Java"],"title":"Java 3","uri":"/java-3/#notice"},{"categories":["Note"],"content":"Notice When you want to use a condition like the following: while (string.equals(null)) You'll get an error. If the string is null, then it points to nothing. Thus, it cannot call the equals() method under Object class. Please revise it as: while(string == null) ","date":"2021-12-25","objectID":"/java-3/:5:2","series":[],"tags":["Java"],"title":"Java 3","uri":"/java-3/#notice-1"},{"categories":["Note"],"content":"JS ","date":"2021-12-25","objectID":"/javascript/:0:0","series":[],"tags":["JavaScript"],"title":"JavaScript","uri":"/javascript/#js"},{"categories":["Note"],"content":"Let/Const function sayHello() { for (var i = 0; i \u003c 5; i++) { console.log(i); } console.log(i); } sayHello(); problem with var: the scope! To solve this problem, we have let. Scope var -\u003e function let -\u003e block const -\u003e block const person = { name: 'Mosh', walk: function() {}, talk() {} //neat way }; person.talk(); person['name'] = 'John'; const targetMember = 'name'; // think about this can be user input person[targetMember] = 'John'; // dynamically manage the access ","date":"2021-12-25","objectID":"/javascript/:1:0","series":[],"tags":["JavaScript"],"title":"JavaScript","uri":"/javascript/#letconst"},{"categories":["Note"],"content":"Let/Const function sayHello() { for (var i = 0; i function let - block const - block const person = { name: 'Mosh', walk: function() {}, talk() {} //neat way }; person.talk(); person['name'] = 'John'; const targetMember = 'name'; // think about this can be user input person[targetMember] = 'John'; // dynamically manage the access ","date":"2021-12-25","objectID":"/javascript/:1:0","series":[],"tags":["JavaScript"],"title":"JavaScript","uri":"/javascript/#scope"},{"categories":["Note"],"content":"Objects ","date":"2021-12-25","objectID":"/javascript/:2:0","series":[],"tags":["JavaScript"],"title":"JavaScript","uri":"/javascript/#objects"},{"categories":["Note"],"content":"this const person = { name: \"Mosh\", walk() { console.log(this); } }; person.walk(); // {name: \"Mosh\", walk: f} const walk = person.walk; walk(); // undefined since the browser runs it in the strict mode What is ‘this’? ‘this’ always return the current object. The value of ‘this’ is determined by how the function is called. If we call a function as a method of a object, ‘this’ returns the ref of the obj. However, if we call a function as a standalone object or outside of an obj, ‘this’ will return the global obj – the browser. const walk = person.walk.bind(person); // now the walk will always be binded to person obj for the new function walk created permanently. walk(); ","date":"2021-12-25","objectID":"/javascript/:3:0","series":[],"tags":["JavaScript"],"title":"JavaScript","uri":"/javascript/#this"},{"categories":["Note"],"content":"Building this How to fix the prob: no matter how we call the function, ‘this’ always returns the person obj. notice that in JS, functions are objs So, person.walk is actually an obj. person.walk.bind(person); will bind the it to the person obj, and ‘this’ will return the person obj. ","date":"2021-12-25","objectID":"/javascript/:3:1","series":[],"tags":["JavaScript"],"title":"JavaScript","uri":"/javascript/#building-this"},{"categories":["Note"],"content":"Arrow Funcs const square = function(number) { return number * number; } const square = number =\u003e { return number * number; } const square = number =\u003e number * number; console.log(square(5)); const jobs = { {id: 1, isActive: true}, {id: 2, isActive: true}, {id: 3, isActive: false} }; const activeJobs = jobs.filter(function(job){ return job.isActive;}); const activeJobs = jobs.filter(job =\u003e job.isActive); ","date":"2021-12-25","objectID":"/javascript/:4:0","series":[],"tags":["JavaScript"],"title":"JavaScript","uri":"/javascript/#arrow-funcs"},{"categories":["Note"],"content":"Arow Funcs and this ","date":"2021-12-25","objectID":"/javascript/:4:1","series":[],"tags":["JavaScript"],"title":"JavaScript","uri":"/javascript/#arow-funcs-and-this"},{"categories":["Note"],"content":"Destructuring ","date":"2021-12-25","objectID":"/javascript/:5:0","series":[],"tags":["JavaScript"],"title":"JavaScript","uri":"/javascript/#destructuring"},{"categories":["Note"],"content":"Spread ","date":"2021-12-25","objectID":"/javascript/:6:0","series":[],"tags":["JavaScript"],"title":"JavaScript","uri":"/javascript/#spread"},{"categories":["Note"],"content":"Classes ","date":"2021-12-25","objectID":"/javascript/:7:0","series":[],"tags":["JavaScript"],"title":"JavaScript","uri":"/javascript/#classes"},{"categories":["Note"],"content":"Modules ","date":"2021-12-25","objectID":"/javascript/:8:0","series":[],"tags":["JavaScript"],"title":"JavaScript","uri":"/javascript/#modules"},{"categories":["Note"],"content":"Integer Arithmetic, Karatsuba Multiplication Irrationals Catalan numbers (cardinality of the set) Set P of balanced parentheses strings 𝜆 ∈ P (𝜆 is the empty string) if 𝛂,𝛃 ∈ P, then (𝛂)𝛃 ∈ P we can get every nonempty balanced paren string via Rule 2 from unique 𝛂,𝛃 pair (())()() obtained by 𝛂=() 𝛃=()() Enumeration Cn: number of balanced paren strings with exactly n pairs of parens C0 = 1 as the base case (empty string) C1 = 1 C2 = C0C1 + C1C0 = 2 Cn+1 = ∑CkCn-k n ≥ 0 from k = 0 to n Newton’s Method say you have y = f(x) and we want to find root of f(x) = 0 through successive approx f(x) = x2 - a [Explaination]([https://amsi.org.au/ESA_Senior_Years/SeniorTopic3/3j/3j_2content_2.html#:~:text=Finding%20a%20solution%20with%20geometry,requires%20calculus%2C%20in%20particular%20differentiation.](https://amsi.org.au/ESA_Senior_Years/SeniorTopic3/3j/3j_2content_2.html#:~:text=Finding a solution with geometry,requires calculus%2C in particular differentiation.)) xi+1 = xi - f(xi)/f ‘(xi) for this case: xi+1 = xi - (xi2 - a) / 2xi = (xi + a/xi) / 2 if we implement it on x2 = 2 x0 = 1.000000000… x1 = 1.500000000… x2 = 1.416666666… x3 = 1.414215686… x4 = 1.414213562… Quadratic convergence! The accurate digits doubles in every iteration So now it’s not a too bad thing for getting a million accurate digits since the exponential change will help us getting there in reasonable time sqrt(2) to d-digit precision we want integer floor(10dsqrt(2)) == floor(sqrt(2•102d)) still use Newton’s Method High Precision Multiplication two n-digit numbers (radix r = 2, 10) 0 ≤ x, y ≤ rn Divide and Conquer x = x1 • rn/2 + x0 where x1 is the high half and x0 is the low half 0 ≤ x0,x1 ≤ rn/2 Do the same to y Then do it recursively here is how we do the multiplication z = xy = x1y1rn + (x0y1 + x1y0)rn/2 + x0y0 4 multiplication of n/2 digit numbers =\u003e Θ(n2) time T(n) = 4T(n/2) + Θ(n) we assume the addition takes linear time We want to do better Karatsuba Multiplication let z0 = x0y0 let z2 = x2y2 let z1 = (x0 + x1)(y0 + y1) - z0 - z2 T(n) = 3T(n/2) + Θ(n) =\u003e Θ(nlog23) = Θ(n1.58) then what about optimize it even more i.e. breaking up this to more chunks, say 3 parts then we have 9 multiplications so we can try to play with it to shrink the times of multiplications down to a small number Fun Geometry Problem a circle with r = 1 trillion units we have CA and CB where C is the center and A,B are two points on the circle now from B we make a line down perpendicular to CA with a intersection of D What is AD? AD = AC - CD = sqrt((0.5trillion)2 - 1) WoW, we can see all the Catalan numbers in the answer! ","date":"2021-12-25","objectID":"/integer-arithmetic-karatsuba-multiplication/:0:1","series":[],"tags":["Algorithm"],"title":"Karatsuba Multiplication","uri":"/integer-arithmetic-karatsuba-multiplication/#integer-arithmetic-karatsuba-multiplication"},{"categories":["Note"],"content":"Integer Arithmetic, Karatsuba Multiplication Irrationals Catalan numbers (cardinality of the set) Set P of balanced parentheses strings 𝜆 ∈ P (𝜆 is the empty string) if 𝛂,𝛃 ∈ P, then (𝛂)𝛃 ∈ P we can get every nonempty balanced paren string via Rule 2 from unique 𝛂,𝛃 pair (())()() obtained by 𝛂=() 𝛃=()() Enumeration Cn: number of balanced paren strings with exactly n pairs of parens C0 = 1 as the base case (empty string) C1 = 1 C2 = C0C1 + C1C0 = 2 Cn+1 = ∑CkCn-k n ≥ 0 from k = 0 to n Newton’s Method say you have y = f(x) and we want to find root of f(x) = 0 through successive approx f(x) = x2 - a [Explaination]([https://amsi.org.au/ESA_Senior_Years/SeniorTopic3/3j/3j_2content_2.html#:~:text=Finding%20a%20solution%20with%20geometry,requires%20calculus%2C%20in%20particular%20differentiation.](https://amsi.org.au/ESA_Senior_Years/SeniorTopic3/3j/3j_2content_2.html#:~:text=Finding a solution with geometry,requires calculus%2C in particular differentiation.)) xi+1 = xi - f(xi)/f ‘(xi) for this case: xi+1 = xi - (xi2 - a) / 2xi = (xi + a/xi) / 2 if we implement it on x2 = 2 x0 = 1.000000000… x1 = 1.500000000… x2 = 1.416666666… x3 = 1.414215686… x4 = 1.414213562… Quadratic convergence! The accurate digits doubles in every iteration So now it’s not a too bad thing for getting a million accurate digits since the exponential change will help us getting there in reasonable time sqrt(2) to d-digit precision we want integer floor(10dsqrt(2)) == floor(sqrt(2•102d)) still use Newton’s Method High Precision Multiplication two n-digit numbers (radix r = 2, 10) 0 ≤ x, y ≤ rn Divide and Conquer x = x1 • rn/2 + x0 where x1 is the high half and x0 is the low half 0 ≤ x0,x1 ≤ rn/2 Do the same to y Then do it recursively here is how we do the multiplication z = xy = x1y1rn + (x0y1 + x1y0)rn/2 + x0y0 4 multiplication of n/2 digit numbers = Θ(n2) time T(n) = 4T(n/2) + Θ(n) we assume the addition takes linear time We want to do better Karatsuba Multiplication let z0 = x0y0 let z2 = x2y2 let z1 = (x0 + x1)(y0 + y1) - z0 - z2 T(n) = 3T(n/2) + Θ(n) = Θ(nlog23) = Θ(n1.58) then what about optimize it even more i.e. breaking up this to more chunks, say 3 parts then we have 9 multiplications so we can try to play with it to shrink the times of multiplications down to a small number Fun Geometry Problem a circle with r = 1 trillion units we have CA and CB where C is the center and A,B are two points on the circle now from B we make a line down perpendicular to CA with a intersection of D What is AD? AD = AC - CD = sqrt((0.5trillion)2 - 1) WoW, we can see all the Catalan numbers in the answer! ","date":"2021-12-25","objectID":"/integer-arithmetic-karatsuba-multiplication/:0:1","series":[],"tags":["Algorithm"],"title":"Karatsuba Multiplication","uri":"/integer-arithmetic-karatsuba-multiplication/#irrationals"},{"categories":["Note"],"content":"Integer Arithmetic, Karatsuba Multiplication Irrationals Catalan numbers (cardinality of the set) Set P of balanced parentheses strings 𝜆 ∈ P (𝜆 is the empty string) if 𝛂,𝛃 ∈ P, then (𝛂)𝛃 ∈ P we can get every nonempty balanced paren string via Rule 2 from unique 𝛂,𝛃 pair (())()() obtained by 𝛂=() 𝛃=()() Enumeration Cn: number of balanced paren strings with exactly n pairs of parens C0 = 1 as the base case (empty string) C1 = 1 C2 = C0C1 + C1C0 = 2 Cn+1 = ∑CkCn-k n ≥ 0 from k = 0 to n Newton’s Method say you have y = f(x) and we want to find root of f(x) = 0 through successive approx f(x) = x2 - a [Explaination]([https://amsi.org.au/ESA_Senior_Years/SeniorTopic3/3j/3j_2content_2.html#:~:text=Finding%20a%20solution%20with%20geometry,requires%20calculus%2C%20in%20particular%20differentiation.](https://amsi.org.au/ESA_Senior_Years/SeniorTopic3/3j/3j_2content_2.html#:~:text=Finding a solution with geometry,requires calculus%2C in particular differentiation.)) xi+1 = xi - f(xi)/f ‘(xi) for this case: xi+1 = xi - (xi2 - a) / 2xi = (xi + a/xi) / 2 if we implement it on x2 = 2 x0 = 1.000000000… x1 = 1.500000000… x2 = 1.416666666… x3 = 1.414215686… x4 = 1.414213562… Quadratic convergence! The accurate digits doubles in every iteration So now it’s not a too bad thing for getting a million accurate digits since the exponential change will help us getting there in reasonable time sqrt(2) to d-digit precision we want integer floor(10dsqrt(2)) == floor(sqrt(2•102d)) still use Newton’s Method High Precision Multiplication two n-digit numbers (radix r = 2, 10) 0 ≤ x, y ≤ rn Divide and Conquer x = x1 • rn/2 + x0 where x1 is the high half and x0 is the low half 0 ≤ x0,x1 ≤ rn/2 Do the same to y Then do it recursively here is how we do the multiplication z = xy = x1y1rn + (x0y1 + x1y0)rn/2 + x0y0 4 multiplication of n/2 digit numbers = Θ(n2) time T(n) = 4T(n/2) + Θ(n) we assume the addition takes linear time We want to do better Karatsuba Multiplication let z0 = x0y0 let z2 = x2y2 let z1 = (x0 + x1)(y0 + y1) - z0 - z2 T(n) = 3T(n/2) + Θ(n) = Θ(nlog23) = Θ(n1.58) then what about optimize it even more i.e. breaking up this to more chunks, say 3 parts then we have 9 multiplications so we can try to play with it to shrink the times of multiplications down to a small number Fun Geometry Problem a circle with r = 1 trillion units we have CA and CB where C is the center and A,B are two points on the circle now from B we make a line down perpendicular to CA with a intersection of D What is AD? AD = AC - CD = sqrt((0.5trillion)2 - 1) WoW, we can see all the Catalan numbers in the answer! ","date":"2021-12-25","objectID":"/integer-arithmetic-karatsuba-multiplication/:0:1","series":[],"tags":["Algorithm"],"title":"Karatsuba Multiplication","uri":"/integer-arithmetic-karatsuba-multiplication/#catalan-numbers-cardinality-of-the-set"},{"categories":["Note"],"content":"Integer Arithmetic, Karatsuba Multiplication Irrationals Catalan numbers (cardinality of the set) Set P of balanced parentheses strings 𝜆 ∈ P (𝜆 is the empty string) if 𝛂,𝛃 ∈ P, then (𝛂)𝛃 ∈ P we can get every nonempty balanced paren string via Rule 2 from unique 𝛂,𝛃 pair (())()() obtained by 𝛂=() 𝛃=()() Enumeration Cn: number of balanced paren strings with exactly n pairs of parens C0 = 1 as the base case (empty string) C1 = 1 C2 = C0C1 + C1C0 = 2 Cn+1 = ∑CkCn-k n ≥ 0 from k = 0 to n Newton’s Method say you have y = f(x) and we want to find root of f(x) = 0 through successive approx f(x) = x2 - a [Explaination]([https://amsi.org.au/ESA_Senior_Years/SeniorTopic3/3j/3j_2content_2.html#:~:text=Finding%20a%20solution%20with%20geometry,requires%20calculus%2C%20in%20particular%20differentiation.](https://amsi.org.au/ESA_Senior_Years/SeniorTopic3/3j/3j_2content_2.html#:~:text=Finding a solution with geometry,requires calculus%2C in particular differentiation.)) xi+1 = xi - f(xi)/f ‘(xi) for this case: xi+1 = xi - (xi2 - a) / 2xi = (xi + a/xi) / 2 if we implement it on x2 = 2 x0 = 1.000000000… x1 = 1.500000000… x2 = 1.416666666… x3 = 1.414215686… x4 = 1.414213562… Quadratic convergence! The accurate digits doubles in every iteration So now it’s not a too bad thing for getting a million accurate digits since the exponential change will help us getting there in reasonable time sqrt(2) to d-digit precision we want integer floor(10dsqrt(2)) == floor(sqrt(2•102d)) still use Newton’s Method High Precision Multiplication two n-digit numbers (radix r = 2, 10) 0 ≤ x, y ≤ rn Divide and Conquer x = x1 • rn/2 + x0 where x1 is the high half and x0 is the low half 0 ≤ x0,x1 ≤ rn/2 Do the same to y Then do it recursively here is how we do the multiplication z = xy = x1y1rn + (x0y1 + x1y0)rn/2 + x0y0 4 multiplication of n/2 digit numbers = Θ(n2) time T(n) = 4T(n/2) + Θ(n) we assume the addition takes linear time We want to do better Karatsuba Multiplication let z0 = x0y0 let z2 = x2y2 let z1 = (x0 + x1)(y0 + y1) - z0 - z2 T(n) = 3T(n/2) + Θ(n) = Θ(nlog23) = Θ(n1.58) then what about optimize it even more i.e. breaking up this to more chunks, say 3 parts then we have 9 multiplications so we can try to play with it to shrink the times of multiplications down to a small number Fun Geometry Problem a circle with r = 1 trillion units we have CA and CB where C is the center and A,B are two points on the circle now from B we make a line down perpendicular to CA with a intersection of D What is AD? AD = AC - CD = sqrt((0.5trillion)2 - 1) WoW, we can see all the Catalan numbers in the answer! ","date":"2021-12-25","objectID":"/integer-arithmetic-karatsuba-multiplication/:0:1","series":[],"tags":["Algorithm"],"title":"Karatsuba Multiplication","uri":"/integer-arithmetic-karatsuba-multiplication/#newtons-method"},{"categories":["Note"],"content":"Integer Arithmetic, Karatsuba Multiplication Irrationals Catalan numbers (cardinality of the set) Set P of balanced parentheses strings 𝜆 ∈ P (𝜆 is the empty string) if 𝛂,𝛃 ∈ P, then (𝛂)𝛃 ∈ P we can get every nonempty balanced paren string via Rule 2 from unique 𝛂,𝛃 pair (())()() obtained by 𝛂=() 𝛃=()() Enumeration Cn: number of balanced paren strings with exactly n pairs of parens C0 = 1 as the base case (empty string) C1 = 1 C2 = C0C1 + C1C0 = 2 Cn+1 = ∑CkCn-k n ≥ 0 from k = 0 to n Newton’s Method say you have y = f(x) and we want to find root of f(x) = 0 through successive approx f(x) = x2 - a [Explaination]([https://amsi.org.au/ESA_Senior_Years/SeniorTopic3/3j/3j_2content_2.html#:~:text=Finding%20a%20solution%20with%20geometry,requires%20calculus%2C%20in%20particular%20differentiation.](https://amsi.org.au/ESA_Senior_Years/SeniorTopic3/3j/3j_2content_2.html#:~:text=Finding a solution with geometry,requires calculus%2C in particular differentiation.)) xi+1 = xi - f(xi)/f ‘(xi) for this case: xi+1 = xi - (xi2 - a) / 2xi = (xi + a/xi) / 2 if we implement it on x2 = 2 x0 = 1.000000000… x1 = 1.500000000… x2 = 1.416666666… x3 = 1.414215686… x4 = 1.414213562… Quadratic convergence! The accurate digits doubles in every iteration So now it’s not a too bad thing for getting a million accurate digits since the exponential change will help us getting there in reasonable time sqrt(2) to d-digit precision we want integer floor(10dsqrt(2)) == floor(sqrt(2•102d)) still use Newton’s Method High Precision Multiplication two n-digit numbers (radix r = 2, 10) 0 ≤ x, y ≤ rn Divide and Conquer x = x1 • rn/2 + x0 where x1 is the high half and x0 is the low half 0 ≤ x0,x1 ≤ rn/2 Do the same to y Then do it recursively here is how we do the multiplication z = xy = x1y1rn + (x0y1 + x1y0)rn/2 + x0y0 4 multiplication of n/2 digit numbers = Θ(n2) time T(n) = 4T(n/2) + Θ(n) we assume the addition takes linear time We want to do better Karatsuba Multiplication let z0 = x0y0 let z2 = x2y2 let z1 = (x0 + x1)(y0 + y1) - z0 - z2 T(n) = 3T(n/2) + Θ(n) = Θ(nlog23) = Θ(n1.58) then what about optimize it even more i.e. breaking up this to more chunks, say 3 parts then we have 9 multiplications so we can try to play with it to shrink the times of multiplications down to a small number Fun Geometry Problem a circle with r = 1 trillion units we have CA and CB where C is the center and A,B are two points on the circle now from B we make a line down perpendicular to CA with a intersection of D What is AD? AD = AC - CD = sqrt((0.5trillion)2 - 1) WoW, we can see all the Catalan numbers in the answer! ","date":"2021-12-25","objectID":"/integer-arithmetic-karatsuba-multiplication/:0:1","series":[],"tags":["Algorithm"],"title":"Karatsuba Multiplication","uri":"/integer-arithmetic-karatsuba-multiplication/#sqrt2-to-d-digit-precision"},{"categories":["Note"],"content":"Integer Arithmetic, Karatsuba Multiplication Irrationals Catalan numbers (cardinality of the set) Set P of balanced parentheses strings 𝜆 ∈ P (𝜆 is the empty string) if 𝛂,𝛃 ∈ P, then (𝛂)𝛃 ∈ P we can get every nonempty balanced paren string via Rule 2 from unique 𝛂,𝛃 pair (())()() obtained by 𝛂=() 𝛃=()() Enumeration Cn: number of balanced paren strings with exactly n pairs of parens C0 = 1 as the base case (empty string) C1 = 1 C2 = C0C1 + C1C0 = 2 Cn+1 = ∑CkCn-k n ≥ 0 from k = 0 to n Newton’s Method say you have y = f(x) and we want to find root of f(x) = 0 through successive approx f(x) = x2 - a [Explaination]([https://amsi.org.au/ESA_Senior_Years/SeniorTopic3/3j/3j_2content_2.html#:~:text=Finding%20a%20solution%20with%20geometry,requires%20calculus%2C%20in%20particular%20differentiation.](https://amsi.org.au/ESA_Senior_Years/SeniorTopic3/3j/3j_2content_2.html#:~:text=Finding a solution with geometry,requires calculus%2C in particular differentiation.)) xi+1 = xi - f(xi)/f ‘(xi) for this case: xi+1 = xi - (xi2 - a) / 2xi = (xi + a/xi) / 2 if we implement it on x2 = 2 x0 = 1.000000000… x1 = 1.500000000… x2 = 1.416666666… x3 = 1.414215686… x4 = 1.414213562… Quadratic convergence! The accurate digits doubles in every iteration So now it’s not a too bad thing for getting a million accurate digits since the exponential change will help us getting there in reasonable time sqrt(2) to d-digit precision we want integer floor(10dsqrt(2)) == floor(sqrt(2•102d)) still use Newton’s Method High Precision Multiplication two n-digit numbers (radix r = 2, 10) 0 ≤ x, y ≤ rn Divide and Conquer x = x1 • rn/2 + x0 where x1 is the high half and x0 is the low half 0 ≤ x0,x1 ≤ rn/2 Do the same to y Then do it recursively here is how we do the multiplication z = xy = x1y1rn + (x0y1 + x1y0)rn/2 + x0y0 4 multiplication of n/2 digit numbers = Θ(n2) time T(n) = 4T(n/2) + Θ(n) we assume the addition takes linear time We want to do better Karatsuba Multiplication let z0 = x0y0 let z2 = x2y2 let z1 = (x0 + x1)(y0 + y1) - z0 - z2 T(n) = 3T(n/2) + Θ(n) = Θ(nlog23) = Θ(n1.58) then what about optimize it even more i.e. breaking up this to more chunks, say 3 parts then we have 9 multiplications so we can try to play with it to shrink the times of multiplications down to a small number Fun Geometry Problem a circle with r = 1 trillion units we have CA and CB where C is the center and A,B are two points on the circle now from B we make a line down perpendicular to CA with a intersection of D What is AD? AD = AC - CD = sqrt((0.5trillion)2 - 1) WoW, we can see all the Catalan numbers in the answer! ","date":"2021-12-25","objectID":"/integer-arithmetic-karatsuba-multiplication/:0:1","series":[],"tags":["Algorithm"],"title":"Karatsuba Multiplication","uri":"/integer-arithmetic-karatsuba-multiplication/#high-precision-multiplication"},{"categories":["Note"],"content":"Integer Arithmetic, Karatsuba Multiplication Irrationals Catalan numbers (cardinality of the set) Set P of balanced parentheses strings 𝜆 ∈ P (𝜆 is the empty string) if 𝛂,𝛃 ∈ P, then (𝛂)𝛃 ∈ P we can get every nonempty balanced paren string via Rule 2 from unique 𝛂,𝛃 pair (())()() obtained by 𝛂=() 𝛃=()() Enumeration Cn: number of balanced paren strings with exactly n pairs of parens C0 = 1 as the base case (empty string) C1 = 1 C2 = C0C1 + C1C0 = 2 Cn+1 = ∑CkCn-k n ≥ 0 from k = 0 to n Newton’s Method say you have y = f(x) and we want to find root of f(x) = 0 through successive approx f(x) = x2 - a [Explaination]([https://amsi.org.au/ESA_Senior_Years/SeniorTopic3/3j/3j_2content_2.html#:~:text=Finding%20a%20solution%20with%20geometry,requires%20calculus%2C%20in%20particular%20differentiation.](https://amsi.org.au/ESA_Senior_Years/SeniorTopic3/3j/3j_2content_2.html#:~:text=Finding a solution with geometry,requires calculus%2C in particular differentiation.)) xi+1 = xi - f(xi)/f ‘(xi) for this case: xi+1 = xi - (xi2 - a) / 2xi = (xi + a/xi) / 2 if we implement it on x2 = 2 x0 = 1.000000000… x1 = 1.500000000… x2 = 1.416666666… x3 = 1.414215686… x4 = 1.414213562… Quadratic convergence! The accurate digits doubles in every iteration So now it’s not a too bad thing for getting a million accurate digits since the exponential change will help us getting there in reasonable time sqrt(2) to d-digit precision we want integer floor(10dsqrt(2)) == floor(sqrt(2•102d)) still use Newton’s Method High Precision Multiplication two n-digit numbers (radix r = 2, 10) 0 ≤ x, y ≤ rn Divide and Conquer x = x1 • rn/2 + x0 where x1 is the high half and x0 is the low half 0 ≤ x0,x1 ≤ rn/2 Do the same to y Then do it recursively here is how we do the multiplication z = xy = x1y1rn + (x0y1 + x1y0)rn/2 + x0y0 4 multiplication of n/2 digit numbers = Θ(n2) time T(n) = 4T(n/2) + Θ(n) we assume the addition takes linear time We want to do better Karatsuba Multiplication let z0 = x0y0 let z2 = x2y2 let z1 = (x0 + x1)(y0 + y1) - z0 - z2 T(n) = 3T(n/2) + Θ(n) = Θ(nlog23) = Θ(n1.58) then what about optimize it even more i.e. breaking up this to more chunks, say 3 parts then we have 9 multiplications so we can try to play with it to shrink the times of multiplications down to a small number Fun Geometry Problem a circle with r = 1 trillion units we have CA and CB where C is the center and A,B are two points on the circle now from B we make a line down perpendicular to CA with a intersection of D What is AD? AD = AC - CD = sqrt((0.5trillion)2 - 1) WoW, we can see all the Catalan numbers in the answer! ","date":"2021-12-25","objectID":"/integer-arithmetic-karatsuba-multiplication/:0:1","series":[],"tags":["Algorithm"],"title":"Karatsuba Multiplication","uri":"/integer-arithmetic-karatsuba-multiplication/#karatsuba-multiplication"},{"categories":["Note"],"content":"Integer Arithmetic, Karatsuba Multiplication Irrationals Catalan numbers (cardinality of the set) Set P of balanced parentheses strings 𝜆 ∈ P (𝜆 is the empty string) if 𝛂,𝛃 ∈ P, then (𝛂)𝛃 ∈ P we can get every nonempty balanced paren string via Rule 2 from unique 𝛂,𝛃 pair (())()() obtained by 𝛂=() 𝛃=()() Enumeration Cn: number of balanced paren strings with exactly n pairs of parens C0 = 1 as the base case (empty string) C1 = 1 C2 = C0C1 + C1C0 = 2 Cn+1 = ∑CkCn-k n ≥ 0 from k = 0 to n Newton’s Method say you have y = f(x) and we want to find root of f(x) = 0 through successive approx f(x) = x2 - a [Explaination]([https://amsi.org.au/ESA_Senior_Years/SeniorTopic3/3j/3j_2content_2.html#:~:text=Finding%20a%20solution%20with%20geometry,requires%20calculus%2C%20in%20particular%20differentiation.](https://amsi.org.au/ESA_Senior_Years/SeniorTopic3/3j/3j_2content_2.html#:~:text=Finding a solution with geometry,requires calculus%2C in particular differentiation.)) xi+1 = xi - f(xi)/f ‘(xi) for this case: xi+1 = xi - (xi2 - a) / 2xi = (xi + a/xi) / 2 if we implement it on x2 = 2 x0 = 1.000000000… x1 = 1.500000000… x2 = 1.416666666… x3 = 1.414215686… x4 = 1.414213562… Quadratic convergence! The accurate digits doubles in every iteration So now it’s not a too bad thing for getting a million accurate digits since the exponential change will help us getting there in reasonable time sqrt(2) to d-digit precision we want integer floor(10dsqrt(2)) == floor(sqrt(2•102d)) still use Newton’s Method High Precision Multiplication two n-digit numbers (radix r = 2, 10) 0 ≤ x, y ≤ rn Divide and Conquer x = x1 • rn/2 + x0 where x1 is the high half and x0 is the low half 0 ≤ x0,x1 ≤ rn/2 Do the same to y Then do it recursively here is how we do the multiplication z = xy = x1y1rn + (x0y1 + x1y0)rn/2 + x0y0 4 multiplication of n/2 digit numbers = Θ(n2) time T(n) = 4T(n/2) + Θ(n) we assume the addition takes linear time We want to do better Karatsuba Multiplication let z0 = x0y0 let z2 = x2y2 let z1 = (x0 + x1)(y0 + y1) - z0 - z2 T(n) = 3T(n/2) + Θ(n) = Θ(nlog23) = Θ(n1.58) then what about optimize it even more i.e. breaking up this to more chunks, say 3 parts then we have 9 multiplications so we can try to play with it to shrink the times of multiplications down to a small number Fun Geometry Problem a circle with r = 1 trillion units we have CA and CB where C is the center and A,B are two points on the circle now from B we make a line down perpendicular to CA with a intersection of D What is AD? AD = AC - CD = sqrt((0.5trillion)2 - 1) WoW, we can see all the Catalan numbers in the answer! ","date":"2021-12-25","objectID":"/integer-arithmetic-karatsuba-multiplication/:0:1","series":[],"tags":["Algorithm"],"title":"Karatsuba Multiplication","uri":"/integer-arithmetic-karatsuba-multiplication/#fun-geometry-problem"},{"categories":["Note"],"content":"Table Doubling, Karp-Rabin how to choose m? want m = Θ(n) =\u003e 𝛼 = Θ(1) Idea: start small: m = 8 grow/shrink as necessary If m \u003e n, grow a table make table of size m' build new hash f' rehash insert them in new table T' Θ(n+m+m') in the case above if m' = m + 1 the cost of n insert is Θ(1+2+3+…+n) = Θ(n2) if m' = 2m Oh, Golden cost of n insert is Θ(1+2+4+8+…+n) = Θ(n) Table Doubling =\u003e Amortization operation take “T(n) amortized” if k operations take ≤ k•T(n) time think of meaning “T(n) on average”, where average over all operations SO! table doubling: k insertions take Θ(k) time =\u003e Θ(1) amortized per insertion also: k insertions \u0026 deletions take O(k) Deletion if m = n/2 then shrink to m/2 slow: from 2k \u003c–\u003e 2k+1 =\u003eΘ(n) per operaiton (BAD!) if m = n/4 then shrink to m/2 amortized time to Θ(1) String Matching given two strings s \u0026 t: does s occur as a substring of t? Simple algo: any(s==t)[i:i+len(s)] for i in range(len(t)-len(s)) running time: Θ(|s|•(|t|-|s|)) ≈ Θ(|s|•|t|) Rolling hash ADT r.append(c): add the char to end of x r.skip(c): delete the first char of x r maintains a string x r(): hash value of x is r(x) Karp-Rabin algorithm for c in s: rs.append(c) here it means to append all chars in s for c in t[:len(s)]: rt.append(c) here it means to apend first chars of len(s) in t if rs() == rt() see if two hash values are equivalent for i in range(len(s), len(t)): {rt.skip(t[i - len(s)]) rt.append(t[i]) if rs() == rt() if true check whether s == t[i-len(s)+1 : i+1] if equal: found match else: continue the algo this happens with probability ≤ 1/|s|} =\u003e O(1) expected time O(|s|+|t|+ #match•|s|) For example we use division method: h(k) = k mod m where m is a random prime ≥ |s| Notice We treat x as multi-digit number u in base a where a is the alphabet size if it’s ASCII, a = 256 if it’s UTF 8 or 16 a will be larger r.append(c): u -\u003e u•a + ord(c) r.skip(c): u -\u003e u - ord(c)•a|u|-1 say if we use division method: r -\u003e (r•a +ord(c) - ord(c)•a|x|-1) mod m here it’s order of |x|-1 because r multiplied a at first ","date":"2021-12-25","objectID":"/table-doubling-karp-rabin/:0:1","series":[],"tags":["Algorithm"],"title":"Karp-Rabin","uri":"/table-doubling-karp-rabin/#table-doubling-karp-rabin"},{"categories":["Note"],"content":"Table Doubling, Karp-Rabin how to choose m? want m = Θ(n) = 𝛼 = Θ(1) Idea: start small: m = 8 grow/shrink as necessary If m n, grow a table make table of size m' build new hash f' rehash insert them in new table T' Θ(n+m+m') in the case above if m' = m + 1 the cost of n insert is Θ(1+2+3+…+n) = Θ(n2) if m' = 2m Oh, Golden cost of n insert is Θ(1+2+4+8+…+n) = Θ(n) Table Doubling = Amortization operation take “T(n) amortized” if k operations take ≤ k•T(n) time think of meaning “T(n) on average”, where average over all operations SO! table doubling: k insertions take Θ(k) time = Θ(1) amortized per insertion also: k insertions \u0026 deletions take O(k) Deletion if m = n/2 then shrink to m/2 slow: from 2k 2k+1 =Θ(n) per operaiton (BAD!) if m = n/4 then shrink to m/2 amortized time to Θ(1) String Matching given two strings s \u0026 t: does s occur as a substring of t? Simple algo: any(s==t)[i:i+len(s)] for i in range(len(t)-len(s)) running time: Θ(|s|•(|t|-|s|)) ≈ Θ(|s|•|t|) Rolling hash ADT r.append(c): add the char to end of x r.skip(c): delete the first char of x r maintains a string x r(): hash value of x is r(x) Karp-Rabin algorithm for c in s: rs.append(c) here it means to append all chars in s for c in t[:len(s)]: rt.append(c) here it means to apend first chars of len(s) in t if rs() == rt() see if two hash values are equivalent for i in range(len(s), len(t)): {rt.skip(t[i - len(s)]) rt.append(t[i]) if rs() == rt() if true check whether s == t[i-len(s)+1 : i+1] if equal: found match else: continue the algo this happens with probability ≤ 1/|s|} = O(1) expected time O(|s|+|t|+ #match•|s|) For example we use division method: h(k) = k mod m where m is a random prime ≥ |s| Notice We treat x as multi-digit number u in base a where a is the alphabet size if it’s ASCII, a = 256 if it’s UTF 8 or 16 a will be larger r.append(c): u - u•a + ord(c) r.skip(c): u - u - ord(c)•a|u|-1 say if we use division method: r - (r•a +ord(c) - ord(c)•a|x|-1) mod m here it’s order of |x|-1 because r multiplied a at first ","date":"2021-12-25","objectID":"/table-doubling-karp-rabin/:0:1","series":[],"tags":["Algorithm"],"title":"Karp-Rabin","uri":"/table-doubling-karp-rabin/#string-matching"},{"categories":["Note"],"content":"Table Doubling, Karp-Rabin how to choose m? want m = Θ(n) = 𝛼 = Θ(1) Idea: start small: m = 8 grow/shrink as necessary If m n, grow a table make table of size m' build new hash f' rehash insert them in new table T' Θ(n+m+m') in the case above if m' = m + 1 the cost of n insert is Θ(1+2+3+…+n) = Θ(n2) if m' = 2m Oh, Golden cost of n insert is Θ(1+2+4+8+…+n) = Θ(n) Table Doubling = Amortization operation take “T(n) amortized” if k operations take ≤ k•T(n) time think of meaning “T(n) on average”, where average over all operations SO! table doubling: k insertions take Θ(k) time = Θ(1) amortized per insertion also: k insertions \u0026 deletions take O(k) Deletion if m = n/2 then shrink to m/2 slow: from 2k 2k+1 =Θ(n) per operaiton (BAD!) if m = n/4 then shrink to m/2 amortized time to Θ(1) String Matching given two strings s \u0026 t: does s occur as a substring of t? Simple algo: any(s==t)[i:i+len(s)] for i in range(len(t)-len(s)) running time: Θ(|s|•(|t|-|s|)) ≈ Θ(|s|•|t|) Rolling hash ADT r.append(c): add the char to end of x r.skip(c): delete the first char of x r maintains a string x r(): hash value of x is r(x) Karp-Rabin algorithm for c in s: rs.append(c) here it means to append all chars in s for c in t[:len(s)]: rt.append(c) here it means to apend first chars of len(s) in t if rs() == rt() see if two hash values are equivalent for i in range(len(s), len(t)): {rt.skip(t[i - len(s)]) rt.append(t[i]) if rs() == rt() if true check whether s == t[i-len(s)+1 : i+1] if equal: found match else: continue the algo this happens with probability ≤ 1/|s|} = O(1) expected time O(|s|+|t|+ #match•|s|) For example we use division method: h(k) = k mod m where m is a random prime ≥ |s| Notice We treat x as multi-digit number u in base a where a is the alphabet size if it’s ASCII, a = 256 if it’s UTF 8 or 16 a will be larger r.append(c): u - u•a + ord(c) r.skip(c): u - u - ord(c)•a|u|-1 say if we use division method: r - (r•a +ord(c) - ord(c)•a|x|-1) mod m here it’s order of |x|-1 because r multiplied a at first ","date":"2021-12-25","objectID":"/table-doubling-karp-rabin/:0:1","series":[],"tags":["Algorithm"],"title":"Karp-Rabin","uri":"/table-doubling-karp-rabin/#rolling-hash-adt"},{"categories":["Note"],"content":"Table Doubling, Karp-Rabin how to choose m? want m = Θ(n) = 𝛼 = Θ(1) Idea: start small: m = 8 grow/shrink as necessary If m n, grow a table make table of size m' build new hash f' rehash insert them in new table T' Θ(n+m+m') in the case above if m' = m + 1 the cost of n insert is Θ(1+2+3+…+n) = Θ(n2) if m' = 2m Oh, Golden cost of n insert is Θ(1+2+4+8+…+n) = Θ(n) Table Doubling = Amortization operation take “T(n) amortized” if k operations take ≤ k•T(n) time think of meaning “T(n) on average”, where average over all operations SO! table doubling: k insertions take Θ(k) time = Θ(1) amortized per insertion also: k insertions \u0026 deletions take O(k) Deletion if m = n/2 then shrink to m/2 slow: from 2k 2k+1 =Θ(n) per operaiton (BAD!) if m = n/4 then shrink to m/2 amortized time to Θ(1) String Matching given two strings s \u0026 t: does s occur as a substring of t? Simple algo: any(s==t)[i:i+len(s)] for i in range(len(t)-len(s)) running time: Θ(|s|•(|t|-|s|)) ≈ Θ(|s|•|t|) Rolling hash ADT r.append(c): add the char to end of x r.skip(c): delete the first char of x r maintains a string x r(): hash value of x is r(x) Karp-Rabin algorithm for c in s: rs.append(c) here it means to append all chars in s for c in t[:len(s)]: rt.append(c) here it means to apend first chars of len(s) in t if rs() == rt() see if two hash values are equivalent for i in range(len(s), len(t)): {rt.skip(t[i - len(s)]) rt.append(t[i]) if rs() == rt() if true check whether s == t[i-len(s)+1 : i+1] if equal: found match else: continue the algo this happens with probability ≤ 1/|s|} = O(1) expected time O(|s|+|t|+ #match•|s|) For example we use division method: h(k) = k mod m where m is a random prime ≥ |s| Notice We treat x as multi-digit number u in base a where a is the alphabet size if it’s ASCII, a = 256 if it’s UTF 8 or 16 a will be larger r.append(c): u - u•a + ord(c) r.skip(c): u - u - ord(c)•a|u|-1 say if we use division method: r - (r•a +ord(c) - ord(c)•a|x|-1) mod m here it’s order of |x|-1 because r multiplied a at first ","date":"2021-12-25","objectID":"/table-doubling-karp-rabin/:0:1","series":[],"tags":["Algorithm"],"title":"Karp-Rabin","uri":"/table-doubling-karp-rabin/#karp-rabin-algorithm"},{"categories":["Note"],"content":"Table Doubling, Karp-Rabin how to choose m? want m = Θ(n) = 𝛼 = Θ(1) Idea: start small: m = 8 grow/shrink as necessary If m n, grow a table make table of size m' build new hash f' rehash insert them in new table T' Θ(n+m+m') in the case above if m' = m + 1 the cost of n insert is Θ(1+2+3+…+n) = Θ(n2) if m' = 2m Oh, Golden cost of n insert is Θ(1+2+4+8+…+n) = Θ(n) Table Doubling = Amortization operation take “T(n) amortized” if k operations take ≤ k•T(n) time think of meaning “T(n) on average”, where average over all operations SO! table doubling: k insertions take Θ(k) time = Θ(1) amortized per insertion also: k insertions \u0026 deletions take O(k) Deletion if m = n/2 then shrink to m/2 slow: from 2k 2k+1 =Θ(n) per operaiton (BAD!) if m = n/4 then shrink to m/2 amortized time to Θ(1) String Matching given two strings s \u0026 t: does s occur as a substring of t? Simple algo: any(s==t)[i:i+len(s)] for i in range(len(t)-len(s)) running time: Θ(|s|•(|t|-|s|)) ≈ Θ(|s|•|t|) Rolling hash ADT r.append(c): add the char to end of x r.skip(c): delete the first char of x r maintains a string x r(): hash value of x is r(x) Karp-Rabin algorithm for c in s: rs.append(c) here it means to append all chars in s for c in t[:len(s)]: rt.append(c) here it means to apend first chars of len(s) in t if rs() == rt() see if two hash values are equivalent for i in range(len(s), len(t)): {rt.skip(t[i - len(s)]) rt.append(t[i]) if rs() == rt() if true check whether s == t[i-len(s)+1 : i+1] if equal: found match else: continue the algo this happens with probability ≤ 1/|s|} = O(1) expected time O(|s|+|t|+ #match•|s|) For example we use division method: h(k) = k mod m where m is a random prime ≥ |s| Notice We treat x as multi-digit number u in base a where a is the alphabet size if it’s ASCII, a = 256 if it’s UTF 8 or 16 a will be larger r.append(c): u - u•a + ord(c) r.skip(c): u - u - ord(c)•a|u|-1 say if we use division method: r - (r•a +ord(c) - ord(c)•a|x|-1) mod m here it’s order of |x|-1 because r multiplied a at first ","date":"2021-12-25","objectID":"/table-doubling-karp-rabin/:0:1","series":[],"tags":["Algorithm"],"title":"Karp-Rabin","uri":"/table-doubling-karp-rabin/#notice"},{"categories":["Note"],"content":"Linux ","date":"2021-12-25","objectID":"/linux/:0:0","series":[],"tags":["Linux"],"title":"Linux","uri":"/linux/#linux"},{"categories":["Note"],"content":"Installation VMware ","date":"2021-12-25","objectID":"/linux/:0:1","series":[],"tags":["Linux"],"title":"Linux","uri":"/linux/#installation"},{"categories":["Note"],"content":"Partition Editior 主分区最多只能有4个 扩展分区只能有一个 主分区加扩展分区只能有4个 扩展分区不能写入数据 只能包含逻辑分区 逻辑分区内可以写入数据 格式化（高级格式化）又称逻辑格式化 格式化的目的就是为了写入 就像把柜子中打入隔断（遵守某种规则划分block） 当用户读取文件的时候 调用分区表 每个文件有一个inode 从而找到对应文件 格式化就是制定和实行这一种特定的规则 并创造inode表的过程 建立硬件设备文件（自动的 但我们要看懂） 第一子目录dev下 （linux一切皆文件） IDE硬盘 _dev_hd/[a-d] SCSI_SATA_USB硬盘 _dev_sd/[a-p] 等等…… 分区设备文件名 _dev_hda1（IDE硬盘接口） 等等…….. 挂载（类似win下的分配盘符，写入挂载点） 必须分区 根分区 保证有地方可以写入 2. swap分区（其实就是虚拟内存 交换分区 一般设置内存2倍 ） 当根分区不足时 有备用分区写入 推荐分区 /boot（启动分区）专门保存启动时的数据 以防根分区满了 无法启动 文件系统结构 / /boot /etc passwd shadow group /home 注意 linux可以给任意文件层级分配分区 比如给_分配_dev_sda3 然后给_home分配dev/sda2 等等 ","date":"2021-12-25","objectID":"/linux/:0:2","series":[],"tags":["Linux"],"title":"Linux","uri":"/linux/#partition-editior"},{"categories":["Note"],"content":"远程登录管理 联网 桥接（利用真实网卡，人多可能有IP地址冲突） host only VMnet 配置网卡 ifconfig -ens0 192.168.118.2 虚拟机的网卡一定要和host在一个网段 否则无法通信 注意 这种方法只是临时生效 重启之后就会reset 远程连接工具 SecureCRT quick connect Username: root 一般不推荐用root登陆，因为权限过大，容易出问题，最好用一个普通账户登录 选择带save的 进入了之后即可进入远程操控 操作谨慎，例如关机重启更改ip地址 如果有乱码 把字体改成任何一个中文字体 让他包含乱码的字符集，然后刷新 输入df 查看分区情况 Winscp 文件拷贝工具 登陆 文件协议 SFTP 图形化界面 带加密 简单安全 xshell或者xftp ","date":"2021-12-25","objectID":"/linux/:0:3","series":[],"tags":["Linux"],"title":"Linux","uri":"/linux/#远程登录管理"},{"categories":["Note"],"content":"注意事项 Linux区分大小写 Linux中所有文件以稳健的形式保存，包括硬件！一切皆文件 Linux不靠扩展名区分文件 靠的是文件权限 注意：有一些为了使用方便的扩展名是给操作者看的 实际linux不需要 压缩包 gz bz2 配置文件conf 脚本文件sh 安全 因为病毒没有执行权限 Linux所有存储设备都必须挂在之后才能使用，包括硬盘 u盘 光盘 ","date":"2021-12-25","objectID":"/linux/:0:4","series":[],"tags":["Linux"],"title":"Linux","uri":"/linux/#注意事项"},{"categories":["Note"],"content":"服务器的维护和建议 服务器注意事项 远程服务器不许关机，只能重启…因为远程关了没法开 推荐使用shutdown -r now 在重启前 进行几次-sync 重启时应正确关闭服务！ 不要再服务器访问高峰运行高负载命令 远程配置防火墙时不要把自己踢出服务器 防火墙是个门岗 过滤器，靠ip地址 mac号 端口 协议类型 数据包中的数据等等 并不能防病毒 不能替代放毒软件 配置不好 可能把自己踢出去了 那就凉了 有一个笨办法 设置每五分钟清空防火墙设置 知道配置结束 以防把自己踢出去进不来了 制定合理的密码规范并定期更新 合理分配权限 在够用的情况下尽可能少 就像系统启动的服务越少越好 定期备份重要数据和日志 鸡蛋不要放在同一个篮子里 ","date":"2021-12-25","objectID":"/linux/:0:5","series":[],"tags":["Linux"],"title":"Linux","uri":"/linux/#服务器的维护和建议"},{"categories":["Note"],"content":"开源软件 Apache — web服务器 Nginx — web服务器 MySQL — 数据库（SQLsever，Oracle贵） Samba — Linux和windows之间的内网文件服务器 MongoDB/redis — NoSQL数据库（不遵守SQL规则 辅助MySQL） Sphinx — 中文分词（主要是用来做搜索引擎）（见喜欢迎 —\u003e 见喜｜欢迎） 1. 免费 2. 可以获得源代码 3. 自由传播，改良，甚至销售 支撑互联网的开源技术LAMP or LNMP：Linux Apache/Nginx MySQL PHP 现在还是这样么？ 需要验证 ","date":"2021-12-25","objectID":"/linux/:0:6","series":[],"tags":["Linux"],"title":"Linux","uri":"/linux/#开源软件"},{"categories":["Note"],"content":"一级目录 bin 存放系统命令的目录，普通用户和超级用户都可以执行。不过放在/bin下的命令在单用户模式下也可以执行 sbin 保存和系统环境设置相关的命令，只有超级用户才可以使用他们进行系统环境设置 _usr_bin/ 存放系统命令的目录，普通用户和超级用户都可以执行，这些命令和系统启动无关，在单用户模式下无法执行 _usr_sbin/ 存放根文件系统不必要的系统管理命令，例如多数服务程序，只有超级用户可以使用 boot 系统启动目录，保存系统启动相关的文件，如内核文件和启动引导程序（grub）文件等 强烈建议备份 dev 设备文件的保存位置 etc 配置文件的保存位置，系统内所有采用默认安装方式（rpm安装）的服务配置文件全都保存在这个目录当中，如用户账户密码，服务的启动脚本，常用服务的配置文件等 强烈建议备份 home 普通用户的家目录 lib 系统调用函数库保存位置 lost+found 当系统以外崩溃或机器意外关机，会产生一些文件碎片在这里，可以用作备份恢复等 media 挂载目录 挂在额外设备 mnt 挂载目录挂载NFS服务的共享目录 注意 只有空目录才能作为挂载点 挂哪都行 misc 挂载目录 不大用 opt 第三方安装的软件的保存位置，不过现在已吧还是把软件放在usr_local_中，算是业内的潜规则 proc 虚拟文件系统 该目录中的数据并不保存在硬盘里 在内存里 主要是内存的进程 内核 设备状态 cpu信息等等等等 sys 内核相关 虚拟文件系统 在内存中 root 超级用户的家目录 srv 服务数据目录 服务 应用在启动之后产生的一切数据 tmp 临时目录 系统存放的临时文件 最好每次开机后清空 usr 系统软件资源目录 注意usr不是user的缩写 而是 Unix Software Resource的缩写 系统中安装的软件大多数都保存在这里 var 动态数据保存位置 其实就是日志 邮件等 主要保存缓存 日志以及软件所产生的文件 ","date":"2021-12-25","objectID":"/linux/:0:7","series":[],"tags":["Linux"],"title":"Linux","uri":"/linux/#一级目录"},{"categories":["Note"],"content":"二级目录 usr_lib_ 应用程序调用的函数库保存位置 usr_local_ 安装位置 手工安装软件保存位置，一般建议把源码包软件安装在这个位置 usr_share_ 应用程序的资源文件，如帮助文档，说明文档和字体目录 usr_src_ 源程序位置 我们手动下载的源码包和内核源码包可以保存在这里 不过我觉得 usr_local_src/ 好像更好 这样可以跟内核分开放 usr_src_kernels/ 内核源码的保存位置 var_www_html rpm包安装的Apache的网页主目录 _var_lib/ 程序运行时需要调用或改变的数据保存位置，如MySQL的数据保存在_var_lib_mysql_中 _var_log/ 系统日志的保存位置 _var_run/ 一些服务和程序运行后，它们的PID（进程ID）保存位置。是_run_目录的软链接 _var_spool/ 防止队列数据的目录，就是排队等待其他程序使用的数据，比如邮件队列和打印队列 var_spool_mail 新收到的邮件队列保存位置，系统新收到的邮件回保存在这里 var_spool_cron 系统的定时任务队列保存位置，系统的计划任务会保存在这里 ","date":"2021-12-25","objectID":"/linux/:0:8","series":[],"tags":["Linux"],"title":"Linux","uri":"/linux/#二级目录"},{"categories":["Note"],"content":"常用命令 ","date":"2021-12-25","objectID":"/linux/:1:0","series":[],"tags":["Linux"],"title":"Linux","uri":"/linux/#常用命令"},{"categories":["Note"],"content":"命令的基本格式 命令的提示符 [root@localhost ~] # []：这是提示符的分隔符号，没有特殊含义 root：显示当前的登录用户 @：分隔符号 没有特殊含义 localhost：当前系统的简写主机名 完全的主机名可以通过hostname查看 ~：当前所在目录的最后一级目录 井号是超级用户的命令提示符 $是普通用户的 命令的基本格式 命令 [选项] [参数] ls -l 1. 七列数据 1. 权限 2. 引用计数 1. 文件的引用计数代表该文件的硬链接个数 2. 目录的引用计数代表该目录有多少个一级子目录（注意 有隐藏子目录） 3. 所有者 默认为文件的创建者 4. 所属组 默认所属组是文件建立用户的有效组，一般情况下是建立用户的所属组 5. 文件大小 默认单位byte 1. -h 人性化显示 自动优化大小显示 6. 修改时间和访问时间中最紧的 7. 文件名 **选项是用于调整命令的功能的** ls下支持的部分常用选项 -a 显示所有文件 —color=when 支持颜色输出 when的默认值是always，也可以是never或者auto -d 显示目录信息，而不是目录下的文件 -h 人性化显示 按照我们的习惯显示文件大小 -i 显示文件的i节点号 -l 长格式显示 等等 参数是命令的操作对象，如果省略参数，是因为有默认参数 ","date":"2021-12-25","objectID":"/linux/:1:1","series":[],"tags":["Linux"],"title":"Linux","uri":"/linux/#命令的基本格式"},{"categories":["Note"],"content":"目录操作命令 ls命令 cd命令 change directory 绝对路径和相对路径 绝对路径：以根目录为参照物，从根目录开始一级一级进入目录 相对路径：以当前目录作为参照物进行目录查找 cd后面参数从/开始就是绝对路径 否则就是相对目录 新手建议用绝对命令 简化用法 ~代表用户的家目录 -代表上次目录 .代表当前目录 ..代表上级目录 pwd 显示当前路径 mkdir新建目录 除了家目录和临时目录最好不要新建目录 不安全 make directories -p递归建立所需目录 mkdir 123/234/345 一级一级的递归建立 rmdir命令 remove empty directories 只能删除空目录 -p递归删除 并不推荐使用 太垃圾 rm命令 rm -r 123 递归删除（询问） 进入到最深的空文件然后一级一级上级删除 rm -rf 123 删除了目录本身 非常危险！ 不会进入回收站 用的时候先想清楚 否则手快过大脑就gg 建议预先安装extundelete实现linux下文件和文件夹的数据恢复！！就算这样都不一定能恢复 如果不要删除当前目录，只删除当前目录下的所有子文件 rm -rf 123/* 星号为通配符 可为任意内容 ","date":"2021-12-25","objectID":"/linux/:1:2","series":[],"tags":["Linux"],"title":"Linux","uri":"/linux/#目录操作命令"},{"categories":["Note"],"content":"文件操作命令 touch命令 change file timestamps 创建空文件或或修改文件的时间戳 stat命令 status 显示文件或文件系统的详细信息 注意linux是不记录创建时间的 注意modify和change的区别 cat命令 concatenate 查看文件内容 -n显示行号 -E列出每行结尾的回车符$ -v列出特殊字符 -T把tab用^I显示出来 -A相当于 -vET 用于列出所有隐藏符 有些文件太大了 用cat不行 cat只适合看小文件 more命令 分屏显示文件的命令 用来显示cat无法显示的大文件 交互 空格 向下翻页 b 向上翻页 回车 向下滚动一行 /字符串 搜索制定字符串 q 退出 less命令 分行显示文件的命令 交互 上下 一行一行翻 q 退出 head命令 显示文件头 -n 行数：显示制定行数 -f：监听 不会退出文件 如果其他终端往里写数据了 会继续显示新增内容 要用ctrl+c退出 tail命令 显示文件尾 -n 行数：显示制定行数 ln命令 link make links between files inode inode# 时间 权限 block的位置 block 储存了子文件的文件名和inode 所以如果我要查d文件的inode号， 我需要找到它的上级文件的block，在查询d的inode号…层层递归。所以要从根目录开始，根目录的inode号是固定为2（1在创建内核的时候被占用了） 硬链接 源文件和硬链接会拥有相同的inode和block 引用计数增加 修改其中一个 另一个都改变 删除任意一个文件 另一个都可用 硬链接标记不清，很难确认硬链接文件位置 不建议使用 硬链接 不能链接目录 因为链一个目录 所有子文件都要链 所以linux不让瞎搞 硬链接不能跨分区 俩文件要zhi xiang同一个分区的同一个inode 两东西其实是一个文件 只是名字不同而已 就像一个教室两个门 前门进人人数改变 后面进人人数也改变 堵上一个门 一样能进教室 软链接 ln -s 软链接和源文件拥有不同的Inode和Block 引用计数不会增加 任意修改一个 另一个都改变 删除软链接，源文件不受影响，删除源文件，软链接不能使用 软链接没有实际数据，只保存源文件的Inode，不论源文件多大，软链接的大小不变 软链接的权限是最大权限lrwxrwxrwx，但是由于没有实际数据，最终访问时要参考源文件权限 软链接可以链接目录 也可以跨分区 软链接的标记特征明显 推荐使用 软链接移动要写绝对路径！！！！！否则很容易出错 其实可以理解成快捷方式 是为了照顾老手的使用习惯 因为很多升级改变了文件的位置 不好找 ","date":"2021-12-25","objectID":"/linux/:1:3","series":[],"tags":["Linux"],"title":"Linux","uri":"/linux/#文件操作命令"},{"categories":["Note"],"content":"目录和文件都能操作的命令 rm命令 -f：强制删除 -i：交互删除 默认情况下就是 -r：递归删除，可以删除目录 cp命令 cp [选项] 源文件 目标文件 copy -r递归复制 用于复制目录 -a 相当于 -dpr 保证目标文件和源文件一模一样 -d 如果源文件为软链接，则复制出的目标也为软链接 -i 如果目标文件已经存在，则会询问是否覆盖 -p 复制后目标文件保留源文件的属性，包括所有者 所属组 权限和时间 mv命令 move 移动或重命名 移动目录不需要加-r mv 123 tmp 把123这个文件或者目录原名移动到tmp文件下 mv 123 234 把123重命名为234 ","date":"2021-12-25","objectID":"/linux/:1:4","series":[],"tags":["Linux"],"title":"Linux","uri":"/linux/#目录和文件都能操作的命令"},{"categories":["Note"],"content":"基本权限管理 权限介绍 带.的 表示受SELinux 保护的文件 共10项 文件的类型 具体类型 info ls查询 主要类型 -：普通文件 d：目录 l：软链接 剩下的相对较常见的还有 b 块设备文件比如内存c 设备文件比如鼠标键盘 p 管道服务文件s 套接字文件 千万别动 例如可能导致要重装php或mysql 2-4 所有者权限 5-7 所属组权限 8-10 其他 rwx分别代表读写执行权限 所有者权限优先于所属组权限 基本权限命令 chmod chmod [ugoa] [[+-=] [perm]] change file mode bits 赋予方式 = 例子 chmod u+x bcd 给bcd的所有者添加执行权限 chmod g+w，o+w bcd chmod u-x，g-w，o-w bcd chmod u=rwx bcd 数字权限 4代表r 2代表w 1代表x 例子 chmod 755 bcd 常用权限 644 基本权限 755 文件的执行权限和目录的基本权限 777 除了系统自带的 不允许手动赋予777 会造成安全隐患 有时候改了改了开源软件放进apache 报错权限不足，为了省事所以被改成了777，造成安全隐患 chown命令 change file owner and group chown [选项] 用户:所属组 文件或目录 也可用.分隔 注意：普通用户可以修改所有者是自己的文件的权限 注意：普通用户不能修改文件的所有者 哪怕是属于当前用户的文件 只有超级用户能修改所有者和所属组 测试 在root超级用户下 先添加用户 useradd user1 注意 添加用户就会自动添加进自动创建的同名组 passwd user1 此处输入密码 chown user1 bcd chgrp命令 修改所属组 基本权限的作用（难点） 权限对文件的作用 r：cat more less head tail等文件查看命令 w：vim echo等修改文件数据的命令 注意：对文件有写权限 是不能删除文件的 如果想要删除文件，需要对文件的上级目录有写权限！原理是文件的原理 inode和block的内容，文件名和其对应的inode是存在于上级目录的block中的，而权限是针对inode所对应的block的，也就是说，对block的权限是储存在inode中的 x：对文件来说执行权限是最高权限 也是风险最高的 代表该文件有了执行权限 是否能正确执行 不一定 权限对目录的作用 r：ls w：touch rm cp mv等 对目录来说写是最高权限 x：目录是不能执行的，但是如果目录拥有执行权限 对应到命令上就是可进入 可以执行cd命令 目录的可用权限 0:没有任何权限 5:基本的目录浏览和进入权限 7:完全权限 没有什么6权限 因为不能进入 拥有写权限没有意义 注意：权限对超级用户是没有意义的 不管怎么样实际都是777 ","date":"2021-12-25","objectID":"/linux/:1:5","series":[],"tags":["Linux"],"title":"Linux","uri":"/linux/#基本权限管理"},{"categories":["Note"],"content":"umask默认权限 查看系统的umask权限 默认用八进制数值显示umask的权限 0022 暂时我们忽略第一个数 后面依次是022 即 -S 用字母表示文件和目录的权限 umask权限的计算方法 新建文件的默认最大权限 666 执行权限对文件比较危险，不能在新建时默认赋予，必须用户手动赋予 新建目录的默认最大权限 777 执行权限就是进入目录，所以默认赋予 官方标准算法 umask需要使用二进制进行逻辑与和逻辑非联合运算得到正确的默认权限 将总权限（目录777 文件666）和umask转换为2进制 对umask取反 对两个值做与 转换为十进制即权限 但我们可以这样理解 umask是我们希望从默认最大权限中去掉的权限 如果本来有 则去掉 如果本来就没有 维持原样 所以 对文件来说 umask 033和022的结果都是644 注意 要永久更改umask 要写入配置文件 /etc/profile 环境变量配置文件 否则都是暂时的更改 ","date":"2021-12-25","objectID":"/linux/:1:6","series":[],"tags":["Linux"],"title":"Linux","uri":"/linux/#umask默认权限"},{"categories":["Note"],"content":"帮助命令 man命令 manual man [命令] 快捷键 上下 移动一行 PgUp PgDn 翻页 g 第一页 G/shift+g 最后一页 q 退出 /字符串 从当前向下搜索 ？字符串 从当前向上搜索 N 当搜索字符串时 使用N反向搜索 帮助级别 默认打开1级别 绝大部分命令只有1级别的 帮助级别 普通用户可以执行的系统命令和可执行文件的帮助 内核可以调用的函数和工具的帮助 C语言函数的帮助 设备和特殊文件的帮助 配置文件的帮助 游戏的帮助 杂项的帮助 超级用户可执行的系统命令的帮助 内核的帮助 man -f 命令 或者 whatis 命令 查看命令拥有哪个级别的帮助 小tip：新系统或者刚恢复快照 可能用whatis报错 可用makewhatis 解决 man -k 命令 或者 apropos 命令 查看命令相关的所有帮助 只要包含命令的字符串都会被找到 不常用 info命令 info命令比man更详细，是一套完整的资料 如果man找不到有用的信息，在用info help命令 只能获取shell内置命令的帮助 作用很有限 一般不用 –help选项 绝大多数命令都可以使用–help选项来查看帮助 输出的帮助信息基本是man的简化版 例如 ls –help ","date":"2021-12-25","objectID":"/linux/:1:7","series":[],"tags":["Linux"],"title":"Linux","uri":"/linux/#帮助命令"},{"categories":["Note"],"content":"搜索命令 whereis命令 搜索命令的命令 不能搜索文件 搜索位置和帮助文档的位置 which命令 搜索命令的命令 不能搜索文件 搜索位置和灵命的别名 locate命令 按照文件名搜索普通文件的命令 优点：按照数据库搜索，速度快，消耗资源少，数据库位置/var/lib/mlocate/mlocate.db 缺点；只能按照文件名来搜索文件，不能执行更复杂的搜索 注意：搜索前先更新库 updatedb 否则刚产生的文件夹可能找不着 注意：配置文件里会排除一些文件和目录 例如tmp下的文件是搜不到的 常用 find命令 按照文件名搜索 -name find [路径] -name [文件名] 严格区分大小写 -iname 不区分大小写 -inum 按照inode去搜索文件 按照文件大小搜索 -size find . -size -15 默认单位b 512字节 c for byte w for 2字节 k for KB M for MB G for GB 大小之前- 代表小于 按照修改时间搜索 -atime 访问时间 -mtime 修改时间 -ctime 状态修改时间 前三个时间单位为天 -amin -mmin -cmin 以分钟为单位 格式：find . -atime +5 -5 五天内 5 五到六天前的那24小时 +5 六天之前 按照权限来搜索 -perm 支持+— +444 搜索包含444种任意一个组的权限的文件 三个数任意一个大于等于4 -444 搜索全部包含权限模式的文件 三个数全部大于等于4 444 搜索搞好等于权限模式的文件 按照所有者和所属组搜索 -uid -gid -user -group -nouser 查找没有所有者文件 即外来文件 如光盘和U盘等 否则一般是垃圾文件 常用来搜索垃圾文件 按照文件类型搜索 find . -type d abc 查找目录 -type f 普通文件 -type l 软连接文件 逻辑运算符 find 搜索路径 选项 搜索内容 -a 与 find . -size +2k -a -type f -o 或 -not 或者! 非 其他选项 -exec find 搜索路径 选项 搜索内容 -exec 命令2 {} ; 把find命令的结果交给由-exec调用的命令2来处理 {}就代表find命令的查找结果 find . -size +2k -a -type f -exec ls -lh {} ; 注意命令2不支持别名 -ok 区别是每执行一次命令2 就询问一次 -exec就直接处理了 -ok 比-exec适合执行删除 grep命令 用于在文件中搜索符合条件的字符串 如果需要模糊搜索，使用正则表达式进行匹配 选项 -i 忽略大小写 -n 输出其在原始文件里的行号 -v 取反 –color=auto 搜索的字符串红色高亮 ","date":"2021-12-25","objectID":"/linux/:1:8","series":[],"tags":["Linux"],"title":"Linux","uri":"/linux/#搜索命令"},{"categories":["Note"],"content":"通配符 完全匹配 ?匹配1个任意字符 *匹配任意个数任意字符 可以为0个字符 [] 匹配其中任何一个字符 [-] 表示范围 [^] 表示取反 ","date":"2021-12-25","objectID":"/linux/:1:9","series":[],"tags":["Linux"],"title":"Linux","uri":"/linux/#通配符"},{"categories":["Note"],"content":"正则表达式 用于包含匹配 ? 匹配0或1个前一个字符 属于扩展正则符 需要egrep来识别 * 匹配任意个数前一个字符 “a*” meaningless since it can be any string ^ 限位符 匹配行首 $限位符 匹配行尾 正则一般用来粗过滤 因为文本处理快 占用资源小 支持访问量大 所以一般先用正则粗过滤 然后用程序过滤 对比find和grep find默认完全匹配 grep默认包含匹配 grep搜索的是字符串 ","date":"2021-12-25","objectID":"/linux/:1:10","series":[],"tags":["Linux"],"title":"Linux","uri":"/linux/#正则表达式"},{"categories":["Note"],"content":"正则表达式 用于包含匹配 ? 匹配0或1个前一个字符 属于扩展正则符 需要egrep来识别 * 匹配任意个数前一个字符 “a*” meaningless since it can be any string ^ 限位符 匹配行首 $限位符 匹配行尾 正则一般用来粗过滤 因为文本处理快 占用资源小 支持访问量大 所以一般先用正则粗过滤 然后用程序过滤 对比find和grep find默认完全匹配 grep默认包含匹配 grep搜索的是字符串 ","date":"2021-12-25","objectID":"/linux/:1:10","series":[],"tags":["Linux"],"title":"Linux","uri":"/linux/#对比find和grep"},{"categories":["Note"],"content":"管道符 命令1 | 命令2 命令1的争取输出作为命令2的操作对象 为啥有了-exec还要管道符呢 ｜是文本流操作 find不支持文本流操作 所以不支持管道符 例子 ll /etc/ ｜ more ll /etc/ ｜ grep 注意此处不能用find 因为grep才是搜索字符串的 更别说find不支持文本流 netstat -tuln 查询系统中所有开启的端口 netstat -tuln ｜ grep 80 注意这个是包含匹配 是包含80的端口 netstat -an 所有的端口号 enstat -an | grep ESTABLISED | wc -l 统计正在连接的数量 ","date":"2021-12-25","objectID":"/linux/:1:11","series":[],"tags":["Linux"],"title":"Linux","uri":"/linux/#管道符"},{"categories":["Note"],"content":"命令的别名 alias 别名=' 命令' alias grep=' grep –color=auto' alias ser =' service network restart' 注意！！ 别名的优先级比系统命令高，不要和系统命令重叠 默认是临时的改变 永久更改需要写入配置文件~/bashrc 注意！！*放在/etc/下的配置文件 对所有用户生效 放在家目录~/下的只对该用户生效 ","date":"2021-12-25","objectID":"/linux/:1:12","series":[],"tags":["Linux"],"title":"Linux","uri":"/linux/#命令的别名"},{"categories":["Note"],"content":"常用快捷键 ctrl+a 光标移动到行首 ctrl+e 光标移动到行尾 Tab 命令或文件补全 ctrl+c 强制终止当前的命令 ctrl+l 相当于clear ctrl+u 删除或剪切光标到行首的命令 ctrl+y 粘贴ctrl+u的内容 ","date":"2021-12-25","objectID":"/linux/:1:13","series":[],"tags":["Linux"],"title":"Linux","uri":"/linux/#常用快捷键"},{"categories":["Note"],"content":"压缩和解压缩命令 系统无所谓扩展名 这是个管理员看的 因为不同格式的压缩命令不同 .zip windows下的压缩格式 zip [选项] 压缩文件名 源文件名 -r 压缩目录 -d 解压缩 unzip 文件名 -d 制定解压缩位置 不常用 .gz .gz较古老 压缩比低 占用资源少 bz2压缩比高 消耗资源多 gzip gzip [选项] 源文件 -c 将压缩数据输出到标准输出中，可以用于保留原文件 gzip -c abc » abc.gz 非常规操作 -d 解压缩 -r 压缩目录 不会打包 gzip -r abc abc目录下的每一个文件都压缩了 但是目录本身没有变 gunzip 文件名 解压缩 bz2 bzip2 bzip2 [选项] 源文件名 -k 保留原文件 -d 解压缩 -v显示解压详细信息 bunzip2 文件名 不能压缩目录 .tar格式 打包不会压缩 tar [选项] [-f 压缩包名] 源文件或目录 -c 打包 -f 制定压缩包文件名 压缩包的扩展名是用来给管理员识别格式的，所以一定要正确指定扩展名 -v 显示打包文件过程 tar -cvf anaconda-ks.cfg.tar anaconda-ks.cfg -x 解打包 一般-xvf tar.gz 和 tar.bz2格式 tar [选项] 压缩包 源文件或目录 -z 压缩和解压缩.tar.gz格式 -j 压缩和解压缩.tar.bz2格式 所以 压缩 tar -zcvf 或者tar -jcvf 解压 tar-zxvf 或者tar -jxvf 只查看一下不解压 把c换成t就行了 解压缩到指定位置 解压缩的文件名后面 -C 解压路径 tar -zxvf you.tar.gz -C abc/bcd 解压特定文件到指定位置 tar -ztvf yui.tar.gz先看看里面有啥 tar -zxvf yui.tar.gz -C /tmp test/cde 再解压其中的cde文件到/tmp中 ","date":"2021-12-25","objectID":"/linux/:1:14","series":[],"tags":["Linux"],"title":"Linux","uri":"/linux/#压缩和解压缩命令"},{"categories":["Note"],"content":"关机和重启命令 sync数据同步 flush file system buffers 刷新文件系统缓存 shutdown命令 bring the system down -c 取消已经执行的shutdown命令 -h 关机 -r 重启 shutdown -r now shutdown -r 05:30 最好不要在固定时间重启 比较危险 千分之几的几率存储设备出问题 不推荐让计算机自己执行 一般要有人看着 最安全的关机命令 会先保存各种东西再关 reboot命令 现在的系统中reboot也是安全的 而且不需要加入过多的选项 halt和poweroff 不推荐 不保存 init命令 init是修改Linux运行级别的命令，也可以用于关机和重启，不建议使用 ","date":"2021-12-25","objectID":"/linux/:1:15","series":[],"tags":["Linux"],"title":"Linux","uri":"/linux/#关机和重启命令"},{"categories":["Note"],"content":"常用网络命令 配置IP地址 setup工具 （redhat系列专有） vi /etc/sysconfig/network-scripts/ifcfg-eth0 手工修改配置文件 主流方法 重启网络服务 service network restart 如果是虚拟机 需要侨界到有线网卡，并重启网络服务 复制镜像有可能需要UUID（唯一识别符） 网卡配置文件里有 快照和当前系统UUID一样 或者 由于克隆虚拟机导致的UUID冲突 vi /etc/sysconfig/network-scripts/ifcfg-eth0 删除MAC地址行 rm -rf /etc/udev/rules.d/70-persistent-net.rules 删除MAC地址和UUID绑定文件 reboot 重启Linux 此时UUID会重新计算 不可能像再相同 ifconfig命令 ping命令 ping [选项] IP -c 指定ping的次数 -b 探测整个网段 用于检测整个网段有多少台电脑 -s 指定探测包的大小 感觉没啥用 netstat命令 -a 列出所有网络状态 包括Socket程序 -c 秒数：指定每隔几秒刷新一次网络状态 -n：使用IP地址和端口号显示，不使用域名与服务名 -t 显示使用TCP协议端口的连接状况 -u 显示使用UDP……. -l 仅显示监听状态的连接 -p 查看PID 看哪个程序占用了端口 netstat -tulnp -rn 可以查看网关 write命令 向其他用户发送信息 w 看看谁在登陆中 登陆终端 本地字符终端tty1-6 使用快捷键alt+F1-6 本地图形终端 tty7 ctrl+alt+F7按住3秒 需要安装图形界面才有 远程终端 pts/0-255 write 用户名 终端名 开始写sfsdfdg ctrl+d发送信息 wall命令 给所有人发送信息 mail命令 发邮件 mail 用户名 mail 用户名 输入内容 查看mail 直接输入mail命令 输入标题号查看 h键看标题 发送文件内容 常用 mail -s “the subject” 用户名 /root/anaconda-ks.cfg -s “fsdfwe” 是邮件标题 ","date":"2021-12-25","objectID":"/linux/:1:16","series":[],"tags":["Linux"],"title":"Linux","uri":"/linux/#常用网络命令"},{"categories":["Note"],"content":"系统痕迹命令 系统中的一些重要的痕迹日志文件，如/var/log/wtmp, /var/run/utmp, /var/log/btmp, /var/log/lastlog等日志文件，只能通过对应的命令查看，通过vim打开是乱码 w命令 /var/run/utmp 第一行 系统时间 开机了多少时间 几个用户登陆中 系统前1分钟 5分钟 15分钟的平均负载 1分钟的负载超过核数 一般来说就是负载比较高了 CPU和内存 70/90原则 cpu不要超过70%内存不要超过90% 第二行以后 用户名 终端名 IP 登陆时间 用户闲置时间 所有进程占用CPU时间 当前进程占用CPU时间 在干啥（-bash就是啥也没干 在等待） who命令 也是看的w查看的日志 区别就是显示更简单 last命令 查看系统所有登陆过的用户信息 /var/log/wtmp lastlog命令 查看所有用户最后一次登陆的时间（包括系统用户） /var/log/lastlog lastb命令 查看错误的登陆信息 比如密码输错了 /var/log/btmp ","date":"2021-12-25","objectID":"/linux/:1:17","series":[],"tags":["Linux"],"title":"Linux","uri":"/linux/#系统痕迹命令"},{"categories":["Note"],"content":"挂载命令 mount命令基本格式 mount [-t 文件系统] [-L 卷标名] [-o 特殊选项] 设备文件名 挂载点 linux所有储存设备都必须挂载 把设备名和一个空目录挂载 mount 显示现在系统中挂载的设备 注意swap不用挂载 直接供内核访问 mount -a 自动挂载 移动存储设备最好不要自动挂载 要是没插 会崩溃 命令会依据配置文件 /etc/fstab的内容 自动挂载 如果配置文件出错要修复 必须服务器现场 但现在来说 这个配置文件已经没有这么脆弱了 但是还是要非常注意 -o里面都不建议修改 尤其是执行权限 容易有大问题 如果root所在分区不可执行 系统就崩溃了 无法启动 光盘挂载 mkdir /mnt/cdrom centOS6以后光盘设备名是/dev/sr0 以此类推 同时dev/cdrom是其软链接 mount /dev/sr0 /mnt/cdrom 然后去挂载点访问光盘的内容 注意 一定记得卸载 umount /dev/sr0 或者umount /mnt/cdrom都可以 U盘挂载 fdisk -l U盘跟硬盘共享设备名 所以不固定 要先查询 假设我们查到usb设备名为sdb1 格式为FAT32 mount -t vfat /dev/sdb4 /mnt/usd/ cd /mnt/usb/ ls 发现中文都不能正常显示 要显示中文 首先要安装中文编码 终端要支持 注意本地终端不支持中文 但是远程终端是可以的 所以挂载时要手工指定中文编码 mount -t vfat -o iocharset-utf8 /dev/sdb1 /mnt/usb/ cd /mnt/usb/ ls 这时应该可以了 用完卸载 挂载NTFS分区 （默认不识别 就算挂载了 最多只读） Linux的驱动加载顺序 驱动直接放入内核中，这种主要是系统加载必须的驱动，数量较少 驱动以模块的形式放入硬盘，大多数驱动都用这种方式，保存位置是/lib/modules/kernel/ 驱动模块是以.ko结尾的 驱动可以被Linux识别，但是系统认为这种驱动一般不常用，默认不加载，如果加载需要重新编译内核，而NTFS文件系统的驱动就属于这种情况 硬件不能被Linux内核识别，需要手工安装驱动。当然前提是厂商提供了该硬件针对Linux的驱动，否则就要自己开发驱动了（笑） 使用NTFS-3G安装NTFS文件系统模块 后面学了安装再说 ","date":"2021-12-25","objectID":"/linux/:1:18","series":[],"tags":["Linux"],"title":"Linux","uri":"/linux/#挂载命令"},{"categories":["Note"],"content":"vim编辑器 vim是全屏幕纯文本编辑器，是vi编辑器的增强版 ","date":"2021-12-25","objectID":"/linux/:2:0","series":[],"tags":["Linux"],"title":"Linux","uri":"/linux/#vim编辑器"},{"categories":["Note"],"content":"vim基本使用 vim的工作模式 命令模式 用快捷键操作 无法写入 ZZ 保存退出 插入命令 a 追加 在光标坐在字符后插入 i 插入 在光标坐在字符前插入 A 光标所在行尾插入 I 光标所在行首插入 o 光标下插入新行 O 光标上插入新行 输入模式 输入：进入编辑模式 编辑模式（末行模式） ：w 保存不退出 ：w 新文件名 相当于另存为 ：q不保存退出 ：wq 保存退出 ：！强制 ：q！强制不保存退出，用于修改文件后不保存数据退出 ：wq！强制保存退出，当文件的所有者或者root用户，对文件没有写入权限时候（比如000），强制写入数据使用 ","date":"2021-12-25","objectID":"/linux/:2:1","series":[],"tags":["Linux"],"title":"Linux","uri":"/linux/#vim基本使用"},{"categories":["Note"],"content":"命令模式操作 光标移动 hjkl 左下上右 文件首尾 gg 移动带文件头 G 移动到文件尾 行首行尾 ^ 移动到行首 \u0026 移动到行尾 移动到指定行 :n 其中n是数字 删除和剪切 x 删除单个字母 nx 删除n个字母 dd 删除剪切单行 ndd 删除剪切多行 ：n1,n2d 删除指定范围 例如:3,5d p 粘贴到光标后 P 粘贴到光标前 dG从光标所在行删除到文件尾 yy 复制单行 nyy复制多行 u 撤销 ctrl+r 反撤销 r 替换光标所在处字符 R 从光标所在处开始替换字符，按ESC结束 ","date":"2021-12-25","objectID":"/linux/:2:2","series":[],"tags":["Linux"],"title":"Linux","uri":"/linux/#命令模式操作"},{"categories":["Note"],"content":"末行模式 vim 配置文件 ~/.vimrc ：set all 进行查看 ：set nu ：set nonu 显示与取消行号 ：syntax on ：syntax off 是否根据语法显示相关颜色的帮助 ：set hlsearch ：set nohlsearch 是否将查找的字符串高亮显示 ：set ruler ：set noruler 是否显示右下角状态栏 ：set showmode ：set noshowmode 是否左下角显示模式状态栏 ：set list ：set nolist 是否显示隐藏字符 tab是^I 回车是$ ","date":"2021-12-25","objectID":"/linux/:2:3","series":[],"tags":["Linux"],"title":"Linux","uri":"/linux/#末行模式"},{"categories":["Note"],"content":"查找 /查找内容 从光标所在行向下查找 ?查找内容 从光标坐在行向上搜索 n 下一个 N 上一个 ","date":"2021-12-25","objectID":"/linux/:2:4","series":[],"tags":["Linux"],"title":"Linux","uri":"/linux/#查找"},{"categories":["Note"],"content":"替换 ：1，10s/old/new/g 替换1到10行所有old为new s代表替换 g代表替换所有 ：%s/old/new/g 替换整个文件的old为new %是个变量 这里代表整篇文档 ：1，10s/^ /#/g 注释1到10行 ：1，10/^#//g 取消注释 ：1，10/^///g 1到10行 行首加入// 或者 按esc进入命令模式 ctrl+v 上下移动选取 shift+i and type esc ","date":"2021-12-25","objectID":"/linux/:2:5","series":[],"tags":["Linux"],"title":"Linux","uri":"/linux/#替换"},{"categories":["Note"],"content":"vim使用技巧 在vim中导入其他文件内容或命令结果 ：r 文件名 把文件内容导入光标位置 在vim中执行系统命令 ：！命令 暂时跳出vim执行一次系统命令 导入命令结果 ：r !命令 设定快捷键 ：map 快捷键 快捷键执行的命令 ：map ^P I#\u003cESC\u003e 按ctrl+p在行首加入注释 ：map ^B ^x 按ctrl+b 删除行首第一个字母 注意 ^ 使用 ctrl+v输入的 普通的^并不起作用 要永久生效 写入~/.vimrc 字符替换 ：ab 原字符 替换为字符 在vim编辑中 有时需要频繁输入长字符串 例如邮箱 我们可以用另一个字符串代替 每次输入源字符 自动变 多文件打开 vim -o abc bcd 上下分屏打开两个文件 ctrl+w 再按方向键 在文件之间跳转 如果要左右分屏 则-O ","date":"2021-12-25","objectID":"/linux/:2:6","series":[],"tags":["Linux"],"title":"Linux","uri":"/linux/#vim使用技巧"},{"categories":["Note"],"content":"软件包安装 ","date":"2021-12-25","objectID":"/linux/:3:0","series":[],"tags":["Linux"],"title":"Linux","uri":"/linux/#软件包安装"},{"categories":["Note"],"content":"软件包分类 源码包 二进制包 源码包 开源 可以自己动手改 自由选择所需功能 软件是便衣安装，更加舍和自己的系统，稳定，效率高 卸载方便 安装过程步骤较多，尤其安装较大软件合集时，容易出现拼写错误 编译时间长，比二进制安装时间长 因为是编译安装，安装过程中一旦报错新手很难解决 二进制包 DPKG包 一般叫Deb包 因为由Debian开发 RPM包 由Red Hat开发 简单 命令实现安装升级查询卸载 功能选择不灵活 依赖性 看不到源代码 软件包选择建议 源码包：如果服务是给大量客户端提供访问的，建议使用源码包，源码包效率更高 RPM包：如果程序是给少量用户访问，或者本地使用的，建议RPM包，因为RPM管理 ","date":"2021-12-25","objectID":"/linux/:3:1","series":[],"tags":["Linux"],"title":"Linux","uri":"/linux/#软件包分类"},{"categories":["Note"],"content":"依赖性 树形依赖 a –\u003e b –\u003e c 环形依赖 a –\u003e b –\u003e c –\u003e a 解决办法 同时安装 模块依赖 很多时候 缺的库根本不知道从哪找 还好现在我们有网站 www.rpmfind.net 不过我们现在有两种安装方式 手工安装 yum安装 是一种链接redhat的在线安装 ","date":"2021-12-25","objectID":"/linux/:3:2","series":[],"tags":["Linux"],"title":"Linux","uri":"/linux/#依赖性"},{"categories":["Note"],"content":"rpm rpm包命名规则 以阿帕奇为例：httpd-2.2.15-15.e16.centos.1.i686.rpm 进程名 版本 发布次数 适合的平台 硬件平台 包全名：如果操作的是为安装软件包，则使用包全名，且用绝对路径 包名：如果操作的是已经安装的软件包，系统会产生数据库/var/lib/rpm/ 所以使用包就行了 而且在任意路径下都行 安装命令 rpm -ivh 绝对路径下包全名 然后根据依赖层层安装 建议不要给rmp安装在指定路径 就默认就好了 作者觉的哪好就在哪 还有一个原因是service命令是在固定位置搜索的 另外rmp包管理系统是有卸载命令的 数据库记录安装位置 不怕装得这一个那一个 源码包则不行 必须手动选择安装路径否则很难卸载 如果非要重新定义安装路径 在整个命令后面 –prefix=/dsf/dfd/sd/ –nodeps 不检测依赖性安装 不建议 –force 强制安装 不管安没安过 如果不消息误删了部分文件 可以用这种方法 –test 不会安装 检测一下依赖性 启动命令 service可以启动大部分的rpm包 service httpd start 也可以restart和stop和status /etc/rc.d/init.d/httpd start 更标准 注意这个目录下的阿帕奇是通过软链接启动的 其实service就是搜索的这个目录启动服务的 注意阿帕奇中的网页文件 在/var/www/html/ 写完网页之后就好了 如果没有修改配置文件 是不需要重启阿帕奇的 阿帕奇的配置文在/etc/httpd/conf/httpd.conf rpm包升级 rpm -Uvh 包全名 -U 升级安装 如果没有安装过 直接安装 -F 必须有旧版本才能升级安装 rpm卸载 rpm -e 包名 -e 卸载 –nodeps 不检查依赖 不推荐 按照安装顺序倒序卸载 注意不要用yum卸载 因为yum卸载不检查除卸载程序以外的依赖 而且也不知道包名 有可能装不回来 查询（yum无法取代） rpm -q 包名 查询的是客户端 yum查的是服务器端的 -a 所有 我们可以利用grep查询所需的 rpm -qa ｜ wc -l rpm -qa ｜ grep httpd rpm -qi 包名 -i 软件包说明 rpm -qip 包全名 查询未安装包的信息 rpm -ql 包名 确认软件包的安装位置和完整的目录信息 rpm -qlp 包全名 查询未安装包打算装在哪 rpm -qf 系统文件名 查询系统文件属于哪个软件包 rpm -qR 包名 查询依赖包 没啥用 装没装无法知道 验证 rpm -V 已安装包名 校验已安装的文件 查询结果 S：文件大小是否改变 M：文件的雷总或文件的权限（rwx）是否改变 5：MD5完整性校验 可理解成文件内容是否改变 D：设备的主从代码是否改变 L：文件路径 U：文件所有者 G：文件所属组 T：修改时间 文件类型（以apache为例） c 配置文件 config file d 普通文档 g 鬼文件 很少见 就是该文件不应该属于这个rpm包 l 授权文件 license file r 描述文件 readme 这个校验是和包里面的原始值做对比的 但如果原始值被改了呢？ 答案是数字证书！从官网那里导入数字证书 保证原始值是符合官方验证的 是原厂包 rpm -qa ｜ grep gpg 查询相应的数字证书 此处我们看的数字证书是包含GPG的 如果结果error 就是没导入 rpm –import 包名 再查一遍看看 记住 重要度非常高！！！ rpm -Vf 系统文件 rpm包中文件提取命令 如果我们不是误删除文件 而是误修改了 这时候强制覆盖安装没用 它只会清空配置内容 不会修改已存在的文件的内容 注意 平常修改服务器文件 修改之前要备份 就放在同样的目录下 加个标记就行了 比如后缀.bak cpio命令（太复杂 不用） cpio -o [vcB] \u003e [文件｜备份] cpio -i [vcdu] \u003c [文件｜备份] cp命令 （不用 cp只能拷贝到同一个硬盘 不能把鸡蛋放在同一个篮子里） rpm2cpio 包全名 ｜ cpio -idv .加上文件绝对路径 rpm2cpio 将rpm包转换为cpio格式的命令 rpm包在线安装（yum安装） yum源 文件解析 搭建本地yum源 yum命令 查询（查询的是服务器并不是当前客户端 不能替代rmp的查询） yum list 列出所有可用软件包 可用于区分来自哪个yum源 yum list 包名 yum search 关键字 yum info 包名 安装 yum -y install 包名 注意yum不用区分包名包全名 因为yum源包含了相关信息 -y 自动回答yes 自动解决依赖问题 升级 yum -y update 包名 yum -y update 这个是升级本机所有软件包 包含内核 一般不用 否则可能有重大系统隐患 centOS5之前是禁止的 卸载 yum remove 包名 不要用 无视依赖强行卸载包及其依赖链 老手 并熟悉包才用 yum组管理命令 很多情况下我们无法知道包名 比如由于语言的问题 yum grouplist 查询已安装的组 yum groupinfo 软件组名 yum groupinstall 组名 yum groupremove 组名 ","date":"2021-12-25","objectID":"/linux/:3:3","series":[],"tags":["Linux"],"title":"Linux","uri":"/linux/#rpm"},{"categories":["Note"],"content":"源码包 必须指定安装位置 除非有些指定了位置会导致后续安装包找不到其位置报错 安装 下载 解压 进入解压目录 ./configure –prefix=安装地址 编译前准备 现在有些变成cmake了 作用1: 检测系统环境 作用2：自定义功能选项 作用3: 把前两个的结果写入Makefile文件 后续的操作都依靠这个文件 make 编译 注意4和5是不会写入文件的 如果报错 解决后 只要用make clean 清除临时文件就行了 源码包报错： 安装过程停止 出现了错误关键词 解决问题 make clean：清空编译内容 make install 编译安装 此时如果报错 之前的安装过程是有写入的！ 注意要看安装文档INSTALL 看看各种文件安装到哪了 打补丁 补丁的生成（很少见了） diff 选项 old new diff -Naur 绝对路径 绝对路径 \u003e txt.patch 比较old和new文件的不同 -a 将任何文档当作文本文档处理 -b 忽略空白造成的不同 。。。等等 看文档吧 打入补丁 patch -pn \u003c 补丁文件 具体n写几 参见视频8分钟左右 删除 源码包没有删除 直接删除安装目录即可 ","date":"2021-12-25","objectID":"/linux/:3:4","series":[],"tags":["Linux"],"title":"Linux","uri":"/linux/#源码包"},{"categories":["Note"],"content":"脚本安装包 用一个脚本封装安装过程 优点：快 缺点：版本 功能 安装位置等都得听作者的 案例：Webmin安装 用浏览器来管理Linux 下载 放入Linux 解压缩 进入目录 ./setup.sh 完事 怎么访问？浏览器属通过p：端口访问 ","date":"2021-12-25","objectID":"/linux/:3:5","series":[],"tags":["Linux"],"title":"Linux","uri":"/linux/#脚本安装包"},{"categories":["Note"],"content":"用户管理 防内大于防外 权限划分防患于未然 ","date":"2021-12-25","objectID":"/linux/:4:0","series":[],"tags":["Linux"],"title":"Linux","uri":"/linux/#用户管理"},{"categories":["Note"],"content":"用户相关文件 /etc/passwd 用户信息文件 每一行都是一个用户 大部分都是系统用户 用来启动相应的服务 有7列 用户名 密码标识 x代表有密码 用户名在etc/shadow中加密后显示了 如果没x标志 系统就不会要求密码 用户ID 0 是超级用户UID 如果把普通用户的UID改为0 就成了root 一般情况下不要弄俩root 1-499 系统用户UID也就是伪用户 所有安装的软件都会需要一个为用户启动相应的服务 （65534也是 匿名用户） 500-2^32 普通用户UID 组ID 具体是啥要去查/etc/group 说明 家目录 登陆shell 也就是权限 普通用户是/bin/bash 伪用户都是/sbin/nologin /etc/shadow 影子文件 9 列 用户名称 用户密码（SHA512加密） 伪用户都是*或者！！ 如果想让一个用户暂时不能登陆 在密码前面加个！ 更新密码的时间 时间戳 1770.1.1开始算 +天数 echo $(($(date –date=“2020/08/01” +%s)/86400+1)) 限制两次密码修改的间隔时间 跟3相比 密码有效期 默认99999 也是跟3比的 密码到期前的警报天数 和5相比 密码到期之后的宽限天数 跟5相比 默认-1 意思是无限宽限 密码的失效时间 比如会员有效期 过了就到期了 也是写的时间戳 到了这个时间就失效了 失效了会在密码段加1个！ /etc/group 组信息文件 4列 组名 组密码位 在/etc/gshadow 并不推荐 是用来管理组的 踢人 加人 是有管理风险的 一般不推荐下放 GID 附加组 除了初始组（只能且必须有一个）以外的组 所以只建议改附加组 不建议改初始组 因为改了之后忘了不好查 这不显示 用户的家目录 用户的邮箱目录 /var/spool/mail/用户名 用户模版目录 /etc/skel/ 生成的用户都会拷一份放在新用户的家用户里 可以用来给新用户写警告文档或者操作规范等 ","date":"2021-12-25","objectID":"/linux/:4:1","series":[],"tags":["Linux"],"title":"Linux","uri":"/linux/#用户相关文件"},{"categories":["Note"],"content":"用户管理命令 添加用户 本质就是添加信息到下列文件 /etc/passwd /etc/shadow /etc/group /etc/gshadow /home/用户名 /var/spool/mail/用户名 useradd命令 useradd 选项 命令 -u 550 指定UID -g 组名 指定初始组 useradd -g t1 p1 此时p1的初始组是t1组 p1组是没有建立的 t1组还会是t1的初始组 当然目前t1可能还没建立 非常混乱 不推荐！ -G 组名 指定附加组 -c 说明 添加说明 -d 目录 手工指定家目录 不需要事先建立 -s shell /bin/bash /etc/default/useradd 和 /etc/login.defs 设置密码 对于超级用户 passwd 选项 用户名 -l 暂时锁定用户 -u 解锁用户 –stdin 可以通过管道符输出数据作为用户密码 主要在批量添加用户时使用 记得history -c 否则相当于明文存在了历史记录里 chage -d 0 用户名 把时间戳改成0 登陆就会让该用户改密码 对于普通用户 passwd 用户信息修改 usermod命令 时修改已添加的用户 -G 修改附加组 -L 所用户 -U 解锁 一般不改用户名 容易晕菜 建议删了 再建 用户删除 userdel -r 用户名 不会删除家目录 成为了垃圾文件 所以-r是必备的 切换用户登陆 su - 用户名 注意使用一些命令 仍会显示切换前的信息 中间必须加减号 代表家目录也切换了 ","date":"2021-12-25","objectID":"/linux/:4:2","series":[],"tags":["Linux"],"title":"Linux","uri":"/linux/#用户管理命令"},{"categories":["Note"],"content":"用户组管理 组添加 groupadd 组删除 groupdel 注意 作为用户的初始组的组没法删除 必须先改变其状态 组内添加删除用户 gpasswd -a 用户 组名 加入组 gpasswd -d 用户 组名 踢出组 一般这个比较常用 而不是usermod 改变有效组 所谓有效组 就是新建文件之后的默认所属组 注意用户必须拥有超过一个所属组才能改变有效组 newgrp 组名 组权限实验 分配权限的时候要先搞清身份 再分配权限 ","date":"2021-12-25","objectID":"/linux/:4:3","series":[],"tags":["Linux"],"title":"Linux","uri":"/linux/#用户组管理"},{"categories":["Note"],"content":"权限管理 ","date":"2021-12-25","objectID":"/linux/:5:0","series":[],"tags":["Linux"],"title":"Linux","uri":"/linux/#权限管理"},{"categories":["Note"],"content":"ACL权限 概述 用于解决用户对文件身份不足 直接让用户对特定文件或者目录有权限 开启ACL dumpe2fs -h /dev/需要查询的分区 如果没有开启 手工开启 mount -o remount，acl / 重新挂载分区 并挂载加入acl权限 也可以通过修改/etc/fstab文件永久开启ACL文件 vi /etc/fstab 编辑完mount -o remount / ACL基本命令 getfacl 文件名 查询ACL的权限 setfacl -m u：用户名：权限 文件名 setfacl -m g：用户名：权限 文件名 -m 设定acl权限 -b 删除acl权限 -x：用户 删除某用户的acl权限 -R 递归 只能用于目录 对以前建立的文件生效 setfcal u：user4:5 -R /www/ 但是之后新建的文件不满足acl权限 这时候加一个d 对以后新建的文件生效 setfcal d：u：user4：5 -R /www/ 注意 ACL权限递归之后 很容易出现权限溢出 因为文件的执行文件是很危险的 但是目录的执行权限是必须的 如果你对目录递归了 之后的目录下的文件都有了执行权限 必须用脚本实现区分文件和目录的权限赋予！！！ 最大有效权限mask mask权限是能赋予acl权限的上线 两个权限做与才是真正的权限 默认是rwx 建议默认就好了 删除ACL权限 setfacl -x u：用户名 文件或目录名 删除置顶用户或用户组的acl权限 setfacl -b 文件或目录名 删除文件或目录的所有acl权限 ","date":"2021-12-25","objectID":"/linux/:5:1","series":[],"tags":["Linux"],"title":"Linux","uri":"/linux/#acl权限"},{"categories":["Note"],"content":"sudo授权 给普通用户赋予部分管理员权限 /sbin/和/usr/sbin/目录下只有超级用户才能使用 赋予的权限越详细，普通用户得到的权限越小 在root身份下 visudo 用户名 ALL=/sbin/shutdown -r now 格式其实是 用户名 被管理主机的地址=（可使用的身份） 授权命令（注意是绝对路径） 回到对应用户 sudo -l 查询啥命令可以sudo 然后 sudo /sbin/shutdown -r now 举例：我想授权一个用户管理我的web服务器 可以使用apache管理脚本 可以修改apache配置文件 可以更新网页内容 visudo user1 192.168.0.156=/etc/rc.d/init/httpd reload, /etc/rc.d/init.d/httpd configtest 举例：授权aa用户可以添加其他普通用户 visudo aa ALL=/usr/sbin/useradd aa ALL=/usr/bin/passwd [A-Za-z]*, !/usr/bin/passwd “”, !/usr/bin/passwd root ","date":"2021-12-25","objectID":"/linux/:5:2","series":[],"tags":["Linux"],"title":"Linux","uri":"/linux/#sudo授权"},{"categories":["Note"],"content":"文件特殊权限 SetUID，SetGID，Sticky BIT 前两个非常危险 禁止手动赋予 对应数字4，2，1 ​ SetUID 只有可以执行的二进制文程序才能赋予SetUID 命令执行者要对该程序拥有执行 passwd这个命令其实是有SetUID的 因为它实际上写入了管理密码的shadow文件 但这个文件本应是root才能写的 命令执行者在执行该程序时获得该程序文件属主的身份 SetUID权限仅仅在该程序的执行过程中有效，也就是说身份改变只在程序执行的过程中有效 建议 对系统中默认的应该具有的SetUID列一个列表，定时检查有没有这之外的文件被设置成了SetUID权限 检测SeUID的脚本 SetGID 针对文件的作用 和SetUID相似 唯一的区别是执行过程中会变成相应的所属组 同样高风险 针对目录的作用 无风险 没啥太大的作用 如果执行者对该目录拥有7的权限（这个本身就挺有风险。。。others的权限是7。。。） 新建了文件之后 文件的所属组是文件本来的所属组 而不是执行者的所属组 可能在容器里还有用 StickyBIT 本身没啥风险 但是跟上面那个一样 风险在于文件的权限需要777 就算普通用户对该目录有7的权限 也只能删自己的文件 不能删除其他人的文件 ","date":"2021-12-25","objectID":"/linux/:5:3","series":[],"tags":["Linux"],"title":"Linux","uri":"/linux/#文件特殊权限-setuidsetgidsticky-bit"},{"categories":["Note"],"content":"chattr权限 是可以限制root的 命令格式 chattr [+-=] 选项 文件或目录 i 如果文件则所有的操作都锁了 如果是目录则目录下的文件可以改 a 文件：能增加数据 不能删除 不能修改。 目录：能新建和修改 不能删 lsattr 文件 查看chattr权限 查看目录要加-d ！！！！ 很容易忘 因为ls是看不出来的 ","date":"2021-12-25","objectID":"/linux/:5:4","series":[],"tags":["Linux"],"title":"Linux","uri":"/linux/#chattr权限"},{"categories":["Note"],"content":"文件系统管理 ","date":"2021-12-25","objectID":"/linux/:6:0","series":[],"tags":["Linux"],"title":"Linux","uri":"/linux/#文件系统管理"},{"categories":["Note"],"content":"硬盘结构 硬盘逻辑机构 每个扇区大小是固定的 512B 是磁盘的最小存储单位 接口 IDE SATA PCI-E ","date":"2021-12-25","objectID":"/linux/:6:1","series":[],"tags":["Linux"],"title":"Linux","uri":"/linux/#硬盘结构"},{"categories":["Note"],"content":"文件系统 Linux文件系统特性 super block group block 常见文件系统 ext4 xfs 安全性更好 不容易丢数据 大文件读写更好 常用的硬盘管理命令 df命令 统计分区大小 df -ahT 显示特殊文件 人性化显示 显示文件类型 一般就用-h du命令 du 选项 目录或文件名 -a 显示每个子文件的磁盘占用 而不是默认的仅显示子目录 -h 人性化显示 -s 统计总占用量 不列出子目录和子文件的占用量 ls统计的目录大小是不准确的 他统计的是保存子文件的文件名和inode的地方的大小 所以大部分的大小都是4k的倍数 这是由于分区的block大小决定的 du -h 目录 和df -sh 目录 统计的大小是不一样的 区别是因为太久没重启 临时文件和垃圾文件没有释放 du是统计文件大小，统计的文件大小是准确的 df是统计空间大小 统计的剩余空间是准确的 fsck 文件系统修复命令 开机自动的 一般不用 显示磁盘状态 dumpe2fs dumpe2fs /dev/sda3 stat 文件名 查看文件的详细时间 判断文件类型 file 文件名 type 命令名 手动分区 fdisk -l 查看分区 fdisk /deb/sdb 输入m查看帮助 n 新建分区 分区号 p主分区 first cylinder起始柱面 1 last cylinder终止柱面 +20G e扩展分区 p 查看分区 w保存退出 格式化 mkfs -t ext4 /dev/sdb1 注意扩展分区无法格式化 只能格式化主分区和逻辑分区 建立挂载点 mkdir /disk1 mount /disk1 /dev/sdb1 查看 mount 查看所有已挂载分区和光盘 fdisk -l 查看系统分区 df 查看分区占用百分比 自动挂载 修改分区自动挂载文件 vi/etc/fstab 注意此文件直接参与系统启动，如果修改错误，系统启动报错 6列 分区文件名 或者UUID号 最好是UUID号，因为比如老硬盘坏了 换了个新的但是挂载的名字一样 会报错 但UUID是唯一的，换了盘也能区别 查看UUID的方法 dumpe2fs /dev/sdb5 ls -l /dev/disk/by-uuid/ 挂载点 文件系统 挂载选项 1 是否可以被备份 0不备份 1每天备份 2不定期备份 2 是否检测磁盘fsck 0不检测 1启动时检测 2启动后检测 建议只有根分区启动时检测 其他2 否则启动很慢 重启测试 mount -a 或者 reboot /etc/fstab 文件修复 前提是要拿到本机 远程无法修复 由于启动未成功 网卡没生效 而且分区也只是只读挂载 必须 mount -o remount，rw / vi etc/fstab 修改保存退出 reboot parted 命令分区 ：Linux有两种常见的分区表（主引导记录分区表）和GPT分区表（GUID分区表） MBR分区表：支持的最大分区是2TB 最多支持4个主分区 或者3主分区1扩展分区 GPT分区表：最大支持18EB的分区，支持128分区 其中一个系统保留分区 127个用户自定义分区 注意 一定要把etc/fstab 自动挂载里面的相应的硬盘删了 否则重启会报错 分区：parted 交互模式 修改etc/fstab parted /dev/sdb help获取命令 print 打印列表 其中msdos就是MBR分区 修改成GPT分区 mklabel gpt print 分区消失 这就是为什么要修改那个表 quit reboot parted /dev/sdb mkpart 建立分区 名字 disk1 用来区分的 没啥用 系统类型 只能ext2 大小 格式化 mkfs （注意这个是parted交互内的） quit 要格式化ext4文件系统 要用linux的mkfs mkfs -t ext4 /dev/sdb1 挂载 mount /dev/sdb1 /disk1/ 修改自动挂载文件 测试重启 如果要调整大小 卸载分区 umount resize命令 不常用 因为可以用LVM swap分区 free -h 查内存 能看到swap 是作为内存的缓冲的 buffer是用来提高写入速度的 cache 是用来提高读取速度的 分区 并修改swap ID fdisk /dev/sdb n p t 修改ID 选择分区 82 格式化 mkswap /dev/sdb1 free -h swapon /dev/sdb1 这时暂时生效的 要修改/etc/fstab /dev/sdb1 swap swap defaults 0 0 测试重启 ","date":"2021-12-25","objectID":"/linux/:6:2","series":[],"tags":["Linux"],"title":"Linux","uri":"/linux/#文件系统"},{"categories":["Note"],"content":"高级文件系统管理 ","date":"2021-12-25","objectID":"/linux/:7:0","series":[],"tags":["Linux"],"title":"Linux","uri":"/linux/#高级文件系统管理"},{"categories":["Note"],"content":"磁盘配额 概念 条件 内核支持 grep CONFIG_QUOTA /boot/config-2.6……….. 安装了quota包 rpm -qa ｜ grep quota 概念 用户配额和组配额 组配额几乎没有可用性 因为组配额是先到先得的 可能头几个用户全用完了 磁盘容量限制和文件个数限制 因为空间和inode数量都是有上限的 软限制和硬限制 软限制是发出警告 硬限制就不能用了 宽限时间 超过软限制之后 超过宽限时间之后 变为硬限制 默认7天 磁盘配额规划实验 首先规划出一个分区 建立被限制的用户和用户组 假设需要限制user1，user2，user3用户 组就算了 不怎么使用 user1 50MB 40MB 无限 useradd user1 passwd user1 输入密码 mount -o remount，usrquota，grpquota /disk 在分区上开启磁盘配额功能 想要永久生效 需要修改/etc/fstab vi /etc/fstab /dev/sdb1 /disk ext4 default，usrquota，grpquota 0 0 此种方式需要重启生效 先用4临时生效 在改 可以先临时生效 重启后也会永久生效 quotacheck 选项 分区名 生成磁盘配额 需要关闭SELinux 否则报错 getenforce setenforce 0 getenforce 临时关闭 永久生效还得改配置文件/etc/selinux/config quotacheck -avu 如果是根分区还要加个m选项 强制 因为根分区正在使用中 edeuota 选项 用户名 设置配额限制 -u设置用户配额 前三项是block的限制 是大小 后三项是inode的限制 为文件数量的限制 注意 block和inodes不能改 quotaon 选项 分区名 启动用户配额 -avu 自动 显示过程 开启用户配额 quota 选项 用户 查询用户配额 -uvs 用户 详细显示 人性化显示 repquota -avus 查分区的 用user1测试 cd /disk/ dd if=/dev/zero of=/disk/testfile bs=1M count=60 建立testfile 往目标目录写入60个1M文件 直到写完或写满 磁盘配额的其他命令 复制命令 edquota -p user1 -u user2 将user1的配额复制到user2 非交互设定用户磁盘配额 setquota -u 用户 软限制 硬限制 个数软限制 个数硬限制 /disk/ 这个适合写脚本 因为不需要进入edquota交互界面 更改宽限时间 edquota -t ","date":"2021-12-25","objectID":"/linux/:7:1","series":[],"tags":["Linux"],"title":"Linux","uri":"/linux/#磁盘配额"},{"categories":["Note"],"content":"LVM逻辑卷管理 简介 与sda1 sda2这种传统主分区不同 逻辑分区可以动态调整大小 如果硬盘不够了 还能把新的加入进去 实际工作中 至少也是LVM 物理卷 PV：真正的物理硬盘或分区 卷组 VG：多个物理卷的组合，可以来自于一块硬盘，也可以来自其他 逻辑卷 LV：卷组是一个逻辑硬盘，硬盘必须分区才能使用，这个分区我们称做逻辑卷 物理扩展 PE：最小单位是4MB 是逻辑卷的最小单位 但它不是block 最后还要格式化成block 建立LVM的步骤 硬盘分区 把ID号改成8e 具体操作往回看 建立物理卷 pvcreate /dev/sdb5 pvcreate /dev/sdb6 pvcreate /dev/sdb7 pvscan pvdisplay 查看 建立卷组 vgcreate vg /dev/sdb5 /dev/sdb6 添加物理卷 vgextend vg /dev/sdb7 添加逻辑卷 建立逻辑卷 lvcreate 选项 -n 逻辑卷名 卷组名 -L 容量 指定逻辑卷大小 lvcreate -L 3G -n userlv vg 格式化和挂载 mkfs -t ext4 /dev/vg/userlv mkdir /disklvm mount /dev/vg/userlv /disklvm/ 查看 lvdisplay 调整逻辑卷大小 lvresize 选项 逻辑卷设备文件名 -L 容量：安装容量调整大小 lvresize -L 4G /dev/vg/userlv 把userlv调整到4G 然后我们要让分区知道大小变化了 所以把整个逻辑卷都加入到/disklvm分区 所以我们有调整分区大小的命令 这就是LVM的优势 resize2fs 选项 设备文件名 调整的大小 设备文件名：指定调整哪个分区的大小 调整的大小：指定把分区调整到多大 要加M G等单位 如果不加大小，会使用整个分区 resize2fs /dev/vg/userlv 把整个调整过的逻辑卷加入到分区中 完事 不需要重新挂载或重启 ","date":"2021-12-25","objectID":"/linux/:7:2","series":[],"tags":["Linux"],"title":"Linux","uri":"/linux/#lvm逻辑卷管理"},{"categories":["Note"],"content":"Raid ","date":"2021-12-25","objectID":"/linux/:7:3","series":[],"tags":["Linux"],"title":"Linux","uri":"/linux/#raid"},{"categories":["Note"],"content":"shell基础 ","date":"2021-12-25","objectID":"/linux/:8:0","series":[],"tags":["Linux"],"title":"Linux","uri":"/linux/#shell基础"},{"categories":["Note"],"content":"shell概述 硬件 –\u003e 内核 –\u003e shell命令解释器 –\u003e 外层应用程序 Bourne Again（Bash）zsh也属于这个家族 POSIX Shell（psh） ","date":"2021-12-25","objectID":"/linux/:8:1","series":[],"tags":["Linux"],"title":"Linux","uri":"/linux/#shell概述"},{"categories":["Note"],"content":"脚本的执行 echo命令 echo 选项 输出内容 -n 取消输出后的换行 -e 支持转义字符 具体的转义表 google echo -e “\\e[1;31m abcd \\e[0m” 脚本的开头要写出所用的shell #!/bin/bash 绝对路径执行或相对路径 或者 bash hello.sh ","date":"2021-12-25","objectID":"/linux/:8:2","series":[],"tags":["Linux"],"title":"Linux","uri":"/linux/#脚本的执行"},{"categories":["Note"],"content":"Bash的基本功能 历史命令 history 每次退出之后写在了家目录下。bash_history -c 清空 不建议使用 这个对于查错很有用 一般只有暴露密码的情况下才清空 比如mysql密码明文保存了 -w 把缓存中的卸乳历史命令保存文件 历史文件条数存在/etc/profile 默认1000条 这个是放在硬盘而不是内存 可以多调点 ！！执行上一条命令 其他的不常用 想看可以查 source命令 . 就是source命令 作用是不用重新登陆 就让更新的配置文件生效 source ~/.Bashrc . ~/.Bashrc 命令执行的优先级 用绝对路径或相对路径执行的命令 别名 Bash内部命令 按照$PATH环境变量定义的目录查找顺序找到的第一个命令 Bash常用快捷键 ctrl+A 移动到行首 ctrl+E 移动到行尾 ctrl+C ctrl+L ctrl+U 删除或剪切光标之前的命令 ctrl+K 删除或剪切光标之后的命令 ctrl+Y 粘贴 ctrl+R 在历史命令中搜索 ctrl+D 退出当前终端 或者 发送 ctrl+Z 暂停 ctrl+S 暂停屏幕输出 ctrl+Q 恢复屏幕输出 输入输出重定向 Bash的标准输入输出 设备 设备文件名 文件描述符 类型 键盘 /dev/stdin 0 标准输入 显示器 /dev/stdout 1 标准输出 显示器 /dev/stderr 2 标准错误输出 输出重定向 类型 符号 作用 标准输出重定向 命令 \u003e 文件 以覆盖的方式，把命令的正确输出输出到指定的文件或设备中 命令 » 文件 以追加的方式… 标准错误输出重定向 错误命令 2\u003e文件 以覆盖的方式，把命令的错误输出输出到指定的文件或设备中 错误命令 2»文件 以追加的方式… 正确输出和错误输出同时保存 命令 \u003e 文件 2\u003e\u00261 以覆盖的方式，把正确和错误输出都保存到同一个文件中 命令 \u003e 文件 2\u003e\u00261 以追加的方式… 命令 \u0026\u003e 文件 以覆盖的方式，把正确和错误输出都保存到同一个文件中 命令 \u0026»文件 以追加的方式… 命令»文件1 2»文件2 把正确的输出追加到文件1中，把错误的输出追加到文件2中 输入重定向 wc 选项 文件名 -c 统计字节数 -w 统计单词数 -l 统计行数 wc \u003c abc wc « uio 然后开始输入 知道碰到下一个uio终止 多命令执行顺序 ls \u0026\u0026 echo yes || echo no 后面两个部分不能颠倒，因为如果ls报错了 第二条命令会执行 那么第三条命令也会执行了 多命令执符 格式 作用 ; 命令1 ; 命令2 多个命令顺序执行，之间没有任何逻辑关系联系 \u0026\u0026 命令1 \u0026\u0026 命令2 当命令1正确执行（$?=0），则命令2才执行，当命令1执行不正确（$?≠0），则命令2不会执行 || 命令1 || 命令2 当命令1执行不正确（$?≠0)，命令2才执行，当命令1执行正确）（$?=0），命令2不会执行 管道符 行命令提取命令 grep -A n 列出后续的n行 -B n 列出前面的n行 Bash中的其他符号 符号 作用 '' 单引号内所有符号丧失功能 变成普通字符串 \"\" 双引号中的特殊符号都没有特殊含义，但是\"$\" “`” “\" 是例外，拥有调用变量值 引用命令和转义符的特殊含义 `` 反引号内是系统命令 Bash会先执行它 例如 a = date 只会把date字符赋值给a 而a=date 会把命令执行的结果赋值给a $() 和反引号作用一样 用来引用系统命令 推荐用这个 反引号和单引号容易看混 用这个提高可读性 () 用于一串命令执行时，()中的命令会在子Shell中运行 子Shell中的命令 不会影响父Shell的变量 name=sc （name=lm）这时候父shell的name还是sc {} 用于一串命令执行时，{}中的命令会在当前Shell执行，也可以用于变量变形与替换 大括号的最后一个命令必须用分号 第一个命令和左括号之间必须有一个空格 [] 用于变量测试 后面单独写 # 注释 $ 用于调用变量 \\ 转义符 将特殊符号转换成普通符号 ","date":"2021-12-25","objectID":"/linux/:8:3","series":[],"tags":["Linux"],"title":"Linux","uri":"/linux/#bash的基本功能"},{"categories":["Note"],"content":"变量和运算符 什么是变量 变量的默认类型都是字符串型，如果要进行数值运算，则必须制定变量类型为数值型 变量用等号连接值，等号左右两侧不能有空格 变量的值如果有空格，需要使用单引号或者双引号包括，如test=“hello world” 可以进行变量值的叠加，不过变量需要用双引号包含”$变量名\" 或用 ${变量名} 例如：test=\"$test\"456 test=${test}456 变量的分类 用户自定义变量：自定义变量名和变量的值 环境变量：这种变量中主要保存的是和系统操作环境相关的数据，比如当前登陆用户，用户的家目录，命令的提示符等。 用户自定义环境变量 系统自带环境变量 命令和作用是固定的 内容可以自定义 比如umask的值 history储存的条数 防止混淆 环境变量全部大写！！！ 位置参数变量 这种变量主要是用来向脚本传递参数或者数据的 名称作用确定 内容可以自定义 比较少 要背 预定义变量 同样也是只能改内容 比较少 要背 ","date":"2021-12-25","objectID":"/linux/:8:4","series":[],"tags":["Linux"],"title":"Linux","uri":"/linux/#变量和运算符"},{"categories":["Note"],"content":"自定义变量 调用记得加$ 定义的时候不需要加 查看 set 选项 -u 设定此选项，调用未声明变量时会报错（默认无任何提示）常见选项！！ -x 设定此选项，在民营执行之前，会把命令先输出一次 不大用 如果什么选项都不加 就会查看所有的变量 但是有一部分环境变量看不到 需要用env看(注意 env也看不全 他俩互补) 删除 unset 变量名 注意不需要加$ ","date":"2021-12-25","objectID":"/linux/:8:5","series":[],"tags":["Linux"],"title":"Linux","uri":"/linux/#自定义变量"},{"categories":["Note"],"content":"环境变量 环境变量在全部的shell中都生效 而用户自定义变量只在当前shell生效 声明 export AGE=“18” 也可以先AGE=“18” 再export AGE 查看 set 看不到一部分环境变量 env 看不到一部分环境变量 和 全部的自定义变量 删除 usnet AGE 改 就是覆盖 ","date":"2021-12-25","objectID":"/linux/:8:6","series":[],"tags":["Linux"],"title":"Linux","uri":"/linux/#环境变量"},{"categories":["Note"],"content":"系统自带的环境变量 PATH变量：系统查找命令的路径 各个路径用:分隔 我们可以在后面添加其他的目录 放置自定的命令 PS1变量：命令提示符设置 具体改可以查文档 就是shell中命令行左边的显示的东西 LANG语系变量 查询 locale -a 看可以支持的语言 LANG=“en_US. UTF-8” ","date":"2021-12-25","objectID":"/linux/:8:7","series":[],"tags":["Linux"],"title":"Linux","uri":"/linux/#系统自带的环境变量"},{"categories":["Note"],"content":"位置参数变量 位置参数变量 作用 $n 命令后第n个变量 $0是命令本身 10以上需要大括号 ${10} 缺点是没有提示 一般非作者根本不知道 命令后面应该输入什么 一般是用来写函数的 $* 这个变量代表命令行中的所有参数，不过$*把所有的参数看成一个整体 $@ 这个变量也代表命令行中的所有参数，不过$@把每个参数区分对待 $# 这个变量代表命令行中的所有参数的个数 vi para.sh #!/bin/bash for i in \"$*\" do echo i done echo \"====================\" for j in \"$@\" do echo j done ./para.sh 11 22 33 44 11 22 33 44 ========================= 11 22 33 44 ","date":"2021-12-25","objectID":"/linux/:8:8","series":[],"tags":["Linux"],"title":"Linux","uri":"/linux/#位置参数变量"},{"categories":["Note"],"content":"预定义变量 其实位置参数变量也是预定义变量 只是很常用 预定义变量 作用 $? 最后一次执行命令的返回状态，如果这个变量的值为0，证明上一个证明正确执行；如果这个变量值为非0（具体哪个数由命令自己决定），则证明上一个命令执行不正确 $$ 当前进程的ID号 PID $! 后台运行的最后一个进程的PID ","date":"2021-12-25","objectID":"/linux/:8:9","series":[],"tags":["Linux"],"title":"Linux","uri":"/linux/#预定义变量"},{"categories":["Note"],"content":"接收键盘输入 read 选项 变量名 -t 秒数：等待时间 -p “提示信息”：等待输入时输出的提示信息 -n 字符数：read命令只接受指定的字符数，就会执行 -s：隐藏输入数据，适用于机密信息的输入 #!/bin/bash read -t 30 -p \"Please type in a number: \" num1 read -t 30 -p \"Please type in another number: \" num2 sum=$(( $num1 + $num2 )) echo $sum ","date":"2021-12-25","objectID":"/linux/:8:10","series":[],"tags":["Linux"],"title":"Linux","uri":"/linux/#接收键盘输入"},{"categories":["Note"],"content":"Shell的运算符 使用declare声明变量类型 declare [+/-] 选项 变量名 declare -i $cc=$aa+$bb -：给变量设定类型属性 +：取消变量的类型属性 -a：声明为数组 其实数组直接用就行 因为格式比较特别 name[0]=“RenZhiheng” echo name[0] -i：声明为整数型 -r：只读 一旦设置 既不能修改也不能删除 重启后失效 -x：声明为环境变量 -p：显示指定变量的被声明的类型 数值运算方法 declare法 不推荐 繁琐 expr或let数值运算命令 不好用 expr命令里运算符两遍必须加空格 let稍微好点 **$((运算式))**或者$[运算式] 推荐前者 因为[]还有测试的作用 #!/bin/bash read -t 30 -p \"Num1 is: \" num1 read -t 30 -p \"Num2 is: \" num2 read -n 1 -t 30 -p \"The operator is[+-*/]: \" oper [\"$oper\" == \"+\"] \u0026\u0026 echo \"$(( $num1 + $num2 ))\" \u0026\u0026 exit [\"$oper\" == \"-\"] \u0026\u0026 echo \"$(( $num1 - $num2 ))\" \u0026\u0026 exit [\"$oper\" == \"*\"] \u0026\u0026 echo \"$(( $num1 * $num2 ))\" \u0026\u0026 exit [\"$oper\" == \"/\"] \u0026\u0026 echo \"$(( $num1 / $num2 ))\" \u0026\u0026 exit echo \"Incorrect input\" #缺点很明显 没有判断num1和num2的输入是否正确 输错没有报错 变量的测试与内容置换 变量置换方式 变量y没有设置 变量y为空值 变量y设置值 x=${y-新值} x=新值 x为空 x=$y x=${y:-新值} x=新值 x=新值 x=$y x=${y+新值} x为空 x=新值 x=新值 x=${y:+新值} x为空 x为空 x=新值 x=${y=新值} x=新值 y=新值 x为空 y值不变 x=$y y值不变 x=${y:=新值} x=新值 y=新值 x=新值 y=新值 x=$y y值不变 x=${y?新值} 新值输出到标准错误输出（就是屏幕） x为空 x=$y x=${y:?新值} 新值输出到标准错误输出 新值输出到标准错误输出 x=$y ","date":"2021-12-25","objectID":"/linux/:8:11","series":[],"tags":["Linux"],"title":"Linux","uri":"/linux/#shell的运算符"},{"categories":["Note"],"content":"环境变量配置文件 source命令 让环境变量配置文件直接生效 source 配置文件 . 配置文件 环境变量配置文件 登陆时生效的环境变量配置文件有以下五个： /etc/profile /etc/profile.d/*.sh ~/.bash_profile ~/.bashrc /etc/bashrc 其中etc下的对所有用户生效 环境变量配置文件的调用过程 {其中的具体内容 包括两条调用路线：登陆与非登陆(sudo)}(https://www.bilibili.com/video/BV1ut411a7ro?p=126) 注销时生效的环境配置文件~/.bash_logout 这个文件默认没有写入任何内容，可是如果我们希望再退出登录执行一些操作，比如hostory -c，备份某些数据，就可以把命令写入这个文件。 其他配置文件 ~/bash_history 也就是历史命令的保存文件。 Shell登录信息 /etc/issue 也就是所谓的欢迎信息 其中的转义符代表的具体信息 man aagetty查询 常用的是\\l显示当前终端号 /etc/issue.net 远程登陆生效 同时要修改ssh的配置文件/etc/ssh/sshd_config 中的Banner none 为 Banner /etc/issue.net 因为ssh远程登录决定是否执行/etc/issue.net 注意/etc/issue.net不能支持issue文件中的转义符 重启生效 etc/motd 也是欢迎信息，不同点是这个文件的欢迎信息在正确输入用户名密码登陆之后显示，这个不论是本地还是远程登陆都可以显示 一般写的是警告信息，如果你没有被授权，请你离开 一般来说这个常用一些 定义Bash快捷键 stty -a 查询所有快捷键 stty 关键字 快捷键 stty intr ^p ctrl+p强制终止 并不建议改 ","date":"2021-12-25","objectID":"/linux/:8:12","series":[],"tags":["Linux"],"title":"Linux","uri":"/linux/#环境变量配置文件"},{"categories":["Note"],"content":"Shell编程 ","date":"2021-12-25","objectID":"/linux/:9:0","series":[],"tags":["Linux"],"title":"Linux","uri":"/linux/#shell编程"},{"categories":["Note"],"content":"正则表达式 概述 和通配符的区别 完全匹配和包含匹配 支持正则的常用命令 grep awk sed 支持通配符的常用命令 ls find cp 基础正则表达式 元字符 作用 * 前一个字符匹配0次或任意多次 注意a*没有任何意义 因为可以为0个 aa*才代表至少包含1个a 但是这种情况直接搜a就行了 因为是包含匹配 . 匹配除换行符外任意一个字符 ^ 匹配行首 $ 匹配行尾 “^$“可以匹配空白行 主要用来取反 剔除空白行 grep -v “^$” test.txt [] [-] 匹配中括号中指定或指定范围的任意一个字符 [^] 取反 ^[ ^a-zA-Z] 匹配不以字母开头的内容 注意！[^]匹配除中括号的字符以外的任意一个字符 \\ 转义符 \\.$ 匹配以.结尾的 \\{n\\} 前一个字符刚好出现了n次 “^[0-9]\\{3\\}[ ^0-9]” 一般用于数字 注意前后一般要有限位符 因为是包含匹配 \\{n, \\} 前一个字符出现了大于等于n次 \\{n, m\\} 前一个字符出现了大于等于n次小于等于m次 “sa\\{1, 3\\}i” 扩展正则表达式(egrep 或者 grep -E 来支持) 扩展元字符 作用 + 前一个字符匹配1次或多次 ? 前一个字符匹配0或1次 | 匹配两个或多个分支选择 was|were 会匹配包含was的也匹配包含were的 () 匹配以整体进行，即模式单元 (hey)+ 会匹配hey出现1次或多次的字符串 正则实例 匹配邮箱： [0-9a-zA-Z_]+@[0-9a-zA-Z_]+(\\.[0-9a-zA-Z_]+)\\{1, 3\\} 注意：grep -E 之后的正则会跟一般语言的正则类似于 表示出现次数范围的正则元字符不用加反斜杠了 grep -E [0-9a-zA-Z_]+@[0-9a-zA-Z_]+(\\.[0-9a-zA-Z_]+){1, 3} mails.txt 过滤IP：建议用程序 不要用正则 太复杂 每一位是从0-255而不是0-999 ","date":"2021-12-25","objectID":"/linux/:9:1","series":[],"tags":["Linux"],"title":"Linux","uri":"/linux/#正则表达式-1"},{"categories":["Note"],"content":"字符的截取和替换 cut 列提取命令 cut 选项 文件名 -f 列号 -d 分隔符：按照指定的分隔符分割列 默认为tab制表符 不识别空格 -c 字符范围： 不依赖分隔符来区分列，而是通过字符范围（行首为0）来进行字段提取 “n-”表示从第n个字符到行尾 同理“n-m” “-m” 不咋好用 每列的字符数不确定 awk编程 概述 printf格式化输出 printf ‘输出类型输出格式’ 输出内容 输出类型 %ns：输出字符串 n个字符 %ni：输出n个整数 %m.nf：输出浮点数 共m位 其中n位小数 输出格式 \\a：输出警告声 \\b：输出退格键 \\f：清屏 \\n：换行 \\r：回车 \\t：Tab \\v：垂直Tab printf ‘%s’ $(cat test.txt) awk的基本使用 awk ‘条件1 {动作1} 条件2 {动作2} …’ 文件名 例子： awk ' {printf $2 “\\t” $6 “\\n”}' student.txt df -h | awk \" {printf $5 “\\n”}” df -h | grep “dev/sda3” | awk ' {printf $5 “\\n”}' | cut -d “%” -f 1 查看根分区的使用占比（假设根分区是sda3） awk的条件 条件的类型 条件 作用 awk保留字 BEGIN 在执行后续命令之前优先执行 END 关系运算符 \u003e \u003c \u003e= \u003c= == != A~B 判断字符串A中是否包含能匹配B表达式的子字符串 A!~B 正则 /regex/ awk首先执行BEGIN 然后一行一行执行，先把整行给$0 然后每一列赋给对应的$n，然后进行条件判断例如$1 \u003e= 80 或者 $3 ~ /name/ 然后执行相应的动作 最后则执行END 当然条件里可以直接用正则 注意必须用/正则/括起来才能识别字符串 awk ' /WangGang/ {printf $5 “\\n”}' student.txt 这个相当于在整行里搜索包含WangGang的情况 如果有 输出那一行里对应的列 awk内置变量 awk内置变量 作用 $0 目前awk所读入的整行数据 $n 代表当前读入行的第n个字段 NF 当前行拥有的子段总数 NR 当前awk所处理的行，是总数据的第几行 FS 用户定义分隔符awk的默认分隔符是任何空格，如果想要使用其他分隔符如：就需要FS变量定义 ARGC 命令行参数个数 ARGV 命令行参数组数 FNR 当前文件中的当前记录数（对输入文件起始为1） OFMT 数值的输出格式 默认为%. 6g OFS 输出字段的分隔符 默认为空格 ORS 输出记录分隔符 默认为换行符 RS 输入记录分隔符 默认换行符 cat /etc/passwd | grep “/bin/bash” | awk ' {FS=\":\"} {printf $1 “\\n”}' 这是有问题的，因为awk已经读入了$0才知道了分隔符是：所以第一行没处理成功 cat /etc/passwd | grep “/bin/bash” | awk ' BEGIN {FS=\":\"} {printf $1 “\\n”}' cat /etc/passwd | grep “/bin/bash” | awk ' BEGIN {FS=\":\"} $3==“500” {printf $1 “\\n”}' 进阶： cat /etc/passwd | grep “/bin/bash” | awk ' BEGIN {FS=\":\"} {printf $1 “\\t” $3 “\\t 行号：” NR “\\t 字段数：” NF “\\n”}' 字符串和转义字符需要放在双引号里 变量放在外面 sed命令 sed主要是用来将数据进行选取 替换 删除 新增的命令 sed 选项 ‘动作’ 文件名 选项 作用 -n sed默认会把所有数据都输出到屏幕，如果加入-n，则只会把经过sed处理的行输出到屏幕 -e 允许对输入数据应用多条sed命令编辑 -f 脚本文件名 从sed脚本中读入sed操作，和awk中的-f非常类似 -r 在sed中支持扩展正则表达式 -i 用sed的修改结果直接修改读取数据的文件而不是输出到屏幕上 动作 a \\ 追加 在当前行后添加一行或多行 添加多行时 用\\表示数据未完结 也就是换行 i \\ 插入 d 删除 p 打印 输出指定行 s 字串替换 用一个字符串替换另外一个字符串，格式为“行范围 s/旧字串/新字串/g” 例子： sed -i -e ‘3d ; 4d’ test.txt 注意 -e需要挨着命令 sed -n ‘2, 5d’ test.txt sed ’s/LiGang/WangGang/g' test.txt ","date":"2021-12-25","objectID":"/linux/:9:2","series":[],"tags":["Linux"],"title":"Linux","uri":"/linux/#字符的截取和替换"},{"categories":["Note"],"content":"字符处理命令 排序命令sort sort 选项 文件名 -f 忽略大小写 -b 忽略行前空白部分 -n 以数值型进行排序，默认使用字符串型排序 -r 反向排序 -u 删除重复行 就是uniq命令 -t 指定分隔符，默认时制表符 -k n, m 按照指定的字段范围排序，从n字段开始到m字段结束 如果不输入, m 就默认到行尾 sort -n -k 3, 3 /etc/passwd 如果不用-n是按照字段的首字母进行排序 导致11排在2前面 uniq uniq 选项 文件名 统计 wc wc 选项 文件名 -l 只统计行数 -w 只统计单词数 -m 只统计字符数 ","date":"2021-12-25","objectID":"/linux/:9:3","series":[],"tags":["Linux"],"title":"Linux","uri":"/linux/#字符处理命令"},{"categories":["Note"],"content":"条件判断 test 或者 [测试选项 文件名] 按照文件类型进行判断 测试选项 作用 -b 文件 是否块设备 -c 文件 是否字符设备文件 -d 文件 是否目录 目录为真 [-d abc] 然后echo $? -f 文件 是否普通文件 -L 文件 是否为符号链接文件 -p 文件 是否为管道文件 -s 文件 是否文件为空 非空为真 -S 文件 是否为套接字文件 按照文件权限判断 测试选项 作用 -r 文件 判断该文件是否存在，并且是否该文件拥有读权限 有为真 注意判断的整个文件的权限 无法具体区分是所有者所属组和其他的 -w 文件 写 -x 文件 执行 -u 文件 SUID -g 文件 GUID -k 文件 SBit 两个文件之间进行比较 测试选项 作用 文件1 -nt 文件2 判断文件1的修改时间是否比文件2新 新为真 文件1 -ot 文件2 旧为真 文件1 -ef 文件2 判断inode是否一致 一致为真 是判断硬链接的好方法 两个整数之间的比较 测试选项 作用 整数1 -eq 整数2 是否相等 相等为真 整数1 -ne 整数2 不相等为真 整数1 -gt 整数2 整数1\u003e整数2 为真 整数1 -lt 整数2 小于为真 整数1 -ge 整数2 大于等于为真 整数1 -le 整数2 小于等于为真 字符串的判断 测试选项 作用 -z 字符串 是否为空 为空为真 -n 字符串 非空为真 字串1 == 字串2 判断字符串1是否和字符串2相等 相等为真 [\"$a” == “$b”] 字串1 != 字串2 不等为真 多重判断 测试选项 作用 判断1 -a 判断2 与 皆真为真 判断1 -o 判断2 或 ！判断 非 ","date":"2021-12-25","objectID":"/linux/:9:4","series":[],"tags":["Linux"],"title":"Linux","uri":"/linux/#条件判断-test-或者-测试选项-文件名"},{"categories":["Note"],"content":"流程控制 if 条件判断 单分支 #!/bin/bash if [condition] then #code fi example: #!/bin/bash aa=$(df -h | grep /dev/sda3 | awk ' {printf $5 \"\\n\"' | cut -d \"%\" -f 1) if [\"%aa\" -ge 80] then echo \"greater than 80 !\" fi chmod 755 example.sh ./example.sh 双分支 #!/bin/bash if [condition] then #code else #code fi example(稍微不太合理 只是个例子) 备份mysql #!/bin/bash ntpdate asia.pool.ntp.org \u0026\u003e/dev/null #同步时间 date=$(date +%y%m%d) #日期按照年/月/日格式 size=$(du -sh /var/lib/mysql) #统计mysql数据库的大小 if [-d /tmp/dbbak] #判断备份目录是否存在，是否为目录 then #如果为真执行一下脚本 echo \"Date: $date!\" \u003e /tmp/dbbak/dbinfo.txt #把当前日期写入临时文件 echo \"Data size: $size\" \u003e\u003e /tmp/dbbak/dbinfo.txt #把大小写入 cd /tmp/dbbak #进入备份目录 tar -zcf mysql-lib-$date.tar.gz /var/mysql dbinfo.txt \u0026\u003e/dev/null #打包压缩数据库与临时文件 #注意/dev/null相当于垃圾站 把命令的输出丢进垃圾站就会屏蔽它 但是报错会正常报错 写脚本很常用 rm -rf /tmp/dbbak/dbinfo.txt #删除临时文件 else mkdir /tmp/dbbak #如果判断为假，则建立备份目录 echo \"Date: $date!\" \u003e /tmp/dbbak/dbinfo.txt echo \"Date size: $size\" \u003e\u003e /tmp/dbbak/dbinfo.txt #保存数据库大小和当前日期 cd/tmp/dbbak tar -zcf mysql-lib-$date.tar.gz dbinfo.txt /var/lib/mysql \u0026\u003e/dev/null rm -rf /tmp/dbbak/dbinfo.txt fi #问题是 备份和原始数据在一块硬盘里 而且只能完全备份 exmple2 每五分钟检测apache有没有当机并重启 #!/bin/bash aa=$(netstat -tuln | awk ' {printf $4 \"\\n\"}' | grep \":80\u0026\") if [\"$aa\" == \"\"] then echo \"httpd is down, restarting...\" /etc/tc.d/init.d/httpd start \u0026\u003e/dev/null else echo \"httpd is working fine\" fi nmap -sT 192.168.4.210 扫描本机所有端口 看看有无应答 $(nmap -sT 192.168.4.210 | grep tcp | grep httpd | awk ' printf $2 “\\n”') == “open” 判断有无应答 因为有的时候虽然服务开启 访问量量过大会导致无应答 多分支 if [condition] then do elif do else do fi ","date":"2021-12-25","objectID":"/linux/:9:5","series":[],"tags":["Linux"],"title":"Linux","uri":"/linux/#流程控制"},{"categories":["Note"],"content":"Primitive Calculator #!/bin/bash #Command line calculator Ver0.1 read -t 30 -p \"Please enter the first operand: \" num1 read -t 30 -p \"Please enter the operator: \" op read -t 30 -p \"Please enter the second operand: \" num2 if [ -n \"$num1\" -a -n \"$num2\" -a -n \"$op\" ] then ifInt1=$(echo $num1 | sed ' s/[0-9]//g') ifInt2=$(echo $num2 | sed ' s/[0-9]//g') if [ \"$ifInt1\" == \"\" -a -z \"$ifInt2\" ] then if [ \"$op\" == \"+\" ] then result=$(($num1 + $num2)) elif [ \"$op\" == \"-\" ] then result=$(($num1 - $num2)) elif [ \"$op\" == \"*\" ] then result=$(($num1 * $num2)) elif [ \"$op\" == \"/\" ] then result=$(($num1 / $num2)) else echo \"Please enter a valid operator\" exit 11 fi else echo \"Please enter valid operands\" exit 11 fi else echo \"Please assign all 3 variables properly\" exit 11 fi echo \"$num1$op$num2= $result\" ","date":"2021-12-25","objectID":"/linux/:9:6","series":[],"tags":["Linux"],"title":"Linux","uri":"/linux/#primitive-calculator"},{"categories":["Note"],"content":"Case Statement case $var in \"val1\") do ;; \"val2\") do ;; \"val3\") do ;; *) do ;; esac ","date":"2021-12-25","objectID":"/linux/:9:7","series":[],"tags":["Linux"],"title":"Linux","uri":"/linux/#case-statement"},{"categories":["Note"],"content":"for loop #Most common one for system maintenance for var in val1 val2 val3 ... do echo $var done #Common in other langs s=0 for (( i=1;i\u003c=100;i=i+1 )) do echo s=$(( $s + $i )) done #Batch decompressing #ls *.tar.gz \u003e tar.log #ls *.tgz \u003e\u003e tar.log \u0026\u003e/dev/null aa=$( cat /root/sh/tar/tar.log | wc -l) for((i=1;i\u003c=\"$aa\";i=i+1)) do bb=$( cat tar.log | awk 'NR==\"$i\" {printf $1 \"\\n\"}' ) tar -zxvf $bb -C /root/sh/tar done #The better version ls *.tar.gz \u003e tar.log for i in $(cat tar.log) do tar -zxvf $i done #This is why you'll see the first type of for loop way more often... it would be silly to use it for arithmetic purposes though #!/bin/bash #Legal IP filter #Use regex as a sketchy filter grep \"^[0-9]\\[1,3\\].[0-9]\\[1,3\\].[0-9]\\[1,3\\].[0-9]\\[1,3\\]$\" /root/sh/ip.txt \u003e /root/sh/ip_test1.txt #Get the num of IPs we got line=$(wc -l /root/sh/ip_test1.txt | awk ' {printf $1 \"\\n\"}') #line=$(cat ip_test1.txt | wc -l) #Get your final file ready echo \"\" \u003e /root/sh/ip_test.txt for (( i=1;i\u003c$line;i=i+1 )) #for i in $(cat /root/sh/ip_test1.txt) do cat /root/sh/ip_test1.txt | awk 'NR=='$i'{print}' \u003e /root/sh/ip_test2.txt #In the file, there lies the only one IP of the ith column #Type 2 for-loop body starts from here a=$( cat /root/sh/ip_test2.txt | cut -d '.' -f 1) b=$( cat /root/sh/ip_test2.txt | cut -d '.' -f 2) c=$( cat /root/sh/ip_test2.txt | cut -d '.' -f 3) d=$( cat /root/sh/ip_test2.txt | cut -d '.' -f 4) if [ \"$a\" -lt 1 -o \"$a\" -gt 255 ] then continue fi if [ \"$b\" -lt 0 -o \"$b\" -gt 255 ] then continue fi if [ \"$c\" -lt 0 -o \"$c\" -gt 255 ] then continue fi if [ \"$d\" -lt 0 -o \"$d\" -gt 255 ] then continue fi cat /root/sh/ip_test2.txt \u003e\u003e /root/sh/ip_test.txt done rm -rf /root/sh/ip_test1.txt rm -rf /root/sh/ip_test2.txt #To be validated... #batch adding a fixed number of users read -t 30 -p \"User name: \" name read -t 30 -p \"Number of users: \" num read -t -30 -p \"Password: \" pwd if [ -n \"$name\" -a ! -z \"$pwd\" -a -n \"$num\" ] then y=$(echo $num | sed ' s/[0-9]//g') if [ -z \"$y\" ] then for (( i=1;i\u003c$num;i=i+1 )) do /usr/sbin/useradd $name$i \u0026\u003e/dev/null echo $pwd | /usr/bin/passwd --stdin $name$i \u0026\u003e/dev/null chage -d 0 $name$i \u0026\u003e/dev/null done fi fi #!/bin/bash #Batch deleting users. Avoid deleting root and system users user=$(cat /etc/passwd | grep \"/bin/bash\" | grep -v \"root\" | cut -d \":\" -f l) for i in $user do userdel -r $i done ","date":"2021-12-25","objectID":"/linux/:9:8","series":[],"tags":["Linux"],"title":"Linux","uri":"/linux/#for-loop"},{"categories":["Note"],"content":"while loop while [condition] do code done Not common since it’s for arithmetic mainly. ","date":"2021-12-25","objectID":"/linux/:9:9","series":[],"tags":["Linux"],"title":"Linux","uri":"/linux/#while-loop"},{"categories":["Note"],"content":"until loop until [condition] do code done ","date":"2021-12-25","objectID":"/linux/:9:10","series":[],"tags":["Linux"],"title":"Linux","uri":"/linux/#until-loop"},{"categories":["Note"],"content":"Function function func { echo $1 } func Hello func World func () { echo Hello $1 local var = 'local' } var = 'global' func Mars Other Flow Control Commands exit exit [value] exit the current script break Jump out of the current loop completely continue End the current iteration(1 time execution of loop) and execute the next in the loop if possible ","date":"2021-12-25","objectID":"/linux/:9:11","series":[],"tags":["Linux"],"title":"Linux","uri":"/linux/#function"},{"categories":["Note"],"content":"启动引导和系统修复 ","date":"2021-12-25","objectID":"/linux/:10:0","series":[],"tags":["Linux"],"title":"Linux","uri":"/linux/#启动引导和系统修复"},{"categories":["Note"],"content":"概念 系统运行级别 运行级别 含义 0 关机 1 单用户模式，主要用于系统修复 （对表win的安全模式） 2 不完全的命令行模式，不含NFS服务 3 完全的命令行模式，就是标准字符界面 4 系统保留 5 图形模式 6 重启动 runlevel x y x is the previous level before entering the current one y is the current runlevel init n enter level n not safe using this to reboot System Default Runlevel /etc/inittab /etc/rc.local or /etc/rc.d/rc.local This will be executed before user login You can run apache while system starts by edit this file ","date":"2021-12-25","objectID":"/linux/:10:1","series":[],"tags":["Linux"],"title":"Linux","uri":"/linux/#概念"},{"categories":["Note"],"content":"Boot Loader 启动引导程序 /boot/grub boot/grub/grub.conf \u0026 menu.lst (soft link) partition representation hd(x,y) x for the number of current SCSI disk starting from 0 y for the current partition starting from 0 0 - 3 for primary partition 4 - for logic partition /boot/grub/splash.xpm.gz The background of booting interface grub configuration Notice that you cannot do anything through distant control since the network module has’t been loaded yet default=0 boot the first sys as default after x seconds if no choce was made timeout=5 waiting time of selecting sys if it’s -1, sys will wait till any decision is made splashimage=(hd0,0) /grub/splash.xpm.gz where the background image is located hiddenmenu by default, the menu is hidden, you can see the counting only. cancel it by commenting the line. title display this for the corresponding sys root (hd0,0) where is the root directory notice it doesn’t stand for the root user kernal content /vnlinuz-2.6.32-279.el6.i686 indicate the location of the kernal files and the ‘/’ means /boot here ro mount the /boot as read-only it bans RAID, LVM… that’s why you can only mount your /boot on the primary partition when installing the sys root=UUID….. KEYBOARDTYPE=pc KEYTABLE=US LANG language env rhgb use image to substitute the literal info you can check the literals with command dmesg quiet hide the boot messages except the important ones initrd/initramfs…. indicate the location of the img of the memory files grub encryption grub-md5-crypt Then the sys will show the md5 code copy it vim /etc/grub.config put it at the line after “timeout=5” as below password –md5 here is the md5 code now if you want to edit the passwd while the grub interface, a password is needed if you add lock after the title… that would be a disaster since you need the password for booting and the distant tool cannot connect… Check the flight LOL 系统密码–\u003e grub密码–\u003e BIOS密码 单用户模式破解 光盘安全模式破解 扣主板电池 ","date":"2021-12-25","objectID":"/linux/:10:2","series":[],"tags":["Linux"],"title":"Linux","uri":"/linux/#boot-loader-启动引导程序"},{"categories":["Note"],"content":"System Repair Single User Mode runlevel 1 Need to be with the server pysically at grub interface enter the os press e to edit append ' 1' after the quiet notice there is a space between quiet and 1 it means to enter runlevel 1 this time (cause it’s a temporally change, edit the config file to change it permanently) passwd root reboot CD-ROM Repair Need to pysically be with the server BIOS –\u003e boot from CD Rescue install mode continue start shell Notice we did not enter the real / the CDROM simulated this one chroot /mnt/sysimage change the root to the real one since the it’s treated as an external device do whatever you need to repair the sys ","date":"2021-12-25","objectID":"/linux/:10:3","series":[],"tags":["Linux"],"title":"Linux","uri":"/linux/#system-repair"},{"categories":["Note"],"content":"Services Management System 服务管理系统 ","date":"2021-12-25","objectID":"/linux/:11:0","series":[],"tags":["Linux"],"title":"Linux","uri":"/linux/#services-management-system-服务管理系统"},{"categories":["Note"],"content":"Classification RPM package installed Independent directly listed in memory chkconfig –list if there shows 0-6, it’s a inde service notice that 0-6 show the options under different runlevel Based on xinetd only xinetd service is on memory, other services will be managed by it (Not the mainsteam now since the server is much more powerful and there is no need to save that little memory) Source code package installed ","date":"2021-12-25","objectID":"/linux/:11:1","series":[],"tags":["Linux"],"title":"Linux","uri":"/linux/#classification"},{"categories":["Note"],"content":"Services installed by RPM Independent Services start /etc/init.d/serviceName start service serviceName start|stop|restart|… automatic chkconfig –level runlevelNum serviceName on|off Next time of booting it will run automatically /etc/rc.local add a standard way of starting This method is recommended ntsysv Notice: ckconfig cannot check the service started by /etc/rc.local, vise-versa And Only one way for the auto start, if it’s started more than once, you’ll earn your error message xinetd I don’t care about it because no one will use it nowadays Example of Apache /etc/rc.d/init.d/httpd ","date":"2021-12-25","objectID":"/linux/:11:2","series":[],"tags":["Linux"],"title":"Linux","uri":"/linux/#services-installed-by-rpm"},{"categories":["Note"],"content":"Services installed by RPM Independent Services start /etc/init.d/serviceName start service serviceName start|stop|restart|… automatic chkconfig –level runlevelNum serviceName on|off Next time of booting it will run automatically /etc/rc.local add a standard way of starting This method is recommended ntsysv Notice: ckconfig cannot check the service started by /etc/rc.local, vise-versa And Only one way for the auto start, if it’s started more than once, you’ll earn your error message xinetd I don’t care about it because no one will use it nowadays Example of Apache /etc/rc.d/init.d/httpd ","date":"2021-12-25","objectID":"/linux/:11:2","series":[],"tags":["Linux"],"title":"Linux","uri":"/linux/#independent-services"},{"categories":["Note"],"content":"Services installed by RPM Independent Services start /etc/init.d/serviceName start service serviceName start|stop|restart|… automatic chkconfig –level runlevelNum serviceName on|off Next time of booting it will run automatically /etc/rc.local add a standard way of starting This method is recommended ntsysv Notice: ckconfig cannot check the service started by /etc/rc.local, vise-versa And Only one way for the auto start, if it’s started more than once, you’ll earn your error message xinetd I don’t care about it because no one will use it nowadays Example of Apache /etc/rc.d/init.d/httpd ","date":"2021-12-25","objectID":"/linux/:11:2","series":[],"tags":["Linux"],"title":"Linux","uri":"/linux/#xinetd"},{"categories":["Note"],"content":"Services installed by RPM Independent Services start /etc/init.d/serviceName start service serviceName start|stop|restart|… automatic chkconfig –level runlevelNum serviceName on|off Next time of booting it will run automatically /etc/rc.local add a standard way of starting This method is recommended ntsysv Notice: ckconfig cannot check the service started by /etc/rc.local, vise-versa And Only one way for the auto start, if it’s started more than once, you’ll earn your error message xinetd I don’t care about it because no one will use it nowadays Example of Apache /etc/rc.d/init.d/httpd ","date":"2021-12-25","objectID":"/linux/:11:2","series":[],"tags":["Linux"],"title":"Linux","uri":"/linux/#example-of-apache"},{"categories":["Note"],"content":"Services installed by Source Code start start by the command (check its offical docs) /usr/local/apache2/bin/apachectl start|stop|restart|… auto vim /etc/rc.local add –\u003e /usr/local/apache2/bin/apachectl start let the source code service be recognized by service \u0026 chkconfig \u0026 ntsysv (not recommended since you can not distinguish RPM and Source code versions of services) ln -s /usr/local/apache2/bin/apachectl /etc/rc.d/init.d/ now it’s good with service command vim /etc/rc.d/init.d/apachectl add –\u003e chkconfig: 35 86 76 35 is the runlevel 3 and 5 86 is the starting sequence, just make sure it’s not conflict with other services 76 is the ending sequence, notice the same thing above chkconfig –add apachectl chkconfig –list | grep “apachectl” now should be good with chkconfig \u0026 ntsysv ","date":"2021-12-25","objectID":"/linux/:11:3","series":[],"tags":["Linux"],"title":"Linux","uri":"/linux/#services-installed-by-source-code"},{"categories":["Note"],"content":"Common Services in Linux Service Name Function Recommendation See here ","date":"2021-12-25","objectID":"/linux/:11:4","series":[],"tags":["Linux"],"title":"Linux","uri":"/linux/#common-services-in-linux"},{"categories":["Note"],"content":"System Management ","date":"2021-12-25","objectID":"/linux/:12:0","series":[],"tags":["Linux"],"title":"Linux","uri":"/linux/#system-management"},{"categories":["Note"],"content":"Process What is process The functions of porcess management check if the system is running healthy 70/90 principle: mem \u003c 70% cpu \u003c 90% change it with your needs check all processes status kill a process (rare) Check a process ps command ps aux no ‘-’ a: show all processes on the terminal except 会话引线 u: show the owner of the processes and mem usage x: show the processes without terminal control USER PID %CPU %MEM VSZ: the virtual mem occupied RSS: the physical mem occupied TTY: on which terminal it runs if it’s ?, means it is started by the kernal STAT: status od the process D: sleep status that cannot be awoke R: running S: sleep … check the docs START TIME COMMAND (usually the most useful part to know what on earth is the process you are looking at) top command -d n: n is the number of seconds to refresh, set to 3 by default too lazy today…check here the most important parts are average loads, cpu idle, mem and swap free interaction P: sorted by CPU usage M: sorted by mem usage q: quit options -p pid: check a specific process -b -n common use: top -b -n 1 \u003e test pstree -p ","date":"2021-12-25","objectID":"/linux/:12:1","series":[],"tags":["Linux"],"title":"Linux","uri":"/linux/#process"},{"categories":["Note"],"content":"Process Management check signal: kill -l SIGHUP: shutdown the process immediately, read the config file and reboot SIGKILL: to end a process at once, this signal cannot be stopped, processed, or ignored. common for terminate processes forcedly kill process kill signal PID kill -9 53734 forcedly shutdown a process killall option signal processName -i: interactive -I: ignore the capitalization of processName kill -9 httpd (common for kill processes of a service) pkill option signal processName -t: terminal number pkill -9 -t pts/1 (common for kick out users) kick out the distant terminal pts/1 ","date":"2021-12-25","objectID":"/linux/:12:2","series":[],"tags":["Linux"],"title":"Linux","uri":"/linux/#process-management"},{"categories":["Note"],"content":"Jobs Management Cautions Put command to backstage command \u0026 ctrl+z: pause and put it to backstage Query ​ jobs command jobs -l check all backstage services with PID Recover fg %jobNum: put the job back to frontstage bg %jobNum: recover the stopped backg3round job to excute Seperate the job from terminals edit the /etc/rc.local (drawback: need to reboot) realize through system tasks nohup [command] \u0026 ","date":"2021-12-25","objectID":"/linux/:12:3","series":[],"tags":["Linux"],"title":"Linux","uri":"/linux/#jobs-management"},{"categories":["Note"],"content":"System Resource Query vmstat refreshDelay refreshTimes vmstat 1 3 refresh every sec for 3 times dmesg | grep keywords get info from booting messages free -h /proc/cpuinfo /proc/meminfo uptime uname this is kernalinfo -a -r file /bin/ls check if the os is 32-bit or 64-bit lsb_release -a check the release ver ","date":"2021-12-25","objectID":"/linux/:12:4","series":[],"tags":["Linux"],"title":"Linux","uri":"/linux/#system-resource-query"},{"categories":["Note"],"content":"系统定时任务 at 一次性执行定时任务 at 服务管理与访问控制 at 是由atd服务支持的 首先启动atd 或者将它设置为自启动 当然 一般是默认启动的 service atd start chkconfig atd on at 的访问控制 /etc/at.deny /etc/at.allow 默认不存在 他的优先度高 一旦存在 只有写入这个文件的用户能执行at 还得在文件中手动加入用户 如果两个文件都没有，则只有root能使用at at 选项 时间 -m 工作完成后 email通知 -c 工作号 显示at工作的实际内容 时间的格式 HH:MM HH:MM[am|pm] [month] [date] HH:MM[am|pm] + [minutes|hours|days|weeks] 在指定的时间再加多久执行 输入命令内容 ctrl+D发送 查询at任务 at -c atq 删除 atrm 工作号 crontab循环定时任务 服务管理和访问控制 由crond服务支持 service crond restart chkconfig crond on /etc/cron.deny \u0026 /etc/cron.allow 用户的crontab设置 -e：编辑crontab定时任务 -l：查询 -r：删除当前用户所有的crontab任务，如果有多的任务只想删除一个，可以用 crontab -e -u 用户名：修改或删除其他用户的crontab任务 只有root可以用 或者可以用root修改/etc/crontab 并且可以指定其他用户来执行 格式：* * * * * 执行的任务 一小时中的第几分钟 0-59 一天中的第几个小时 0-23 一个月当中的第几天 1-31 一年当中的第几个月 1-12 一周中的星期几 0-7 10 * * * * 命令 代表每个小时的第10分钟执行一次 0 8, 12, 16 * * * 命令 代表每天的8点0分 12点0分 16点0分 都执行一次 0 5 * * 1-6 命令 周一到周六5点执行 */10 * * * * 命令 每隔10分钟 执行一次 0 0 1, 15 * 1 命令 每个月的1号15号和每周1都会执行！最好不要这么写 因为容易搞晕别的管理员 注意事项 六个选项都不能为空 不确定就用* 最小是分钟 最大是月 没法确定年和秒 星期和天不要同时出现 便于理解 定时任务 所有都用绝对路径 系统的crontab设置 crontab -e 是每个用户执行的命令 其他两种方法 直接修改/etc/crontab 修改配置文件 定时任务的执行者默认是当前用户 0 * * * * root runparts /etc/cron.hourly/ 每小时0分钟 用root用户的身份 用runparts脚本 执行目录下的每一个 把脚本放入相应的执行目录 /etc/cron.hourly/或者/etc/cron.daily/等 但是没法设置具体的时间，是系统自己决定的 anacron /var/spool/anacron 如果该执行任务的时候因为某种任务没有执行 比如关机了 它会检测所有的定时任务，看情况补上没执行的任务 新版本/etc/cron.{hourly｜daily｜weekly}是由anacron自动调用的 以防止cron和anacron重复执行任务发生报错 anacron 选项 工作名 /etc/anacrontab RANDON_DELAY=45 开机之后45分钟内任意时间开始执行第一个任务 然后45分钟内执行第二个…以此类推 START_HOURS_RANGE=3-22 允许执行时间为3点到22点 ","date":"2021-12-25","objectID":"/linux/:12:5","series":[],"tags":["Linux"],"title":"Linux","uri":"/linux/#系统定时任务"},{"categories":["Note"],"content":"日志管理 ","date":"2021-12-25","objectID":"/linux/:13:0","series":[],"tags":["Linux"],"title":"Linux","uri":"/linux/#日志管理"},{"categories":["Note"],"content":"简介 LAMP下的ELK的日志分析工具 常见日志 日志文件 作用 /var/log/cron 定时文件 /var/log/cups/ 打印信息 /var/log/btmp 记录错误登陆日志 二进制文件 要用lastb命令查看 /var/log/lastlog 所有用户最后登陆时间的日志 lastlog查看 /var/log/mailog 邮件信息 /var/log/message 系统重要信息日志 如果系统出现问题 首先查这个 /var/log/secure 记录验证和授权方面的信息 涉及账号密码的程序都会记录 例如系统登陆 sudo授权 切换用户等 /var/log/wtmp 永久记录所有用户的登陆注销信息 系统的启动重启关机事件 用last查看 /var/log/utmp 记录当前已登陆用户的信息 注意 只记录当前登陆用户的信息 会随着用户的登录和注销不断变化 要用w who users等命令查询 RPM产生的日志 在/var/log/相应的位置 源码包的日志全部在手工安装的目录下 ","date":"2021-12-25","objectID":"/linux/:13:1","series":[],"tags":["Linux"],"title":"Linux","uri":"/linux/#简介"},{"categories":["Note"],"content":"日志服务rsyslogd 格式 配置文件/etc/rsyslog.conf 规则和日志等级 内容解释 ","date":"2021-12-25","objectID":"/linux/:13:2","series":[],"tags":["Linux"],"title":"Linux","uri":"/linux/#日志服务rsyslogd"},{"categories":["Note"],"content":"日志轮替 把旧的日志文件移动并改名，同时建立新的空日志文件，当旧日志文件超出保存的范围之后，就会进行删除 注意源码包的日志文件要手动加入轮替的配置文件 命名–\u003e/etc/logrotate.conf配置文件中的dateext参数 日志会变成 logname-20200806 /etc/logrotate.conf 如果没写自己的轮替时间 就按开始自带写入的weekly 其他同理 打开看了看 很简单 没必要记了参考 写的时候 参考一下轮替代码里的命令 平滑重启： /bin/kill -HUP $(/bin/cat /usr/local/nginx/logs/nginx.pid) \u0026\u003e/dev/null 如果有人正在访问 会等访问进程结束之后再重启服务 注意：在重启服务之前也要重启rsyslogd postrotate /bin/kill -HUP cat /var/run/syslogd.pid 2\u003e /dev/null 2\u003e /dev/null || true endscript 加入自己的日志轮替 先写好自己的配置文件 logrotate 选项 配置文件名 -v：显示日志轮替过程 -f：强制进行日志轮替 不管是否已经符合条件 ","date":"2021-12-25","objectID":"/linux/:13:3","series":[],"tags":["Linux"],"title":"Linux","uri":"/linux/#日志轮替"},{"categories":["Note"],"content":"Square Roots, Newton’s Method Square Roots recall the sqrt(2) problem xi+1 = (xi + a/xi) / 2 Notice the division in it that’s what we’ll settle down Error Analysis of Newton’s Method xn = √a (1 + 𝛆n) 𝛆n may +/- xn+1 = ( √a ( 1 + 𝛆n ) + a / ( √a ( 1 + 𝛆n ) ) / 2 = ( √a ( 1 + 𝛆n ) + 1 / ( 1 + 𝛆n ) ) / 2 = √a (1 + 𝛆n2 / 2( 1 + 𝛆n )) Therefore 𝛆n+1 = 𝛆n2 / 2( 1 + 𝛆n ) ≈ 𝛆n2 / 2 say if we have a 0.01 error the next iteration will make it 0.0001 this is why we have a quadratic convergence that the accurate digits doubles every time d-digit of precision =\u003e lgd iterations Multiplication Algo recall Karatsuba Algo Toom-Cook (k≥2 k parts) say we use Toom-3 T(n) = 5T(n/3) Θ(n) T(n) = Θ(nlog35) = Θ(n1.465) Schonhage-Strassen Θ(n lgn lglgn) time use FFT in gmpy package in Python Furer (2007) Θ(nlgn 22O( log*n )) nlgn is for sorting log*n is the # of log needs to be applied to get a result that ≤ 1 High-precision Division we want a high-precision rep of a/b we need a high-precision rep of 1/b first we will compute floor(R/b) where R is a really large value, s.t.(such that) it’s easy to divide by R (R = 2k) by shift the floating point Division Newton’s Method for computing R/b f(x) = 1/x - b/R (zero at x = R/b) f ‘(x) = -1/x2 xi+1 = 2xi - bxi2/R i.e. R/b = 216/5 = 65536/2 = 13107.2 Initial guess: 216/4 = 214 -\u003e x0 = 16384 x1 = 2(16384) - 5(16384)2/65536 = 12288 x2 = 2(12288) - 5(12288)2/65536 = 13056 … lgd times to get the needed accurate digits Division: quadratic convergence: # digits doubles at each step d-digit of precision =\u003e lgd iterations Multiplication in Θ(n𝛂) 𝛂 ≥ 1 =\u003e O(lgd n𝛂) =\u003eO(lgn n𝛂) BUT! Let’s look into it more carefully for d digits precision every time of multiplication we have constant time of division T(n) = C1𝛂 + C2𝛂 + … + C(d/2)𝛂 + Cd𝛂 \u003c 2Cd𝛂 SO! Complexity of division == Complexity of multiplication O(n𝛂) Time Complexity Analysis of Square Root √a with d-digit precision floor(102da) =\u003e Newton’s method: xi+1 = (xi + a/xi) / 2 =\u003e Division =\u003e Newtion’s method: xi+1 = 2xi - bxi2/R Complexity of Square Root ≈ Complexity of division ≈ Complexity of multiplication ","date":"2021-12-25","objectID":"/square-roots-newtons-method/:0:1","series":[],"tags":["Algorithm"],"title":"Newton's Method","uri":"/square-roots-newtons-method/#square-roots-newtons-method"},{"categories":["Note"],"content":"Square Roots, Newton’s Method Square Roots recall the sqrt(2) problem xi+1 = (xi + a/xi) / 2 Notice the division in it that’s what we’ll settle down Error Analysis of Newton’s Method xn = √a (1 + 𝛆n) 𝛆n may +/- xn+1 = ( √a ( 1 + 𝛆n ) + a / ( √a ( 1 + 𝛆n ) ) / 2 = ( √a ( 1 + 𝛆n ) + 1 / ( 1 + 𝛆n ) ) / 2 = √a (1 + 𝛆n2 / 2( 1 + 𝛆n )) Therefore 𝛆n+1 = 𝛆n2 / 2( 1 + 𝛆n ) ≈ 𝛆n2 / 2 say if we have a 0.01 error the next iteration will make it 0.0001 this is why we have a quadratic convergence that the accurate digits doubles every time d-digit of precision = lgd iterations Multiplication Algo recall Karatsuba Algo Toom-Cook (k≥2 k parts) say we use Toom-3 T(n) = 5T(n/3) Θ(n) T(n) = Θ(nlog35) = Θ(n1.465) Schonhage-Strassen Θ(n lgn lglgn) time use FFT in gmpy package in Python Furer (2007) Θ(nlgn 22O( log*n )) nlgn is for sorting log*n is the # of log needs to be applied to get a result that ≤ 1 High-precision Division we want a high-precision rep of a/b we need a high-precision rep of 1/b first we will compute floor(R/b) where R is a really large value, s.t.(such that) it’s easy to divide by R (R = 2k) by shift the floating point Division Newton’s Method for computing R/b f(x) = 1/x - b/R (zero at x = R/b) f ‘(x) = -1/x2 xi+1 = 2xi - bxi2/R i.e. R/b = 216/5 = 65536/2 = 13107.2 Initial guess: 216/4 = 214 - x0 = 16384 x1 = 2(16384) - 5(16384)2/65536 = 12288 x2 = 2(12288) - 5(12288)2/65536 = 13056 … lgd times to get the needed accurate digits Division: quadratic convergence: # digits doubles at each step d-digit of precision = lgd iterations Multiplication in Θ(n𝛂) 𝛂 ≥ 1 = O(lgd n𝛂) =O(lgn n𝛂) BUT! Let’s look into it more carefully for d digits precision every time of multiplication we have constant time of division T(n) = C1𝛂 + C2𝛂 + … + C(d/2)𝛂 + Cd𝛂 Newton’s method: xi+1 = (xi + a/xi) / 2 = Division = Newtion’s method: xi+1 = 2xi - bxi2/R Complexity of Square Root ≈ Complexity of division ≈ Complexity of multiplication ","date":"2021-12-25","objectID":"/square-roots-newtons-method/:0:1","series":[],"tags":["Algorithm"],"title":"Newton's Method","uri":"/square-roots-newtons-method/#square-roots"},{"categories":["Note"],"content":"Square Roots, Newton’s Method Square Roots recall the sqrt(2) problem xi+1 = (xi + a/xi) / 2 Notice the division in it that’s what we’ll settle down Error Analysis of Newton’s Method xn = √a (1 + 𝛆n) 𝛆n may +/- xn+1 = ( √a ( 1 + 𝛆n ) + a / ( √a ( 1 + 𝛆n ) ) / 2 = ( √a ( 1 + 𝛆n ) + 1 / ( 1 + 𝛆n ) ) / 2 = √a (1 + 𝛆n2 / 2( 1 + 𝛆n )) Therefore 𝛆n+1 = 𝛆n2 / 2( 1 + 𝛆n ) ≈ 𝛆n2 / 2 say if we have a 0.01 error the next iteration will make it 0.0001 this is why we have a quadratic convergence that the accurate digits doubles every time d-digit of precision = lgd iterations Multiplication Algo recall Karatsuba Algo Toom-Cook (k≥2 k parts) say we use Toom-3 T(n) = 5T(n/3) Θ(n) T(n) = Θ(nlog35) = Θ(n1.465) Schonhage-Strassen Θ(n lgn lglgn) time use FFT in gmpy package in Python Furer (2007) Θ(nlgn 22O( log*n )) nlgn is for sorting log*n is the # of log needs to be applied to get a result that ≤ 1 High-precision Division we want a high-precision rep of a/b we need a high-precision rep of 1/b first we will compute floor(R/b) where R is a really large value, s.t.(such that) it’s easy to divide by R (R = 2k) by shift the floating point Division Newton’s Method for computing R/b f(x) = 1/x - b/R (zero at x = R/b) f ‘(x) = -1/x2 xi+1 = 2xi - bxi2/R i.e. R/b = 216/5 = 65536/2 = 13107.2 Initial guess: 216/4 = 214 - x0 = 16384 x1 = 2(16384) - 5(16384)2/65536 = 12288 x2 = 2(12288) - 5(12288)2/65536 = 13056 … lgd times to get the needed accurate digits Division: quadratic convergence: # digits doubles at each step d-digit of precision = lgd iterations Multiplication in Θ(n𝛂) 𝛂 ≥ 1 = O(lgd n𝛂) =O(lgn n𝛂) BUT! Let’s look into it more carefully for d digits precision every time of multiplication we have constant time of division T(n) = C1𝛂 + C2𝛂 + … + C(d/2)𝛂 + Cd𝛂 Newton’s method: xi+1 = (xi + a/xi) / 2 = Division = Newtion’s method: xi+1 = 2xi - bxi2/R Complexity of Square Root ≈ Complexity of division ≈ Complexity of multiplication ","date":"2021-12-25","objectID":"/square-roots-newtons-method/:0:1","series":[],"tags":["Algorithm"],"title":"Newton's Method","uri":"/square-roots-newtons-method/#error-analysis-of-newtons-method"},{"categories":["Note"],"content":"Square Roots, Newton’s Method Square Roots recall the sqrt(2) problem xi+1 = (xi + a/xi) / 2 Notice the division in it that’s what we’ll settle down Error Analysis of Newton’s Method xn = √a (1 + 𝛆n) 𝛆n may +/- xn+1 = ( √a ( 1 + 𝛆n ) + a / ( √a ( 1 + 𝛆n ) ) / 2 = ( √a ( 1 + 𝛆n ) + 1 / ( 1 + 𝛆n ) ) / 2 = √a (1 + 𝛆n2 / 2( 1 + 𝛆n )) Therefore 𝛆n+1 = 𝛆n2 / 2( 1 + 𝛆n ) ≈ 𝛆n2 / 2 say if we have a 0.01 error the next iteration will make it 0.0001 this is why we have a quadratic convergence that the accurate digits doubles every time d-digit of precision = lgd iterations Multiplication Algo recall Karatsuba Algo Toom-Cook (k≥2 k parts) say we use Toom-3 T(n) = 5T(n/3) Θ(n) T(n) = Θ(nlog35) = Θ(n1.465) Schonhage-Strassen Θ(n lgn lglgn) time use FFT in gmpy package in Python Furer (2007) Θ(nlgn 22O( log*n )) nlgn is for sorting log*n is the # of log needs to be applied to get a result that ≤ 1 High-precision Division we want a high-precision rep of a/b we need a high-precision rep of 1/b first we will compute floor(R/b) where R is a really large value, s.t.(such that) it’s easy to divide by R (R = 2k) by shift the floating point Division Newton’s Method for computing R/b f(x) = 1/x - b/R (zero at x = R/b) f ‘(x) = -1/x2 xi+1 = 2xi - bxi2/R i.e. R/b = 216/5 = 65536/2 = 13107.2 Initial guess: 216/4 = 214 - x0 = 16384 x1 = 2(16384) - 5(16384)2/65536 = 12288 x2 = 2(12288) - 5(12288)2/65536 = 13056 … lgd times to get the needed accurate digits Division: quadratic convergence: # digits doubles at each step d-digit of precision = lgd iterations Multiplication in Θ(n𝛂) 𝛂 ≥ 1 = O(lgd n𝛂) =O(lgn n𝛂) BUT! Let’s look into it more carefully for d digits precision every time of multiplication we have constant time of division T(n) = C1𝛂 + C2𝛂 + … + C(d/2)𝛂 + Cd𝛂 Newton’s method: xi+1 = (xi + a/xi) / 2 = Division = Newtion’s method: xi+1 = 2xi - bxi2/R Complexity of Square Root ≈ Complexity of division ≈ Complexity of multiplication ","date":"2021-12-25","objectID":"/square-roots-newtons-method/:0:1","series":[],"tags":["Algorithm"],"title":"Newton's Method","uri":"/square-roots-newtons-method/#multiplication-algo"},{"categories":["Note"],"content":"Square Roots, Newton’s Method Square Roots recall the sqrt(2) problem xi+1 = (xi + a/xi) / 2 Notice the division in it that’s what we’ll settle down Error Analysis of Newton’s Method xn = √a (1 + 𝛆n) 𝛆n may +/- xn+1 = ( √a ( 1 + 𝛆n ) + a / ( √a ( 1 + 𝛆n ) ) / 2 = ( √a ( 1 + 𝛆n ) + 1 / ( 1 + 𝛆n ) ) / 2 = √a (1 + 𝛆n2 / 2( 1 + 𝛆n )) Therefore 𝛆n+1 = 𝛆n2 / 2( 1 + 𝛆n ) ≈ 𝛆n2 / 2 say if we have a 0.01 error the next iteration will make it 0.0001 this is why we have a quadratic convergence that the accurate digits doubles every time d-digit of precision = lgd iterations Multiplication Algo recall Karatsuba Algo Toom-Cook (k≥2 k parts) say we use Toom-3 T(n) = 5T(n/3) Θ(n) T(n) = Θ(nlog35) = Θ(n1.465) Schonhage-Strassen Θ(n lgn lglgn) time use FFT in gmpy package in Python Furer (2007) Θ(nlgn 22O( log*n )) nlgn is for sorting log*n is the # of log needs to be applied to get a result that ≤ 1 High-precision Division we want a high-precision rep of a/b we need a high-precision rep of 1/b first we will compute floor(R/b) where R is a really large value, s.t.(such that) it’s easy to divide by R (R = 2k) by shift the floating point Division Newton’s Method for computing R/b f(x) = 1/x - b/R (zero at x = R/b) f ‘(x) = -1/x2 xi+1 = 2xi - bxi2/R i.e. R/b = 216/5 = 65536/2 = 13107.2 Initial guess: 216/4 = 214 - x0 = 16384 x1 = 2(16384) - 5(16384)2/65536 = 12288 x2 = 2(12288) - 5(12288)2/65536 = 13056 … lgd times to get the needed accurate digits Division: quadratic convergence: # digits doubles at each step d-digit of precision = lgd iterations Multiplication in Θ(n𝛂) 𝛂 ≥ 1 = O(lgd n𝛂) =O(lgn n𝛂) BUT! Let’s look into it more carefully for d digits precision every time of multiplication we have constant time of division T(n) = C1𝛂 + C2𝛂 + … + C(d/2)𝛂 + Cd𝛂 Newton’s method: xi+1 = (xi + a/xi) / 2 = Division = Newtion’s method: xi+1 = 2xi - bxi2/R Complexity of Square Root ≈ Complexity of division ≈ Complexity of multiplication ","date":"2021-12-25","objectID":"/square-roots-newtons-method/:0:1","series":[],"tags":["Algorithm"],"title":"Newton's Method","uri":"/square-roots-newtons-method/#high-precision-division"},{"categories":["Note"],"content":"Square Roots, Newton’s Method Square Roots recall the sqrt(2) problem xi+1 = (xi + a/xi) / 2 Notice the division in it that’s what we’ll settle down Error Analysis of Newton’s Method xn = √a (1 + 𝛆n) 𝛆n may +/- xn+1 = ( √a ( 1 + 𝛆n ) + a / ( √a ( 1 + 𝛆n ) ) / 2 = ( √a ( 1 + 𝛆n ) + 1 / ( 1 + 𝛆n ) ) / 2 = √a (1 + 𝛆n2 / 2( 1 + 𝛆n )) Therefore 𝛆n+1 = 𝛆n2 / 2( 1 + 𝛆n ) ≈ 𝛆n2 / 2 say if we have a 0.01 error the next iteration will make it 0.0001 this is why we have a quadratic convergence that the accurate digits doubles every time d-digit of precision = lgd iterations Multiplication Algo recall Karatsuba Algo Toom-Cook (k≥2 k parts) say we use Toom-3 T(n) = 5T(n/3) Θ(n) T(n) = Θ(nlog35) = Θ(n1.465) Schonhage-Strassen Θ(n lgn lglgn) time use FFT in gmpy package in Python Furer (2007) Θ(nlgn 22O( log*n )) nlgn is for sorting log*n is the # of log needs to be applied to get a result that ≤ 1 High-precision Division we want a high-precision rep of a/b we need a high-precision rep of 1/b first we will compute floor(R/b) where R is a really large value, s.t.(such that) it’s easy to divide by R (R = 2k) by shift the floating point Division Newton’s Method for computing R/b f(x) = 1/x - b/R (zero at x = R/b) f ‘(x) = -1/x2 xi+1 = 2xi - bxi2/R i.e. R/b = 216/5 = 65536/2 = 13107.2 Initial guess: 216/4 = 214 - x0 = 16384 x1 = 2(16384) - 5(16384)2/65536 = 12288 x2 = 2(12288) - 5(12288)2/65536 = 13056 … lgd times to get the needed accurate digits Division: quadratic convergence: # digits doubles at each step d-digit of precision = lgd iterations Multiplication in Θ(n𝛂) 𝛂 ≥ 1 = O(lgd n𝛂) =O(lgn n𝛂) BUT! Let’s look into it more carefully for d digits precision every time of multiplication we have constant time of division T(n) = C1𝛂 + C2𝛂 + … + C(d/2)𝛂 + Cd𝛂 Newton’s method: xi+1 = (xi + a/xi) / 2 = Division = Newtion’s method: xi+1 = 2xi - bxi2/R Complexity of Square Root ≈ Complexity of division ≈ Complexity of multiplication ","date":"2021-12-25","objectID":"/square-roots-newtons-method/:0:1","series":[],"tags":["Algorithm"],"title":"Newton's Method","uri":"/square-roots-newtons-method/#time-complexity-analysis-of-square-root"},{"categories":["Note"],"content":"Speeding up Dijkstra Optimize Dijkstra Single-Source, single target: s -\u003e t Initialize() where d[s] = 0 d[u≠s] = ∞ Q \u003c- V[a] while Q ≠ 𝜑 do u \u003c- EXTRACT-MIN(Q) for each vertex v∈Adj[u] do Relax(u,v,w) you can add (stop if u == t) rather than quit until Q is null to accelerate it Bi-Directional Search Alternate forward search from s and backward search from t, and we sorts of doubles all the data structures, like we have Qf and Qb, df[u] and db[u] … what is the termination condition? some vertex u has been processed both in the forward search and backward search How do we find the shortest path from s to e? claim: If w was processed first from both Qf, Qb find S.P. using πf from s to w find S.P. using πb from t to w (backward) but the answer will be the shortest length path and may not be the shortest weight path How to fix it? find an x (possibly diff from w) that has minimum value of df + db Goal-Directed Search: Potentials, Landmarks (or A*) -modify edge weights with potential functions W(u,v) = w(u,v) - 𝜆(u) + 𝜆(v) correctness W(p) = w(p) - 𝜆t(s) + 𝜆t(t) landmark ","date":"2021-12-25","objectID":"/speeding-up-dijkstra/:0:1","series":[],"tags":["Algorithm"],"title":"Optimized Dijkstra","uri":"/speeding-up-dijkstra/#speeding-up-dijkstra"},{"categories":["Note"],"content":"Speeding up Dijkstra Optimize Dijkstra Single-Source, single target: s - t Initialize() where d[s] = 0 d[u≠s] = ∞ Q ","date":"2021-12-25","objectID":"/speeding-up-dijkstra/:0:1","series":[],"tags":["Algorithm"],"title":"Optimized Dijkstra","uri":"/speeding-up-dijkstra/#optimize-dijkstra"},{"categories":["Note"],"content":"Speeding up Dijkstra Optimize Dijkstra Single-Source, single target: s - t Initialize() where d[s] = 0 d[u≠s] = ∞ Q ","date":"2021-12-25","objectID":"/speeding-up-dijkstra/:0:1","series":[],"tags":["Algorithm"],"title":"Optimized Dijkstra","uri":"/speeding-up-dijkstra/#single-source-single-target-s---t"},{"categories":["Note"],"content":"Speeding up Dijkstra Optimize Dijkstra Single-Source, single target: s - t Initialize() where d[s] = 0 d[u≠s] = ∞ Q ","date":"2021-12-25","objectID":"/speeding-up-dijkstra/:0:1","series":[],"tags":["Algorithm"],"title":"Optimized Dijkstra","uri":"/speeding-up-dijkstra/#bi-directional-search"},{"categories":["Note"],"content":"Speeding up Dijkstra Optimize Dijkstra Single-Source, single target: s - t Initialize() where d[s] = 0 d[u≠s] = ∞ Q ","date":"2021-12-25","objectID":"/speeding-up-dijkstra/:0:1","series":[],"tags":["Algorithm"],"title":"Optimized Dijkstra","uri":"/speeding-up-dijkstra/#what-is-the-termination-condition"},{"categories":["Note"],"content":"Speeding up Dijkstra Optimize Dijkstra Single-Source, single target: s - t Initialize() where d[s] = 0 d[u≠s] = ∞ Q ","date":"2021-12-25","objectID":"/speeding-up-dijkstra/:0:1","series":[],"tags":["Algorithm"],"title":"Optimized Dijkstra","uri":"/speeding-up-dijkstra/#goal-directed-search-potentials-landmarks-or-a"},{"categories":["Note"],"content":"OS_notes_for book_reading ","date":"2021-12-25","objectID":"/os_reading_note/:0:0","series":[],"tags":["OS"],"title":"OS","uri":"/os_reading_note/#os_notes_for-book_reading"},{"categories":["Note"],"content":"Virtual Memory ","date":"2021-12-25","objectID":"/os_reading_note/:1:0","series":[],"tags":["OS"],"title":"OS","uri":"/os_reading_note/#virtual-memory"},{"categories":["Note"],"content":"Paging Segmentation leads to fragmentation so that we need the new idea of paging. Pages are memory chunks with fixed size, we can view physical memory as an array of fixed-sized slots called page frames. Paging gives us flexibility so that we don’t need to whether the way a process uses to address space will cause external fragmentation. Paging also gives us the simplicity of free-space management that paging affords. The OS keeps a free list of all free pages. ","date":"2021-12-25","objectID":"/os_reading_note/:1:1","series":[],"tags":["OS"],"title":"OS","uri":"/os_reading_note/#paging"},{"categories":["Note"],"content":"Page Table The major role of page table is to store address translations for each of the virtual pages of the address space, thus letting us know where in physical memory each page resides. It’s important to know that page table is a per-process data structure. An exception of this is the inverted page table. Notice Notice that two same virtual addresses in different processes may lead to a same physical frame. Translation VA –\u003e VPN(Virtual Address Number) + offset For example, the page size is 16 bytes in a 64-byte address space. Then we need 4 pages, the virtual page number will be indicated by the first 2-bit. VPN –\u003e PFN(Physical Frame Number) Physical Address = VFN + offset Where are page tables stored? Page tables can get terribly large, much larger than the small segment table or base/bounds pair. For example, for a typical 32-bit address space, with 4KB pages. This VA splits into 20-bit VPN and 12-bit offset. 20 bits implies 2^20 translations that the OS would have to manage for each process. Assuming we need 4 bytes per PTE to hold the PFN + control bits, then we need an immense 4MB of memory for each page table. And this is only for one process. What’s in the page table? The simplest one is the linear page table, which is just an array. The OS indexes the array by the virtual page number, and looks up the page-table entry at that VPN to find the desired PFN. We also have control bits such as: Valid bit ==\u003e indicating whether the particular translation is valid. All unused space will be marked invalid. Protection bit ==\u003e indicating whether the page can be read, written, or executed. Present bit ==\u003e indicating whether this page is in physical memory or on disk. Dirty bit ==\u003e indicating whether the page has been modified Reference bit(accessed bit) ==\u003e track whether a page has been accessed, and this is useful to tell which page is popular so that we should keep in memory. Problem: paging is so slow To fetch the desired data: fetch the proper page table entry from the process’s page table. Perform the translation. Load the data from ther physical memory. To do so, the hardware must know where to find the page table of the current running process. Thus we need a page-table base register holding the location. However, implementing paging without care will lead to a slower machine as well as memory waste. ","date":"2021-12-25","objectID":"/os_reading_note/:1:2","series":[],"tags":["OS"],"title":"OS","uri":"/os_reading_note/#page-table"},{"categories":["Note"],"content":"Page Table The major role of page table is to store address translations for each of the virtual pages of the address space, thus letting us know where in physical memory each page resides. It’s important to know that page table is a per-process data structure. An exception of this is the inverted page table. Notice Notice that two same virtual addresses in different processes may lead to a same physical frame. Translation VA – VPN(Virtual Address Number) + offset For example, the page size is 16 bytes in a 64-byte address space. Then we need 4 pages, the virtual page number will be indicated by the first 2-bit. VPN – PFN(Physical Frame Number) Physical Address = VFN + offset Where are page tables stored? Page tables can get terribly large, much larger than the small segment table or base/bounds pair. For example, for a typical 32-bit address space, with 4KB pages. This VA splits into 20-bit VPN and 12-bit offset. 20 bits implies 2^20 translations that the OS would have to manage for each process. Assuming we need 4 bytes per PTE to hold the PFN + control bits, then we need an immense 4MB of memory for each page table. And this is only for one process. What’s in the page table? The simplest one is the linear page table, which is just an array. The OS indexes the array by the virtual page number, and looks up the page-table entry at that VPN to find the desired PFN. We also have control bits such as: Valid bit == indicating whether the particular translation is valid. All unused space will be marked invalid. Protection bit == indicating whether the page can be read, written, or executed. Present bit == indicating whether this page is in physical memory or on disk. Dirty bit == indicating whether the page has been modified Reference bit(accessed bit) == track whether a page has been accessed, and this is useful to tell which page is popular so that we should keep in memory. Problem: paging is so slow To fetch the desired data: fetch the proper page table entry from the process’s page table. Perform the translation. Load the data from ther physical memory. To do so, the hardware must know where to find the page table of the current running process. Thus we need a page-table base register holding the location. However, implementing paging without care will lead to a slower machine as well as memory waste. ","date":"2021-12-25","objectID":"/os_reading_note/:1:2","series":[],"tags":["OS"],"title":"OS","uri":"/os_reading_note/#notice"},{"categories":["Note"],"content":"Page Table The major role of page table is to store address translations for each of the virtual pages of the address space, thus letting us know where in physical memory each page resides. It’s important to know that page table is a per-process data structure. An exception of this is the inverted page table. Notice Notice that two same virtual addresses in different processes may lead to a same physical frame. Translation VA – VPN(Virtual Address Number) + offset For example, the page size is 16 bytes in a 64-byte address space. Then we need 4 pages, the virtual page number will be indicated by the first 2-bit. VPN – PFN(Physical Frame Number) Physical Address = VFN + offset Where are page tables stored? Page tables can get terribly large, much larger than the small segment table or base/bounds pair. For example, for a typical 32-bit address space, with 4KB pages. This VA splits into 20-bit VPN and 12-bit offset. 20 bits implies 2^20 translations that the OS would have to manage for each process. Assuming we need 4 bytes per PTE to hold the PFN + control bits, then we need an immense 4MB of memory for each page table. And this is only for one process. What’s in the page table? The simplest one is the linear page table, which is just an array. The OS indexes the array by the virtual page number, and looks up the page-table entry at that VPN to find the desired PFN. We also have control bits such as: Valid bit == indicating whether the particular translation is valid. All unused space will be marked invalid. Protection bit == indicating whether the page can be read, written, or executed. Present bit == indicating whether this page is in physical memory or on disk. Dirty bit == indicating whether the page has been modified Reference bit(accessed bit) == track whether a page has been accessed, and this is useful to tell which page is popular so that we should keep in memory. Problem: paging is so slow To fetch the desired data: fetch the proper page table entry from the process’s page table. Perform the translation. Load the data from ther physical memory. To do so, the hardware must know where to find the page table of the current running process. Thus we need a page-table base register holding the location. However, implementing paging without care will lead to a slower machine as well as memory waste. ","date":"2021-12-25","objectID":"/os_reading_note/:1:2","series":[],"tags":["OS"],"title":"OS","uri":"/os_reading_note/#translation"},{"categories":["Note"],"content":"Page Table The major role of page table is to store address translations for each of the virtual pages of the address space, thus letting us know where in physical memory each page resides. It’s important to know that page table is a per-process data structure. An exception of this is the inverted page table. Notice Notice that two same virtual addresses in different processes may lead to a same physical frame. Translation VA – VPN(Virtual Address Number) + offset For example, the page size is 16 bytes in a 64-byte address space. Then we need 4 pages, the virtual page number will be indicated by the first 2-bit. VPN – PFN(Physical Frame Number) Physical Address = VFN + offset Where are page tables stored? Page tables can get terribly large, much larger than the small segment table or base/bounds pair. For example, for a typical 32-bit address space, with 4KB pages. This VA splits into 20-bit VPN and 12-bit offset. 20 bits implies 2^20 translations that the OS would have to manage for each process. Assuming we need 4 bytes per PTE to hold the PFN + control bits, then we need an immense 4MB of memory for each page table. And this is only for one process. What’s in the page table? The simplest one is the linear page table, which is just an array. The OS indexes the array by the virtual page number, and looks up the page-table entry at that VPN to find the desired PFN. We also have control bits such as: Valid bit == indicating whether the particular translation is valid. All unused space will be marked invalid. Protection bit == indicating whether the page can be read, written, or executed. Present bit == indicating whether this page is in physical memory or on disk. Dirty bit == indicating whether the page has been modified Reference bit(accessed bit) == track whether a page has been accessed, and this is useful to tell which page is popular so that we should keep in memory. Problem: paging is so slow To fetch the desired data: fetch the proper page table entry from the process’s page table. Perform the translation. Load the data from ther physical memory. To do so, the hardware must know where to find the page table of the current running process. Thus we need a page-table base register holding the location. However, implementing paging without care will lead to a slower machine as well as memory waste. ","date":"2021-12-25","objectID":"/os_reading_note/:1:2","series":[],"tags":["OS"],"title":"OS","uri":"/os_reading_note/#where-are-page-tables-stored"},{"categories":["Note"],"content":"Page Table The major role of page table is to store address translations for each of the virtual pages of the address space, thus letting us know where in physical memory each page resides. It’s important to know that page table is a per-process data structure. An exception of this is the inverted page table. Notice Notice that two same virtual addresses in different processes may lead to a same physical frame. Translation VA – VPN(Virtual Address Number) + offset For example, the page size is 16 bytes in a 64-byte address space. Then we need 4 pages, the virtual page number will be indicated by the first 2-bit. VPN – PFN(Physical Frame Number) Physical Address = VFN + offset Where are page tables stored? Page tables can get terribly large, much larger than the small segment table or base/bounds pair. For example, for a typical 32-bit address space, with 4KB pages. This VA splits into 20-bit VPN and 12-bit offset. 20 bits implies 2^20 translations that the OS would have to manage for each process. Assuming we need 4 bytes per PTE to hold the PFN + control bits, then we need an immense 4MB of memory for each page table. And this is only for one process. What’s in the page table? The simplest one is the linear page table, which is just an array. The OS indexes the array by the virtual page number, and looks up the page-table entry at that VPN to find the desired PFN. We also have control bits such as: Valid bit == indicating whether the particular translation is valid. All unused space will be marked invalid. Protection bit == indicating whether the page can be read, written, or executed. Present bit == indicating whether this page is in physical memory or on disk. Dirty bit == indicating whether the page has been modified Reference bit(accessed bit) == track whether a page has been accessed, and this is useful to tell which page is popular so that we should keep in memory. Problem: paging is so slow To fetch the desired data: fetch the proper page table entry from the process’s page table. Perform the translation. Load the data from ther physical memory. To do so, the hardware must know where to find the page table of the current running process. Thus we need a page-table base register holding the location. However, implementing paging without care will lead to a slower machine as well as memory waste. ","date":"2021-12-25","objectID":"/os_reading_note/:1:2","series":[],"tags":["OS"],"title":"OS","uri":"/os_reading_note/#whats-in-the-page-table"},{"categories":["Note"],"content":"Page Table The major role of page table is to store address translations for each of the virtual pages of the address space, thus letting us know where in physical memory each page resides. It’s important to know that page table is a per-process data structure. An exception of this is the inverted page table. Notice Notice that two same virtual addresses in different processes may lead to a same physical frame. Translation VA – VPN(Virtual Address Number) + offset For example, the page size is 16 bytes in a 64-byte address space. Then we need 4 pages, the virtual page number will be indicated by the first 2-bit. VPN – PFN(Physical Frame Number) Physical Address = VFN + offset Where are page tables stored? Page tables can get terribly large, much larger than the small segment table or base/bounds pair. For example, for a typical 32-bit address space, with 4KB pages. This VA splits into 20-bit VPN and 12-bit offset. 20 bits implies 2^20 translations that the OS would have to manage for each process. Assuming we need 4 bytes per PTE to hold the PFN + control bits, then we need an immense 4MB of memory for each page table. And this is only for one process. What’s in the page table? The simplest one is the linear page table, which is just an array. The OS indexes the array by the virtual page number, and looks up the page-table entry at that VPN to find the desired PFN. We also have control bits such as: Valid bit == indicating whether the particular translation is valid. All unused space will be marked invalid. Protection bit == indicating whether the page can be read, written, or executed. Present bit == indicating whether this page is in physical memory or on disk. Dirty bit == indicating whether the page has been modified Reference bit(accessed bit) == track whether a page has been accessed, and this is useful to tell which page is popular so that we should keep in memory. Problem: paging is so slow To fetch the desired data: fetch the proper page table entry from the process’s page table. Perform the translation. Load the data from ther physical memory. To do so, the hardware must know where to find the page table of the current running process. Thus we need a page-table base register holding the location. However, implementing paging without care will lead to a slower machine as well as memory waste. ","date":"2021-12-25","objectID":"/os_reading_note/:1:2","series":[],"tags":["OS"],"title":"OS","uri":"/os_reading_note/#problem-paging-is-so-slow"},{"categories":["Note"],"content":"TLBs Translation-lookaside Buffer(TLB) A TLB is a part of memory-management unit(MMU), and is a hardware cache. TLB Basic Algorithm Extract the VPN from the VA and check if the TLB holds it. If yes, then we have a TLB hit. We can now extract the PFN from the relevant TLB entry, concatenate that onto the offset from the original VA, and form the PA we want. If protection checks do not fail, then we can perform the operation correctly. If no, then we have a TLB miss. Then we have to walk the page table, the memory, or even copy the data from disk. And then update the TLB. Note that page fault can be triggered by both TLB hit and TLB miss. The TLB hit rate will greatly affect the performance, so we need to find the sweet spot for the TLB size. Also, if the TLB size is too large, walk the TLB will consume more time. And also, if you want a fast cache, it has to be small. This is the physical limit. TLB also improves the performance due to spatial locality even if it’s the first time to visit that memory space. Who handle the TLB miss? Could be hardware or software. Hardware: the hardware has to know where exactly the page tables are located in memory(page-table base register), as well as the format. On a miss, the hardware will walk through the page table, find the right PTE and extract the desired translation, update the TLB with the translation, and retry the instruction. For example, the Intel x86 architecture uses a fixed multi-level page table, and the current table is pointed to by the CR3 register. Software: More modern architecture such as RISC, has a software-managed TLB. On a TLB miss, the hardware will raise an exception to pause the current instruction stream. Then it traps into kernel mode and jumps to a trap handler dealing with TLB misses. The code will look up the page table and update the TLB and return from the trap. The hardware will retry the instruction. Notice that the return-from-trap behaves differently from that in a system call. In the system call case, it should resume execution at the instruction after the trap into the OS. However, in this case, the hardware must resume execution at the instruction that cause the trap and retry it so that it will has a TLB hit this time. We need be aware of the OS need to save different PC in these two cases. Also, when running the TLB miss-handling code, the OS need to be extra careful not to cause an infinite chain of TLB misses to occur. The solution would be to keep TLB miss handlers in physical memory that are unmapped and not subject to address translation. Or reserve some entries in the TLB for permanently-valid translations and use some of those permanent translation slots for the handler code itself, these wired translations always hit in the TLB. Aside: TLB valid bit != page table valid bit TLB valid bit indicates whether a TLB entry has a valid translation in it. The page table valid bit indicates the page has not been allocated by the process, and should not be accessed by a correctly working program. The TLB valid bit is quite useful when performing a context switch too. By setting all TLB entries to invalid, the system can ensure that the about-to-run process does not accidentally use a virtual-to-physical translation from a previous process. IMPORTANT: The dirty bit in PTE indicates where the PTE is modified rather than whether the memory location is modified, which is indicated by the dirty bit of that memory location. Based on this fact, we can know that the content of PTE in TLB does not need to be the same as the one in the page table since whether the memory is modified is indicated by the memory itself rather than the PTE. In addition, TLB PTE doesn’t need to be the as same as the one in the page table because the OS can keep just TLB updated rather than both. Think of about this, if we have the PTE in TLB, when we want to go to that PA, we always get a TLB hit and will never walk the page table. The additional work would be to update the PTE in th","date":"2021-12-25","objectID":"/os_reading_note/:1:3","series":[],"tags":["OS"],"title":"OS","uri":"/os_reading_note/#tlbs"},{"categories":["Note"],"content":"TLBs Translation-lookaside Buffer(TLB) A TLB is a part of memory-management unit(MMU), and is a hardware cache. TLB Basic Algorithm Extract the VPN from the VA and check if the TLB holds it. If yes, then we have a TLB hit. We can now extract the PFN from the relevant TLB entry, concatenate that onto the offset from the original VA, and form the PA we want. If protection checks do not fail, then we can perform the operation correctly. If no, then we have a TLB miss. Then we have to walk the page table, the memory, or even copy the data from disk. And then update the TLB. Note that page fault can be triggered by both TLB hit and TLB miss. The TLB hit rate will greatly affect the performance, so we need to find the sweet spot for the TLB size. Also, if the TLB size is too large, walk the TLB will consume more time. And also, if you want a fast cache, it has to be small. This is the physical limit. TLB also improves the performance due to spatial locality even if it’s the first time to visit that memory space. Who handle the TLB miss? Could be hardware or software. Hardware: the hardware has to know where exactly the page tables are located in memory(page-table base register), as well as the format. On a miss, the hardware will walk through the page table, find the right PTE and extract the desired translation, update the TLB with the translation, and retry the instruction. For example, the Intel x86 architecture uses a fixed multi-level page table, and the current table is pointed to by the CR3 register. Software: More modern architecture such as RISC, has a software-managed TLB. On a TLB miss, the hardware will raise an exception to pause the current instruction stream. Then it traps into kernel mode and jumps to a trap handler dealing with TLB misses. The code will look up the page table and update the TLB and return from the trap. The hardware will retry the instruction. Notice that the return-from-trap behaves differently from that in a system call. In the system call case, it should resume execution at the instruction after the trap into the OS. However, in this case, the hardware must resume execution at the instruction that cause the trap and retry it so that it will has a TLB hit this time. We need be aware of the OS need to save different PC in these two cases. Also, when running the TLB miss-handling code, the OS need to be extra careful not to cause an infinite chain of TLB misses to occur. The solution would be to keep TLB miss handlers in physical memory that are unmapped and not subject to address translation. Or reserve some entries in the TLB for permanently-valid translations and use some of those permanent translation slots for the handler code itself, these wired translations always hit in the TLB. Aside: TLB valid bit != page table valid bit TLB valid bit indicates whether a TLB entry has a valid translation in it. The page table valid bit indicates the page has not been allocated by the process, and should not be accessed by a correctly working program. The TLB valid bit is quite useful when performing a context switch too. By setting all TLB entries to invalid, the system can ensure that the about-to-run process does not accidentally use a virtual-to-physical translation from a previous process. IMPORTANT: The dirty bit in PTE indicates where the PTE is modified rather than whether the memory location is modified, which is indicated by the dirty bit of that memory location. Based on this fact, we can know that the content of PTE in TLB does not need to be the same as the one in the page table since whether the memory is modified is indicated by the memory itself rather than the PTE. In addition, TLB PTE doesn’t need to be the as same as the one in the page table because the OS can keep just TLB updated rather than both. Think of about this, if we have the PTE in TLB, when we want to go to that PA, we always get a TLB hit and will never walk the page table. The additional work would be to update the PTE in th","date":"2021-12-25","objectID":"/os_reading_note/:1:3","series":[],"tags":["OS"],"title":"OS","uri":"/os_reading_note/#translation-lookaside-buffertlb"},{"categories":["Note"],"content":"TLBs Translation-lookaside Buffer(TLB) A TLB is a part of memory-management unit(MMU), and is a hardware cache. TLB Basic Algorithm Extract the VPN from the VA and check if the TLB holds it. If yes, then we have a TLB hit. We can now extract the PFN from the relevant TLB entry, concatenate that onto the offset from the original VA, and form the PA we want. If protection checks do not fail, then we can perform the operation correctly. If no, then we have a TLB miss. Then we have to walk the page table, the memory, or even copy the data from disk. And then update the TLB. Note that page fault can be triggered by both TLB hit and TLB miss. The TLB hit rate will greatly affect the performance, so we need to find the sweet spot for the TLB size. Also, if the TLB size is too large, walk the TLB will consume more time. And also, if you want a fast cache, it has to be small. This is the physical limit. TLB also improves the performance due to spatial locality even if it’s the first time to visit that memory space. Who handle the TLB miss? Could be hardware or software. Hardware: the hardware has to know where exactly the page tables are located in memory(page-table base register), as well as the format. On a miss, the hardware will walk through the page table, find the right PTE and extract the desired translation, update the TLB with the translation, and retry the instruction. For example, the Intel x86 architecture uses a fixed multi-level page table, and the current table is pointed to by the CR3 register. Software: More modern architecture such as RISC, has a software-managed TLB. On a TLB miss, the hardware will raise an exception to pause the current instruction stream. Then it traps into kernel mode and jumps to a trap handler dealing with TLB misses. The code will look up the page table and update the TLB and return from the trap. The hardware will retry the instruction. Notice that the return-from-trap behaves differently from that in a system call. In the system call case, it should resume execution at the instruction after the trap into the OS. However, in this case, the hardware must resume execution at the instruction that cause the trap and retry it so that it will has a TLB hit this time. We need be aware of the OS need to save different PC in these two cases. Also, when running the TLB miss-handling code, the OS need to be extra careful not to cause an infinite chain of TLB misses to occur. The solution would be to keep TLB miss handlers in physical memory that are unmapped and not subject to address translation. Or reserve some entries in the TLB for permanently-valid translations and use some of those permanent translation slots for the handler code itself, these wired translations always hit in the TLB. Aside: TLB valid bit != page table valid bit TLB valid bit indicates whether a TLB entry has a valid translation in it. The page table valid bit indicates the page has not been allocated by the process, and should not be accessed by a correctly working program. The TLB valid bit is quite useful when performing a context switch too. By setting all TLB entries to invalid, the system can ensure that the about-to-run process does not accidentally use a virtual-to-physical translation from a previous process. IMPORTANT: The dirty bit in PTE indicates where the PTE is modified rather than whether the memory location is modified, which is indicated by the dirty bit of that memory location. Based on this fact, we can know that the content of PTE in TLB does not need to be the same as the one in the page table since whether the memory is modified is indicated by the memory itself rather than the PTE. In addition, TLB PTE doesn’t need to be the as same as the one in the page table because the OS can keep just TLB updated rather than both. Think of about this, if we have the PTE in TLB, when we want to go to that PA, we always get a TLB hit and will never walk the page table. The additional work would be to update the PTE in th","date":"2021-12-25","objectID":"/os_reading_note/:1:3","series":[],"tags":["OS"],"title":"OS","uri":"/os_reading_note/#tlb-basic-algorithm"},{"categories":["Note"],"content":"TLBs Translation-lookaside Buffer(TLB) A TLB is a part of memory-management unit(MMU), and is a hardware cache. TLB Basic Algorithm Extract the VPN from the VA and check if the TLB holds it. If yes, then we have a TLB hit. We can now extract the PFN from the relevant TLB entry, concatenate that onto the offset from the original VA, and form the PA we want. If protection checks do not fail, then we can perform the operation correctly. If no, then we have a TLB miss. Then we have to walk the page table, the memory, or even copy the data from disk. And then update the TLB. Note that page fault can be triggered by both TLB hit and TLB miss. The TLB hit rate will greatly affect the performance, so we need to find the sweet spot for the TLB size. Also, if the TLB size is too large, walk the TLB will consume more time. And also, if you want a fast cache, it has to be small. This is the physical limit. TLB also improves the performance due to spatial locality even if it’s the first time to visit that memory space. Who handle the TLB miss? Could be hardware or software. Hardware: the hardware has to know where exactly the page tables are located in memory(page-table base register), as well as the format. On a miss, the hardware will walk through the page table, find the right PTE and extract the desired translation, update the TLB with the translation, and retry the instruction. For example, the Intel x86 architecture uses a fixed multi-level page table, and the current table is pointed to by the CR3 register. Software: More modern architecture such as RISC, has a software-managed TLB. On a TLB miss, the hardware will raise an exception to pause the current instruction stream. Then it traps into kernel mode and jumps to a trap handler dealing with TLB misses. The code will look up the page table and update the TLB and return from the trap. The hardware will retry the instruction. Notice that the return-from-trap behaves differently from that in a system call. In the system call case, it should resume execution at the instruction after the trap into the OS. However, in this case, the hardware must resume execution at the instruction that cause the trap and retry it so that it will has a TLB hit this time. We need be aware of the OS need to save different PC in these two cases. Also, when running the TLB miss-handling code, the OS need to be extra careful not to cause an infinite chain of TLB misses to occur. The solution would be to keep TLB miss handlers in physical memory that are unmapped and not subject to address translation. Or reserve some entries in the TLB for permanently-valid translations and use some of those permanent translation slots for the handler code itself, these wired translations always hit in the TLB. Aside: TLB valid bit != page table valid bit TLB valid bit indicates whether a TLB entry has a valid translation in it. The page table valid bit indicates the page has not been allocated by the process, and should not be accessed by a correctly working program. The TLB valid bit is quite useful when performing a context switch too. By setting all TLB entries to invalid, the system can ensure that the about-to-run process does not accidentally use a virtual-to-physical translation from a previous process. IMPORTANT: The dirty bit in PTE indicates where the PTE is modified rather than whether the memory location is modified, which is indicated by the dirty bit of that memory location. Based on this fact, we can know that the content of PTE in TLB does not need to be the same as the one in the page table since whether the memory is modified is indicated by the memory itself rather than the PTE. In addition, TLB PTE doesn’t need to be the as same as the one in the page table because the OS can keep just TLB updated rather than both. Think of about this, if we have the PTE in TLB, when we want to go to that PA, we always get a TLB hit and will never walk the page table. The additional work would be to update the PTE in th","date":"2021-12-25","objectID":"/os_reading_note/:1:3","series":[],"tags":["OS"],"title":"OS","uri":"/os_reading_note/#who-handle-the-tlb-miss"},{"categories":["Note"],"content":"TLBs Translation-lookaside Buffer(TLB) A TLB is a part of memory-management unit(MMU), and is a hardware cache. TLB Basic Algorithm Extract the VPN from the VA and check if the TLB holds it. If yes, then we have a TLB hit. We can now extract the PFN from the relevant TLB entry, concatenate that onto the offset from the original VA, and form the PA we want. If protection checks do not fail, then we can perform the operation correctly. If no, then we have a TLB miss. Then we have to walk the page table, the memory, or even copy the data from disk. And then update the TLB. Note that page fault can be triggered by both TLB hit and TLB miss. The TLB hit rate will greatly affect the performance, so we need to find the sweet spot for the TLB size. Also, if the TLB size is too large, walk the TLB will consume more time. And also, if you want a fast cache, it has to be small. This is the physical limit. TLB also improves the performance due to spatial locality even if it’s the first time to visit that memory space. Who handle the TLB miss? Could be hardware or software. Hardware: the hardware has to know where exactly the page tables are located in memory(page-table base register), as well as the format. On a miss, the hardware will walk through the page table, find the right PTE and extract the desired translation, update the TLB with the translation, and retry the instruction. For example, the Intel x86 architecture uses a fixed multi-level page table, and the current table is pointed to by the CR3 register. Software: More modern architecture such as RISC, has a software-managed TLB. On a TLB miss, the hardware will raise an exception to pause the current instruction stream. Then it traps into kernel mode and jumps to a trap handler dealing with TLB misses. The code will look up the page table and update the TLB and return from the trap. The hardware will retry the instruction. Notice that the return-from-trap behaves differently from that in a system call. In the system call case, it should resume execution at the instruction after the trap into the OS. However, in this case, the hardware must resume execution at the instruction that cause the trap and retry it so that it will has a TLB hit this time. We need be aware of the OS need to save different PC in these two cases. Also, when running the TLB miss-handling code, the OS need to be extra careful not to cause an infinite chain of TLB misses to occur. The solution would be to keep TLB miss handlers in physical memory that are unmapped and not subject to address translation. Or reserve some entries in the TLB for permanently-valid translations and use some of those permanent translation slots for the handler code itself, these wired translations always hit in the TLB. Aside: TLB valid bit != page table valid bit TLB valid bit indicates whether a TLB entry has a valid translation in it. The page table valid bit indicates the page has not been allocated by the process, and should not be accessed by a correctly working program. The TLB valid bit is quite useful when performing a context switch too. By setting all TLB entries to invalid, the system can ensure that the about-to-run process does not accidentally use a virtual-to-physical translation from a previous process. IMPORTANT: The dirty bit in PTE indicates where the PTE is modified rather than whether the memory location is modified, which is indicated by the dirty bit of that memory location. Based on this fact, we can know that the content of PTE in TLB does not need to be the same as the one in the page table since whether the memory is modified is indicated by the memory itself rather than the PTE. In addition, TLB PTE doesn’t need to be the as same as the one in the page table because the OS can keep just TLB updated rather than both. Think of about this, if we have the PTE in TLB, when we want to go to that PA, we always get a TLB hit and will never walk the page table. The additional work would be to update the PTE in th","date":"2021-12-25","objectID":"/os_reading_note/:1:3","series":[],"tags":["OS"],"title":"OS","uri":"/os_reading_note/#aside-tlb-valid-bit--page-table-valid-bit"},{"categories":["Note"],"content":"TLBs Translation-lookaside Buffer(TLB) A TLB is a part of memory-management unit(MMU), and is a hardware cache. TLB Basic Algorithm Extract the VPN from the VA and check if the TLB holds it. If yes, then we have a TLB hit. We can now extract the PFN from the relevant TLB entry, concatenate that onto the offset from the original VA, and form the PA we want. If protection checks do not fail, then we can perform the operation correctly. If no, then we have a TLB miss. Then we have to walk the page table, the memory, or even copy the data from disk. And then update the TLB. Note that page fault can be triggered by both TLB hit and TLB miss. The TLB hit rate will greatly affect the performance, so we need to find the sweet spot for the TLB size. Also, if the TLB size is too large, walk the TLB will consume more time. And also, if you want a fast cache, it has to be small. This is the physical limit. TLB also improves the performance due to spatial locality even if it’s the first time to visit that memory space. Who handle the TLB miss? Could be hardware or software. Hardware: the hardware has to know where exactly the page tables are located in memory(page-table base register), as well as the format. On a miss, the hardware will walk through the page table, find the right PTE and extract the desired translation, update the TLB with the translation, and retry the instruction. For example, the Intel x86 architecture uses a fixed multi-level page table, and the current table is pointed to by the CR3 register. Software: More modern architecture such as RISC, has a software-managed TLB. On a TLB miss, the hardware will raise an exception to pause the current instruction stream. Then it traps into kernel mode and jumps to a trap handler dealing with TLB misses. The code will look up the page table and update the TLB and return from the trap. The hardware will retry the instruction. Notice that the return-from-trap behaves differently from that in a system call. In the system call case, it should resume execution at the instruction after the trap into the OS. However, in this case, the hardware must resume execution at the instruction that cause the trap and retry it so that it will has a TLB hit this time. We need be aware of the OS need to save different PC in these two cases. Also, when running the TLB miss-handling code, the OS need to be extra careful not to cause an infinite chain of TLB misses to occur. The solution would be to keep TLB miss handlers in physical memory that are unmapped and not subject to address translation. Or reserve some entries in the TLB for permanently-valid translations and use some of those permanent translation slots for the handler code itself, these wired translations always hit in the TLB. Aside: TLB valid bit != page table valid bit TLB valid bit indicates whether a TLB entry has a valid translation in it. The page table valid bit indicates the page has not been allocated by the process, and should not be accessed by a correctly working program. The TLB valid bit is quite useful when performing a context switch too. By setting all TLB entries to invalid, the system can ensure that the about-to-run process does not accidentally use a virtual-to-physical translation from a previous process. IMPORTANT: The dirty bit in PTE indicates where the PTE is modified rather than whether the memory location is modified, which is indicated by the dirty bit of that memory location. Based on this fact, we can know that the content of PTE in TLB does not need to be the same as the one in the page table since whether the memory is modified is indicated by the memory itself rather than the PTE. In addition, TLB PTE doesn’t need to be the as same as the one in the page table because the OS can keep just TLB updated rather than both. Think of about this, if we have the PTE in TLB, when we want to go to that PA, we always get a TLB hit and will never walk the page table. The additional work would be to update the PTE in th","date":"2021-12-25","objectID":"/os_reading_note/:1:3","series":[],"tags":["OS"],"title":"OS","uri":"/os_reading_note/#important"},{"categories":["Note"],"content":"TLBs Translation-lookaside Buffer(TLB) A TLB is a part of memory-management unit(MMU), and is a hardware cache. TLB Basic Algorithm Extract the VPN from the VA and check if the TLB holds it. If yes, then we have a TLB hit. We can now extract the PFN from the relevant TLB entry, concatenate that onto the offset from the original VA, and form the PA we want. If protection checks do not fail, then we can perform the operation correctly. If no, then we have a TLB miss. Then we have to walk the page table, the memory, or even copy the data from disk. And then update the TLB. Note that page fault can be triggered by both TLB hit and TLB miss. The TLB hit rate will greatly affect the performance, so we need to find the sweet spot for the TLB size. Also, if the TLB size is too large, walk the TLB will consume more time. And also, if you want a fast cache, it has to be small. This is the physical limit. TLB also improves the performance due to spatial locality even if it’s the first time to visit that memory space. Who handle the TLB miss? Could be hardware or software. Hardware: the hardware has to know where exactly the page tables are located in memory(page-table base register), as well as the format. On a miss, the hardware will walk through the page table, find the right PTE and extract the desired translation, update the TLB with the translation, and retry the instruction. For example, the Intel x86 architecture uses a fixed multi-level page table, and the current table is pointed to by the CR3 register. Software: More modern architecture such as RISC, has a software-managed TLB. On a TLB miss, the hardware will raise an exception to pause the current instruction stream. Then it traps into kernel mode and jumps to a trap handler dealing with TLB misses. The code will look up the page table and update the TLB and return from the trap. The hardware will retry the instruction. Notice that the return-from-trap behaves differently from that in a system call. In the system call case, it should resume execution at the instruction after the trap into the OS. However, in this case, the hardware must resume execution at the instruction that cause the trap and retry it so that it will has a TLB hit this time. We need be aware of the OS need to save different PC in these two cases. Also, when running the TLB miss-handling code, the OS need to be extra careful not to cause an infinite chain of TLB misses to occur. The solution would be to keep TLB miss handlers in physical memory that are unmapped and not subject to address translation. Or reserve some entries in the TLB for permanently-valid translations and use some of those permanent translation slots for the handler code itself, these wired translations always hit in the TLB. Aside: TLB valid bit != page table valid bit TLB valid bit indicates whether a TLB entry has a valid translation in it. The page table valid bit indicates the page has not been allocated by the process, and should not be accessed by a correctly working program. The TLB valid bit is quite useful when performing a context switch too. By setting all TLB entries to invalid, the system can ensure that the about-to-run process does not accidentally use a virtual-to-physical translation from a previous process. IMPORTANT: The dirty bit in PTE indicates where the PTE is modified rather than whether the memory location is modified, which is indicated by the dirty bit of that memory location. Based on this fact, we can know that the content of PTE in TLB does not need to be the same as the one in the page table since whether the memory is modified is indicated by the memory itself rather than the PTE. In addition, TLB PTE doesn’t need to be the as same as the one in the page table because the OS can keep just TLB updated rather than both. Think of about this, if we have the PTE in TLB, when we want to go to that PA, we always get a TLB hit and will never walk the page table. The additional work would be to update the PTE in th","date":"2021-12-25","objectID":"/os_reading_note/:1:3","series":[],"tags":["OS"],"title":"OS","uri":"/os_reading_note/#my-question-here-is-whether-the-same-tlb-is-shared-by-processes-or-even-cores"},{"categories":["Note"],"content":"TLBs Translation-lookaside Buffer(TLB) A TLB is a part of memory-management unit(MMU), and is a hardware cache. TLB Basic Algorithm Extract the VPN from the VA and check if the TLB holds it. If yes, then we have a TLB hit. We can now extract the PFN from the relevant TLB entry, concatenate that onto the offset from the original VA, and form the PA we want. If protection checks do not fail, then we can perform the operation correctly. If no, then we have a TLB miss. Then we have to walk the page table, the memory, or even copy the data from disk. And then update the TLB. Note that page fault can be triggered by both TLB hit and TLB miss. The TLB hit rate will greatly affect the performance, so we need to find the sweet spot for the TLB size. Also, if the TLB size is too large, walk the TLB will consume more time. And also, if you want a fast cache, it has to be small. This is the physical limit. TLB also improves the performance due to spatial locality even if it’s the first time to visit that memory space. Who handle the TLB miss? Could be hardware or software. Hardware: the hardware has to know where exactly the page tables are located in memory(page-table base register), as well as the format. On a miss, the hardware will walk through the page table, find the right PTE and extract the desired translation, update the TLB with the translation, and retry the instruction. For example, the Intel x86 architecture uses a fixed multi-level page table, and the current table is pointed to by the CR3 register. Software: More modern architecture such as RISC, has a software-managed TLB. On a TLB miss, the hardware will raise an exception to pause the current instruction stream. Then it traps into kernel mode and jumps to a trap handler dealing with TLB misses. The code will look up the page table and update the TLB and return from the trap. The hardware will retry the instruction. Notice that the return-from-trap behaves differently from that in a system call. In the system call case, it should resume execution at the instruction after the trap into the OS. However, in this case, the hardware must resume execution at the instruction that cause the trap and retry it so that it will has a TLB hit this time. We need be aware of the OS need to save different PC in these two cases. Also, when running the TLB miss-handling code, the OS need to be extra careful not to cause an infinite chain of TLB misses to occur. The solution would be to keep TLB miss handlers in physical memory that are unmapped and not subject to address translation. Or reserve some entries in the TLB for permanently-valid translations and use some of those permanent translation slots for the handler code itself, these wired translations always hit in the TLB. Aside: TLB valid bit != page table valid bit TLB valid bit indicates whether a TLB entry has a valid translation in it. The page table valid bit indicates the page has not been allocated by the process, and should not be accessed by a correctly working program. The TLB valid bit is quite useful when performing a context switch too. By setting all TLB entries to invalid, the system can ensure that the about-to-run process does not accidentally use a virtual-to-physical translation from a previous process. IMPORTANT: The dirty bit in PTE indicates where the PTE is modified rather than whether the memory location is modified, which is indicated by the dirty bit of that memory location. Based on this fact, we can know that the content of PTE in TLB does not need to be the same as the one in the page table since whether the memory is modified is indicated by the memory itself rather than the PTE. In addition, TLB PTE doesn’t need to be the as same as the one in the page table because the OS can keep just TLB updated rather than both. Think of about this, if we have the PTE in TLB, when we want to go to that PA, we always get a TLB hit and will never walk the page table. The additional work would be to update the PTE in th","date":"2021-12-25","objectID":"/os_reading_note/:1:3","series":[],"tags":["OS"],"title":"OS","uri":"/os_reading_note/#whats-in-the-tlb"},{"categories":["Note"],"content":"TLBs Translation-lookaside Buffer(TLB) A TLB is a part of memory-management unit(MMU), and is a hardware cache. TLB Basic Algorithm Extract the VPN from the VA and check if the TLB holds it. If yes, then we have a TLB hit. We can now extract the PFN from the relevant TLB entry, concatenate that onto the offset from the original VA, and form the PA we want. If protection checks do not fail, then we can perform the operation correctly. If no, then we have a TLB miss. Then we have to walk the page table, the memory, or even copy the data from disk. And then update the TLB. Note that page fault can be triggered by both TLB hit and TLB miss. The TLB hit rate will greatly affect the performance, so we need to find the sweet spot for the TLB size. Also, if the TLB size is too large, walk the TLB will consume more time. And also, if you want a fast cache, it has to be small. This is the physical limit. TLB also improves the performance due to spatial locality even if it’s the first time to visit that memory space. Who handle the TLB miss? Could be hardware or software. Hardware: the hardware has to know where exactly the page tables are located in memory(page-table base register), as well as the format. On a miss, the hardware will walk through the page table, find the right PTE and extract the desired translation, update the TLB with the translation, and retry the instruction. For example, the Intel x86 architecture uses a fixed multi-level page table, and the current table is pointed to by the CR3 register. Software: More modern architecture such as RISC, has a software-managed TLB. On a TLB miss, the hardware will raise an exception to pause the current instruction stream. Then it traps into kernel mode and jumps to a trap handler dealing with TLB misses. The code will look up the page table and update the TLB and return from the trap. The hardware will retry the instruction. Notice that the return-from-trap behaves differently from that in a system call. In the system call case, it should resume execution at the instruction after the trap into the OS. However, in this case, the hardware must resume execution at the instruction that cause the trap and retry it so that it will has a TLB hit this time. We need be aware of the OS need to save different PC in these two cases. Also, when running the TLB miss-handling code, the OS need to be extra careful not to cause an infinite chain of TLB misses to occur. The solution would be to keep TLB miss handlers in physical memory that are unmapped and not subject to address translation. Or reserve some entries in the TLB for permanently-valid translations and use some of those permanent translation slots for the handler code itself, these wired translations always hit in the TLB. Aside: TLB valid bit != page table valid bit TLB valid bit indicates whether a TLB entry has a valid translation in it. The page table valid bit indicates the page has not been allocated by the process, and should not be accessed by a correctly working program. The TLB valid bit is quite useful when performing a context switch too. By setting all TLB entries to invalid, the system can ensure that the about-to-run process does not accidentally use a virtual-to-physical translation from a previous process. IMPORTANT: The dirty bit in PTE indicates where the PTE is modified rather than whether the memory location is modified, which is indicated by the dirty bit of that memory location. Based on this fact, we can know that the content of PTE in TLB does not need to be the same as the one in the page table since whether the memory is modified is indicated by the memory itself rather than the PTE. In addition, TLB PTE doesn’t need to be the as same as the one in the page table because the OS can keep just TLB updated rather than both. Think of about this, if we have the PTE in TLB, when we want to go to that PA, we always get a TLB hit and will never walk the page table. The additional work would be to update the PTE in th","date":"2021-12-25","objectID":"/os_reading_note/:1:3","series":[],"tags":["OS"],"title":"OS","uri":"/os_reading_note/#tlb-issue-context-switches"},{"categories":["Note"],"content":"TLBs Translation-lookaside Buffer(TLB) A TLB is a part of memory-management unit(MMU), and is a hardware cache. TLB Basic Algorithm Extract the VPN from the VA and check if the TLB holds it. If yes, then we have a TLB hit. We can now extract the PFN from the relevant TLB entry, concatenate that onto the offset from the original VA, and form the PA we want. If protection checks do not fail, then we can perform the operation correctly. If no, then we have a TLB miss. Then we have to walk the page table, the memory, or even copy the data from disk. And then update the TLB. Note that page fault can be triggered by both TLB hit and TLB miss. The TLB hit rate will greatly affect the performance, so we need to find the sweet spot for the TLB size. Also, if the TLB size is too large, walk the TLB will consume more time. And also, if you want a fast cache, it has to be small. This is the physical limit. TLB also improves the performance due to spatial locality even if it’s the first time to visit that memory space. Who handle the TLB miss? Could be hardware or software. Hardware: the hardware has to know where exactly the page tables are located in memory(page-table base register), as well as the format. On a miss, the hardware will walk through the page table, find the right PTE and extract the desired translation, update the TLB with the translation, and retry the instruction. For example, the Intel x86 architecture uses a fixed multi-level page table, and the current table is pointed to by the CR3 register. Software: More modern architecture such as RISC, has a software-managed TLB. On a TLB miss, the hardware will raise an exception to pause the current instruction stream. Then it traps into kernel mode and jumps to a trap handler dealing with TLB misses. The code will look up the page table and update the TLB and return from the trap. The hardware will retry the instruction. Notice that the return-from-trap behaves differently from that in a system call. In the system call case, it should resume execution at the instruction after the trap into the OS. However, in this case, the hardware must resume execution at the instruction that cause the trap and retry it so that it will has a TLB hit this time. We need be aware of the OS need to save different PC in these two cases. Also, when running the TLB miss-handling code, the OS need to be extra careful not to cause an infinite chain of TLB misses to occur. The solution would be to keep TLB miss handlers in physical memory that are unmapped and not subject to address translation. Or reserve some entries in the TLB for permanently-valid translations and use some of those permanent translation slots for the handler code itself, these wired translations always hit in the TLB. Aside: TLB valid bit != page table valid bit TLB valid bit indicates whether a TLB entry has a valid translation in it. The page table valid bit indicates the page has not been allocated by the process, and should not be accessed by a correctly working program. The TLB valid bit is quite useful when performing a context switch too. By setting all TLB entries to invalid, the system can ensure that the about-to-run process does not accidentally use a virtual-to-physical translation from a previous process. IMPORTANT: The dirty bit in PTE indicates where the PTE is modified rather than whether the memory location is modified, which is indicated by the dirty bit of that memory location. Based on this fact, we can know that the content of PTE in TLB does not need to be the same as the one in the page table since whether the memory is modified is indicated by the memory itself rather than the PTE. In addition, TLB PTE doesn’t need to be the as same as the one in the page table because the OS can keep just TLB updated rather than both. Think of about this, if we have the PTE in TLB, when we want to go to that PA, we always get a TLB hit and will never walk the page table. The additional work would be to update the PTE in th","date":"2021-12-25","objectID":"/os_reading_note/:1:3","series":[],"tags":["OS"],"title":"OS","uri":"/os_reading_note/#issue-replacement-policy"},{"categories":["Note"],"content":"TLBs Translation-lookaside Buffer(TLB) A TLB is a part of memory-management unit(MMU), and is a hardware cache. TLB Basic Algorithm Extract the VPN from the VA and check if the TLB holds it. If yes, then we have a TLB hit. We can now extract the PFN from the relevant TLB entry, concatenate that onto the offset from the original VA, and form the PA we want. If protection checks do not fail, then we can perform the operation correctly. If no, then we have a TLB miss. Then we have to walk the page table, the memory, or even copy the data from disk. And then update the TLB. Note that page fault can be triggered by both TLB hit and TLB miss. The TLB hit rate will greatly affect the performance, so we need to find the sweet spot for the TLB size. Also, if the TLB size is too large, walk the TLB will consume more time. And also, if you want a fast cache, it has to be small. This is the physical limit. TLB also improves the performance due to spatial locality even if it’s the first time to visit that memory space. Who handle the TLB miss? Could be hardware or software. Hardware: the hardware has to know where exactly the page tables are located in memory(page-table base register), as well as the format. On a miss, the hardware will walk through the page table, find the right PTE and extract the desired translation, update the TLB with the translation, and retry the instruction. For example, the Intel x86 architecture uses a fixed multi-level page table, and the current table is pointed to by the CR3 register. Software: More modern architecture such as RISC, has a software-managed TLB. On a TLB miss, the hardware will raise an exception to pause the current instruction stream. Then it traps into kernel mode and jumps to a trap handler dealing with TLB misses. The code will look up the page table and update the TLB and return from the trap. The hardware will retry the instruction. Notice that the return-from-trap behaves differently from that in a system call. In the system call case, it should resume execution at the instruction after the trap into the OS. However, in this case, the hardware must resume execution at the instruction that cause the trap and retry it so that it will has a TLB hit this time. We need be aware of the OS need to save different PC in these two cases. Also, when running the TLB miss-handling code, the OS need to be extra careful not to cause an infinite chain of TLB misses to occur. The solution would be to keep TLB miss handlers in physical memory that are unmapped and not subject to address translation. Or reserve some entries in the TLB for permanently-valid translations and use some of those permanent translation slots for the handler code itself, these wired translations always hit in the TLB. Aside: TLB valid bit != page table valid bit TLB valid bit indicates whether a TLB entry has a valid translation in it. The page table valid bit indicates the page has not been allocated by the process, and should not be accessed by a correctly working program. The TLB valid bit is quite useful when performing a context switch too. By setting all TLB entries to invalid, the system can ensure that the about-to-run process does not accidentally use a virtual-to-physical translation from a previous process. IMPORTANT: The dirty bit in PTE indicates where the PTE is modified rather than whether the memory location is modified, which is indicated by the dirty bit of that memory location. Based on this fact, we can know that the content of PTE in TLB does not need to be the same as the one in the page table since whether the memory is modified is indicated by the memory itself rather than the PTE. In addition, TLB PTE doesn’t need to be the as same as the one in the page table because the OS can keep just TLB updated rather than both. Think of about this, if we have the PTE in TLB, when we want to go to that PA, we always get a TLB hit and will never walk the page table. The additional work would be to update the PTE in th","date":"2021-12-25","objectID":"/os_reading_note/:1:3","series":[],"tags":["OS"],"title":"OS","uri":"/os_reading_note/#how-to-design-tlb-replacement-policy"},{"categories":["Note"],"content":"TLBs Translation-lookaside Buffer(TLB) A TLB is a part of memory-management unit(MMU), and is a hardware cache. TLB Basic Algorithm Extract the VPN from the VA and check if the TLB holds it. If yes, then we have a TLB hit. We can now extract the PFN from the relevant TLB entry, concatenate that onto the offset from the original VA, and form the PA we want. If protection checks do not fail, then we can perform the operation correctly. If no, then we have a TLB miss. Then we have to walk the page table, the memory, or even copy the data from disk. And then update the TLB. Note that page fault can be triggered by both TLB hit and TLB miss. The TLB hit rate will greatly affect the performance, so we need to find the sweet spot for the TLB size. Also, if the TLB size is too large, walk the TLB will consume more time. And also, if you want a fast cache, it has to be small. This is the physical limit. TLB also improves the performance due to spatial locality even if it’s the first time to visit that memory space. Who handle the TLB miss? Could be hardware or software. Hardware: the hardware has to know where exactly the page tables are located in memory(page-table base register), as well as the format. On a miss, the hardware will walk through the page table, find the right PTE and extract the desired translation, update the TLB with the translation, and retry the instruction. For example, the Intel x86 architecture uses a fixed multi-level page table, and the current table is pointed to by the CR3 register. Software: More modern architecture such as RISC, has a software-managed TLB. On a TLB miss, the hardware will raise an exception to pause the current instruction stream. Then it traps into kernel mode and jumps to a trap handler dealing with TLB misses. The code will look up the page table and update the TLB and return from the trap. The hardware will retry the instruction. Notice that the return-from-trap behaves differently from that in a system call. In the system call case, it should resume execution at the instruction after the trap into the OS. However, in this case, the hardware must resume execution at the instruction that cause the trap and retry it so that it will has a TLB hit this time. We need be aware of the OS need to save different PC in these two cases. Also, when running the TLB miss-handling code, the OS need to be extra careful not to cause an infinite chain of TLB misses to occur. The solution would be to keep TLB miss handlers in physical memory that are unmapped and not subject to address translation. Or reserve some entries in the TLB for permanently-valid translations and use some of those permanent translation slots for the handler code itself, these wired translations always hit in the TLB. Aside: TLB valid bit != page table valid bit TLB valid bit indicates whether a TLB entry has a valid translation in it. The page table valid bit indicates the page has not been allocated by the process, and should not be accessed by a correctly working program. The TLB valid bit is quite useful when performing a context switch too. By setting all TLB entries to invalid, the system can ensure that the about-to-run process does not accidentally use a virtual-to-physical translation from a previous process. IMPORTANT: The dirty bit in PTE indicates where the PTE is modified rather than whether the memory location is modified, which is indicated by the dirty bit of that memory location. Based on this fact, we can know that the content of PTE in TLB does not need to be the same as the one in the page table since whether the memory is modified is indicated by the memory itself rather than the PTE. In addition, TLB PTE doesn’t need to be the as same as the one in the page table because the OS can keep just TLB updated rather than both. Think of about this, if we have the PTE in TLB, when we want to go to that PA, we always get a TLB hit and will never walk the page table. The additional work would be to update the PTE in th","date":"2021-12-25","objectID":"/os_reading_note/:1:3","series":[],"tags":["OS"],"title":"OS","uri":"/os_reading_note/#a-real-tlb-entry"},{"categories":["Note"],"content":"TLBs Translation-lookaside Buffer(TLB) A TLB is a part of memory-management unit(MMU), and is a hardware cache. TLB Basic Algorithm Extract the VPN from the VA and check if the TLB holds it. If yes, then we have a TLB hit. We can now extract the PFN from the relevant TLB entry, concatenate that onto the offset from the original VA, and form the PA we want. If protection checks do not fail, then we can perform the operation correctly. If no, then we have a TLB miss. Then we have to walk the page table, the memory, or even copy the data from disk. And then update the TLB. Note that page fault can be triggered by both TLB hit and TLB miss. The TLB hit rate will greatly affect the performance, so we need to find the sweet spot for the TLB size. Also, if the TLB size is too large, walk the TLB will consume more time. And also, if you want a fast cache, it has to be small. This is the physical limit. TLB also improves the performance due to spatial locality even if it’s the first time to visit that memory space. Who handle the TLB miss? Could be hardware or software. Hardware: the hardware has to know where exactly the page tables are located in memory(page-table base register), as well as the format. On a miss, the hardware will walk through the page table, find the right PTE and extract the desired translation, update the TLB with the translation, and retry the instruction. For example, the Intel x86 architecture uses a fixed multi-level page table, and the current table is pointed to by the CR3 register. Software: More modern architecture such as RISC, has a software-managed TLB. On a TLB miss, the hardware will raise an exception to pause the current instruction stream. Then it traps into kernel mode and jumps to a trap handler dealing with TLB misses. The code will look up the page table and update the TLB and return from the trap. The hardware will retry the instruction. Notice that the return-from-trap behaves differently from that in a system call. In the system call case, it should resume execution at the instruction after the trap into the OS. However, in this case, the hardware must resume execution at the instruction that cause the trap and retry it so that it will has a TLB hit this time. We need be aware of the OS need to save different PC in these two cases. Also, when running the TLB miss-handling code, the OS need to be extra careful not to cause an infinite chain of TLB misses to occur. The solution would be to keep TLB miss handlers in physical memory that are unmapped and not subject to address translation. Or reserve some entries in the TLB for permanently-valid translations and use some of those permanent translation slots for the handler code itself, these wired translations always hit in the TLB. Aside: TLB valid bit != page table valid bit TLB valid bit indicates whether a TLB entry has a valid translation in it. The page table valid bit indicates the page has not been allocated by the process, and should not be accessed by a correctly working program. The TLB valid bit is quite useful when performing a context switch too. By setting all TLB entries to invalid, the system can ensure that the about-to-run process does not accidentally use a virtual-to-physical translation from a previous process. IMPORTANT: The dirty bit in PTE indicates where the PTE is modified rather than whether the memory location is modified, which is indicated by the dirty bit of that memory location. Based on this fact, we can know that the content of PTE in TLB does not need to be the same as the one in the page table since whether the memory is modified is indicated by the memory itself rather than the PTE. In addition, TLB PTE doesn’t need to be the as same as the one in the page table because the OS can keep just TLB updated rather than both. Think of about this, if we have the PTE in TLB, when we want to go to that PA, we always get a TLB hit and will never walk the page table. The additional work would be to update the PTE in th","date":"2021-12-25","objectID":"/os_reading_note/:1:3","series":[],"tags":["OS"],"title":"OS","uri":"/os_reading_note/#ram-isnt-always-ram"},{"categories":["Note"],"content":"Smaller Tables Page tables are too big Linear page tables are pretty big. Assuming a 32-bit address space, with 4KB pages and a 4-byte page-table size. There are roughly one million virtual pages in it, which will occupy 4MB memory. Simple Solution: Bigger Pages Side note: many archs now support multiple page sizes. Bigger pages may cause internal fragmentation. Hybrid Approach: Paging and Segments Most of the page table is unused, full of invalid entries. Instead of havin a single page table for the entris, why not one per logical segment. Base tells us the address of each segment. It holds the pysical address of the page table of that segment. Bound tells us the size of each segment. Thus the VA looks like: Seg | VPN | Offset The hardware use segment bit(SN) to determine which base and bound pair to use. IDEA: When you have two good and seemly opposite ideas, you should always see if you can combine them into hybrid that manage to achieve the best of both worlds. So if the code segment just have three entries, then the bound will be set to 3. This greatly reduces the waste of space for page tables. However, the problem is that if we have a large but sparsely-used heap. This will cause the external fragmentation again. Multi-level Page Tables It turns the linear page table like a tree. We use page directory to find the valid page tables. The page directory, in a simple two-level table, contains of a number of PDE(page directory entry). A PDE has a valid bit and a PFN, similar to PTE. However, the valid bit in PDE indcates whether at least one of the PTEs on the page pointed to by this PDE is valid. If the PDE is not valid, then the rest of the PDE is not defined. (The valid bit is the first bit in PDE) Advantage: Better supports sparse address spaces. If carefully constructed, each portion of the page table fits neatly within a page, so it’s easier to manage memory to avoid internal fragmentation. Disadvantage: If we have a TLB miss, two loads from memory will be required to get the right translation, one for the page directory and one for the PTE itself. So there is a time-space trade-off. Smaller cache is faster but not for free. The TLB miss suffers from higher cost with this smaller table. More Than Two Levels IMPORTANT: The PDT’s PA will be stored in a register, but it does not mean that the addr of PDT has to be in a fixed PA, it just has to be memorized. Inverted Page Tables Inverted page tables are even more space saving. We keep a single page table that has an entry for each physical page of the system. The entry tells use which prcess is using this page, and which virtual page of that process maps to this physical page. ","date":"2021-12-25","objectID":"/os_reading_note/:1:4","series":[],"tags":["OS"],"title":"OS","uri":"/os_reading_note/#smaller-tables"},{"categories":["Note"],"content":"Smaller Tables Page tables are too big Linear page tables are pretty big. Assuming a 32-bit address space, with 4KB pages and a 4-byte page-table size. There are roughly one million virtual pages in it, which will occupy 4MB memory. Simple Solution: Bigger Pages Side note: many archs now support multiple page sizes. Bigger pages may cause internal fragmentation. Hybrid Approach: Paging and Segments Most of the page table is unused, full of invalid entries. Instead of havin a single page table for the entris, why not one per logical segment. Base tells us the address of each segment. It holds the pysical address of the page table of that segment. Bound tells us the size of each segment. Thus the VA looks like: Seg | VPN | Offset The hardware use segment bit(SN) to determine which base and bound pair to use. IDEA: When you have two good and seemly opposite ideas, you should always see if you can combine them into hybrid that manage to achieve the best of both worlds. So if the code segment just have three entries, then the bound will be set to 3. This greatly reduces the waste of space for page tables. However, the problem is that if we have a large but sparsely-used heap. This will cause the external fragmentation again. Multi-level Page Tables It turns the linear page table like a tree. We use page directory to find the valid page tables. The page directory, in a simple two-level table, contains of a number of PDE(page directory entry). A PDE has a valid bit and a PFN, similar to PTE. However, the valid bit in PDE indcates whether at least one of the PTEs on the page pointed to by this PDE is valid. If the PDE is not valid, then the rest of the PDE is not defined. (The valid bit is the first bit in PDE) Advantage: Better supports sparse address spaces. If carefully constructed, each portion of the page table fits neatly within a page, so it’s easier to manage memory to avoid internal fragmentation. Disadvantage: If we have a TLB miss, two loads from memory will be required to get the right translation, one for the page directory and one for the PTE itself. So there is a time-space trade-off. Smaller cache is faster but not for free. The TLB miss suffers from higher cost with this smaller table. More Than Two Levels IMPORTANT: The PDT’s PA will be stored in a register, but it does not mean that the addr of PDT has to be in a fixed PA, it just has to be memorized. Inverted Page Tables Inverted page tables are even more space saving. We keep a single page table that has an entry for each physical page of the system. The entry tells use which prcess is using this page, and which virtual page of that process maps to this physical page. ","date":"2021-12-25","objectID":"/os_reading_note/:1:4","series":[],"tags":["OS"],"title":"OS","uri":"/os_reading_note/#page-tables-are-too-big"},{"categories":["Note"],"content":"Smaller Tables Page tables are too big Linear page tables are pretty big. Assuming a 32-bit address space, with 4KB pages and a 4-byte page-table size. There are roughly one million virtual pages in it, which will occupy 4MB memory. Simple Solution: Bigger Pages Side note: many archs now support multiple page sizes. Bigger pages may cause internal fragmentation. Hybrid Approach: Paging and Segments Most of the page table is unused, full of invalid entries. Instead of havin a single page table for the entris, why not one per logical segment. Base tells us the address of each segment. It holds the pysical address of the page table of that segment. Bound tells us the size of each segment. Thus the VA looks like: Seg | VPN | Offset The hardware use segment bit(SN) to determine which base and bound pair to use. IDEA: When you have two good and seemly opposite ideas, you should always see if you can combine them into hybrid that manage to achieve the best of both worlds. So if the code segment just have three entries, then the bound will be set to 3. This greatly reduces the waste of space for page tables. However, the problem is that if we have a large but sparsely-used heap. This will cause the external fragmentation again. Multi-level Page Tables It turns the linear page table like a tree. We use page directory to find the valid page tables. The page directory, in a simple two-level table, contains of a number of PDE(page directory entry). A PDE has a valid bit and a PFN, similar to PTE. However, the valid bit in PDE indcates whether at least one of the PTEs on the page pointed to by this PDE is valid. If the PDE is not valid, then the rest of the PDE is not defined. (The valid bit is the first bit in PDE) Advantage: Better supports sparse address spaces. If carefully constructed, each portion of the page table fits neatly within a page, so it’s easier to manage memory to avoid internal fragmentation. Disadvantage: If we have a TLB miss, two loads from memory will be required to get the right translation, one for the page directory and one for the PTE itself. So there is a time-space trade-off. Smaller cache is faster but not for free. The TLB miss suffers from higher cost with this smaller table. More Than Two Levels IMPORTANT: The PDT’s PA will be stored in a register, but it does not mean that the addr of PDT has to be in a fixed PA, it just has to be memorized. Inverted Page Tables Inverted page tables are even more space saving. We keep a single page table that has an entry for each physical page of the system. The entry tells use which prcess is using this page, and which virtual page of that process maps to this physical page. ","date":"2021-12-25","objectID":"/os_reading_note/:1:4","series":[],"tags":["OS"],"title":"OS","uri":"/os_reading_note/#simple-solution-bigger-pages"},{"categories":["Note"],"content":"Smaller Tables Page tables are too big Linear page tables are pretty big. Assuming a 32-bit address space, with 4KB pages and a 4-byte page-table size. There are roughly one million virtual pages in it, which will occupy 4MB memory. Simple Solution: Bigger Pages Side note: many archs now support multiple page sizes. Bigger pages may cause internal fragmentation. Hybrid Approach: Paging and Segments Most of the page table is unused, full of invalid entries. Instead of havin a single page table for the entris, why not one per logical segment. Base tells us the address of each segment. It holds the pysical address of the page table of that segment. Bound tells us the size of each segment. Thus the VA looks like: Seg | VPN | Offset The hardware use segment bit(SN) to determine which base and bound pair to use. IDEA: When you have two good and seemly opposite ideas, you should always see if you can combine them into hybrid that manage to achieve the best of both worlds. So if the code segment just have three entries, then the bound will be set to 3. This greatly reduces the waste of space for page tables. However, the problem is that if we have a large but sparsely-used heap. This will cause the external fragmentation again. Multi-level Page Tables It turns the linear page table like a tree. We use page directory to find the valid page tables. The page directory, in a simple two-level table, contains of a number of PDE(page directory entry). A PDE has a valid bit and a PFN, similar to PTE. However, the valid bit in PDE indcates whether at least one of the PTEs on the page pointed to by this PDE is valid. If the PDE is not valid, then the rest of the PDE is not defined. (The valid bit is the first bit in PDE) Advantage: Better supports sparse address spaces. If carefully constructed, each portion of the page table fits neatly within a page, so it’s easier to manage memory to avoid internal fragmentation. Disadvantage: If we have a TLB miss, two loads from memory will be required to get the right translation, one for the page directory and one for the PTE itself. So there is a time-space trade-off. Smaller cache is faster but not for free. The TLB miss suffers from higher cost with this smaller table. More Than Two Levels IMPORTANT: The PDT’s PA will be stored in a register, but it does not mean that the addr of PDT has to be in a fixed PA, it just has to be memorized. Inverted Page Tables Inverted page tables are even more space saving. We keep a single page table that has an entry for each physical page of the system. The entry tells use which prcess is using this page, and which virtual page of that process maps to this physical page. ","date":"2021-12-25","objectID":"/os_reading_note/:1:4","series":[],"tags":["OS"],"title":"OS","uri":"/os_reading_note/#side-note-many-archs-now-support-multiple-page-sizes"},{"categories":["Note"],"content":"Smaller Tables Page tables are too big Linear page tables are pretty big. Assuming a 32-bit address space, with 4KB pages and a 4-byte page-table size. There are roughly one million virtual pages in it, which will occupy 4MB memory. Simple Solution: Bigger Pages Side note: many archs now support multiple page sizes. Bigger pages may cause internal fragmentation. Hybrid Approach: Paging and Segments Most of the page table is unused, full of invalid entries. Instead of havin a single page table for the entris, why not one per logical segment. Base tells us the address of each segment. It holds the pysical address of the page table of that segment. Bound tells us the size of each segment. Thus the VA looks like: Seg | VPN | Offset The hardware use segment bit(SN) to determine which base and bound pair to use. IDEA: When you have two good and seemly opposite ideas, you should always see if you can combine them into hybrid that manage to achieve the best of both worlds. So if the code segment just have three entries, then the bound will be set to 3. This greatly reduces the waste of space for page tables. However, the problem is that if we have a large but sparsely-used heap. This will cause the external fragmentation again. Multi-level Page Tables It turns the linear page table like a tree. We use page directory to find the valid page tables. The page directory, in a simple two-level table, contains of a number of PDE(page directory entry). A PDE has a valid bit and a PFN, similar to PTE. However, the valid bit in PDE indcates whether at least one of the PTEs on the page pointed to by this PDE is valid. If the PDE is not valid, then the rest of the PDE is not defined. (The valid bit is the first bit in PDE) Advantage: Better supports sparse address spaces. If carefully constructed, each portion of the page table fits neatly within a page, so it’s easier to manage memory to avoid internal fragmentation. Disadvantage: If we have a TLB miss, two loads from memory will be required to get the right translation, one for the page directory and one for the PTE itself. So there is a time-space trade-off. Smaller cache is faster but not for free. The TLB miss suffers from higher cost with this smaller table. More Than Two Levels IMPORTANT: The PDT’s PA will be stored in a register, but it does not mean that the addr of PDT has to be in a fixed PA, it just has to be memorized. Inverted Page Tables Inverted page tables are even more space saving. We keep a single page table that has an entry for each physical page of the system. The entry tells use which prcess is using this page, and which virtual page of that process maps to this physical page. ","date":"2021-12-25","objectID":"/os_reading_note/:1:4","series":[],"tags":["OS"],"title":"OS","uri":"/os_reading_note/#hybrid-approach-paging-and-segments"},{"categories":["Note"],"content":"Smaller Tables Page tables are too big Linear page tables are pretty big. Assuming a 32-bit address space, with 4KB pages and a 4-byte page-table size. There are roughly one million virtual pages in it, which will occupy 4MB memory. Simple Solution: Bigger Pages Side note: many archs now support multiple page sizes. Bigger pages may cause internal fragmentation. Hybrid Approach: Paging and Segments Most of the page table is unused, full of invalid entries. Instead of havin a single page table for the entris, why not one per logical segment. Base tells us the address of each segment. It holds the pysical address of the page table of that segment. Bound tells us the size of each segment. Thus the VA looks like: Seg | VPN | Offset The hardware use segment bit(SN) to determine which base and bound pair to use. IDEA: When you have two good and seemly opposite ideas, you should always see if you can combine them into hybrid that manage to achieve the best of both worlds. So if the code segment just have three entries, then the bound will be set to 3. This greatly reduces the waste of space for page tables. However, the problem is that if we have a large but sparsely-used heap. This will cause the external fragmentation again. Multi-level Page Tables It turns the linear page table like a tree. We use page directory to find the valid page tables. The page directory, in a simple two-level table, contains of a number of PDE(page directory entry). A PDE has a valid bit and a PFN, similar to PTE. However, the valid bit in PDE indcates whether at least one of the PTEs on the page pointed to by this PDE is valid. If the PDE is not valid, then the rest of the PDE is not defined. (The valid bit is the first bit in PDE) Advantage: Better supports sparse address spaces. If carefully constructed, each portion of the page table fits neatly within a page, so it’s easier to manage memory to avoid internal fragmentation. Disadvantage: If we have a TLB miss, two loads from memory will be required to get the right translation, one for the page directory and one for the PTE itself. So there is a time-space trade-off. Smaller cache is faster but not for free. The TLB miss suffers from higher cost with this smaller table. More Than Two Levels IMPORTANT: The PDT’s PA will be stored in a register, but it does not mean that the addr of PDT has to be in a fixed PA, it just has to be memorized. Inverted Page Tables Inverted page tables are even more space saving. We keep a single page table that has an entry for each physical page of the system. The entry tells use which prcess is using this page, and which virtual page of that process maps to this physical page. ","date":"2021-12-25","objectID":"/os_reading_note/:1:4","series":[],"tags":["OS"],"title":"OS","uri":"/os_reading_note/#idea-when-you-have-two-good-and-seemly-opposite-ideas-you-should-always-see-if-you-can-combine-them-into-hybrid-that-manage-to-achieve-the-best-of-both-worlds"},{"categories":["Note"],"content":"Smaller Tables Page tables are too big Linear page tables are pretty big. Assuming a 32-bit address space, with 4KB pages and a 4-byte page-table size. There are roughly one million virtual pages in it, which will occupy 4MB memory. Simple Solution: Bigger Pages Side note: many archs now support multiple page sizes. Bigger pages may cause internal fragmentation. Hybrid Approach: Paging and Segments Most of the page table is unused, full of invalid entries. Instead of havin a single page table for the entris, why not one per logical segment. Base tells us the address of each segment. It holds the pysical address of the page table of that segment. Bound tells us the size of each segment. Thus the VA looks like: Seg | VPN | Offset The hardware use segment bit(SN) to determine which base and bound pair to use. IDEA: When you have two good and seemly opposite ideas, you should always see if you can combine them into hybrid that manage to achieve the best of both worlds. So if the code segment just have three entries, then the bound will be set to 3. This greatly reduces the waste of space for page tables. However, the problem is that if we have a large but sparsely-used heap. This will cause the external fragmentation again. Multi-level Page Tables It turns the linear page table like a tree. We use page directory to find the valid page tables. The page directory, in a simple two-level table, contains of a number of PDE(page directory entry). A PDE has a valid bit and a PFN, similar to PTE. However, the valid bit in PDE indcates whether at least one of the PTEs on the page pointed to by this PDE is valid. If the PDE is not valid, then the rest of the PDE is not defined. (The valid bit is the first bit in PDE) Advantage: Better supports sparse address spaces. If carefully constructed, each portion of the page table fits neatly within a page, so it’s easier to manage memory to avoid internal fragmentation. Disadvantage: If we have a TLB miss, two loads from memory will be required to get the right translation, one for the page directory and one for the PTE itself. So there is a time-space trade-off. Smaller cache is faster but not for free. The TLB miss suffers from higher cost with this smaller table. More Than Two Levels IMPORTANT: The PDT’s PA will be stored in a register, but it does not mean that the addr of PDT has to be in a fixed PA, it just has to be memorized. Inverted Page Tables Inverted page tables are even more space saving. We keep a single page table that has an entry for each physical page of the system. The entry tells use which prcess is using this page, and which virtual page of that process maps to this physical page. ","date":"2021-12-25","objectID":"/os_reading_note/:1:4","series":[],"tags":["OS"],"title":"OS","uri":"/os_reading_note/#multi-level-page-tables"},{"categories":["Note"],"content":"Smaller Tables Page tables are too big Linear page tables are pretty big. Assuming a 32-bit address space, with 4KB pages and a 4-byte page-table size. There are roughly one million virtual pages in it, which will occupy 4MB memory. Simple Solution: Bigger Pages Side note: many archs now support multiple page sizes. Bigger pages may cause internal fragmentation. Hybrid Approach: Paging and Segments Most of the page table is unused, full of invalid entries. Instead of havin a single page table for the entris, why not one per logical segment. Base tells us the address of each segment. It holds the pysical address of the page table of that segment. Bound tells us the size of each segment. Thus the VA looks like: Seg | VPN | Offset The hardware use segment bit(SN) to determine which base and bound pair to use. IDEA: When you have two good and seemly opposite ideas, you should always see if you can combine them into hybrid that manage to achieve the best of both worlds. So if the code segment just have three entries, then the bound will be set to 3. This greatly reduces the waste of space for page tables. However, the problem is that if we have a large but sparsely-used heap. This will cause the external fragmentation again. Multi-level Page Tables It turns the linear page table like a tree. We use page directory to find the valid page tables. The page directory, in a simple two-level table, contains of a number of PDE(page directory entry). A PDE has a valid bit and a PFN, similar to PTE. However, the valid bit in PDE indcates whether at least one of the PTEs on the page pointed to by this PDE is valid. If the PDE is not valid, then the rest of the PDE is not defined. (The valid bit is the first bit in PDE) Advantage: Better supports sparse address spaces. If carefully constructed, each portion of the page table fits neatly within a page, so it’s easier to manage memory to avoid internal fragmentation. Disadvantage: If we have a TLB miss, two loads from memory will be required to get the right translation, one for the page directory and one for the PTE itself. So there is a time-space trade-off. Smaller cache is faster but not for free. The TLB miss suffers from higher cost with this smaller table. More Than Two Levels IMPORTANT: The PDT’s PA will be stored in a register, but it does not mean that the addr of PDT has to be in a fixed PA, it just has to be memorized. Inverted Page Tables Inverted page tables are even more space saving. We keep a single page table that has an entry for each physical page of the system. The entry tells use which prcess is using this page, and which virtual page of that process maps to this physical page. ","date":"2021-12-25","objectID":"/os_reading_note/:1:4","series":[],"tags":["OS"],"title":"OS","uri":"/os_reading_note/#advantage"},{"categories":["Note"],"content":"Smaller Tables Page tables are too big Linear page tables are pretty big. Assuming a 32-bit address space, with 4KB pages and a 4-byte page-table size. There are roughly one million virtual pages in it, which will occupy 4MB memory. Simple Solution: Bigger Pages Side note: many archs now support multiple page sizes. Bigger pages may cause internal fragmentation. Hybrid Approach: Paging and Segments Most of the page table is unused, full of invalid entries. Instead of havin a single page table for the entris, why not one per logical segment. Base tells us the address of each segment. It holds the pysical address of the page table of that segment. Bound tells us the size of each segment. Thus the VA looks like: Seg | VPN | Offset The hardware use segment bit(SN) to determine which base and bound pair to use. IDEA: When you have two good and seemly opposite ideas, you should always see if you can combine them into hybrid that manage to achieve the best of both worlds. So if the code segment just have three entries, then the bound will be set to 3. This greatly reduces the waste of space for page tables. However, the problem is that if we have a large but sparsely-used heap. This will cause the external fragmentation again. Multi-level Page Tables It turns the linear page table like a tree. We use page directory to find the valid page tables. The page directory, in a simple two-level table, contains of a number of PDE(page directory entry). A PDE has a valid bit and a PFN, similar to PTE. However, the valid bit in PDE indcates whether at least one of the PTEs on the page pointed to by this PDE is valid. If the PDE is not valid, then the rest of the PDE is not defined. (The valid bit is the first bit in PDE) Advantage: Better supports sparse address spaces. If carefully constructed, each portion of the page table fits neatly within a page, so it’s easier to manage memory to avoid internal fragmentation. Disadvantage: If we have a TLB miss, two loads from memory will be required to get the right translation, one for the page directory and one for the PTE itself. So there is a time-space trade-off. Smaller cache is faster but not for free. The TLB miss suffers from higher cost with this smaller table. More Than Two Levels IMPORTANT: The PDT’s PA will be stored in a register, but it does not mean that the addr of PDT has to be in a fixed PA, it just has to be memorized. Inverted Page Tables Inverted page tables are even more space saving. We keep a single page table that has an entry for each physical page of the system. The entry tells use which prcess is using this page, and which virtual page of that process maps to this physical page. ","date":"2021-12-25","objectID":"/os_reading_note/:1:4","series":[],"tags":["OS"],"title":"OS","uri":"/os_reading_note/#disadvantage"},{"categories":["Note"],"content":"Smaller Tables Page tables are too big Linear page tables are pretty big. Assuming a 32-bit address space, with 4KB pages and a 4-byte page-table size. There are roughly one million virtual pages in it, which will occupy 4MB memory. Simple Solution: Bigger Pages Side note: many archs now support multiple page sizes. Bigger pages may cause internal fragmentation. Hybrid Approach: Paging and Segments Most of the page table is unused, full of invalid entries. Instead of havin a single page table for the entris, why not one per logical segment. Base tells us the address of each segment. It holds the pysical address of the page table of that segment. Bound tells us the size of each segment. Thus the VA looks like: Seg | VPN | Offset The hardware use segment bit(SN) to determine which base and bound pair to use. IDEA: When you have two good and seemly opposite ideas, you should always see if you can combine them into hybrid that manage to achieve the best of both worlds. So if the code segment just have three entries, then the bound will be set to 3. This greatly reduces the waste of space for page tables. However, the problem is that if we have a large but sparsely-used heap. This will cause the external fragmentation again. Multi-level Page Tables It turns the linear page table like a tree. We use page directory to find the valid page tables. The page directory, in a simple two-level table, contains of a number of PDE(page directory entry). A PDE has a valid bit and a PFN, similar to PTE. However, the valid bit in PDE indcates whether at least one of the PTEs on the page pointed to by this PDE is valid. If the PDE is not valid, then the rest of the PDE is not defined. (The valid bit is the first bit in PDE) Advantage: Better supports sparse address spaces. If carefully constructed, each portion of the page table fits neatly within a page, so it’s easier to manage memory to avoid internal fragmentation. Disadvantage: If we have a TLB miss, two loads from memory will be required to get the right translation, one for the page directory and one for the PTE itself. So there is a time-space trade-off. Smaller cache is faster but not for free. The TLB miss suffers from higher cost with this smaller table. More Than Two Levels IMPORTANT: The PDT’s PA will be stored in a register, but it does not mean that the addr of PDT has to be in a fixed PA, it just has to be memorized. Inverted Page Tables Inverted page tables are even more space saving. We keep a single page table that has an entry for each physical page of the system. The entry tells use which prcess is using this page, and which virtual page of that process maps to this physical page. ","date":"2021-12-25","objectID":"/os_reading_note/:1:4","series":[],"tags":["OS"],"title":"OS","uri":"/os_reading_note/#more-than-two-levels"},{"categories":["Note"],"content":"Smaller Tables Page tables are too big Linear page tables are pretty big. Assuming a 32-bit address space, with 4KB pages and a 4-byte page-table size. There are roughly one million virtual pages in it, which will occupy 4MB memory. Simple Solution: Bigger Pages Side note: many archs now support multiple page sizes. Bigger pages may cause internal fragmentation. Hybrid Approach: Paging and Segments Most of the page table is unused, full of invalid entries. Instead of havin a single page table for the entris, why not one per logical segment. Base tells us the address of each segment. It holds the pysical address of the page table of that segment. Bound tells us the size of each segment. Thus the VA looks like: Seg | VPN | Offset The hardware use segment bit(SN) to determine which base and bound pair to use. IDEA: When you have two good and seemly opposite ideas, you should always see if you can combine them into hybrid that manage to achieve the best of both worlds. So if the code segment just have three entries, then the bound will be set to 3. This greatly reduces the waste of space for page tables. However, the problem is that if we have a large but sparsely-used heap. This will cause the external fragmentation again. Multi-level Page Tables It turns the linear page table like a tree. We use page directory to find the valid page tables. The page directory, in a simple two-level table, contains of a number of PDE(page directory entry). A PDE has a valid bit and a PFN, similar to PTE. However, the valid bit in PDE indcates whether at least one of the PTEs on the page pointed to by this PDE is valid. If the PDE is not valid, then the rest of the PDE is not defined. (The valid bit is the first bit in PDE) Advantage: Better supports sparse address spaces. If carefully constructed, each portion of the page table fits neatly within a page, so it’s easier to manage memory to avoid internal fragmentation. Disadvantage: If we have a TLB miss, two loads from memory will be required to get the right translation, one for the page directory and one for the PTE itself. So there is a time-space trade-off. Smaller cache is faster but not for free. The TLB miss suffers from higher cost with this smaller table. More Than Two Levels IMPORTANT: The PDT’s PA will be stored in a register, but it does not mean that the addr of PDT has to be in a fixed PA, it just has to be memorized. Inverted Page Tables Inverted page tables are even more space saving. We keep a single page table that has an entry for each physical page of the system. The entry tells use which prcess is using this page, and which virtual page of that process maps to this physical page. ","date":"2021-12-25","objectID":"/os_reading_note/:1:4","series":[],"tags":["OS"],"title":"OS","uri":"/os_reading_note/#important-the-pdts-pa-will-be-stored-in-a-register-but-it-does-not-mean-that-the-addr-of-pdt-has-to-be-in-a-fixed-pa-it-just-has-to-be-memorized"},{"categories":["Note"],"content":"Smaller Tables Page tables are too big Linear page tables are pretty big. Assuming a 32-bit address space, with 4KB pages and a 4-byte page-table size. There are roughly one million virtual pages in it, which will occupy 4MB memory. Simple Solution: Bigger Pages Side note: many archs now support multiple page sizes. Bigger pages may cause internal fragmentation. Hybrid Approach: Paging and Segments Most of the page table is unused, full of invalid entries. Instead of havin a single page table for the entris, why not one per logical segment. Base tells us the address of each segment. It holds the pysical address of the page table of that segment. Bound tells us the size of each segment. Thus the VA looks like: Seg | VPN | Offset The hardware use segment bit(SN) to determine which base and bound pair to use. IDEA: When you have two good and seemly opposite ideas, you should always see if you can combine them into hybrid that manage to achieve the best of both worlds. So if the code segment just have three entries, then the bound will be set to 3. This greatly reduces the waste of space for page tables. However, the problem is that if we have a large but sparsely-used heap. This will cause the external fragmentation again. Multi-level Page Tables It turns the linear page table like a tree. We use page directory to find the valid page tables. The page directory, in a simple two-level table, contains of a number of PDE(page directory entry). A PDE has a valid bit and a PFN, similar to PTE. However, the valid bit in PDE indcates whether at least one of the PTEs on the page pointed to by this PDE is valid. If the PDE is not valid, then the rest of the PDE is not defined. (The valid bit is the first bit in PDE) Advantage: Better supports sparse address spaces. If carefully constructed, each portion of the page table fits neatly within a page, so it’s easier to manage memory to avoid internal fragmentation. Disadvantage: If we have a TLB miss, two loads from memory will be required to get the right translation, one for the page directory and one for the PTE itself. So there is a time-space trade-off. Smaller cache is faster but not for free. The TLB miss suffers from higher cost with this smaller table. More Than Two Levels IMPORTANT: The PDT’s PA will be stored in a register, but it does not mean that the addr of PDT has to be in a fixed PA, it just has to be memorized. Inverted Page Tables Inverted page tables are even more space saving. We keep a single page table that has an entry for each physical page of the system. The entry tells use which prcess is using this page, and which virtual page of that process maps to this physical page. ","date":"2021-12-25","objectID":"/os_reading_note/:1:4","series":[],"tags":["OS"],"title":"OS","uri":"/os_reading_note/#inverted-page-tables"},{"categories":["Note"],"content":"Swapping: Mechanisms Swap space Firstly, we need to reserve some space on the disk for moving pages back and forth. Then the OS need to remember the disk address of a given page. The size of the swap space is important since it determines the maximum number of memory pages that can be in use by a system in a ginven time. The Present Bit The hardware first extract the VPN from the VA, the check the TLB for a match. If a miss, the hardware locates the PDT and corresponding page tables and look up the PTE, and the present bit on the PTE is 0, it means that the page is not in physical memory, which is commonly referred to as a page fault. Nowadays not only swapping will trigger page fault but also illegal memory accesses and so on. It becomes a more general term for “page missing”. The Page Fault Upon a page fault, the OS invokes page-fault handler to deal with the issue, no matter for a hardware or software managed TLBs. When a page fault happens, the OS needs to swap the page into memory in order to service the page fault. When the disk I/O completes, the OS will then update the page table to mark the page as present, update the PFN of the PTE, and retry the instruction. Notice that this next attampt still may generate a TLB miss, which would the be serviced and update the TLB with the translation.(The other approach is to update the TLB when handling the page fault.) Finally, a last attampt will get a TLB hit. Note that while the I/O is in flight, the process will be blocked, and other processes will execute. How will the OS know where to find the desired page? The OS could use the bits in the PTE normally used for data such as the PFN of the page for a disk address. When the OS receives a page fault for a page, it looks in the PTE to find the address, and issues the request to disk to fetch the page into memory. Why hardware doesn’t handle page faults? Page fault to disk is slow, even if the OS takes a long time to handle it, there is not to much of a difference. To deal with the page fault, the hardware need to know the swap space, the I/Os to disk, and a lot of other details. What if memory is full? The OS may lie to first page out one or more pages to make room for the new pages. The process of picking a page to kick out, or replace is known as the page-replacement policy. Page Fault Control Flow If the page was both present and valid, the TLB miss handler will just grab the PFN from the PTE into TLB and try again. If the page was not present but valid, then the page fault handler will run. If the page is not valid, in this case, no other bits matter. The hardware traps this invalid access, and the OS trap handler runs, likely terminating the offending process. When Replacement Really occur PLACEHOLDER ","date":"2021-12-25","objectID":"/os_reading_note/:1:5","series":[],"tags":["OS"],"title":"OS","uri":"/os_reading_note/#swapping-mechanisms"},{"categories":["Note"],"content":"Swapping: Mechanisms Swap space Firstly, we need to reserve some space on the disk for moving pages back and forth. Then the OS need to remember the disk address of a given page. The size of the swap space is important since it determines the maximum number of memory pages that can be in use by a system in a ginven time. The Present Bit The hardware first extract the VPN from the VA, the check the TLB for a match. If a miss, the hardware locates the PDT and corresponding page tables and look up the PTE, and the present bit on the PTE is 0, it means that the page is not in physical memory, which is commonly referred to as a page fault. Nowadays not only swapping will trigger page fault but also illegal memory accesses and so on. It becomes a more general term for “page missing”. The Page Fault Upon a page fault, the OS invokes page-fault handler to deal with the issue, no matter for a hardware or software managed TLBs. When a page fault happens, the OS needs to swap the page into memory in order to service the page fault. When the disk I/O completes, the OS will then update the page table to mark the page as present, update the PFN of the PTE, and retry the instruction. Notice that this next attampt still may generate a TLB miss, which would the be serviced and update the TLB with the translation.(The other approach is to update the TLB when handling the page fault.) Finally, a last attampt will get a TLB hit. Note that while the I/O is in flight, the process will be blocked, and other processes will execute. How will the OS know where to find the desired page? The OS could use the bits in the PTE normally used for data such as the PFN of the page for a disk address. When the OS receives a page fault for a page, it looks in the PTE to find the address, and issues the request to disk to fetch the page into memory. Why hardware doesn’t handle page faults? Page fault to disk is slow, even if the OS takes a long time to handle it, there is not to much of a difference. To deal with the page fault, the hardware need to know the swap space, the I/Os to disk, and a lot of other details. What if memory is full? The OS may lie to first page out one or more pages to make room for the new pages. The process of picking a page to kick out, or replace is known as the page-replacement policy. Page Fault Control Flow If the page was both present and valid, the TLB miss handler will just grab the PFN from the PTE into TLB and try again. If the page was not present but valid, then the page fault handler will run. If the page is not valid, in this case, no other bits matter. The hardware traps this invalid access, and the OS trap handler runs, likely terminating the offending process. When Replacement Really occur PLACEHOLDER ","date":"2021-12-25","objectID":"/os_reading_note/:1:5","series":[],"tags":["OS"],"title":"OS","uri":"/os_reading_note/#swap-space"},{"categories":["Note"],"content":"Swapping: Mechanisms Swap space Firstly, we need to reserve some space on the disk for moving pages back and forth. Then the OS need to remember the disk address of a given page. The size of the swap space is important since it determines the maximum number of memory pages that can be in use by a system in a ginven time. The Present Bit The hardware first extract the VPN from the VA, the check the TLB for a match. If a miss, the hardware locates the PDT and corresponding page tables and look up the PTE, and the present bit on the PTE is 0, it means that the page is not in physical memory, which is commonly referred to as a page fault. Nowadays not only swapping will trigger page fault but also illegal memory accesses and so on. It becomes a more general term for “page missing”. The Page Fault Upon a page fault, the OS invokes page-fault handler to deal with the issue, no matter for a hardware or software managed TLBs. When a page fault happens, the OS needs to swap the page into memory in order to service the page fault. When the disk I/O completes, the OS will then update the page table to mark the page as present, update the PFN of the PTE, and retry the instruction. Notice that this next attampt still may generate a TLB miss, which would the be serviced and update the TLB with the translation.(The other approach is to update the TLB when handling the page fault.) Finally, a last attampt will get a TLB hit. Note that while the I/O is in flight, the process will be blocked, and other processes will execute. How will the OS know where to find the desired page? The OS could use the bits in the PTE normally used for data such as the PFN of the page for a disk address. When the OS receives a page fault for a page, it looks in the PTE to find the address, and issues the request to disk to fetch the page into memory. Why hardware doesn’t handle page faults? Page fault to disk is slow, even if the OS takes a long time to handle it, there is not to much of a difference. To deal with the page fault, the hardware need to know the swap space, the I/Os to disk, and a lot of other details. What if memory is full? The OS may lie to first page out one or more pages to make room for the new pages. The process of picking a page to kick out, or replace is known as the page-replacement policy. Page Fault Control Flow If the page was both present and valid, the TLB miss handler will just grab the PFN from the PTE into TLB and try again. If the page was not present but valid, then the page fault handler will run. If the page is not valid, in this case, no other bits matter. The hardware traps this invalid access, and the OS trap handler runs, likely terminating the offending process. When Replacement Really occur PLACEHOLDER ","date":"2021-12-25","objectID":"/os_reading_note/:1:5","series":[],"tags":["OS"],"title":"OS","uri":"/os_reading_note/#the-present-bit"},{"categories":["Note"],"content":"Swapping: Mechanisms Swap space Firstly, we need to reserve some space on the disk for moving pages back and forth. Then the OS need to remember the disk address of a given page. The size of the swap space is important since it determines the maximum number of memory pages that can be in use by a system in a ginven time. The Present Bit The hardware first extract the VPN from the VA, the check the TLB for a match. If a miss, the hardware locates the PDT and corresponding page tables and look up the PTE, and the present bit on the PTE is 0, it means that the page is not in physical memory, which is commonly referred to as a page fault. Nowadays not only swapping will trigger page fault but also illegal memory accesses and so on. It becomes a more general term for “page missing”. The Page Fault Upon a page fault, the OS invokes page-fault handler to deal with the issue, no matter for a hardware or software managed TLBs. When a page fault happens, the OS needs to swap the page into memory in order to service the page fault. When the disk I/O completes, the OS will then update the page table to mark the page as present, update the PFN of the PTE, and retry the instruction. Notice that this next attampt still may generate a TLB miss, which would the be serviced and update the TLB with the translation.(The other approach is to update the TLB when handling the page fault.) Finally, a last attampt will get a TLB hit. Note that while the I/O is in flight, the process will be blocked, and other processes will execute. How will the OS know where to find the desired page? The OS could use the bits in the PTE normally used for data such as the PFN of the page for a disk address. When the OS receives a page fault for a page, it looks in the PTE to find the address, and issues the request to disk to fetch the page into memory. Why hardware doesn’t handle page faults? Page fault to disk is slow, even if the OS takes a long time to handle it, there is not to much of a difference. To deal with the page fault, the hardware need to know the swap space, the I/Os to disk, and a lot of other details. What if memory is full? The OS may lie to first page out one or more pages to make room for the new pages. The process of picking a page to kick out, or replace is known as the page-replacement policy. Page Fault Control Flow If the page was both present and valid, the TLB miss handler will just grab the PFN from the PTE into TLB and try again. If the page was not present but valid, then the page fault handler will run. If the page is not valid, in this case, no other bits matter. The hardware traps this invalid access, and the OS trap handler runs, likely terminating the offending process. When Replacement Really occur PLACEHOLDER ","date":"2021-12-25","objectID":"/os_reading_note/:1:5","series":[],"tags":["OS"],"title":"OS","uri":"/os_reading_note/#the-page-fault"},{"categories":["Note"],"content":"Swapping: Mechanisms Swap space Firstly, we need to reserve some space on the disk for moving pages back and forth. Then the OS need to remember the disk address of a given page. The size of the swap space is important since it determines the maximum number of memory pages that can be in use by a system in a ginven time. The Present Bit The hardware first extract the VPN from the VA, the check the TLB for a match. If a miss, the hardware locates the PDT and corresponding page tables and look up the PTE, and the present bit on the PTE is 0, it means that the page is not in physical memory, which is commonly referred to as a page fault. Nowadays not only swapping will trigger page fault but also illegal memory accesses and so on. It becomes a more general term for “page missing”. The Page Fault Upon a page fault, the OS invokes page-fault handler to deal with the issue, no matter for a hardware or software managed TLBs. When a page fault happens, the OS needs to swap the page into memory in order to service the page fault. When the disk I/O completes, the OS will then update the page table to mark the page as present, update the PFN of the PTE, and retry the instruction. Notice that this next attampt still may generate a TLB miss, which would the be serviced and update the TLB with the translation.(The other approach is to update the TLB when handling the page fault.) Finally, a last attampt will get a TLB hit. Note that while the I/O is in flight, the process will be blocked, and other processes will execute. How will the OS know where to find the desired page? The OS could use the bits in the PTE normally used for data such as the PFN of the page for a disk address. When the OS receives a page fault for a page, it looks in the PTE to find the address, and issues the request to disk to fetch the page into memory. Why hardware doesn’t handle page faults? Page fault to disk is slow, even if the OS takes a long time to handle it, there is not to much of a difference. To deal with the page fault, the hardware need to know the swap space, the I/Os to disk, and a lot of other details. What if memory is full? The OS may lie to first page out one or more pages to make room for the new pages. The process of picking a page to kick out, or replace is known as the page-replacement policy. Page Fault Control Flow If the page was both present and valid, the TLB miss handler will just grab the PFN from the PTE into TLB and try again. If the page was not present but valid, then the page fault handler will run. If the page is not valid, in this case, no other bits matter. The hardware traps this invalid access, and the OS trap handler runs, likely terminating the offending process. When Replacement Really occur PLACEHOLDER ","date":"2021-12-25","objectID":"/os_reading_note/:1:5","series":[],"tags":["OS"],"title":"OS","uri":"/os_reading_note/#how-will-the-os-know-where-to-find-the-desired-page"},{"categories":["Note"],"content":"Swapping: Mechanisms Swap space Firstly, we need to reserve some space on the disk for moving pages back and forth. Then the OS need to remember the disk address of a given page. The size of the swap space is important since it determines the maximum number of memory pages that can be in use by a system in a ginven time. The Present Bit The hardware first extract the VPN from the VA, the check the TLB for a match. If a miss, the hardware locates the PDT and corresponding page tables and look up the PTE, and the present bit on the PTE is 0, it means that the page is not in physical memory, which is commonly referred to as a page fault. Nowadays not only swapping will trigger page fault but also illegal memory accesses and so on. It becomes a more general term for “page missing”. The Page Fault Upon a page fault, the OS invokes page-fault handler to deal with the issue, no matter for a hardware or software managed TLBs. When a page fault happens, the OS needs to swap the page into memory in order to service the page fault. When the disk I/O completes, the OS will then update the page table to mark the page as present, update the PFN of the PTE, and retry the instruction. Notice that this next attampt still may generate a TLB miss, which would the be serviced and update the TLB with the translation.(The other approach is to update the TLB when handling the page fault.) Finally, a last attampt will get a TLB hit. Note that while the I/O is in flight, the process will be blocked, and other processes will execute. How will the OS know where to find the desired page? The OS could use the bits in the PTE normally used for data such as the PFN of the page for a disk address. When the OS receives a page fault for a page, it looks in the PTE to find the address, and issues the request to disk to fetch the page into memory. Why hardware doesn’t handle page faults? Page fault to disk is slow, even if the OS takes a long time to handle it, there is not to much of a difference. To deal with the page fault, the hardware need to know the swap space, the I/Os to disk, and a lot of other details. What if memory is full? The OS may lie to first page out one or more pages to make room for the new pages. The process of picking a page to kick out, or replace is known as the page-replacement policy. Page Fault Control Flow If the page was both present and valid, the TLB miss handler will just grab the PFN from the PTE into TLB and try again. If the page was not present but valid, then the page fault handler will run. If the page is not valid, in this case, no other bits matter. The hardware traps this invalid access, and the OS trap handler runs, likely terminating the offending process. When Replacement Really occur PLACEHOLDER ","date":"2021-12-25","objectID":"/os_reading_note/:1:5","series":[],"tags":["OS"],"title":"OS","uri":"/os_reading_note/#why-hardware-doesnt-handle-page-faults"},{"categories":["Note"],"content":"Swapping: Mechanisms Swap space Firstly, we need to reserve some space on the disk for moving pages back and forth. Then the OS need to remember the disk address of a given page. The size of the swap space is important since it determines the maximum number of memory pages that can be in use by a system in a ginven time. The Present Bit The hardware first extract the VPN from the VA, the check the TLB for a match. If a miss, the hardware locates the PDT and corresponding page tables and look up the PTE, and the present bit on the PTE is 0, it means that the page is not in physical memory, which is commonly referred to as a page fault. Nowadays not only swapping will trigger page fault but also illegal memory accesses and so on. It becomes a more general term for “page missing”. The Page Fault Upon a page fault, the OS invokes page-fault handler to deal with the issue, no matter for a hardware or software managed TLBs. When a page fault happens, the OS needs to swap the page into memory in order to service the page fault. When the disk I/O completes, the OS will then update the page table to mark the page as present, update the PFN of the PTE, and retry the instruction. Notice that this next attampt still may generate a TLB miss, which would the be serviced and update the TLB with the translation.(The other approach is to update the TLB when handling the page fault.) Finally, a last attampt will get a TLB hit. Note that while the I/O is in flight, the process will be blocked, and other processes will execute. How will the OS know where to find the desired page? The OS could use the bits in the PTE normally used for data such as the PFN of the page for a disk address. When the OS receives a page fault for a page, it looks in the PTE to find the address, and issues the request to disk to fetch the page into memory. Why hardware doesn’t handle page faults? Page fault to disk is slow, even if the OS takes a long time to handle it, there is not to much of a difference. To deal with the page fault, the hardware need to know the swap space, the I/Os to disk, and a lot of other details. What if memory is full? The OS may lie to first page out one or more pages to make room for the new pages. The process of picking a page to kick out, or replace is known as the page-replacement policy. Page Fault Control Flow If the page was both present and valid, the TLB miss handler will just grab the PFN from the PTE into TLB and try again. If the page was not present but valid, then the page fault handler will run. If the page is not valid, in this case, no other bits matter. The hardware traps this invalid access, and the OS trap handler runs, likely terminating the offending process. When Replacement Really occur PLACEHOLDER ","date":"2021-12-25","objectID":"/os_reading_note/:1:5","series":[],"tags":["OS"],"title":"OS","uri":"/os_reading_note/#what-if-memory-is-full"},{"categories":["Note"],"content":"Swapping: Mechanisms Swap space Firstly, we need to reserve some space on the disk for moving pages back and forth. Then the OS need to remember the disk address of a given page. The size of the swap space is important since it determines the maximum number of memory pages that can be in use by a system in a ginven time. The Present Bit The hardware first extract the VPN from the VA, the check the TLB for a match. If a miss, the hardware locates the PDT and corresponding page tables and look up the PTE, and the present bit on the PTE is 0, it means that the page is not in physical memory, which is commonly referred to as a page fault. Nowadays not only swapping will trigger page fault but also illegal memory accesses and so on. It becomes a more general term for “page missing”. The Page Fault Upon a page fault, the OS invokes page-fault handler to deal with the issue, no matter for a hardware or software managed TLBs. When a page fault happens, the OS needs to swap the page into memory in order to service the page fault. When the disk I/O completes, the OS will then update the page table to mark the page as present, update the PFN of the PTE, and retry the instruction. Notice that this next attampt still may generate a TLB miss, which would the be serviced and update the TLB with the translation.(The other approach is to update the TLB when handling the page fault.) Finally, a last attampt will get a TLB hit. Note that while the I/O is in flight, the process will be blocked, and other processes will execute. How will the OS know where to find the desired page? The OS could use the bits in the PTE normally used for data such as the PFN of the page for a disk address. When the OS receives a page fault for a page, it looks in the PTE to find the address, and issues the request to disk to fetch the page into memory. Why hardware doesn’t handle page faults? Page fault to disk is slow, even if the OS takes a long time to handle it, there is not to much of a difference. To deal with the page fault, the hardware need to know the swap space, the I/Os to disk, and a lot of other details. What if memory is full? The OS may lie to first page out one or more pages to make room for the new pages. The process of picking a page to kick out, or replace is known as the page-replacement policy. Page Fault Control Flow If the page was both present and valid, the TLB miss handler will just grab the PFN from the PTE into TLB and try again. If the page was not present but valid, then the page fault handler will run. If the page is not valid, in this case, no other bits matter. The hardware traps this invalid access, and the OS trap handler runs, likely terminating the offending process. When Replacement Really occur PLACEHOLDER ","date":"2021-12-25","objectID":"/os_reading_note/:1:5","series":[],"tags":["OS"],"title":"OS","uri":"/os_reading_note/#page-fault-control-flow"},{"categories":["Note"],"content":"Swapping: Mechanisms Swap space Firstly, we need to reserve some space on the disk for moving pages back and forth. Then the OS need to remember the disk address of a given page. The size of the swap space is important since it determines the maximum number of memory pages that can be in use by a system in a ginven time. The Present Bit The hardware first extract the VPN from the VA, the check the TLB for a match. If a miss, the hardware locates the PDT and corresponding page tables and look up the PTE, and the present bit on the PTE is 0, it means that the page is not in physical memory, which is commonly referred to as a page fault. Nowadays not only swapping will trigger page fault but also illegal memory accesses and so on. It becomes a more general term for “page missing”. The Page Fault Upon a page fault, the OS invokes page-fault handler to deal with the issue, no matter for a hardware or software managed TLBs. When a page fault happens, the OS needs to swap the page into memory in order to service the page fault. When the disk I/O completes, the OS will then update the page table to mark the page as present, update the PFN of the PTE, and retry the instruction. Notice that this next attampt still may generate a TLB miss, which would the be serviced and update the TLB with the translation.(The other approach is to update the TLB when handling the page fault.) Finally, a last attampt will get a TLB hit. Note that while the I/O is in flight, the process will be blocked, and other processes will execute. How will the OS know where to find the desired page? The OS could use the bits in the PTE normally used for data such as the PFN of the page for a disk address. When the OS receives a page fault for a page, it looks in the PTE to find the address, and issues the request to disk to fetch the page into memory. Why hardware doesn’t handle page faults? Page fault to disk is slow, even if the OS takes a long time to handle it, there is not to much of a difference. To deal with the page fault, the hardware need to know the swap space, the I/Os to disk, and a lot of other details. What if memory is full? The OS may lie to first page out one or more pages to make room for the new pages. The process of picking a page to kick out, or replace is known as the page-replacement policy. Page Fault Control Flow If the page was both present and valid, the TLB miss handler will just grab the PFN from the PTE into TLB and try again. If the page was not present but valid, then the page fault handler will run. If the page is not valid, in this case, no other bits matter. The hardware traps this invalid access, and the OS trap handler runs, likely terminating the offending process. When Replacement Really occur PLACEHOLDER ","date":"2021-12-25","objectID":"/os_reading_note/:1:5","series":[],"tags":["OS"],"title":"OS","uri":"/os_reading_note/#when-replacement-really-occur"},{"categories":["Note"],"content":"Swapping Policies Cache management The Optimal Replacement Policy FIFO Random LRU Approximating LRU The key is the use bit and clock algorithm. Thrashing ","date":"2021-12-25","objectID":"/os_reading_note/:1:6","series":[],"tags":["OS"],"title":"OS","uri":"/os_reading_note/#swapping-policies"},{"categories":["Note"],"content":"Swapping Policies Cache management The Optimal Replacement Policy FIFO Random LRU Approximating LRU The key is the use bit and clock algorithm. Thrashing ","date":"2021-12-25","objectID":"/os_reading_note/:1:6","series":[],"tags":["OS"],"title":"OS","uri":"/os_reading_note/#cache-management"},{"categories":["Note"],"content":"Swapping Policies Cache management The Optimal Replacement Policy FIFO Random LRU Approximating LRU The key is the use bit and clock algorithm. Thrashing ","date":"2021-12-25","objectID":"/os_reading_note/:1:6","series":[],"tags":["OS"],"title":"OS","uri":"/os_reading_note/#the-optimal-replacement-policy"},{"categories":["Note"],"content":"Swapping Policies Cache management The Optimal Replacement Policy FIFO Random LRU Approximating LRU The key is the use bit and clock algorithm. Thrashing ","date":"2021-12-25","objectID":"/os_reading_note/:1:6","series":[],"tags":["OS"],"title":"OS","uri":"/os_reading_note/#fifo"},{"categories":["Note"],"content":"Swapping Policies Cache management The Optimal Replacement Policy FIFO Random LRU Approximating LRU The key is the use bit and clock algorithm. Thrashing ","date":"2021-12-25","objectID":"/os_reading_note/:1:6","series":[],"tags":["OS"],"title":"OS","uri":"/os_reading_note/#random"},{"categories":["Note"],"content":"Swapping Policies Cache management The Optimal Replacement Policy FIFO Random LRU Approximating LRU The key is the use bit and clock algorithm. Thrashing ","date":"2021-12-25","objectID":"/os_reading_note/:1:6","series":[],"tags":["OS"],"title":"OS","uri":"/os_reading_note/#lru"},{"categories":["Note"],"content":"Swapping Policies Cache management The Optimal Replacement Policy FIFO Random LRU Approximating LRU The key is the use bit and clock algorithm. Thrashing ","date":"2021-12-25","objectID":"/os_reading_note/:1:6","series":[],"tags":["OS"],"title":"OS","uri":"/os_reading_note/#approximating-lru"},{"categories":["Note"],"content":"Swapping Policies Cache management The Optimal Replacement Policy FIFO Random LRU Approximating LRU The key is the use bit and clock algorithm. Thrashing ","date":"2021-12-25","objectID":"/os_reading_note/:1:6","series":[],"tags":["OS"],"title":"OS","uri":"/os_reading_note/#thrashing"},{"categories":["Note"],"content":"Concurrency ","date":"2021-12-25","objectID":"/os_reading_note/:2:0","series":[],"tags":["OS"],"title":"OS","uri":"/os_reading_note/#concurrency"},{"categories":["Note"],"content":"Intro Each thread is very much like a separate process, except for one difference: they share the same address space and thus can access the same data. Context switch between threads are similar to that between processes. We save the PC, registers, state and so on in TCB. The difference is that the address space remains the same. why thread? Parallelism To avoid blocking program progress due to slow I/O Thread Creation After the threads are created, the OS scheduler decides who runs the next. Why It Gets Worse: Shared Data [recall the concept if the Hazard] Data Hazards RAW i1. R2 \u003c- R5 + R3 i2. R4 \u003c- R2 + R3 WAR i1. R4 \u003c- R1 + R5 i2. R5 \u003c- R1 + R2 WAW i1. R2 \u003c- R4 + R7 i2. R2 \u003c- R1 + R3 Structural Hazards Control Hazards // compile with -g will include symbol info in the program. Then `prompt \u003e objdump -d main will give you the assembly code neatly labeled. // You may want to master debugger gdb, memory profilers valgrind or purify, and the compiler itself. Core Problem: Uncontrolled Scheduling We may have a race condition, or so to speak, a data race. Anindeterminateprogramconsistsofoneormoreraceconditions; the output of the program varies from run to run, depending on which threads ran when. The outcome is thus not deterministic, something we usually expect from computer systems. A critical section is a piece of code that accesses a shared variable (or more generally, a shared resource) and must not be concurrently executed by more than one thread. What we really want for this code is what we call mutual exclusion. This property guarantees that if one thread is executing within the critical section, the others will be prevented from doing so. One More Problem: Waiting For Another ","date":"2021-12-25","objectID":"/os_reading_note/:2:1","series":[],"tags":["OS"],"title":"OS","uri":"/os_reading_note/#intro"},{"categories":["Note"],"content":"Intro Each thread is very much like a separate process, except for one difference: they share the same address space and thus can access the same data. Context switch between threads are similar to that between processes. We save the PC, registers, state and so on in TCB. The difference is that the address space remains the same. why thread? Parallelism To avoid blocking program progress due to slow I/O Thread Creation After the threads are created, the OS scheduler decides who runs the next. Why It Gets Worse: Shared Data [recall the concept if the Hazard] Data Hazards RAW i1. R2 objdump -d main will give you the assembly code neatly labeled. // You may want to master debugger gdb, memory profilers valgrind or purify, and the compiler itself. Core Problem: Uncontrolled Scheduling We may have a race condition, or so to speak, a data race. Anindeterminateprogramconsistsofoneormoreraceconditions; the output of the program varies from run to run, depending on which threads ran when. The outcome is thus not deterministic, something we usually expect from computer systems. A critical section is a piece of code that accesses a shared variable (or more generally, a shared resource) and must not be concurrently executed by more than one thread. What we really want for this code is what we call mutual exclusion. This property guarantees that if one thread is executing within the critical section, the others will be prevented from doing so. One More Problem: Waiting For Another ","date":"2021-12-25","objectID":"/os_reading_note/:2:1","series":[],"tags":["OS"],"title":"OS","uri":"/os_reading_note/#why-thread"},{"categories":["Note"],"content":"Intro Each thread is very much like a separate process, except for one difference: they share the same address space and thus can access the same data. Context switch between threads are similar to that between processes. We save the PC, registers, state and so on in TCB. The difference is that the address space remains the same. why thread? Parallelism To avoid blocking program progress due to slow I/O Thread Creation After the threads are created, the OS scheduler decides who runs the next. Why It Gets Worse: Shared Data [recall the concept if the Hazard] Data Hazards RAW i1. R2 objdump -d main will give you the assembly code neatly labeled. // You may want to master debugger gdb, memory profilers valgrind or purify, and the compiler itself. Core Problem: Uncontrolled Scheduling We may have a race condition, or so to speak, a data race. Anindeterminateprogramconsistsofoneormoreraceconditions; the output of the program varies from run to run, depending on which threads ran when. The outcome is thus not deterministic, something we usually expect from computer systems. A critical section is a piece of code that accesses a shared variable (or more generally, a shared resource) and must not be concurrently executed by more than one thread. What we really want for this code is what we call mutual exclusion. This property guarantees that if one thread is executing within the critical section, the others will be prevented from doing so. One More Problem: Waiting For Another ","date":"2021-12-25","objectID":"/os_reading_note/:2:1","series":[],"tags":["OS"],"title":"OS","uri":"/os_reading_note/#thread-creation"},{"categories":["Note"],"content":"Intro Each thread is very much like a separate process, except for one difference: they share the same address space and thus can access the same data. Context switch between threads are similar to that between processes. We save the PC, registers, state and so on in TCB. The difference is that the address space remains the same. why thread? Parallelism To avoid blocking program progress due to slow I/O Thread Creation After the threads are created, the OS scheduler decides who runs the next. Why It Gets Worse: Shared Data [recall the concept if the Hazard] Data Hazards RAW i1. R2 objdump -d main will give you the assembly code neatly labeled. // You may want to master debugger gdb, memory profilers valgrind or purify, and the compiler itself. Core Problem: Uncontrolled Scheduling We may have a race condition, or so to speak, a data race. Anindeterminateprogramconsistsofoneormoreraceconditions; the output of the program varies from run to run, depending on which threads ran when. The outcome is thus not deterministic, something we usually expect from computer systems. A critical section is a piece of code that accesses a shared variable (or more generally, a shared resource) and must not be concurrently executed by more than one thread. What we really want for this code is what we call mutual exclusion. This property guarantees that if one thread is executing within the critical section, the others will be prevented from doing so. One More Problem: Waiting For Another ","date":"2021-12-25","objectID":"/os_reading_note/:2:1","series":[],"tags":["OS"],"title":"OS","uri":"/os_reading_note/#why-it-gets-worse-shared-data"},{"categories":["Note"],"content":"Intro Each thread is very much like a separate process, except for one difference: they share the same address space and thus can access the same data. Context switch between threads are similar to that between processes. We save the PC, registers, state and so on in TCB. The difference is that the address space remains the same. why thread? Parallelism To avoid blocking program progress due to slow I/O Thread Creation After the threads are created, the OS scheduler decides who runs the next. Why It Gets Worse: Shared Data [recall the concept if the Hazard] Data Hazards RAW i1. R2 objdump -d main will give you the assembly code neatly labeled. // You may want to master debugger gdb, memory profilers valgrind or purify, and the compiler itself. Core Problem: Uncontrolled Scheduling We may have a race condition, or so to speak, a data race. Anindeterminateprogramconsistsofoneormoreraceconditions; the output of the program varies from run to run, depending on which threads ran when. The outcome is thus not deterministic, something we usually expect from computer systems. A critical section is a piece of code that accesses a shared variable (or more generally, a shared resource) and must not be concurrently executed by more than one thread. What we really want for this code is what we call mutual exclusion. This property guarantees that if one thread is executing within the critical section, the others will be prevented from doing so. One More Problem: Waiting For Another ","date":"2021-12-25","objectID":"/os_reading_note/:2:1","series":[],"tags":["OS"],"title":"OS","uri":"/os_reading_note/#recall-the-concept-if-the-hazard"},{"categories":["Note"],"content":"Intro Each thread is very much like a separate process, except for one difference: they share the same address space and thus can access the same data. Context switch between threads are similar to that between processes. We save the PC, registers, state and so on in TCB. The difference is that the address space remains the same. why thread? Parallelism To avoid blocking program progress due to slow I/O Thread Creation After the threads are created, the OS scheduler decides who runs the next. Why It Gets Worse: Shared Data [recall the concept if the Hazard] Data Hazards RAW i1. R2 objdump -d main will give you the assembly code neatly labeled. // You may want to master debugger gdb, memory profilers valgrind or purify, and the compiler itself. Core Problem: Uncontrolled Scheduling We may have a race condition, or so to speak, a data race. Anindeterminateprogramconsistsofoneormoreraceconditions; the output of the program varies from run to run, depending on which threads ran when. The outcome is thus not deterministic, something we usually expect from computer systems. A critical section is a piece of code that accesses a shared variable (or more generally, a shared resource) and must not be concurrently executed by more than one thread. What we really want for this code is what we call mutual exclusion. This property guarantees that if one thread is executing within the critical section, the others will be prevented from doing so. One More Problem: Waiting For Another ","date":"2021-12-25","objectID":"/os_reading_note/:2:1","series":[],"tags":["OS"],"title":"OS","uri":"/os_reading_note/#core-problem-uncontrolled-scheduling"},{"categories":["Note"],"content":"Intro Each thread is very much like a separate process, except for one difference: they share the same address space and thus can access the same data. Context switch between threads are similar to that between processes. We save the PC, registers, state and so on in TCB. The difference is that the address space remains the same. why thread? Parallelism To avoid blocking program progress due to slow I/O Thread Creation After the threads are created, the OS scheduler decides who runs the next. Why It Gets Worse: Shared Data [recall the concept if the Hazard] Data Hazards RAW i1. R2 objdump -d main will give you the assembly code neatly labeled. // You may want to master debugger gdb, memory profilers valgrind or purify, and the compiler itself. Core Problem: Uncontrolled Scheduling We may have a race condition, or so to speak, a data race. Anindeterminateprogramconsistsofoneormoreraceconditions; the output of the program varies from run to run, depending on which threads ran when. The outcome is thus not deterministic, something we usually expect from computer systems. A critical section is a piece of code that accesses a shared variable (or more generally, a shared resource) and must not be concurrently executed by more than one thread. What we really want for this code is what we call mutual exclusion. This property guarantees that if one thread is executing within the critical section, the others will be prevented from doing so. One More Problem: Waiting For Another ","date":"2021-12-25","objectID":"/os_reading_note/:2:1","series":[],"tags":["OS"],"title":"OS","uri":"/os_reading_note/#one-more-problem-waiting-for-another"},{"categories":["Note"],"content":"Interlude: Thread API Thread Creation #include \u003cpthread.h\u003eint pthread_create(pthread_t* thread, const pthread_attr_t * attr, void* (*start_routine) (void*), void *arg); /* The second argument, attr, is used to specify any attributes this thread might have. Some examples include setting the stack size or perhaps in- formation about the scheduling priority of the thread. An attribute is initialized with a separate call to pthread attr init(); see the man- ual page for details. However, in most cases, the defaults will be fine; in this case, we will simply pass the value NULL in. The third argument is the most complex, but is really just asking: which function should this thread start running in? In C, we call this a function pointer, and this one tells us the following is expected: a function name (start routine), which is passed a single argument of type void * (as indicated in the parentheses after start routine), and which returns a value of type void * (i.e., a void pointer). Finally, the fourth argument, arg, is exactly the argument to be passed to the function where the thread begins execution. */ /* having a void pointer as an argument to the function start routine allows us to pass in any type of argument; having it as a return value allows the thread to return any type of result. */ #include \u003cstdio.h\u003e#include \u003cpthread.h\u003e typedef struct { int a; int b; } myarg_t; void *mythread(void *arg) { myarg_t *args = (myarg_t*) arg; printf(\"%d %d\\n\", args-\u003ea, args-\u003eb); return NULL; } int main(int argc, char* argv[]){ pthread_t p; myarg_t args = { 10, 20 }; int rc = pthread_create(\u0026p, NULL, mythread, \u0026args); } Thread Completion // What if you want to wait for a thread to complete? int pthread_join(pthread_t thread, void **value_ptr); /* This routine takes two arguments. The first is of type pthread t, and is used to specify which thread to wait for. This variable is initialized by the thread creation routine (when you pass a pointer to it as an argument to pthread create()); if you keep it around, you can use it to wait for that thread to terminate. The second argument is a pointer to the return value you expect to get back. Because the routine can return anything, it is defined to return a pointer to void; because the pthread join() routine changes the value of the passed in argument, you need to pass in a pointer to that value, not just the value itself. */ typedef struct { int a; int b; } myarg_t; typedef struct { int x; int y; } myret_t; void *mythread(void *arg) { myret_t *rvals = Malloc(sizeof(myret_t)); rvals-\u003ex = 1; rvals-\u003ey = 2; return (void *) rvals; } int main(int argc, char *argv[]) { pthread_t p; myret_t *rvals; myarg_t args = { 10, 20 }; Pthread_create(\u0026p, NULL, mythread, \u0026args); Pthread_join(p, (void **) \u0026rvals); printf(\"returned %d %d\\n\", rvals-\u003ex, rvals-\u003ey); free(rvals); return 0; } If we just create a thread with no args, we can pass NULL in as an arg. Similarly, we can pass NULL into pthread_join() if we care nothing about the return value. If we are just passing in a single value, then we don’t need to package it up as a arg. We should be extremely careful with how values are returned from a thread. Never return a pointer which refers to something allocated on the thread’s call stack. We have a pthread_create() followed bypthread_join(). We can use procedure call instead. Locks The routines should be easy to understand and use. When you have a region of code that is a critical section, and thus needs to be protected to ensure correct operation, locks are quite useful. int pthread_mutex_lock(pthread_mutex_t *mutex) int pthread_mutex_unlock(pthread_mutex_t *mutex) pthread_mutex_t lock = PTHREAD_MUTEX_INITIALIZER; // we must do the init for locks // or we can do as int rc = pthread_mutex_init(\u0026lock, NULL); assert(rc == 0); // always check success! pthread_mutex_lock(\u0026lock); x = x + 1; // or whatever your critical section is pthread_mutex_unlock(\u0026lock); Also, pthread mutex destroy() should be called afterwards. There","date":"2021-12-25","objectID":"/os_reading_note/:2:2","series":[],"tags":["OS"],"title":"OS","uri":"/os_reading_note/#interlude-thread-api"},{"categories":["Note"],"content":"Interlude: Thread API Thread Creation #include int pthread_create(pthread_t* thread, const pthread_attr_t * attr, void* (*start_routine) (void*), void *arg); /* The second argument, attr, is used to specify any attributes this thread might have. Some examples include setting the stack size or perhaps in- formation about the scheduling priority of the thread. An attribute is initialized with a separate call to pthread attr init(); see the man- ual page for details. However, in most cases, the defaults will be fine; in this case, we will simply pass the value NULL in. The third argument is the most complex, but is really just asking: which function should this thread start running in? In C, we call this a function pointer, and this one tells us the following is expected: a function name (start routine), which is passed a single argument of type void * (as indicated in the parentheses after start routine), and which returns a value of type void * (i.e., a void pointer). Finally, the fourth argument, arg, is exactly the argument to be passed to the function where the thread begins execution. */ /* having a void pointer as an argument to the function start routine allows us to pass in any type of argument; having it as a return value allows the thread to return any type of result. */ #include #include typedef struct { int a; int b; } myarg_t; void *mythread(void *arg) { myarg_t *args = (myarg_t*) arg; printf(\"%d %d\\n\", args-a, args-b); return NULL; } int main(int argc, char* argv[]){ pthread_t p; myarg_t args = { 10, 20 }; int rc = pthread_create(\u0026p, NULL, mythread, \u0026args); } Thread Completion // What if you want to wait for a thread to complete? int pthread_join(pthread_t thread, void **value_ptr); /* This routine takes two arguments. The first is of type pthread t, and is used to specify which thread to wait for. This variable is initialized by the thread creation routine (when you pass a pointer to it as an argument to pthread create()); if you keep it around, you can use it to wait for that thread to terminate. The second argument is a pointer to the return value you expect to get back. Because the routine can return anything, it is defined to return a pointer to void; because the pthread join() routine changes the value of the passed in argument, you need to pass in a pointer to that value, not just the value itself. */ typedef struct { int a; int b; } myarg_t; typedef struct { int x; int y; } myret_t; void *mythread(void *arg) { myret_t *rvals = Malloc(sizeof(myret_t)); rvals-x = 1; rvals-y = 2; return (void *) rvals; } int main(int argc, char *argv[]) { pthread_t p; myret_t *rvals; myarg_t args = { 10, 20 }; Pthread_create(\u0026p, NULL, mythread, \u0026args); Pthread_join(p, (void **) \u0026rvals); printf(\"returned %d %d\\n\", rvals-x, rvals-y); free(rvals); return 0; } If we just create a thread with no args, we can pass NULL in as an arg. Similarly, we can pass NULL into pthread_join() if we care nothing about the return value. If we are just passing in a single value, then we don’t need to package it up as a arg. We should be extremely careful with how values are returned from a thread. Never return a pointer which refers to something allocated on the thread’s call stack. We have a pthread_create() followed bypthread_join(). We can use procedure call instead. Locks The routines should be easy to understand and use. When you have a region of code that is a critical section, and thus needs to be protected to ensure correct operation, locks are quite useful. int pthread_mutex_lock(pthread_mutex_t *mutex) int pthread_mutex_unlock(pthread_mutex_t *mutex) pthread_mutex_t lock = PTHREAD_MUTEX_INITIALIZER; // we must do the init for locks // or we can do as int rc = pthread_mutex_init(\u0026lock, NULL); assert(rc == 0); // always check success! pthread_mutex_lock(\u0026lock); x = x + 1; // or whatever your critical section is pthread_mutex_unlock(\u0026lock); Also, pthread mutex destroy() should be called afterwards. There","date":"2021-12-25","objectID":"/os_reading_note/:2:2","series":[],"tags":["OS"],"title":"OS","uri":"/os_reading_note/#thread-creation-1"},{"categories":["Note"],"content":"Interlude: Thread API Thread Creation #include int pthread_create(pthread_t* thread, const pthread_attr_t * attr, void* (*start_routine) (void*), void *arg); /* The second argument, attr, is used to specify any attributes this thread might have. Some examples include setting the stack size or perhaps in- formation about the scheduling priority of the thread. An attribute is initialized with a separate call to pthread attr init(); see the man- ual page for details. However, in most cases, the defaults will be fine; in this case, we will simply pass the value NULL in. The third argument is the most complex, but is really just asking: which function should this thread start running in? In C, we call this a function pointer, and this one tells us the following is expected: a function name (start routine), which is passed a single argument of type void * (as indicated in the parentheses after start routine), and which returns a value of type void * (i.e., a void pointer). Finally, the fourth argument, arg, is exactly the argument to be passed to the function where the thread begins execution. */ /* having a void pointer as an argument to the function start routine allows us to pass in any type of argument; having it as a return value allows the thread to return any type of result. */ #include #include typedef struct { int a; int b; } myarg_t; void *mythread(void *arg) { myarg_t *args = (myarg_t*) arg; printf(\"%d %d\\n\", args-a, args-b); return NULL; } int main(int argc, char* argv[]){ pthread_t p; myarg_t args = { 10, 20 }; int rc = pthread_create(\u0026p, NULL, mythread, \u0026args); } Thread Completion // What if you want to wait for a thread to complete? int pthread_join(pthread_t thread, void **value_ptr); /* This routine takes two arguments. The first is of type pthread t, and is used to specify which thread to wait for. This variable is initialized by the thread creation routine (when you pass a pointer to it as an argument to pthread create()); if you keep it around, you can use it to wait for that thread to terminate. The second argument is a pointer to the return value you expect to get back. Because the routine can return anything, it is defined to return a pointer to void; because the pthread join() routine changes the value of the passed in argument, you need to pass in a pointer to that value, not just the value itself. */ typedef struct { int a; int b; } myarg_t; typedef struct { int x; int y; } myret_t; void *mythread(void *arg) { myret_t *rvals = Malloc(sizeof(myret_t)); rvals-x = 1; rvals-y = 2; return (void *) rvals; } int main(int argc, char *argv[]) { pthread_t p; myret_t *rvals; myarg_t args = { 10, 20 }; Pthread_create(\u0026p, NULL, mythread, \u0026args); Pthread_join(p, (void **) \u0026rvals); printf(\"returned %d %d\\n\", rvals-x, rvals-y); free(rvals); return 0; } If we just create a thread with no args, we can pass NULL in as an arg. Similarly, we can pass NULL into pthread_join() if we care nothing about the return value. If we are just passing in a single value, then we don’t need to package it up as a arg. We should be extremely careful with how values are returned from a thread. Never return a pointer which refers to something allocated on the thread’s call stack. We have a pthread_create() followed bypthread_join(). We can use procedure call instead. Locks The routines should be easy to understand and use. When you have a region of code that is a critical section, and thus needs to be protected to ensure correct operation, locks are quite useful. int pthread_mutex_lock(pthread_mutex_t *mutex) int pthread_mutex_unlock(pthread_mutex_t *mutex) pthread_mutex_t lock = PTHREAD_MUTEX_INITIALIZER; // we must do the init for locks // or we can do as int rc = pthread_mutex_init(\u0026lock, NULL); assert(rc == 0); // always check success! pthread_mutex_lock(\u0026lock); x = x + 1; // or whatever your critical section is pthread_mutex_unlock(\u0026lock); Also, pthread mutex destroy() should be called afterwards. There","date":"2021-12-25","objectID":"/os_reading_note/:2:2","series":[],"tags":["OS"],"title":"OS","uri":"/os_reading_note/#thread-completion"},{"categories":["Note"],"content":"Interlude: Thread API Thread Creation #include int pthread_create(pthread_t* thread, const pthread_attr_t * attr, void* (*start_routine) (void*), void *arg); /* The second argument, attr, is used to specify any attributes this thread might have. Some examples include setting the stack size or perhaps in- formation about the scheduling priority of the thread. An attribute is initialized with a separate call to pthread attr init(); see the man- ual page for details. However, in most cases, the defaults will be fine; in this case, we will simply pass the value NULL in. The third argument is the most complex, but is really just asking: which function should this thread start running in? In C, we call this a function pointer, and this one tells us the following is expected: a function name (start routine), which is passed a single argument of type void * (as indicated in the parentheses after start routine), and which returns a value of type void * (i.e., a void pointer). Finally, the fourth argument, arg, is exactly the argument to be passed to the function where the thread begins execution. */ /* having a void pointer as an argument to the function start routine allows us to pass in any type of argument; having it as a return value allows the thread to return any type of result. */ #include #include typedef struct { int a; int b; } myarg_t; void *mythread(void *arg) { myarg_t *args = (myarg_t*) arg; printf(\"%d %d\\n\", args-a, args-b); return NULL; } int main(int argc, char* argv[]){ pthread_t p; myarg_t args = { 10, 20 }; int rc = pthread_create(\u0026p, NULL, mythread, \u0026args); } Thread Completion // What if you want to wait for a thread to complete? int pthread_join(pthread_t thread, void **value_ptr); /* This routine takes two arguments. The first is of type pthread t, and is used to specify which thread to wait for. This variable is initialized by the thread creation routine (when you pass a pointer to it as an argument to pthread create()); if you keep it around, you can use it to wait for that thread to terminate. The second argument is a pointer to the return value you expect to get back. Because the routine can return anything, it is defined to return a pointer to void; because the pthread join() routine changes the value of the passed in argument, you need to pass in a pointer to that value, not just the value itself. */ typedef struct { int a; int b; } myarg_t; typedef struct { int x; int y; } myret_t; void *mythread(void *arg) { myret_t *rvals = Malloc(sizeof(myret_t)); rvals-x = 1; rvals-y = 2; return (void *) rvals; } int main(int argc, char *argv[]) { pthread_t p; myret_t *rvals; myarg_t args = { 10, 20 }; Pthread_create(\u0026p, NULL, mythread, \u0026args); Pthread_join(p, (void **) \u0026rvals); printf(\"returned %d %d\\n\", rvals-x, rvals-y); free(rvals); return 0; } If we just create a thread with no args, we can pass NULL in as an arg. Similarly, we can pass NULL into pthread_join() if we care nothing about the return value. If we are just passing in a single value, then we don’t need to package it up as a arg. We should be extremely careful with how values are returned from a thread. Never return a pointer which refers to something allocated on the thread’s call stack. We have a pthread_create() followed bypthread_join(). We can use procedure call instead. Locks The routines should be easy to understand and use. When you have a region of code that is a critical section, and thus needs to be protected to ensure correct operation, locks are quite useful. int pthread_mutex_lock(pthread_mutex_t *mutex) int pthread_mutex_unlock(pthread_mutex_t *mutex) pthread_mutex_t lock = PTHREAD_MUTEX_INITIALIZER; // we must do the init for locks // or we can do as int rc = pthread_mutex_init(\u0026lock, NULL); assert(rc == 0); // always check success! pthread_mutex_lock(\u0026lock); x = x + 1; // or whatever your critical section is pthread_mutex_unlock(\u0026lock); Also, pthread mutex destroy() should be called afterwards. There","date":"2021-12-25","objectID":"/os_reading_note/:2:2","series":[],"tags":["OS"],"title":"OS","uri":"/os_reading_note/#locks"},{"categories":["Note"],"content":"Interlude: Thread API Thread Creation #include int pthread_create(pthread_t* thread, const pthread_attr_t * attr, void* (*start_routine) (void*), void *arg); /* The second argument, attr, is used to specify any attributes this thread might have. Some examples include setting the stack size or perhaps in- formation about the scheduling priority of the thread. An attribute is initialized with a separate call to pthread attr init(); see the man- ual page for details. However, in most cases, the defaults will be fine; in this case, we will simply pass the value NULL in. The third argument is the most complex, but is really just asking: which function should this thread start running in? In C, we call this a function pointer, and this one tells us the following is expected: a function name (start routine), which is passed a single argument of type void * (as indicated in the parentheses after start routine), and which returns a value of type void * (i.e., a void pointer). Finally, the fourth argument, arg, is exactly the argument to be passed to the function where the thread begins execution. */ /* having a void pointer as an argument to the function start routine allows us to pass in any type of argument; having it as a return value allows the thread to return any type of result. */ #include #include typedef struct { int a; int b; } myarg_t; void *mythread(void *arg) { myarg_t *args = (myarg_t*) arg; printf(\"%d %d\\n\", args-a, args-b); return NULL; } int main(int argc, char* argv[]){ pthread_t p; myarg_t args = { 10, 20 }; int rc = pthread_create(\u0026p, NULL, mythread, \u0026args); } Thread Completion // What if you want to wait for a thread to complete? int pthread_join(pthread_t thread, void **value_ptr); /* This routine takes two arguments. The first is of type pthread t, and is used to specify which thread to wait for. This variable is initialized by the thread creation routine (when you pass a pointer to it as an argument to pthread create()); if you keep it around, you can use it to wait for that thread to terminate. The second argument is a pointer to the return value you expect to get back. Because the routine can return anything, it is defined to return a pointer to void; because the pthread join() routine changes the value of the passed in argument, you need to pass in a pointer to that value, not just the value itself. */ typedef struct { int a; int b; } myarg_t; typedef struct { int x; int y; } myret_t; void *mythread(void *arg) { myret_t *rvals = Malloc(sizeof(myret_t)); rvals-x = 1; rvals-y = 2; return (void *) rvals; } int main(int argc, char *argv[]) { pthread_t p; myret_t *rvals; myarg_t args = { 10, 20 }; Pthread_create(\u0026p, NULL, mythread, \u0026args); Pthread_join(p, (void **) \u0026rvals); printf(\"returned %d %d\\n\", rvals-x, rvals-y); free(rvals); return 0; } If we just create a thread with no args, we can pass NULL in as an arg. Similarly, we can pass NULL into pthread_join() if we care nothing about the return value. If we are just passing in a single value, then we don’t need to package it up as a arg. We should be extremely careful with how values are returned from a thread. Never return a pointer which refers to something allocated on the thread’s call stack. We have a pthread_create() followed bypthread_join(). We can use procedure call instead. Locks The routines should be easy to understand and use. When you have a region of code that is a critical section, and thus needs to be protected to ensure correct operation, locks are quite useful. int pthread_mutex_lock(pthread_mutex_t *mutex) int pthread_mutex_unlock(pthread_mutex_t *mutex) pthread_mutex_t lock = PTHREAD_MUTEX_INITIALIZER; // we must do the init for locks // or we can do as int rc = pthread_mutex_init(\u0026lock, NULL); assert(rc == 0); // always check success! pthread_mutex_lock(\u0026lock); x = x + 1; // or whatever your critical section is pthread_mutex_unlock(\u0026lock); Also, pthread mutex destroy() should be called afterwards. There","date":"2021-12-25","objectID":"/os_reading_note/:2:2","series":[],"tags":["OS"],"title":"OS","uri":"/os_reading_note/#condition-variables"},{"categories":["Note"],"content":"Interlude: Thread API Thread Creation #include int pthread_create(pthread_t* thread, const pthread_attr_t * attr, void* (*start_routine) (void*), void *arg); /* The second argument, attr, is used to specify any attributes this thread might have. Some examples include setting the stack size or perhaps in- formation about the scheduling priority of the thread. An attribute is initialized with a separate call to pthread attr init(); see the man- ual page for details. However, in most cases, the defaults will be fine; in this case, we will simply pass the value NULL in. The third argument is the most complex, but is really just asking: which function should this thread start running in? In C, we call this a function pointer, and this one tells us the following is expected: a function name (start routine), which is passed a single argument of type void * (as indicated in the parentheses after start routine), and which returns a value of type void * (i.e., a void pointer). Finally, the fourth argument, arg, is exactly the argument to be passed to the function where the thread begins execution. */ /* having a void pointer as an argument to the function start routine allows us to pass in any type of argument; having it as a return value allows the thread to return any type of result. */ #include #include typedef struct { int a; int b; } myarg_t; void *mythread(void *arg) { myarg_t *args = (myarg_t*) arg; printf(\"%d %d\\n\", args-a, args-b); return NULL; } int main(int argc, char* argv[]){ pthread_t p; myarg_t args = { 10, 20 }; int rc = pthread_create(\u0026p, NULL, mythread, \u0026args); } Thread Completion // What if you want to wait for a thread to complete? int pthread_join(pthread_t thread, void **value_ptr); /* This routine takes two arguments. The first is of type pthread t, and is used to specify which thread to wait for. This variable is initialized by the thread creation routine (when you pass a pointer to it as an argument to pthread create()); if you keep it around, you can use it to wait for that thread to terminate. The second argument is a pointer to the return value you expect to get back. Because the routine can return anything, it is defined to return a pointer to void; because the pthread join() routine changes the value of the passed in argument, you need to pass in a pointer to that value, not just the value itself. */ typedef struct { int a; int b; } myarg_t; typedef struct { int x; int y; } myret_t; void *mythread(void *arg) { myret_t *rvals = Malloc(sizeof(myret_t)); rvals-x = 1; rvals-y = 2; return (void *) rvals; } int main(int argc, char *argv[]) { pthread_t p; myret_t *rvals; myarg_t args = { 10, 20 }; Pthread_create(\u0026p, NULL, mythread, \u0026args); Pthread_join(p, (void **) \u0026rvals); printf(\"returned %d %d\\n\", rvals-x, rvals-y); free(rvals); return 0; } If we just create a thread with no args, we can pass NULL in as an arg. Similarly, we can pass NULL into pthread_join() if we care nothing about the return value. If we are just passing in a single value, then we don’t need to package it up as a arg. We should be extremely careful with how values are returned from a thread. Never return a pointer which refers to something allocated on the thread’s call stack. We have a pthread_create() followed bypthread_join(). We can use procedure call instead. Locks The routines should be easy to understand and use. When you have a region of code that is a critical section, and thus needs to be protected to ensure correct operation, locks are quite useful. int pthread_mutex_lock(pthread_mutex_t *mutex) int pthread_mutex_unlock(pthread_mutex_t *mutex) pthread_mutex_t lock = PTHREAD_MUTEX_INITIALIZER; // we must do the init for locks // or we can do as int rc = pthread_mutex_init(\u0026lock, NULL); assert(rc == 0); // always check success! pthread_mutex_lock(\u0026lock); x = x + 1; // or whatever your critical section is pthread_mutex_unlock(\u0026lock); Also, pthread mutex destroy() should be called afterwards. There","date":"2021-12-25","objectID":"/os_reading_note/:2:2","series":[],"tags":["OS"],"title":"OS","uri":"/os_reading_note/#compile-and-run"},{"categories":["Note"],"content":"Interlude: Thread API Thread Creation #include int pthread_create(pthread_t* thread, const pthread_attr_t * attr, void* (*start_routine) (void*), void *arg); /* The second argument, attr, is used to specify any attributes this thread might have. Some examples include setting the stack size or perhaps in- formation about the scheduling priority of the thread. An attribute is initialized with a separate call to pthread attr init(); see the man- ual page for details. However, in most cases, the defaults will be fine; in this case, we will simply pass the value NULL in. The third argument is the most complex, but is really just asking: which function should this thread start running in? In C, we call this a function pointer, and this one tells us the following is expected: a function name (start routine), which is passed a single argument of type void * (as indicated in the parentheses after start routine), and which returns a value of type void * (i.e., a void pointer). Finally, the fourth argument, arg, is exactly the argument to be passed to the function where the thread begins execution. */ /* having a void pointer as an argument to the function start routine allows us to pass in any type of argument; having it as a return value allows the thread to return any type of result. */ #include #include typedef struct { int a; int b; } myarg_t; void *mythread(void *arg) { myarg_t *args = (myarg_t*) arg; printf(\"%d %d\\n\", args-a, args-b); return NULL; } int main(int argc, char* argv[]){ pthread_t p; myarg_t args = { 10, 20 }; int rc = pthread_create(\u0026p, NULL, mythread, \u0026args); } Thread Completion // What if you want to wait for a thread to complete? int pthread_join(pthread_t thread, void **value_ptr); /* This routine takes two arguments. The first is of type pthread t, and is used to specify which thread to wait for. This variable is initialized by the thread creation routine (when you pass a pointer to it as an argument to pthread create()); if you keep it around, you can use it to wait for that thread to terminate. The second argument is a pointer to the return value you expect to get back. Because the routine can return anything, it is defined to return a pointer to void; because the pthread join() routine changes the value of the passed in argument, you need to pass in a pointer to that value, not just the value itself. */ typedef struct { int a; int b; } myarg_t; typedef struct { int x; int y; } myret_t; void *mythread(void *arg) { myret_t *rvals = Malloc(sizeof(myret_t)); rvals-x = 1; rvals-y = 2; return (void *) rvals; } int main(int argc, char *argv[]) { pthread_t p; myret_t *rvals; myarg_t args = { 10, 20 }; Pthread_create(\u0026p, NULL, mythread, \u0026args); Pthread_join(p, (void **) \u0026rvals); printf(\"returned %d %d\\n\", rvals-x, rvals-y); free(rvals); return 0; } If we just create a thread with no args, we can pass NULL in as an arg. Similarly, we can pass NULL into pthread_join() if we care nothing about the return value. If we are just passing in a single value, then we don’t need to package it up as a arg. We should be extremely careful with how values are returned from a thread. Never return a pointer which refers to something allocated on the thread’s call stack. We have a pthread_create() followed bypthread_join(). We can use procedure call instead. Locks The routines should be easy to understand and use. When you have a region of code that is a critical section, and thus needs to be protected to ensure correct operation, locks are quite useful. int pthread_mutex_lock(pthread_mutex_t *mutex) int pthread_mutex_unlock(pthread_mutex_t *mutex) pthread_mutex_t lock = PTHREAD_MUTEX_INITIALIZER; // we must do the init for locks // or we can do as int rc = pthread_mutex_init(\u0026lock, NULL); assert(rc == 0); // always check success! pthread_mutex_lock(\u0026lock); x = x + 1; // or whatever your critical section is pthread_mutex_unlock(\u0026lock); Also, pthread mutex destroy() should be called afterwards. There","date":"2021-12-25","objectID":"/os_reading_note/:2:2","series":[],"tags":["OS"],"title":"OS","uri":"/os_reading_note/#summary"},{"categories":["Note"],"content":"Locks The Basic Idea ","date":"2021-12-25","objectID":"/os_reading_note/:2:3","series":[],"tags":["OS"],"title":"OS","uri":"/os_reading_note/#locks-1"},{"categories":["Note"],"content":"Locks The Basic Idea ","date":"2021-12-25","objectID":"/os_reading_note/:2:3","series":[],"tags":["OS"],"title":"OS","uri":"/os_reading_note/#the-basic-idea"},{"categories":["Note"],"content":"Memory Sharing can we share memory between processors? some page table entries need to be mapped to the same physical frames One can read, other can write?: yes, control bits can be diff Does the shared mem must be the same VA in the two processes?: no How can we know a shared mem can be reclaimed?: have a counter like a ref bit Copy on Write UNIX fork with copy on write copy the parent page table entries to the child, and turn on a special bit called copy-on-write bit on both parent and child’s PTEs Notice this is a OS bit (unused bit modified by the OS), hardware don’t know what it is! read is fine, but if anyone want to write… We need the help from the hardware which means we need to turn on the read-only bit on hardware. When a write happens on either process, exception happens due to read-only bit. Kernel handler will find out the exception is due to copy on write. Kernel then allocate a new physical frame, and copy the content from the current shared frame to the new frame. The offending PTE(whichever need to write) will point to this new frame. So now the shared mem is not shared. Clear copy-on-write bit on the offending PTE, decrease the ref bit for that shared frame, and if the is no body else sharing that shared mem(ref bit is 0), then also clear the other PTE’s copy-on-write bit. We here also need a reverse pointer pointing to the PTE who points to the shared mem. if ref bit is now 0, then follow reverse pointer to clear copy-on-write and read-only bit on the last process. copy-on-write can be implement in the software level since hardware don’t care. Notice that both hardware and software know PTE, but only kernel knows the Copy-on-write Fill On Demand Can I start running a program before its code is in physical memory? Design a page fault handler OS must book-keeping whereabouts of all the physical frames on persistent storage What info shall the kernel maintain? For every swapped out VPN of a process, the disk location of the page content when does such book-keeping info need to be create? the first time a virtual page is swapped out from a process Subsequent swap out of the page amy result in change of the mapping, depending on OS policy What needs to happen during the page fault handler? allocate a free physical frame to copy the page data to how to locate the page data on the persistent storage? use the book-keeping info stored. what kernel data needs to be updated? PTE entry for the virtual page can also update the TLB what other actions need to take place? load the page content from persistent storage into mem while waiting for disk I/O to complete, schedule a diff process to run, mark the offending process as “blocked”. How does the OS know which physical frame this offending PTE used to point? This question is wrong! You should not go to find that physical frame, it might have been used by another process. We should copy the disk data to a new physical frame. Or you might overwrite the data being used by other processor. Transfer the data stored on the persistent storage into mem. ","date":"2021-12-25","objectID":"/os_slides_note/:0:0","series":[],"tags":["OS"],"title":"OS 2","uri":"/os_slides_note/#"},{"categories":["Note"],"content":"Memory Sharing can we share memory between processors? some page table entries need to be mapped to the same physical frames One can read, other can write?: yes, control bits can be diff Does the shared mem must be the same VA in the two processes?: no How can we know a shared mem can be reclaimed?: have a counter like a ref bit Copy on Write UNIX fork with copy on write copy the parent page table entries to the child, and turn on a special bit called copy-on-write bit on both parent and child’s PTEs Notice this is a OS bit (unused bit modified by the OS), hardware don’t know what it is! read is fine, but if anyone want to write… We need the help from the hardware which means we need to turn on the read-only bit on hardware. When a write happens on either process, exception happens due to read-only bit. Kernel handler will find out the exception is due to copy on write. Kernel then allocate a new physical frame, and copy the content from the current shared frame to the new frame. The offending PTE(whichever need to write) will point to this new frame. So now the shared mem is not shared. Clear copy-on-write bit on the offending PTE, decrease the ref bit for that shared frame, and if the is no body else sharing that shared mem(ref bit is 0), then also clear the other PTE’s copy-on-write bit. We here also need a reverse pointer pointing to the PTE who points to the shared mem. if ref bit is now 0, then follow reverse pointer to clear copy-on-write and read-only bit on the last process. copy-on-write can be implement in the software level since hardware don’t care. Notice that both hardware and software know PTE, but only kernel knows the Copy-on-write Fill On Demand Can I start running a program before its code is in physical memory? Design a page fault handler OS must book-keeping whereabouts of all the physical frames on persistent storage What info shall the kernel maintain? For every swapped out VPN of a process, the disk location of the page content when does such book-keeping info need to be create? the first time a virtual page is swapped out from a process Subsequent swap out of the page amy result in change of the mapping, depending on OS policy What needs to happen during the page fault handler? allocate a free physical frame to copy the page data to how to locate the page data on the persistent storage? use the book-keeping info stored. what kernel data needs to be updated? PTE entry for the virtual page can also update the TLB what other actions need to take place? load the page content from persistent storage into mem while waiting for disk I/O to complete, schedule a diff process to run, mark the offending process as “blocked”. How does the OS know which physical frame this offending PTE used to point? This question is wrong! You should not go to find that physical frame, it might have been used by another process. We should copy the disk data to a new physical frame. Or you might overwrite the data being used by other processor. Transfer the data stored on the persistent storage into mem. ","date":"2021-12-25","objectID":"/os_slides_note/:0:0","series":[],"tags":["OS"],"title":"OS 2","uri":"/os_slides_note/#memory-sharing"},{"categories":["Note"],"content":"Memory Sharing can we share memory between processors? some page table entries need to be mapped to the same physical frames One can read, other can write?: yes, control bits can be diff Does the shared mem must be the same VA in the two processes?: no How can we know a shared mem can be reclaimed?: have a counter like a ref bit Copy on Write UNIX fork with copy on write copy the parent page table entries to the child, and turn on a special bit called copy-on-write bit on both parent and child’s PTEs Notice this is a OS bit (unused bit modified by the OS), hardware don’t know what it is! read is fine, but if anyone want to write… We need the help from the hardware which means we need to turn on the read-only bit on hardware. When a write happens on either process, exception happens due to read-only bit. Kernel handler will find out the exception is due to copy on write. Kernel then allocate a new physical frame, and copy the content from the current shared frame to the new frame. The offending PTE(whichever need to write) will point to this new frame. So now the shared mem is not shared. Clear copy-on-write bit on the offending PTE, decrease the ref bit for that shared frame, and if the is no body else sharing that shared mem(ref bit is 0), then also clear the other PTE’s copy-on-write bit. We here also need a reverse pointer pointing to the PTE who points to the shared mem. if ref bit is now 0, then follow reverse pointer to clear copy-on-write and read-only bit on the last process. copy-on-write can be implement in the software level since hardware don’t care. Notice that both hardware and software know PTE, but only kernel knows the Copy-on-write Fill On Demand Can I start running a program before its code is in physical memory? Design a page fault handler OS must book-keeping whereabouts of all the physical frames on persistent storage What info shall the kernel maintain? For every swapped out VPN of a process, the disk location of the page content when does such book-keeping info need to be create? the first time a virtual page is swapped out from a process Subsequent swap out of the page amy result in change of the mapping, depending on OS policy What needs to happen during the page fault handler? allocate a free physical frame to copy the page data to how to locate the page data on the persistent storage? use the book-keeping info stored. what kernel data needs to be updated? PTE entry for the virtual page can also update the TLB what other actions need to take place? load the page content from persistent storage into mem while waiting for disk I/O to complete, schedule a diff process to run, mark the offending process as “blocked”. How does the OS know which physical frame this offending PTE used to point? This question is wrong! You should not go to find that physical frame, it might have been used by another process. We should copy the disk data to a new physical frame. Or you might overwrite the data being used by other processor. Transfer the data stored on the persistent storage into mem. ","date":"2021-12-25","objectID":"/os_slides_note/:0:0","series":[],"tags":["OS"],"title":"OS 2","uri":"/os_slides_note/#copy-on-write"},{"categories":["Note"],"content":"Memory Sharing can we share memory between processors? some page table entries need to be mapped to the same physical frames One can read, other can write?: yes, control bits can be diff Does the shared mem must be the same VA in the two processes?: no How can we know a shared mem can be reclaimed?: have a counter like a ref bit Copy on Write UNIX fork with copy on write copy the parent page table entries to the child, and turn on a special bit called copy-on-write bit on both parent and child’s PTEs Notice this is a OS bit (unused bit modified by the OS), hardware don’t know what it is! read is fine, but if anyone want to write… We need the help from the hardware which means we need to turn on the read-only bit on hardware. When a write happens on either process, exception happens due to read-only bit. Kernel handler will find out the exception is due to copy on write. Kernel then allocate a new physical frame, and copy the content from the current shared frame to the new frame. The offending PTE(whichever need to write) will point to this new frame. So now the shared mem is not shared. Clear copy-on-write bit on the offending PTE, decrease the ref bit for that shared frame, and if the is no body else sharing that shared mem(ref bit is 0), then also clear the other PTE’s copy-on-write bit. We here also need a reverse pointer pointing to the PTE who points to the shared mem. if ref bit is now 0, then follow reverse pointer to clear copy-on-write and read-only bit on the last process. copy-on-write can be implement in the software level since hardware don’t care. Notice that both hardware and software know PTE, but only kernel knows the Copy-on-write Fill On Demand Can I start running a program before its code is in physical memory? Design a page fault handler OS must book-keeping whereabouts of all the physical frames on persistent storage What info shall the kernel maintain? For every swapped out VPN of a process, the disk location of the page content when does such book-keeping info need to be create? the first time a virtual page is swapped out from a process Subsequent swap out of the page amy result in change of the mapping, depending on OS policy What needs to happen during the page fault handler? allocate a free physical frame to copy the page data to how to locate the page data on the persistent storage? use the book-keeping info stored. what kernel data needs to be updated? PTE entry for the virtual page can also update the TLB what other actions need to take place? load the page content from persistent storage into mem while waiting for disk I/O to complete, schedule a diff process to run, mark the offending process as “blocked”. How does the OS know which physical frame this offending PTE used to point? This question is wrong! You should not go to find that physical frame, it might have been used by another process. We should copy the disk data to a new physical frame. Or you might overwrite the data being used by other processor. Transfer the data stored on the persistent storage into mem. ","date":"2021-12-25","objectID":"/os_slides_note/:0:0","series":[],"tags":["OS"],"title":"OS 2","uri":"/os_slides_note/#notice-that-both-hardware-and-software-know-pte-but-only-kernel-knows-the-copy-on-write"},{"categories":["Note"],"content":"Memory Sharing can we share memory between processors? some page table entries need to be mapped to the same physical frames One can read, other can write?: yes, control bits can be diff Does the shared mem must be the same VA in the two processes?: no How can we know a shared mem can be reclaimed?: have a counter like a ref bit Copy on Write UNIX fork with copy on write copy the parent page table entries to the child, and turn on a special bit called copy-on-write bit on both parent and child’s PTEs Notice this is a OS bit (unused bit modified by the OS), hardware don’t know what it is! read is fine, but if anyone want to write… We need the help from the hardware which means we need to turn on the read-only bit on hardware. When a write happens on either process, exception happens due to read-only bit. Kernel handler will find out the exception is due to copy on write. Kernel then allocate a new physical frame, and copy the content from the current shared frame to the new frame. The offending PTE(whichever need to write) will point to this new frame. So now the shared mem is not shared. Clear copy-on-write bit on the offending PTE, decrease the ref bit for that shared frame, and if the is no body else sharing that shared mem(ref bit is 0), then also clear the other PTE’s copy-on-write bit. We here also need a reverse pointer pointing to the PTE who points to the shared mem. if ref bit is now 0, then follow reverse pointer to clear copy-on-write and read-only bit on the last process. copy-on-write can be implement in the software level since hardware don’t care. Notice that both hardware and software know PTE, but only kernel knows the Copy-on-write Fill On Demand Can I start running a program before its code is in physical memory? Design a page fault handler OS must book-keeping whereabouts of all the physical frames on persistent storage What info shall the kernel maintain? For every swapped out VPN of a process, the disk location of the page content when does such book-keeping info need to be create? the first time a virtual page is swapped out from a process Subsequent swap out of the page amy result in change of the mapping, depending on OS policy What needs to happen during the page fault handler? allocate a free physical frame to copy the page data to how to locate the page data on the persistent storage? use the book-keeping info stored. what kernel data needs to be updated? PTE entry for the virtual page can also update the TLB what other actions need to take place? load the page content from persistent storage into mem while waiting for disk I/O to complete, schedule a diff process to run, mark the offending process as “blocked”. How does the OS know which physical frame this offending PTE used to point? This question is wrong! You should not go to find that physical frame, it might have been used by another process. We should copy the disk data to a new physical frame. Or you might overwrite the data being used by other processor. Transfer the data stored on the persistent storage into mem. ","date":"2021-12-25","objectID":"/os_slides_note/:0:0","series":[],"tags":["OS"],"title":"OS 2","uri":"/os_slides_note/#fill-on-demand"},{"categories":["Note"],"content":"Memory Sharing can we share memory between processors? some page table entries need to be mapped to the same physical frames One can read, other can write?: yes, control bits can be diff Does the shared mem must be the same VA in the two processes?: no How can we know a shared mem can be reclaimed?: have a counter like a ref bit Copy on Write UNIX fork with copy on write copy the parent page table entries to the child, and turn on a special bit called copy-on-write bit on both parent and child’s PTEs Notice this is a OS bit (unused bit modified by the OS), hardware don’t know what it is! read is fine, but if anyone want to write… We need the help from the hardware which means we need to turn on the read-only bit on hardware. When a write happens on either process, exception happens due to read-only bit. Kernel handler will find out the exception is due to copy on write. Kernel then allocate a new physical frame, and copy the content from the current shared frame to the new frame. The offending PTE(whichever need to write) will point to this new frame. So now the shared mem is not shared. Clear copy-on-write bit on the offending PTE, decrease the ref bit for that shared frame, and if the is no body else sharing that shared mem(ref bit is 0), then also clear the other PTE’s copy-on-write bit. We here also need a reverse pointer pointing to the PTE who points to the shared mem. if ref bit is now 0, then follow reverse pointer to clear copy-on-write and read-only bit on the last process. copy-on-write can be implement in the software level since hardware don’t care. Notice that both hardware and software know PTE, but only kernel knows the Copy-on-write Fill On Demand Can I start running a program before its code is in physical memory? Design a page fault handler OS must book-keeping whereabouts of all the physical frames on persistent storage What info shall the kernel maintain? For every swapped out VPN of a process, the disk location of the page content when does such book-keeping info need to be create? the first time a virtual page is swapped out from a process Subsequent swap out of the page amy result in change of the mapping, depending on OS policy What needs to happen during the page fault handler? allocate a free physical frame to copy the page data to how to locate the page data on the persistent storage? use the book-keeping info stored. what kernel data needs to be updated? PTE entry for the virtual page can also update the TLB what other actions need to take place? load the page content from persistent storage into mem while waiting for disk I/O to complete, schedule a diff process to run, mark the offending process as “blocked”. How does the OS know which physical frame this offending PTE used to point? This question is wrong! You should not go to find that physical frame, it might have been used by another process. We should copy the disk data to a new physical frame. Or you might overwrite the data being used by other processor. Transfer the data stored on the persistent storage into mem. ","date":"2021-12-25","objectID":"/os_slides_note/:0:0","series":[],"tags":["OS"],"title":"OS 2","uri":"/os_slides_note/#design-a-page-fault-handler"},{"categories":["Note"],"content":"Lecture 16: Concurrency II Synchronization: Mutual Exclusive + Ordering By the definition of thread, its access to shared memory space is unfettered. And its scheduling is completely unpredictable. So, from this angle, all threads race to access data! ==\u003e very bad design Defs: Race condition Mutual exclusion Lock Critical section ","date":"2021-12-25","objectID":"/os_slides_note/:1:0","series":[],"tags":["OS"],"title":"OS 2","uri":"/os_slides_note/#lecture-16-concurrency-ii"},{"categories":["Note"],"content":"Locks Lock::acquire Lock::release Milk problem: Liveness: Someone buys if needed Safety: At most one person buys Fairness: Everyone has fair chances to get the lock 1 \u0026 2 are the most important, 3 is good to have. If you only have a single processor, we should disable the interrupt, or we may have a dead lock. ","date":"2021-12-25","objectID":"/os_slides_note/:1:1","series":[],"tags":["OS"],"title":"OS 2","uri":"/os_slides_note/#locks"},{"categories":["Note"],"content":"ONLY IN LECTURE Once you acquire the lock, you can assume that it’s in persistant state. // Basic programming pattern for Critical section Lock::acquire Manipulation of shared data Lock::release One lock per shared data To be effective, all threads must apply locking on the data The difference between Concurrency access in OS v.s. program: OS does not trust others. The program can behave like designed, there is no enforcement. So Synchronization is kinda weird for the OS since it’s more of a cooperation rather than enforcement. The lock does not really lock it, it just signal others that the data is occupied by me, do not come. When you have some threads, you’ll never know when they will be executed. Implementing Threads: kernel Threads: to the kernel, a kernel thread and a single threaded user processor looks quite similar. multithreads processes using kernel threads User-level threads We are going to focus on the first possibility. Thread data structure: TCB and stack TCB –\u003e stack info, saved registers, thread meta data shared state are shared among all threads: code global vars, heap Thread Context Switch Voluntary yield and join Involuntary Interrupt or exception Some other thread is higher priority How does it happen? return to a new place The key trick: void thread_switch(oldThreadTCB, newTheadTCB){ pushad; oldThreadTCB-\u003esp = %esp; %esp = newThreadTCB-\u003esp; popad; return; } How to implement thread_yield()? in the thread_yield(), there is thread_switch() in the yield() after the swith(), the it’s resumed to the old TCB NOT THE chosen TCB. And the eableInterrupt() is not re-eable the one at the beginning of the yield(), but that in another thread. the yield() is very fast so that do not worry about the length of the time of interrupt.(for single core) void thread_yield(){ TCB *previous_runningTCB, *chosenTCB, *finishedTCB; //Prevent an interrupt from stopping us in the middle of a switch disableInterrupts(); // choose another TCB from the ready list chosenTCB = readyList.getNextThread(); if (chosenTCB == NULL){ //Nothing, go back to the original thread } else{ runningThread-\u003estate = ready; readyList.add(runningThread); previous_runningTCB = runningThread; runningThread = chosenTCB; thread_switch(*previous_runningTCB, chosenTCB); runningThread-\u003estate = running; } while((finishedTCB = finishedList-\u003egetNextThread()) != NULL){ delete finishedTCB-\u003estack; delete finishedTCB; } enableInterrupts(); } why disable the interrupt? to protect the shared data: ready list! If this is not kernel code, we have to use other tricks like locks. Never acquire a lock in interrupt handler!!! because if the interrupt handler tries to acquire a lock that being held by others, DEAD LOK!! In this case, one CPU core own their own ready list. Or there still may be a race condition on the ready list since the disableInterrupt() only works on the current CPU. The downside is that if a thread is ready but other cores are not doing anything. ","date":"2021-12-25","objectID":"/os_slides_note/:1:2","series":[],"tags":["OS"],"title":"OS 2","uri":"/os_slides_note/#only-in-lecture"},{"categories":["Note"],"content":"ONLY IN LECTURE Once you acquire the lock, you can assume that it’s in persistant state. // Basic programming pattern for Critical section Lock::acquire Manipulation of shared data Lock::release One lock per shared data To be effective, all threads must apply locking on the data The difference between Concurrency access in OS v.s. program: OS does not trust others. The program can behave like designed, there is no enforcement. So Synchronization is kinda weird for the OS since it’s more of a cooperation rather than enforcement. The lock does not really lock it, it just signal others that the data is occupied by me, do not come. When you have some threads, you’ll never know when they will be executed. Implementing Threads: kernel Threads: to the kernel, a kernel thread and a single threaded user processor looks quite similar. multithreads processes using kernel threads User-level threads We are going to focus on the first possibility. Thread data structure: TCB and stack TCB – stack info, saved registers, thread meta data shared state are shared among all threads: code global vars, heap Thread Context Switch Voluntary yield and join Involuntary Interrupt or exception Some other thread is higher priority How does it happen? return to a new place The key trick: void thread_switch(oldThreadTCB, newTheadTCB){ pushad; oldThreadTCB-sp = %esp; %esp = newThreadTCB-sp; popad; return; } How to implement thread_yield()? in the thread_yield(), there is thread_switch() in the yield() after the swith(), the it’s resumed to the old TCB NOT THE chosen TCB. And the eableInterrupt() is not re-eable the one at the beginning of the yield(), but that in another thread. the yield() is very fast so that do not worry about the length of the time of interrupt.(for single core) void thread_yield(){ TCB *previous_runningTCB, *chosenTCB, *finishedTCB; //Prevent an interrupt from stopping us in the middle of a switch disableInterrupts(); // choose another TCB from the ready list chosenTCB = readyList.getNextThread(); if (chosenTCB == NULL){ //Nothing, go back to the original thread } else{ runningThread-state = ready; readyList.add(runningThread); previous_runningTCB = runningThread; runningThread = chosenTCB; thread_switch(*previous_runningTCB, chosenTCB); runningThread-state = running; } while((finishedTCB = finishedList-getNextThread()) != NULL){ delete finishedTCB-stack; delete finishedTCB; } enableInterrupts(); } why disable the interrupt? to protect the shared data: ready list! If this is not kernel code, we have to use other tricks like locks. Never acquire a lock in interrupt handler!!! because if the interrupt handler tries to acquire a lock that being held by others, DEAD LOK!! In this case, one CPU core own their own ready list. Or there still may be a race condition on the ready list since the disableInterrupt() only works on the current CPU. The downside is that if a thread is ready but other cores are not doing anything. ","date":"2021-12-25","objectID":"/os_slides_note/:1:2","series":[],"tags":["OS"],"title":"OS 2","uri":"/os_slides_note/#how-to-implement-thread_yield"},{"categories":["Note"],"content":"ONLY IN LECTURE Once you acquire the lock, you can assume that it’s in persistant state. // Basic programming pattern for Critical section Lock::acquire Manipulation of shared data Lock::release One lock per shared data To be effective, all threads must apply locking on the data The difference between Concurrency access in OS v.s. program: OS does not trust others. The program can behave like designed, there is no enforcement. So Synchronization is kinda weird for the OS since it’s more of a cooperation rather than enforcement. The lock does not really lock it, it just signal others that the data is occupied by me, do not come. When you have some threads, you’ll never know when they will be executed. Implementing Threads: kernel Threads: to the kernel, a kernel thread and a single threaded user processor looks quite similar. multithreads processes using kernel threads User-level threads We are going to focus on the first possibility. Thread data structure: TCB and stack TCB – stack info, saved registers, thread meta data shared state are shared among all threads: code global vars, heap Thread Context Switch Voluntary yield and join Involuntary Interrupt or exception Some other thread is higher priority How does it happen? return to a new place The key trick: void thread_switch(oldThreadTCB, newTheadTCB){ pushad; oldThreadTCB-sp = %esp; %esp = newThreadTCB-sp; popad; return; } How to implement thread_yield()? in the thread_yield(), there is thread_switch() in the yield() after the swith(), the it’s resumed to the old TCB NOT THE chosen TCB. And the eableInterrupt() is not re-eable the one at the beginning of the yield(), but that in another thread. the yield() is very fast so that do not worry about the length of the time of interrupt.(for single core) void thread_yield(){ TCB *previous_runningTCB, *chosenTCB, *finishedTCB; //Prevent an interrupt from stopping us in the middle of a switch disableInterrupts(); // choose another TCB from the ready list chosenTCB = readyList.getNextThread(); if (chosenTCB == NULL){ //Nothing, go back to the original thread } else{ runningThread-state = ready; readyList.add(runningThread); previous_runningTCB = runningThread; runningThread = chosenTCB; thread_switch(*previous_runningTCB, chosenTCB); runningThread-state = running; } while((finishedTCB = finishedList-getNextThread()) != NULL){ delete finishedTCB-stack; delete finishedTCB; } enableInterrupts(); } why disable the interrupt? to protect the shared data: ready list! If this is not kernel code, we have to use other tricks like locks. Never acquire a lock in interrupt handler!!! because if the interrupt handler tries to acquire a lock that being held by others, DEAD LOK!! In this case, one CPU core own their own ready list. Or there still may be a race condition on the ready list since the disableInterrupt() only works on the current CPU. The downside is that if a thread is ready but other cores are not doing anything. ","date":"2021-12-25","objectID":"/os_slides_note/:1:2","series":[],"tags":["OS"],"title":"OS 2","uri":"/os_slides_note/#why-disable-the-interrupt"},{"categories":["Note"],"content":"ONLY IN LECTURE Once you acquire the lock, you can assume that it’s in persistant state. // Basic programming pattern for Critical section Lock::acquire Manipulation of shared data Lock::release One lock per shared data To be effective, all threads must apply locking on the data The difference between Concurrency access in OS v.s. program: OS does not trust others. The program can behave like designed, there is no enforcement. So Synchronization is kinda weird for the OS since it’s more of a cooperation rather than enforcement. The lock does not really lock it, it just signal others that the data is occupied by me, do not come. When you have some threads, you’ll never know when they will be executed. Implementing Threads: kernel Threads: to the kernel, a kernel thread and a single threaded user processor looks quite similar. multithreads processes using kernel threads User-level threads We are going to focus on the first possibility. Thread data structure: TCB and stack TCB – stack info, saved registers, thread meta data shared state are shared among all threads: code global vars, heap Thread Context Switch Voluntary yield and join Involuntary Interrupt or exception Some other thread is higher priority How does it happen? return to a new place The key trick: void thread_switch(oldThreadTCB, newTheadTCB){ pushad; oldThreadTCB-sp = %esp; %esp = newThreadTCB-sp; popad; return; } How to implement thread_yield()? in the thread_yield(), there is thread_switch() in the yield() after the swith(), the it’s resumed to the old TCB NOT THE chosen TCB. And the eableInterrupt() is not re-eable the one at the beginning of the yield(), but that in another thread. the yield() is very fast so that do not worry about the length of the time of interrupt.(for single core) void thread_yield(){ TCB *previous_runningTCB, *chosenTCB, *finishedTCB; //Prevent an interrupt from stopping us in the middle of a switch disableInterrupts(); // choose another TCB from the ready list chosenTCB = readyList.getNextThread(); if (chosenTCB == NULL){ //Nothing, go back to the original thread } else{ runningThread-state = ready; readyList.add(runningThread); previous_runningTCB = runningThread; runningThread = chosenTCB; thread_switch(*previous_runningTCB, chosenTCB); runningThread-state = running; } while((finishedTCB = finishedList-getNextThread()) != NULL){ delete finishedTCB-stack; delete finishedTCB; } enableInterrupts(); } why disable the interrupt? to protect the shared data: ready list! If this is not kernel code, we have to use other tricks like locks. Never acquire a lock in interrupt handler!!! because if the interrupt handler tries to acquire a lock that being held by others, DEAD LOK!! In this case, one CPU core own their own ready list. Or there still may be a race condition on the ready list since the disableInterrupt() only works on the current CPU. The downside is that if a thread is ready but other cores are not doing anything. ","date":"2021-12-25","objectID":"/os_slides_note/:1:2","series":[],"tags":["OS"],"title":"OS 2","uri":"/os_slides_note/#never-acquire-a-lock-in-interrupt-handler"},{"categories":["Note"],"content":"Lecture 18 EXAM: what does this line do? Is there anything wrong? yield() switch() join() … we should be able to implement those. All these funtions have nothing special that make them can be only done in kernel, you can implement similar things in user mode with proper coding. Thread_create() need a wrapper, to call the create() and exit once created, since we might not use it immediately after creating it. allocate TCB allocate stack build stack frame for base of stack (stub) put thread on ready list will run sometime later (maybe right away) thread_create(thread_t thread, void (*func)(int), int arg){ TCB* tcb = new TCB(); thread-\u003etcb = tcb; tcb-\u003estack_size = INIT_STACK_SIZE; tcb-\u003estack = new Stack(INIT_STACK_SIZE); // now the TCB and stack are allocated tcb-\u003esp = stack + INIT_STACK_SIZE; tcb-\u003epc = stub; // init the register to let the program run at the stub *(tcb-\u003esp--) = stub; *(tcb-\u003esp) = func; tcb-\u003esp -= SizeOfPopad; tcb-\u003estate = READY; readyList.add(tcb); // put tcb on ready readyList } stub(func, args){ (*func)(args); thread_exit(); } Notice here the tcb’s member vars: tcb, stack_size, stack, sp, pc, state… the create() function pretend it’s resuming from another thread, so that every function is in a unified format, which means they can all use thread_swith(). When it gets resumed, it needs certain words int the stack to fufill the popad instructions in thread_switch(). Thus, we need a fake funcion like stub() to create that stack space. The popad will add those random vals into the stack but it doesn’t matter since a new thread should not trust any un-init vals. Subtlety thread_create() puts new thread on ready list When it first runs, some thread needs to call thread_switch() save old thread state to stack pop the new thread state from stack into the registers Set up new thread’s stack as if it has saved its state in thread_switch() return to the sub at the base address of the stack to run the func ","date":"2021-12-25","objectID":"/os_slides_note/:2:0","series":[],"tags":["OS"],"title":"OS 2","uri":"/os_slides_note/#lecture-18"},{"categories":["Note"],"content":"Lecture 18 EXAM: what does this line do? Is there anything wrong? yield() switch() join() … we should be able to implement those. All these funtions have nothing special that make them can be only done in kernel, you can implement similar things in user mode with proper coding. Thread_create() need a wrapper, to call the create() and exit once created, since we might not use it immediately after creating it. allocate TCB allocate stack build stack frame for base of stack (stub) put thread on ready list will run sometime later (maybe right away) thread_create(thread_t thread, void (*func)(int), int arg){ TCB* tcb = new TCB(); thread-tcb = tcb; tcb-stack_size = INIT_STACK_SIZE; tcb-stack = new Stack(INIT_STACK_SIZE); // now the TCB and stack are allocated tcb-sp = stack + INIT_STACK_SIZE; tcb-pc = stub; // init the register to let the program run at the stub *(tcb-sp--) = stub; *(tcb-sp) = func; tcb-sp -= SizeOfPopad; tcb-state = READY; readyList.add(tcb); // put tcb on ready readyList } stub(func, args){ (*func)(args); thread_exit(); } Notice here the tcb’s member vars: tcb, stack_size, stack, sp, pc, state… the create() function pretend it’s resuming from another thread, so that every function is in a unified format, which means they can all use thread_swith(). When it gets resumed, it needs certain words int the stack to fufill the popad instructions in thread_switch(). Thus, we need a fake funcion like stub() to create that stack space. The popad will add those random vals into the stack but it doesn’t matter since a new thread should not trust any un-init vals. Subtlety thread_create() puts new thread on ready list When it first runs, some thread needs to call thread_switch() save old thread state to stack pop the new thread state from stack into the registers Set up new thread’s stack as if it has saved its state in thread_switch() return to the sub at the base address of the stack to run the func ","date":"2021-12-25","objectID":"/os_slides_note/:2:0","series":[],"tags":["OS"],"title":"OS 2","uri":"/os_slides_note/#thread_create"},{"categories":["Note"],"content":"Lecture 18 EXAM: what does this line do? Is there anything wrong? yield() switch() join() … we should be able to implement those. All these funtions have nothing special that make them can be only done in kernel, you can implement similar things in user mode with proper coding. Thread_create() need a wrapper, to call the create() and exit once created, since we might not use it immediately after creating it. allocate TCB allocate stack build stack frame for base of stack (stub) put thread on ready list will run sometime later (maybe right away) thread_create(thread_t thread, void (*func)(int), int arg){ TCB* tcb = new TCB(); thread-tcb = tcb; tcb-stack_size = INIT_STACK_SIZE; tcb-stack = new Stack(INIT_STACK_SIZE); // now the TCB and stack are allocated tcb-sp = stack + INIT_STACK_SIZE; tcb-pc = stub; // init the register to let the program run at the stub *(tcb-sp--) = stub; *(tcb-sp) = func; tcb-sp -= SizeOfPopad; tcb-state = READY; readyList.add(tcb); // put tcb on ready readyList } stub(func, args){ (*func)(args); thread_exit(); } Notice here the tcb’s member vars: tcb, stack_size, stack, sp, pc, state… the create() function pretend it’s resuming from another thread, so that every function is in a unified format, which means they can all use thread_swith(). When it gets resumed, it needs certain words int the stack to fufill the popad instructions in thread_switch(). Thus, we need a fake funcion like stub() to create that stack space. The popad will add those random vals into the stack but it doesn’t matter since a new thread should not trust any un-init vals. Subtlety thread_create() puts new thread on ready list When it first runs, some thread needs to call thread_switch() save old thread state to stack pop the new thread state from stack into the registers Set up new thread’s stack as if it has saved its state in thread_switch() return to the sub at the base address of the stack to run the func ","date":"2021-12-25","objectID":"/os_slides_note/:2:0","series":[],"tags":["OS"],"title":"OS 2","uri":"/os_slides_note/#subtlety"},{"categories":["Note"],"content":"Involuntary timer or I/O interrput lernel can decide that some other thread should run once you are in the kernel, the process are seen as threads. notice that user process has the kernel stack and the user stack, but the kernel thread only has the kernel stack we can use switch() as context switch simple version End of interrupt handler calls thread_switch() when resumed, return from handler resumes kernel thread or uer process. Thus, processor context is saved/restored twice.(once by thread switch, and once by interrupt handler) It seems that we need to do sth like in the yield(), call the scheduler to run to give us a chosen pcb and call swith(), in the switch() we use iret after popad. However, think about this. Since you are already in an interrupt, we have states saved in the trap frame, on top of that we also do pushad in the swith(), which is redundant. Resuming a thread from the switch() which is also interrupted let the resumed thread start at the interrupt handler, which will next do the popad again followed by an iret. Faster Thread/Process Switch Essentially tail call elimination \u003c== if the context switch is cause by interrupt interrupt handler will saved all the states decide to run a new thread throw away current state of interrupt handler you DO NOT really call thread_switch() and create a new frame for it, which would save the registers and return address. Instead it become a jump. reuse the thread’s saved state when entering the interrupt handler Set saved stack pointer to trap frame (on x86, including the saved registers and six vals) On resume, pops trap frame to restore interrupt thread This requires thread_switch() use the same format stack frame as trap frame. On x86, this also means thread_switch() will use iret, instead of ret instruction. Now both voluntary and involuntary context switch are all looks like resume from an interrupt so that they are uniform. Can we support user level threads without the help of kernel? reason: kernel only has one way of scheduling, which is less flexible for the need from app to app. In this case, the kernel may not know the existence of the user threads since the thread context swith is not down throught kernel. What if there is an I/O request and the kernel block the whole processor? How do we preempt other threads when kernel does not kick in (one way to do is to use yield() everywhere to let threads balance the workload but this is unpractical)? ","date":"2021-12-25","objectID":"/os_slides_note/:2:1","series":[],"tags":["OS"],"title":"OS 2","uri":"/os_slides_note/#involuntary"},{"categories":["Note"],"content":"Involuntary timer or I/O interrput lernel can decide that some other thread should run once you are in the kernel, the process are seen as threads. notice that user process has the kernel stack and the user stack, but the kernel thread only has the kernel stack we can use switch() as context switch simple version End of interrupt handler calls thread_switch() when resumed, return from handler resumes kernel thread or uer process. Thus, processor context is saved/restored twice.(once by thread switch, and once by interrupt handler) It seems that we need to do sth like in the yield(), call the scheduler to run to give us a chosen pcb and call swith(), in the switch() we use iret after popad. However, think about this. Since you are already in an interrupt, we have states saved in the trap frame, on top of that we also do pushad in the swith(), which is redundant. Resuming a thread from the switch() which is also interrupted let the resumed thread start at the interrupt handler, which will next do the popad again followed by an iret. Faster Thread/Process Switch Essentially tail call elimination ","date":"2021-12-25","objectID":"/os_slides_note/:2:1","series":[],"tags":["OS"],"title":"OS 2","uri":"/os_slides_note/#faster-threadprocess-switch"},{"categories":["Note"],"content":"Involuntary timer or I/O interrput lernel can decide that some other thread should run once you are in the kernel, the process are seen as threads. notice that user process has the kernel stack and the user stack, but the kernel thread only has the kernel stack we can use switch() as context switch simple version End of interrupt handler calls thread_switch() when resumed, return from handler resumes kernel thread or uer process. Thus, processor context is saved/restored twice.(once by thread switch, and once by interrupt handler) It seems that we need to do sth like in the yield(), call the scheduler to run to give us a chosen pcb and call swith(), in the switch() we use iret after popad. However, think about this. Since you are already in an interrupt, we have states saved in the trap frame, on top of that we also do pushad in the swith(), which is redundant. Resuming a thread from the switch() which is also interrupted let the resumed thread start at the interrupt handler, which will next do the popad again followed by an iret. Faster Thread/Process Switch Essentially tail call elimination ","date":"2021-12-25","objectID":"/os_slides_note/:2:1","series":[],"tags":["OS"],"title":"OS 2","uri":"/os_slides_note/#can-we-support-user-level-threads-without-the-help-of-kernel"},{"categories":["Note"],"content":"Involuntary timer or I/O interrput lernel can decide that some other thread should run once you are in the kernel, the process are seen as threads. notice that user process has the kernel stack and the user stack, but the kernel thread only has the kernel stack we can use switch() as context switch simple version End of interrupt handler calls thread_switch() when resumed, return from handler resumes kernel thread or uer process. Thus, processor context is saved/restored twice.(once by thread switch, and once by interrupt handler) It seems that we need to do sth like in the yield(), call the scheduler to run to give us a chosen pcb and call swith(), in the switch() we use iret after popad. However, think about this. Since you are already in an interrupt, we have states saved in the trap frame, on top of that we also do pushad in the swith(), which is redundant. Resuming a thread from the switch() which is also interrupted let the resumed thread start at the interrupt handler, which will next do the popad again followed by an iret. Faster Thread/Process Switch Essentially tail call elimination ","date":"2021-12-25","objectID":"/os_slides_note/:2:1","series":[],"tags":["OS"],"title":"OS 2","uri":"/os_slides_note/#reason-kernel-only-has-one-way-of-scheduling-which-is-less-flexible-for-the-need-from-app-to-app"},{"categories":["Note"],"content":"Lecture 19 We can use signal. Like in the terminal \u003cctr + c\u003e is s signal to do a up call, and kernel will ask the user processor to do something. And then we can write our own signal handler. For example, kernel has timer interrupt, so kernel can decide to send a signal to a process who need it periodically. /* An upcall is a mechanism that allows the kernel to execute a function in userspace, and potentially be returned information as a result. An upcall is like a signal, except that the kernel may use it at any time, for any purpose, including in an interrupt handler. This means that an upcall can potentially destroy the behaviour of the kernel. If an interrupt handler decides to ask a user space function for some information, and the function page faults or does blocking IO, your kernel is quite likely trashed. So, upcalls aren't there for everyday software development. But for specific purposes, they can be extremely useful. */ Green thread(early JAVA) user level lib, within a process lub does thread context swtich preemption via upcall/UNIX signal on timer interrupt use multiple processes for multi-core parallelism shared mem region mapped into each process Since the process can change the user level stack for the threads Say if we have a multi-core CPU, this does not work. Because when you want to let a core to take care of a thread, it needs kernel to kick in. However, the green thread does everthing at user level. The solution is to use shared mem region mapped into each process. More modern way Scheduler activations kernel allocates processors to user-level thread lib (after the specific core take over, the scheduling will be done in that core, which are decided by the user level processors in that core, and we have the following 2 bullet points) thread lib implements context switch thread lib decides what thread to run next upcall whenever kernel needs a user level scheduling decision (if there is I/O interrupt, kernel will ask the process to do sth or it will be blocked) process assigned a new processor processor removed from process sys call blocks in kernel ","date":"2021-12-25","objectID":"/os_slides_note/:3:0","series":[],"tags":["OS"],"title":"OS 2","uri":"/os_slides_note/#lecture-19"},{"categories":["Note"],"content":"Lecture 19 We can use signal. Like in the terminal is s signal to do a up call, and kernel will ask the user processor to do something. And then we can write our own signal handler. For example, kernel has timer interrupt, so kernel can decide to send a signal to a process who need it periodically. /* An upcall is a mechanism that allows the kernel to execute a function in userspace, and potentially be returned information as a result. An upcall is like a signal, except that the kernel may use it at any time, for any purpose, including in an interrupt handler. This means that an upcall can potentially destroy the behaviour of the kernel. If an interrupt handler decides to ask a user space function for some information, and the function page faults or does blocking IO, your kernel is quite likely trashed. So, upcalls aren't there for everyday software development. But for specific purposes, they can be extremely useful. */ Green thread(early JAVA) user level lib, within a process lub does thread context swtich preemption via upcall/UNIX signal on timer interrupt use multiple processes for multi-core parallelism shared mem region mapped into each process Since the process can change the user level stack for the threads Say if we have a multi-core CPU, this does not work. Because when you want to let a core to take care of a thread, it needs kernel to kick in. However, the green thread does everthing at user level. The solution is to use shared mem region mapped into each process. More modern way Scheduler activations kernel allocates processors to user-level thread lib (after the specific core take over, the scheduling will be done in that core, which are decided by the user level processors in that core, and we have the following 2 bullet points) thread lib implements context switch thread lib decides what thread to run next upcall whenever kernel needs a user level scheduling decision (if there is I/O interrupt, kernel will ask the process to do sth or it will be blocked) process assigned a new processor processor removed from process sys call blocks in kernel ","date":"2021-12-25","objectID":"/os_slides_note/:3:0","series":[],"tags":["OS"],"title":"OS 2","uri":"/os_slides_note/#green-threadearly-java"},{"categories":["Note"],"content":"Lecture 19 We can use signal. Like in the terminal is s signal to do a up call, and kernel will ask the user processor to do something. And then we can write our own signal handler. For example, kernel has timer interrupt, so kernel can decide to send a signal to a process who need it periodically. /* An upcall is a mechanism that allows the kernel to execute a function in userspace, and potentially be returned information as a result. An upcall is like a signal, except that the kernel may use it at any time, for any purpose, including in an interrupt handler. This means that an upcall can potentially destroy the behaviour of the kernel. If an interrupt handler decides to ask a user space function for some information, and the function page faults or does blocking IO, your kernel is quite likely trashed. So, upcalls aren't there for everyday software development. But for specific purposes, they can be extremely useful. */ Green thread(early JAVA) user level lib, within a process lub does thread context swtich preemption via upcall/UNIX signal on timer interrupt use multiple processes for multi-core parallelism shared mem region mapped into each process Since the process can change the user level stack for the threads Say if we have a multi-core CPU, this does not work. Because when you want to let a core to take care of a thread, it needs kernel to kick in. However, the green thread does everthing at user level. The solution is to use shared mem region mapped into each process. More modern way Scheduler activations kernel allocates processors to user-level thread lib (after the specific core take over, the scheduling will be done in that core, which are decided by the user level processors in that core, and we have the following 2 bullet points) thread lib implements context switch thread lib decides what thread to run next upcall whenever kernel needs a user level scheduling decision (if there is I/O interrupt, kernel will ask the process to do sth or it will be blocked) process assigned a new processor processor removed from process sys call blocks in kernel ","date":"2021-12-25","objectID":"/os_slides_note/:3:0","series":[],"tags":["OS"],"title":"OS 2","uri":"/os_slides_note/#more-modern-way"},{"categories":["Note"],"content":"Spinlock issue Spinlock::acquire() { while (testAndSet(\u0026lockValue) == BUSY){ } } Spinlock::release() { lockValue = FREE } // downside: a waste of cpu resources // fairness issues: generally cannot assure fairness How to solve it? we may try to make the spinlock less aggressive. for perfomance and we should have a wait queue? for fairness // There might be multiple threads trying to acquire the lock and put themselves into the wait list. So there will be race conditions(since you will have the pointers to move and change). // Thus, they have to be synchronized ==\u003e they have to be protected by another lock -- a spinlock class Lock { private: SpinLock spinLock; // ==\u003e to protext the lock data structure int value = FREE; Queue waiting; public: void acquire(); void release(); } Lock::acquire() { spinLock.acquire(); if (value == BUSY) { waiting.add(myTCB); scheduler-\u003esuspend(\u0026spinLock); }else { value = BUSY; spinLock.release(); } } Lock::release() { spinLock.aquire(); if (!waiting.empty()) { next = waiting.remove(); scheduler-\u003emakeReady(next); }else { value = FREE; } spinLock.release(); } Sched::suspend(SpinLock *spinLock) { TCB* next; disableInterrupts(); // we need to disable interrupt to ensure the data consistancy? schedSpinLock.acquire(); // we need a seperate spin lock to protect the ready list spinLock-\u003erelease(); runningThread-\u003estate = WAITING; next = readyList.remove(); runningThread = next; thread_switch(myTCB, next); runningThread-\u003e RUNNING; schedSpinLock-\u003erelease(); enableInterrupts(); } Notice that the suspend() can resume the thread stopped by yield(). why we want interrupt if the interrupt handler need to modify the ready list, then it will acquire the spin lock that may be held by others. DEAD LOCK! Sched::makeReady(TCB* thread) { disableInterrupt(); schedSpinLock.acquire(); readyList.add(thread); thread-\u003estate = READY; schedSpinLock.release(); enableInterrupts(); } IMPORTANT: in Lock::acquire(), can we release the spinLock right after the waiting.add()? Because other threads may do sth before we change the readyList. maybe makeReady the thread that we are about to suspend. You won’t have a dead lock. But I’m about to put myself to waitList having a state of WAITING after someone put me in the readyList. The problem here is that every thread in ready list should have a state of ready, it’s about the data consistency. It’s not a bug though We really need to acqurie the lock in a order so that we don’t generate a gap between and may produce flaws. ","date":"2021-12-25","objectID":"/os_slides_note/:3:1","series":[],"tags":["OS"],"title":"OS 2","uri":"/os_slides_note/#spinlock-issue"},{"categories":["Note"],"content":"Spinlock issue Spinlock::acquire() { while (testAndSet(\u0026lockValue) == BUSY){ } } Spinlock::release() { lockValue = FREE } // downside: a waste of cpu resources // fairness issues: generally cannot assure fairness How to solve it? we may try to make the spinlock less aggressive. for perfomance and we should have a wait queue? for fairness // There might be multiple threads trying to acquire the lock and put themselves into the wait list. So there will be race conditions(since you will have the pointers to move and change). // Thus, they have to be synchronized == they have to be protected by another lock -- a spinlock class Lock { private: SpinLock spinLock; // == to protext the lock data structure int value = FREE; Queue waiting; public: void acquire(); void release(); } Lock::acquire() { spinLock.acquire(); if (value == BUSY) { waiting.add(myTCB); scheduler-suspend(\u0026spinLock); }else { value = BUSY; spinLock.release(); } } Lock::release() { spinLock.aquire(); if (!waiting.empty()) { next = waiting.remove(); scheduler-makeReady(next); }else { value = FREE; } spinLock.release(); } Sched::suspend(SpinLock *spinLock) { TCB* next; disableInterrupts(); // we need to disable interrupt to ensure the data consistancy? schedSpinLock.acquire(); // we need a seperate spin lock to protect the ready list spinLock-release(); runningThread-state = WAITING; next = readyList.remove(); runningThread = next; thread_switch(myTCB, next); runningThread- RUNNING; schedSpinLock-release(); enableInterrupts(); } Notice that the suspend() can resume the thread stopped by yield(). why we want interrupt if the interrupt handler need to modify the ready list, then it will acquire the spin lock that may be held by others. DEAD LOCK! Sched::makeReady(TCB* thread) { disableInterrupt(); schedSpinLock.acquire(); readyList.add(thread); thread-state = READY; schedSpinLock.release(); enableInterrupts(); } IMPORTANT: in Lock::acquire(), can we release the spinLock right after the waiting.add()? Because other threads may do sth before we change the readyList. maybe makeReady the thread that we are about to suspend. You won’t have a dead lock. But I’m about to put myself to waitList having a state of WAITING after someone put me in the readyList. The problem here is that every thread in ready list should have a state of ready, it’s about the data consistency. It’s not a bug though We really need to acqurie the lock in a order so that we don’t generate a gap between and may produce flaws. ","date":"2021-12-25","objectID":"/os_slides_note/:3:1","series":[],"tags":["OS"],"title":"OS 2","uri":"/os_slides_note/#how-to-solve-it"},{"categories":["Note"],"content":"Spinlock issue Spinlock::acquire() { while (testAndSet(\u0026lockValue) == BUSY){ } } Spinlock::release() { lockValue = FREE } // downside: a waste of cpu resources // fairness issues: generally cannot assure fairness How to solve it? we may try to make the spinlock less aggressive. for perfomance and we should have a wait queue? for fairness // There might be multiple threads trying to acquire the lock and put themselves into the wait list. So there will be race conditions(since you will have the pointers to move and change). // Thus, they have to be synchronized == they have to be protected by another lock -- a spinlock class Lock { private: SpinLock spinLock; // == to protext the lock data structure int value = FREE; Queue waiting; public: void acquire(); void release(); } Lock::acquire() { spinLock.acquire(); if (value == BUSY) { waiting.add(myTCB); scheduler-suspend(\u0026spinLock); }else { value = BUSY; spinLock.release(); } } Lock::release() { spinLock.aquire(); if (!waiting.empty()) { next = waiting.remove(); scheduler-makeReady(next); }else { value = FREE; } spinLock.release(); } Sched::suspend(SpinLock *spinLock) { TCB* next; disableInterrupts(); // we need to disable interrupt to ensure the data consistancy? schedSpinLock.acquire(); // we need a seperate spin lock to protect the ready list spinLock-release(); runningThread-state = WAITING; next = readyList.remove(); runningThread = next; thread_switch(myTCB, next); runningThread- RUNNING; schedSpinLock-release(); enableInterrupts(); } Notice that the suspend() can resume the thread stopped by yield(). why we want interrupt if the interrupt handler need to modify the ready list, then it will acquire the spin lock that may be held by others. DEAD LOCK! Sched::makeReady(TCB* thread) { disableInterrupt(); schedSpinLock.acquire(); readyList.add(thread); thread-state = READY; schedSpinLock.release(); enableInterrupts(); } IMPORTANT: in Lock::acquire(), can we release the spinLock right after the waiting.add()? Because other threads may do sth before we change the readyList. maybe makeReady the thread that we are about to suspend. You won’t have a dead lock. But I’m about to put myself to waitList having a state of WAITING after someone put me in the readyList. The problem here is that every thread in ready list should have a state of ready, it’s about the data consistency. It’s not a bug though We really need to acqurie the lock in a order so that we don’t generate a gap between and may produce flaws. ","date":"2021-12-25","objectID":"/os_slides_note/:3:1","series":[],"tags":["OS"],"title":"OS 2","uri":"/os_slides_note/#why-we-want-interrupt"},{"categories":["Note"],"content":"Lecture 20 Ordering, Condition Variable IMPORTANT, EXAM: why should we release the lock in suspend() rather than in the acquire() after waiting.add() // If we release the spinLock right after the waiting.add(), we will fail to keep the consistency. Other thread may get in and put that thread we just added in to the waiting list in the ready list. // And since the state update and switch() does not get to run, the vals of the TCB get put in the ready list is stale. // So when get resumed, it kind of walking back the time. Since the pointer to the code section may still point to somewhere it has executed in the past. Exam may ask where the lastest timing we can put the release() ","date":"2021-12-25","objectID":"/os_slides_note/:4:0","series":[],"tags":["OS"],"title":"OS 2","uri":"/os_slides_note/#lecture-20-ordering-condition-variable"},{"categories":["Note"],"content":"Ordering we can do thread_join() for every thread thread_join() is like a waiting list to synchronize all threads Shared Bounded Buffer A bounded buffer is shared among multiple threads for message exchange producer threads put items into the buffer (sending the message) consumerj thread get items from the buffer (receiving a message) Requirement: each message is received by only one thread. implementation // Consumer while(!(item=tryget())) { } use(item); // producer while(!tryput(item) { } tryget() { item = NULL; lock.acquire(); if (front \u003c tail) { item = buf(front % MAX); front++; notify threads waiting on condition (tail - front) \u003c MAX } else { go to sleep on condition front \u003c tail put thread on waiting list and release the lock lock.acquire } lock.release(); return item; } tryput(item) { success = 0; lock.acquire(); if (tail - front != 0) { buf(tail % MAX) = item; tail++; success = 1; notify threads waiting on condition front \u003c tail } else { go to sleep on condition (tail - front) \u003c MAX put thread on waiting list and release the lock lock.acquire } lock.release(); return success; } // need to have separate waiting queues for differnent conditions of interest Should we assume the condition is right after being waken up. NO!! Since other threads may take over in between right after the thread was woken up. How to fix this? tryget() { item = NULL; lock.acquire(); while (!(front \u003c tail) { go to sleep on condition front \u003c tail put thread on waiting list and release the lock // context switch (suspend or yield) lock.acquire } item = buf(front % MAX); front++; notify threads waiting on condition (tail - front) \u003c MAX lock.release(); return item; } tryput(item) { success = 0; lock.acquire(); while (!((tail - front) \u003c MAX)) { go to sleep on condition (tail - front) \u003c MAX put thread on waiting list and release the lock // context switch (suspend or yield) lock.acquire } buf(tail % MAX) = item; tail++; success = 1; notify threads waiting on condition front \u003c tail lock.release(); return success; } ","date":"2021-12-25","objectID":"/os_slides_note/:4:1","series":[],"tags":["OS"],"title":"OS 2","uri":"/os_slides_note/#ordering"},{"categories":["Note"],"content":"Ordering we can do thread_join() for every thread thread_join() is like a waiting list to synchronize all threads Shared Bounded Buffer A bounded buffer is shared among multiple threads for message exchange producer threads put items into the buffer (sending the message) consumerj thread get items from the buffer (receiving a message) Requirement: each message is received by only one thread. implementation // Consumer while(!(item=tryget())) { } use(item); // producer while(!tryput(item) { } tryget() { item = NULL; lock.acquire(); if (front ","date":"2021-12-25","objectID":"/os_slides_note/:4:1","series":[],"tags":["OS"],"title":"OS 2","uri":"/os_slides_note/#shared-bounded-buffer"},{"categories":["Note"],"content":"Ordering we can do thread_join() for every thread thread_join() is like a waiting list to synchronize all threads Shared Bounded Buffer A bounded buffer is shared among multiple threads for message exchange producer threads put items into the buffer (sending the message) consumerj thread get items from the buffer (receiving a message) Requirement: each message is received by only one thread. implementation // Consumer while(!(item=tryget())) { } use(item); // producer while(!tryput(item) { } tryget() { item = NULL; lock.acquire(); if (front ","date":"2021-12-25","objectID":"/os_slides_note/:4:1","series":[],"tags":["OS"],"title":"OS 2","uri":"/os_slides_note/#implementation"},{"categories":["Note"],"content":"Condition Variables Indicates a condition that needs to be satisfied for a thread to proceed. if condition is not satisfied, a thread can be put on a wait queue associated with the condition variable. Must call wait() inside a critical section, while holding the lock wait() atomically releases the lock and put the thread on the wait queue. when woken, reacquires the lock before returning from wait() A thread can wake thread(s) waiting on a condition variable signal broadcast ","date":"2021-12-25","objectID":"/os_slides_note/:4:2","series":[],"tags":["OS"],"title":"OS 2","uri":"/os_slides_note/#condition-variables"},{"categories":["Note"],"content":"CV Design Pattern methodThatWaits() { lock.acquire(); // R/W shared state while (!testSharedState()) { cv.wait(\u0026lock); } // R/W shared state lock.release(); } methodThatSignals() { lock.acquire(); // R/W shared state // if testSharedState is no true cv.signal(); // R/W shared state lock.release(); } ","date":"2021-12-25","objectID":"/os_slides_note/:4:3","series":[],"tags":["OS"],"title":"OS 2","uri":"/os_slides_note/#cv-design-pattern"},{"categories":["Note"],"content":"Shared Bounded Buffer get() { lock.acquire(); while(front == tail) { empty.wait(\u0026lock); } item = buf[front % MAX]; front++; full.signal(); lock.release(); return item; } put(item) { lock.acquire(); while ((tail - front) == MAX) { full.wait(\u0026lock); } buf[tail % MAX] = item; tail++; empty.signal(); lock.release*(); } // Initially: front = tail = 0; MAX is buffer capacity // empty/full are condition variables pre/post CV ","date":"2021-12-25","objectID":"/os_slides_note/:4:4","series":[],"tags":["OS"],"title":"OS 2","uri":"/os_slides_note/#shared-bounded-buffer-1"},{"categories":["Note"],"content":"Key Pionts for CV ALWAYS hold lock when calling wait, signal, broadcast Condition variable is sync FOR shared state ALWAYS hold lock when accessing shared state CV is memoryless if signal when no one is waiting, no op if wait before signal, waiter wakes up Wait atomically releases lock and put the thread into waiting list why? we might lost the signal, since before putting the thread into the waiting list, the signal might be emitted. When a thread is woken up from wait, it may not run immediately (this is why we need to put it in a loop) signal/broadcast put thread on ready list Wait MUST be in a loop while(needToWait()) { condition.Wait(\u0026lock); } simplified implementation of condition vars and locks of code that uses condition vars and locks ","date":"2021-12-25","objectID":"/os_slides_note/:4:5","series":[],"tags":["OS"],"title":"OS 2","uri":"/os_slides_note/#key-pionts-for-cv"},{"categories":["Note"],"content":"CV implementation class CV { private: Queue waiting; public: void wait(lock.isHeld()); void signal(); void broadcast(); } void CV::wait(Lock *lock) { assert(lock.isHeld()); waiting.add(myTCB); scheduler.suspend(\u0026lock); lock-\u003eacquire(); } void CV::signal() { if (waiting.notEmpty()) { thread = waiting.remove(); scheduler.makeReady(thread); } } void CV::broadcast() { while (waiting.notEmpty()) { thread = waiting.remove(); scheduler.makeReady(thread); } } ","date":"2021-12-25","objectID":"/os_slides_note/:4:6","series":[],"tags":["OS"],"title":"OS 2","uri":"/os_slides_note/#cv-implementation"},{"categories":["Note"],"content":"Lecture 21 Semaphore (Dijkstra again) One execution sequence waits for another purpose 1: mutual exclusion purpose 2: ordering (we use CV) Block oneself Unblock others Mutual Exclusion Lock.acquire() Lock.release() Ordering Cond.wait() Cond.signal() ","date":"2021-12-25","objectID":"/os_slides_note/:5:0","series":[],"tags":["OS"],"title":"OS 2","uri":"/os_slides_note/#lecture-21-semaphore"},{"categories":["Note"],"content":"Semaphore Concept Semaphore has a non-negative integer value P() atomically waits for value to become \u003e 0,. then decrements V() atomically increments value (waking up waiter if needed) Operations are atomic e.g., if value is 1, two P’s will result in value 0 and one waiter Block oneself Unblock others Mutual Exclusion Sem.P() Sem.V() Ordering Sem.P() Sem.V() Prob: it may hard to understand the code since this is too elegant Init val! Sem.init(N) sets an initial value of the semaphore The init val determines the behavior of the semaphore in subsequent use Using Sem for Mutual Exclusion Sem.init(1) EXAM: how to implement sth in Semaphore! The atomic means the whole things have to be atomic. From sem operations to wake up funciont and increment/decrement are all atomic! When we use with a init of 1, we call it binary sem, since it works like a lock. Using Sem for Ordering why you can’t do sem_mutex.P() first? // Becase if you do a sem_full.P(), you can potentially get blocked. // You can only be woken up by another thread using V(). // However, you are holding the sem_mutex.P() so that nobody can get in // DEAD LOCK! empty is init with 0 and full is init with MAX. Since the put() will work first and get() will wait first. Notice: For singals, they can emit singals and nobody is waiting. But for V(), if no one is waiting, then we will change the val! Which is not acceptable. V() will increment the val by 1. Signal is memoryless, but V() is not. Thus,semaphore is harder to implement. Also, for signal, when you wake up, you have to check the condition since it can be false by then. However, semaphore is differnent. Sem for CV? ","date":"2021-12-25","objectID":"/os_slides_note/:5:1","series":[],"tags":["OS"],"title":"OS 2","uri":"/os_slides_note/#semaphore-concept"},{"categories":["Note"],"content":"Semaphore Concept Semaphore has a non-negative integer value P() atomically waits for value to become 0,. then decrements V() atomically increments value (waking up waiter if needed) Operations are atomic e.g., if value is 1, two P’s will result in value 0 and one waiter Block oneself Unblock others Mutual Exclusion Sem.P() Sem.V() Ordering Sem.P() Sem.V() Prob: it may hard to understand the code since this is too elegant Init val! Sem.init(N) sets an initial value of the semaphore The init val determines the behavior of the semaphore in subsequent use Using Sem for Mutual Exclusion Sem.init(1) EXAM: how to implement sth in Semaphore! The atomic means the whole things have to be atomic. From sem operations to wake up funciont and increment/decrement are all atomic! When we use with a init of 1, we call it binary sem, since it works like a lock. Using Sem for Ordering why you can’t do sem_mutex.P() first? // Becase if you do a sem_full.P(), you can potentially get blocked. // You can only be woken up by another thread using V(). // However, you are holding the sem_mutex.P() so that nobody can get in // DEAD LOCK! empty is init with 0 and full is init with MAX. Since the put() will work first and get() will wait first. Notice: For singals, they can emit singals and nobody is waiting. But for V(), if no one is waiting, then we will change the val! Which is not acceptable. V() will increment the val by 1. Signal is memoryless, but V() is not. Thus,semaphore is harder to implement. Also, for signal, when you wake up, you have to check the condition since it can be false by then. However, semaphore is differnent. Sem for CV? ","date":"2021-12-25","objectID":"/os_slides_note/:5:1","series":[],"tags":["OS"],"title":"OS 2","uri":"/os_slides_note/#init-val"},{"categories":["Note"],"content":"Semaphore Concept Semaphore has a non-negative integer value P() atomically waits for value to become 0,. then decrements V() atomically increments value (waking up waiter if needed) Operations are atomic e.g., if value is 1, two P’s will result in value 0 and one waiter Block oneself Unblock others Mutual Exclusion Sem.P() Sem.V() Ordering Sem.P() Sem.V() Prob: it may hard to understand the code since this is too elegant Init val! Sem.init(N) sets an initial value of the semaphore The init val determines the behavior of the semaphore in subsequent use Using Sem for Mutual Exclusion Sem.init(1) EXAM: how to implement sth in Semaphore! The atomic means the whole things have to be atomic. From sem operations to wake up funciont and increment/decrement are all atomic! When we use with a init of 1, we call it binary sem, since it works like a lock. Using Sem for Ordering why you can’t do sem_mutex.P() first? // Becase if you do a sem_full.P(), you can potentially get blocked. // You can only be woken up by another thread using V(). // However, you are holding the sem_mutex.P() so that nobody can get in // DEAD LOCK! empty is init with 0 and full is init with MAX. Since the put() will work first and get() will wait first. Notice: For singals, they can emit singals and nobody is waiting. But for V(), if no one is waiting, then we will change the val! Which is not acceptable. V() will increment the val by 1. Signal is memoryless, but V() is not. Thus,semaphore is harder to implement. Also, for signal, when you wake up, you have to check the condition since it can be false by then. However, semaphore is differnent. Sem for CV? ","date":"2021-12-25","objectID":"/os_slides_note/:5:1","series":[],"tags":["OS"],"title":"OS 2","uri":"/os_slides_note/#using-sem-for-mutual-exclusion"},{"categories":["Note"],"content":"Semaphore Concept Semaphore has a non-negative integer value P() atomically waits for value to become 0,. then decrements V() atomically increments value (waking up waiter if needed) Operations are atomic e.g., if value is 1, two P’s will result in value 0 and one waiter Block oneself Unblock others Mutual Exclusion Sem.P() Sem.V() Ordering Sem.P() Sem.V() Prob: it may hard to understand the code since this is too elegant Init val! Sem.init(N) sets an initial value of the semaphore The init val determines the behavior of the semaphore in subsequent use Using Sem for Mutual Exclusion Sem.init(1) EXAM: how to implement sth in Semaphore! The atomic means the whole things have to be atomic. From sem operations to wake up funciont and increment/decrement are all atomic! When we use with a init of 1, we call it binary sem, since it works like a lock. Using Sem for Ordering why you can’t do sem_mutex.P() first? // Becase if you do a sem_full.P(), you can potentially get blocked. // You can only be woken up by another thread using V(). // However, you are holding the sem_mutex.P() so that nobody can get in // DEAD LOCK! empty is init with 0 and full is init with MAX. Since the put() will work first and get() will wait first. Notice: For singals, they can emit singals and nobody is waiting. But for V(), if no one is waiting, then we will change the val! Which is not acceptable. V() will increment the val by 1. Signal is memoryless, but V() is not. Thus,semaphore is harder to implement. Also, for signal, when you wake up, you have to check the condition since it can be false by then. However, semaphore is differnent. Sem for CV? ","date":"2021-12-25","objectID":"/os_slides_note/:5:1","series":[],"tags":["OS"],"title":"OS 2","uri":"/os_slides_note/#using-sem-for-ordering"},{"categories":["Note"],"content":"Semaphore Concept Semaphore has a non-negative integer value P() atomically waits for value to become 0,. then decrements V() atomically increments value (waking up waiter if needed) Operations are atomic e.g., if value is 1, two P’s will result in value 0 and one waiter Block oneself Unblock others Mutual Exclusion Sem.P() Sem.V() Ordering Sem.P() Sem.V() Prob: it may hard to understand the code since this is too elegant Init val! Sem.init(N) sets an initial value of the semaphore The init val determines the behavior of the semaphore in subsequent use Using Sem for Mutual Exclusion Sem.init(1) EXAM: how to implement sth in Semaphore! The atomic means the whole things have to be atomic. From sem operations to wake up funciont and increment/decrement are all atomic! When we use with a init of 1, we call it binary sem, since it works like a lock. Using Sem for Ordering why you can’t do sem_mutex.P() first? // Becase if you do a sem_full.P(), you can potentially get blocked. // You can only be woken up by another thread using V(). // However, you are holding the sem_mutex.P() so that nobody can get in // DEAD LOCK! empty is init with 0 and full is init with MAX. Since the put() will work first and get() will wait first. Notice: For singals, they can emit singals and nobody is waiting. But for V(), if no one is waiting, then we will change the val! Which is not acceptable. V() will increment the val by 1. Signal is memoryless, but V() is not. Thus,semaphore is harder to implement. Also, for signal, when you wake up, you have to check the condition since it can be false by then. However, semaphore is differnent. Sem for CV? ","date":"2021-12-25","objectID":"/os_slides_note/:5:1","series":[],"tags":["OS"],"title":"OS 2","uri":"/os_slides_note/#why-you-cant-do-sem_mutexp-first"},{"categories":["Note"],"content":"Semaphore Concept Semaphore has a non-negative integer value P() atomically waits for value to become 0,. then decrements V() atomically increments value (waking up waiter if needed) Operations are atomic e.g., if value is 1, two P’s will result in value 0 and one waiter Block oneself Unblock others Mutual Exclusion Sem.P() Sem.V() Ordering Sem.P() Sem.V() Prob: it may hard to understand the code since this is too elegant Init val! Sem.init(N) sets an initial value of the semaphore The init val determines the behavior of the semaphore in subsequent use Using Sem for Mutual Exclusion Sem.init(1) EXAM: how to implement sth in Semaphore! The atomic means the whole things have to be atomic. From sem operations to wake up funciont and increment/decrement are all atomic! When we use with a init of 1, we call it binary sem, since it works like a lock. Using Sem for Ordering why you can’t do sem_mutex.P() first? // Becase if you do a sem_full.P(), you can potentially get blocked. // You can only be woken up by another thread using V(). // However, you are holding the sem_mutex.P() so that nobody can get in // DEAD LOCK! empty is init with 0 and full is init with MAX. Since the put() will work first and get() will wait first. Notice: For singals, they can emit singals and nobody is waiting. But for V(), if no one is waiting, then we will change the val! Which is not acceptable. V() will increment the val by 1. Signal is memoryless, but V() is not. Thus,semaphore is harder to implement. Also, for signal, when you wake up, you have to check the condition since it can be false by then. However, semaphore is differnent. Sem for CV? ","date":"2021-12-25","objectID":"/os_slides_note/:5:1","series":[],"tags":["OS"],"title":"OS 2","uri":"/os_slides_note/#sem-for-cv"},{"categories":["Note"],"content":"Bottom Like regarding Semaphore an elegant and uniform solution for Synchronization Require careful design, in particular mapping the semaphore’s initial value to problem domain can be confusing, especially since it can be used for two very differnent purposes Recommendation for general programming: stick with lock and CV ","date":"2021-12-25","objectID":"/os_slides_note/:5:2","series":[],"tags":["OS"],"title":"OS 2","uri":"/os_slides_note/#bottom-like-regarding-semaphore"},{"categories":["Note"],"content":"Concurrency Bugs (safty: race condition progress: dead lock or starvation) did not apply Synchronization deadlock or starvation The Dining Philosopher Problem Principled Synchronization identfy objs or data structures that can be accessed by multiple threads Concurrency in OS kernel, everything Add locks to objs/module grab lock on start to every method/procedure Release lock on finish If need to wait while (needToWait()){condition.Wait(lock);} do not assume when you wake up the condition has become true if do sth that might wake someone up signal or broadcast always leave shared state vars in a consistent state when lock is released, or when entering waiting if need to acquire multiple locks, use the same order across all threads ","date":"2021-12-25","objectID":"/os_slides_note/:5:3","series":[],"tags":["OS"],"title":"OS 2","uri":"/os_slides_note/#concurrency-bugs"},{"categories":["Note"],"content":"Concurrency Bugs (safty: race condition progress: dead lock or starvation) did not apply Synchronization deadlock or starvation The Dining Philosopher Problem Principled Synchronization identfy objs or data structures that can be accessed by multiple threads Concurrency in OS kernel, everything Add locks to objs/module grab lock on start to every method/procedure Release lock on finish If need to wait while (needToWait()){condition.Wait(lock);} do not assume when you wake up the condition has become true if do sth that might wake someone up signal or broadcast always leave shared state vars in a consistent state when lock is released, or when entering waiting if need to acquire multiple locks, use the same order across all threads ","date":"2021-12-25","objectID":"/os_slides_note/:5:3","series":[],"tags":["OS"],"title":"OS 2","uri":"/os_slides_note/#the-dining-philosopher-problem"},{"categories":["Note"],"content":"Concurrency Bugs (safty: race condition progress: dead lock or starvation) did not apply Synchronization deadlock or starvation The Dining Philosopher Problem Principled Synchronization identfy objs or data structures that can be accessed by multiple threads Concurrency in OS kernel, everything Add locks to objs/module grab lock on start to every method/procedure Release lock on finish If need to wait while (needToWait()){condition.Wait(lock);} do not assume when you wake up the condition has become true if do sth that might wake someone up signal or broadcast always leave shared state vars in a consistent state when lock is released, or when entering waiting if need to acquire multiple locks, use the same order across all threads ","date":"2021-12-25","objectID":"/os_slides_note/:5:3","series":[],"tags":["OS"],"title":"OS 2","uri":"/os_slides_note/#principled-synchronization"},{"categories":["Note"],"content":"persistence Closer to the CPU, faster CPU–Mem–Graphics– ","date":"2021-12-25","objectID":"/persistence/:0:0","series":[],"tags":["OS"],"title":"OS 3","uri":"/persistence/#persistence"},{"categories":["Note"],"content":"canonical protocol for programmed I/O Interface: statue: busy or not command data internal: CPU MEM other chips ","date":"2021-12-25","objectID":"/persistence/:0:1","series":[],"tags":["OS"],"title":"OS 3","uri":"/persistence/#canonical-protocol-for-programmed-io"},{"categories":["Note"],"content":"Q should the program running in kernel or user mode? in kernel. you don’t want the user level program to touch the devices directly, since devices are shared bewteen processes. Device doesn’t not have any protection from other processes. It can change the data on behalf of anyone. ","date":"2021-12-25","objectID":"/persistence/:0:2","series":[],"tags":["OS"],"title":"OS 3","uri":"/persistence/#q"},{"categories":["Note"],"content":"key features of programmed IO CPU is involved every step of the way A process invkes a system call, which results in device access Under PIO, the process is spinning on the CPU waiting for the IO to complete cons: kernel involved everywhere since devices are so slow compareing with cpu, cpu has to do a lot of unuseful spinning to do status check. just like what we do for the spinning lock. pros: simple and straight forward cpu will keep checking so no time is wasted once the devices are available, so the responsive time is good. ","date":"2021-12-25","objectID":"/persistence/:0:3","series":[],"tags":["OS"],"title":"OS 3","uri":"/persistence/#key-features-of-programmed-io"},{"categories":["Note"],"content":"Scheduling Picture ","date":"2021-12-25","objectID":"/persistence/:0:4","series":[],"tags":["OS"],"title":"OS 3","uri":"/persistence/#scheduling-picture"},{"categories":["Note"],"content":"Other approach: interrupt you don’t need to keep pooling, the device will raise the exception to interrupt, and the handler will deal with it. pro: no wasting of cpu source con: if there are a lot of i/o devices, and they wake up one by one? the interrupts will happen consecutively. So interrupt does have overhead. canonical protocol for programmed io very low latencty, it’s watching. the moment it’s ready, it leaves interrupt need to go wait and switch back. overhead always there. Latency for some device it’s ok, but not for everyone. use programmed io if fast response is needed Q: if a process si running in the interrupt mode in a system call, and it goes to sleep. which mode is the process in? (running ready blocked?) it’s blocked. instead in programmed io mode, the process is running. ","date":"2021-12-25","objectID":"/persistence/:0:5","series":[],"tags":["OS"],"title":"OS 3","uri":"/persistence/#other-approach-interrupt"},{"categories":["Note"],"content":"Other approach: interrupt you don’t need to keep pooling, the device will raise the exception to interrupt, and the handler will deal with it. pro: no wasting of cpu source con: if there are a lot of i/o devices, and they wake up one by one? the interrupts will happen consecutively. So interrupt does have overhead. canonical protocol for programmed io very low latencty, it’s watching. the moment it’s ready, it leaves interrupt need to go wait and switch back. overhead always there. Latency for some device it’s ok, but not for everyone. use programmed io if fast response is needed Q: if a process si running in the interrupt mode in a system call, and it goes to sleep. which mode is the process in? (running ready blocked?) it’s blocked. instead in programmed io mode, the process is running. ","date":"2021-12-25","objectID":"/persistence/:0:5","series":[],"tags":["OS"],"title":"OS 3","uri":"/persistence/#canonical-protocol-for-programmed-io-1"},{"categories":["Note"],"content":"Other approach: interrupt you don’t need to keep pooling, the device will raise the exception to interrupt, and the handler will deal with it. pro: no wasting of cpu source con: if there are a lot of i/o devices, and they wake up one by one? the interrupts will happen consecutively. So interrupt does have overhead. canonical protocol for programmed io very low latencty, it’s watching. the moment it’s ready, it leaves interrupt need to go wait and switch back. overhead always there. Latency for some device it’s ok, but not for everyone. use programmed io if fast response is needed Q: if a process si running in the interrupt mode in a system call, and it goes to sleep. which mode is the process in? (running ready blocked?) it’s blocked. instead in programmed io mode, the process is running. ","date":"2021-12-25","objectID":"/persistence/:0:5","series":[],"tags":["OS"],"title":"OS 3","uri":"/persistence/#interrupt"},{"categories":["Note"],"content":"Other approach: interrupt you don’t need to keep pooling, the device will raise the exception to interrupt, and the handler will deal with it. pro: no wasting of cpu source con: if there are a lot of i/o devices, and they wake up one by one? the interrupts will happen consecutively. So interrupt does have overhead. canonical protocol for programmed io very low latencty, it’s watching. the moment it’s ready, it leaves interrupt need to go wait and switch back. overhead always there. Latency for some device it’s ok, but not for everyone. use programmed io if fast response is needed Q: if a process si running in the interrupt mode in a system call, and it goes to sleep. which mode is the process in? (running ready blocked?) it’s blocked. instead in programmed io mode, the process is running. ","date":"2021-12-25","objectID":"/persistence/:0:5","series":[],"tags":["OS"],"title":"OS 3","uri":"/persistence/#use-programmed-io-if-fast-response-is-needed"},{"categories":["Note"],"content":"Further improvement: DMA even with interrupt, cpu is still involved in all data transfers Direct Memory Access allows devices to transfer data to/from memory without CPU involvement. CPU sets up DMA, and context switch to run other process when mem transfer finishes, interrupt raised Kernel interrupt handler runs and wakes up the sleeping process DMA uses kernel page table there are some space reserved for dma so that kernel know where they are, just like how driver files are set. the kernel page table can have physical mem 1-1 matched scheduling pic ","date":"2021-12-25","objectID":"/persistence/:0:6","series":[],"tags":["OS"],"title":"OS 3","uri":"/persistence/#further-improvement-dma"},{"categories":["Note"],"content":"Further improvement: DMA even with interrupt, cpu is still involved in all data transfers Direct Memory Access allows devices to transfer data to/from memory without CPU involvement. CPU sets up DMA, and context switch to run other process when mem transfer finishes, interrupt raised Kernel interrupt handler runs and wakes up the sleeping process DMA uses kernel page table there are some space reserved for dma so that kernel know where they are, just like how driver files are set. the kernel page table can have physical mem 1-1 matched scheduling pic ","date":"2021-12-25","objectID":"/persistence/:0:6","series":[],"tags":["OS"],"title":"OS 3","uri":"/persistence/#dma-uses-kernel-page-table"},{"categories":["Note"],"content":"Further improvement: DMA even with interrupt, cpu is still involved in all data transfers Direct Memory Access allows devices to transfer data to/from memory without CPU involvement. CPU sets up DMA, and context switch to run other process when mem transfer finishes, interrupt raised Kernel interrupt handler runs and wakes up the sleeping process DMA uses kernel page table there are some space reserved for dma so that kernel know where they are, just like how driver files are set. the kernel page table can have physical mem 1-1 matched scheduling pic ","date":"2021-12-25","objectID":"/persistence/:0:6","series":[],"tags":["OS"],"title":"OS 3","uri":"/persistence/#scheduling-pic"},{"categories":["Note"],"content":"Device Driver software dealing with devices part of kernel (a big portion) provide uniform abstraction for OS to interact with various types of devices ","date":"2021-12-25","objectID":"/persistence/:0:7","series":[],"tags":["OS"],"title":"OS 3","uri":"/persistence/#device-driver"},{"categories":["Note"],"content":"Linux software stack regarding File System Assuming we have 4 disks!!! ","date":"2021-12-25","objectID":"/persistence/:0:8","series":[],"tags":["OS"],"title":"OS 3","uri":"/persistence/#linux-software-stack-regarding-file-system"},{"categories":["Note"],"content":"Linux software stack regarding File System Assuming we have 4 disks!!! ","date":"2021-12-25","objectID":"/persistence/:0:8","series":[],"tags":["OS"],"title":"OS 3","uri":"/persistence/#assuming-we-have-4-disks"},{"categories":["Note"],"content":"RAID: redundant arrays of inexpensive disks RAID0: no replication –\u003e Striping capacity: 4 * S bytes, where each disk store S bytes performance: sequential read/write: 4 * times bandwidth random read/write: same as snigle disk reliability: no improvement on reliability, any disk failure means the sys fails RAID1: mirror data across two or more disks –\u003e mirroring RAID1-0: stripe of mirror –\u003e 0011 2233 4455 6677 mirror of strip –\u003e 0101 2323 4545 6767 capacity: performance: 2 * S sequential read: 2 times since the disk head moving take time to skip blocks sequential write: 2 * bandwidth as a single disk random read: same as single random write: write both copys at same time, about the same as single disk, slightly higher Reliability: Tolerate one total disk failure RAID4/5: split data across disks bit-wise XOR all blocks in the same stripe, and store the result in the parity block Can reconstruct any missing block from the others RAID 4/5 differ on how parity blocks are distributed read is like raid 0 with one fewer disk write will additionly write the parity disk! for example, if we only change 2, then we can change P0 by (old_p0 XOR old_2) XOR new_2 so To write one block: read old data read old p write new data write new p = (old_p0 XOR old_2) XOR new_2 RAID4 0123 P0 4567 P2 … Performance: the writing process is bottle neck RAID5: rotating parity p0 0 1 2 3 4 p1 5 6 7 … Raid4/5: capacity: 4 * S bytes performance: sequential read: 4 sequential write: bottle necked by parity disk for raid 4, improve for raid5 Reliability: any single disk failure can be tolerated ","date":"2021-12-25","objectID":"/persistence/:0:9","series":[],"tags":["OS"],"title":"OS 3","uri":"/persistence/#raid-redundant-arrays-of-inexpensive-disks"},{"categories":["Note"],"content":"Unix File System to understand the design principles of a very important file system A few main considerations in Unix File sys Design provide a uniform structure for naming and accessing data objects throughout the system Enable data sharing between different programs Ensure consistency with concurrent access acheve good performance/reliability balance hard drive is slow, buffer si important care need to be taken to account for failure Naming file file are organized in a directory tree a dir is also a file —\u003e mapping from name to inode inode is the Unix sys internal data structure for a file ​ inode number uniquely identifies a file across the system FIle sys Metadata Inode: stored in persistent storage, and cached in mem for faster access Directory: special file that contains mapping from names in that dir to their inode numbers Operating on Files ","date":"2021-12-25","objectID":"/persistence/:0:10","series":[],"tags":["OS"],"title":"OS 3","uri":"/persistence/#unix-file-system"},{"categories":["Note"],"content":"Unix File System to understand the design principles of a very important file system A few main considerations in Unix File sys Design provide a uniform structure for naming and accessing data objects throughout the system Enable data sharing between different programs Ensure consistency with concurrent access acheve good performance/reliability balance hard drive is slow, buffer si important care need to be taken to account for failure Naming file file are organized in a directory tree a dir is also a file — mapping from name to inode inode is the Unix sys internal data structure for a file ​ inode number uniquely identifies a file across the system FIle sys Metadata Inode: stored in persistent storage, and cached in mem for faster access Directory: special file that contains mapping from names in that dir to their inode numbers Operating on Files ","date":"2021-12-25","objectID":"/persistence/:0:10","series":[],"tags":["OS"],"title":"OS 3","uri":"/persistence/#a-few-main-considerations-in-unix-file-sys-design"},{"categories":["Note"],"content":"Unix File System to understand the design principles of a very important file system A few main considerations in Unix File sys Design provide a uniform structure for naming and accessing data objects throughout the system Enable data sharing between different programs Ensure consistency with concurrent access acheve good performance/reliability balance hard drive is slow, buffer si important care need to be taken to account for failure Naming file file are organized in a directory tree a dir is also a file — mapping from name to inode inode is the Unix sys internal data structure for a file ​ inode number uniquely identifies a file across the system FIle sys Metadata Inode: stored in persistent storage, and cached in mem for faster access Directory: special file that contains mapping from names in that dir to their inode numbers Operating on Files ","date":"2021-12-25","objectID":"/persistence/:0:10","series":[],"tags":["OS"],"title":"OS 3","uri":"/persistence/#naming-file"},{"categories":["Note"],"content":"Unix File System to understand the design principles of a very important file system A few main considerations in Unix File sys Design provide a uniform structure for naming and accessing data objects throughout the system Enable data sharing between different programs Ensure consistency with concurrent access acheve good performance/reliability balance hard drive is slow, buffer si important care need to be taken to account for failure Naming file file are organized in a directory tree a dir is also a file — mapping from name to inode inode is the Unix sys internal data structure for a file ​ inode number uniquely identifies a file across the system FIle sys Metadata Inode: stored in persistent storage, and cached in mem for faster access Directory: special file that contains mapping from names in that dir to their inode numbers Operating on Files ","date":"2021-12-25","objectID":"/persistence/:0:10","series":[],"tags":["OS"],"title":"OS 3","uri":"/persistence/#file-sys-metadata"},{"categories":["Note"],"content":"Unix File System to understand the design principles of a very important file system A few main considerations in Unix File sys Design provide a uniform structure for naming and accessing data objects throughout the system Enable data sharing between different programs Ensure consistency with concurrent access acheve good performance/reliability balance hard drive is slow, buffer si important care need to be taken to account for failure Naming file file are organized in a directory tree a dir is also a file — mapping from name to inode inode is the Unix sys internal data structure for a file ​ inode number uniquely identifies a file across the system FIle sys Metadata Inode: stored in persistent storage, and cached in mem for faster access Directory: special file that contains mapping from names in that dir to their inode numbers Operating on Files ","date":"2021-12-25","objectID":"/persistence/:0:10","series":[],"tags":["OS"],"title":"OS 3","uri":"/persistence/#operating-on-files"},{"categories":["Note"],"content":"von Neumann Architecture (realization of Turing Machine) ","date":"2021-12-25","objectID":"/os_review/:0:0","series":[],"tags":["OS"],"title":"OS Review","uri":"/os_review/#"},{"categories":["Note"],"content":"What are programs? Process – a running program To allow for running multiple processes, a running program must be able to be interrupted OS provides a virtualization of CPUs, so each program can assume they have their “own” virtual CPU at its disposal ","date":"2021-12-25","objectID":"/os_review/:0:1","series":[],"tags":["OS"],"title":"OS Review","uri":"/os_review/#what-are-programs"},{"categories":["Note"],"content":"Memory Space of a Program A variable of a program corresponds to a location in memory Code address, e.g., function entrance addresses, corresponds to a location in memory ","date":"2021-12-25","objectID":"/os_review/:0:2","series":[],"tags":["OS"],"title":"OS Review","uri":"/os_review/#memory-space-of-a-program"},{"categories":["Note"],"content":"Concurrency Two scenarios of concurrency Interleaving Parallel execution Concurrency when happening on shared data May lead to undefined result under thread semantics Have to apply synchronization to ensure consistent semantics ","date":"2021-12-25","objectID":"/os_review/:0:3","series":[],"tags":["OS"],"title":"OS Review","uri":"/os_review/#concurrency"},{"categories":["Note"],"content":"Three Easy Pieces Virtualization Concurrency Persistence ","date":"2021-12-25","objectID":"/os_review/:0:4","series":[],"tags":["OS"],"title":"OS Review","uri":"/os_review/#three-easy-pieces"},{"categories":["Note"],"content":"How CPU virtualization can be realized One Straightforward Approach OS emulates the real CPU Each instruction is interpreted by the OS, as opposed to running on the bare metal. OS has full control of a process, and can interrupt it at will. OS can refuse to run an instruction that directly accesses I/O. What is the drawback? Very slow. Does not fully utilize the hardware’s capability Direct Execution Let processes’ code run directly on CPU How to preempt a running process? Timer interrupt. Need to be frequent enough, e.g., every a few ms. Interrupt handler is run upon an interrupt. Interrupt is widely used to handle device I/O. Exception can also interrupt a running process. How to protect OS from the processes? What about kernel code in memory? How to protect processes from one another? Kernel needs to do A LOT OF book keeping. Let’s introduce a few important concepts about processes Let’s look at some important UNIX process APIs ","date":"2021-12-25","objectID":"/os_review/:0:5","series":[],"tags":["OS"],"title":"OS Review","uri":"/os_review/#how-cpu-virtualization-can-be-realized"},{"categories":["Note"],"content":"What are the main problems to be solved? How to preempt a process How to protect shared resources, i.e., I/O –I/O shall not be directly accessed by processes. All access to I/O must be mediated by OS. The CPU must be able to distinguish two different modes: in one mode, the instructions running are those of the processes; in the other mode, the instructions running are those of the OS. We call the prior mode user mode, and the second mode kernel mode. Notion of OS Kernel: An OS kernel consists of code that runs on behalf of the OS N.B., this does not include OS library code In user mode, certain instructions are not permitted. Examples? If a process attempts to execute one such instruction, the CPU will raise an exception and the process will be interrupted In kernel mode, all instructions are allowed. When the CPU starts up, it is normally in kernel mode. Transition between the two modes. from kernel to user – simpler, since OS is in control from user to kernel – care must be taken to ensure protection How to protect OS from the processes? – wait until Virtual Memory How to protect processes from one another. – wait until Virtual Memory Performance \u0026 Efficiency Other considerations Parallel execution ","date":"2021-12-25","objectID":"/os_review/:0:6","series":[],"tags":["OS"],"title":"OS Review","uri":"/os_review/#what-are-the-main-problems-to-be-solved"},{"categories":["Note"],"content":"Context Switches Always between user mode and kernel mode Can a process directly switch to another process without going through kernel? to do so the first process would need to access the other process’s context information, and change the process’s status to running it will also need to switch to the other process’s virtual memory. It will be very hard to grant these privileges, without giving out too much. Reasons for context switches/Cases of Trapping into Kernel Hardware interrupt Timer Device I/O etc. Exception Illegal instruction Non-permitted instruction System calls Requesting kernel to preform privileged operations on the process’s behalf ","date":"2021-12-25","objectID":"/os_review/:0:7","series":[],"tags":["OS"],"title":"OS Review","uri":"/os_review/#context-switches"},{"categories":["Note"],"content":"Kernel vs. User Mode Kernel code runs at full privilege (a.k.a. privileged execution) All instructions are available All physical memory is available Direct access to hardware I/O is available Process code runs at restricted privilege Certain instructions are not permitted – we will encounter quite a few Direct access to physical memory is not possible – more to be discussed later Direct access to hardware I/O is prohibited Don’t take it for granted! ","date":"2021-12-25","objectID":"/os_review/:0:8","series":[],"tags":["OS"],"title":"OS Review","uri":"/os_review/#kernel-vs-user-mode"},{"categories":["Note"],"content":"How context switches can be implemented How to trap into kernel hardware interrupt e.g., timer interrupt… Save the context of the process interrupted CPU saves PC value at the interrupt CPU saves SR at the interrupt CPU/OS saves GRs at the interrupt Transfer control to kernel CPU saves the current SP, find out the current process’s kernel stack through a special register, and changes SP to point to that kernel stack CPU finds out the address of the IDT through a special register IDTR CPU indexes into IDT, finds out the entrance address of the interrupt handler, and populates PC with the address CPU changes from user mode to kernel mode Update book-keeping OS changes the interrupted process from ”running” to “ready” state OS populates the relevant field in PCB regarding the interrupted process’s context info How to return from a trap return from a special return instruction How to switch to a different process while returning from a trap basic notions: PC (program counter): CPU register pointing to the next instruction to fetch SP (stack pointer): CPU register pointing to the current top of stack GR (general registers): CPU general registers for storing temporary results SR (status register): Current CPU status, e.g., arithmetic operation results A device notifies a CPU for an interrupting event through hard-wired signal The CPU can tell which device has sent an interrupt Interrupts from different devices are assigned different numbers, i.e., interrupt no. CPU checks whether there is interrupt waiting, before fetching the next instruction ","date":"2021-12-25","objectID":"/os_review/:0:9","series":[],"tags":["OS"],"title":"OS Review","uri":"/os_review/#how-context-switches-can-be-implemented"},{"categories":["Note"],"content":"Case Study: x86 Interrupt Mechanism Basic PC (program counter): EIP SP (stack pointer): ESP GR (general registers): EAX, EBX, … SR (status register): EFLAGS x86 adopts segmentation in addressing, so each address also needs to have a segment For code, need to use the CS segment register Thus program counter is CS:EIP For stack, need to use the SS segment register Thus stack pointer is SS:ESP ","date":"2021-12-25","objectID":"/os_review/:0:10","series":[],"tags":["OS"],"title":"OS Review","uri":"/os_review/#case-study-x86-interrupt-mechanism"},{"categories":["Note"],"content":"Resume execution of the interrupted process Revert the operating at the beginning of the interrupt Restore the GRs to the value at interrupt Restore SP/SR/PC to the value at interrupt Change CPU mode from kernel to user Part of this is done through a “trap return” instruction The semantics of the trap return instruction is the contract between the hardware and OS The kernel can decide how to fulfill the rest ","date":"2021-12-25","objectID":"/os_review/:0:11","series":[],"tags":["OS"],"title":"OS Review","uri":"/os_review/#resume-execution-of-the-interrupted-process"},{"categories":["Note"],"content":"Resume execution of a different process Similar to before, but using another process’s context Also need to change CPU register pointing to the new process’s kernel stack OS needs to maintain each process’s context consistently, and be able to find the context when needed. ","date":"2021-12-25","objectID":"/os_review/:0:12","series":[],"tags":["OS"],"title":"OS Review","uri":"/os_review/#resume-execution-of-a-different-process"},{"categories":["Note"],"content":"Maintaining each process’s context It is extremely important that kernel maintains each process’s context consistently The biggest part of an OS kernel’s job is book-keeping! Typically the kernel maintains a process control block (PCB) data structure for each active process. The process’s current status The process’s context to resume running The process’s kernel stack (interrupt stack) location ","date":"2021-12-25","objectID":"/os_review/:0:13","series":[],"tags":["OS"],"title":"OS Review","uri":"/os_review/#maintaining-each-processs-context"},{"categories":["Note"],"content":"Other ways of trapping into kernel Exception Similar to interrupt, except that when exception happens, the PC points to the offending instruction, as opposed to the next instruction The hardware may inform CPU the specific nature of the exception through an error number. System call User process explicitly traps into kernel, by invoking a specific interrupt number through “software interrupt” In x86: the “int N” instruction System call number is passed through a register, in x86 it is %EAX All parameters of a system call must be copied into kernel and checked ","date":"2021-12-25","objectID":"/os_review/:0:14","series":[],"tags":["OS"],"title":"OS Review","uri":"/os_review/#other-ways-of-trapping-into-kernel"},{"categories":["Note"],"content":"How system call can be implemented ","date":"2021-12-25","objectID":"/os_review/:0:15","series":[],"tags":["OS"],"title":"OS Review","uri":"/os_review/#how-system-call-can-be-implemented"},{"categories":["Note"],"content":"Important UNIX process APIs Unix History Developed by Dennis Ritchie and Ken Thompson at AT\u0026T Bell Labs Adapted some ideas from the Multics project in 1969 Use man command to read manuals of commands and system calls “man -a topic”: returns all entries on topic Type “q” to exit an entry and move on to the next one UNIX Process APIs fork() Memory space, open files, environmental variables wait() exec() Redirecting input/output An open file is assigned a numeric number as its “file descriptor” 0: standard input 1: standard output 2: standard error UNIX pipes: pipe() returns a unidirectional message queue between processes for inter-process communication Returns two file descriptors, d0 and d1. Bytes written on d1 will be read from d0 in the same order. Use the dup() system call to redirect standard input and output ","date":"2021-12-25","objectID":"/os_review/:0:16","series":[],"tags":["OS"],"title":"OS Review","uri":"/os_review/#important-unix-process-apis"},{"categories":["Note"],"content":"CPU Scheduling ","date":"2021-12-25","objectID":"/os_review/:1:0","series":[],"tags":["OS"],"title":"OS Review","uri":"/os_review/#cpu-scheduling"},{"categories":["Note"],"content":"Policy vs. Mechanisms We have introduced the mechanism of context switches Before returning from kernel space to user space, OS needs to decide which user level process to resume The determination of the choice of which process to resume is the “Policy” ","date":"2021-12-25","objectID":"/os_review/:1:1","series":[],"tags":["OS"],"title":"OS Review","uri":"/os_review/#policy-vs-mechanisms"},{"categories":["Note"],"content":"Desired Properties of the Scheduling Policy What do you think are good outcomes (so we try to achieve them) Fair: Each process occupies about the same amount of CPU time This needs to be modulated through priority I/O intensive processes shall have higher priority How to achieve fairness when every process has the same priority? Two different notions of time: elapsed time vs. virtual time OS can keep track of virtual time of all processes Scheduler always picks the one with the lowest virtual time to run What do you think are bad outcomes (so we try to avoid them) What if a new process joins later? – needs to be adjusted Approach 1: initialize a new process’s virtual time to that of the minimum of the currently ready processes What if a process was blocked in I/O, and is now ready to run. It will have a lower virtual time compared with the other ready processes. Adversarial processes can potentially game the system to deprive other processes opportunity to make progress ","date":"2021-12-25","objectID":"/os_review/:1:2","series":[],"tags":["OS"],"title":"OS Review","uri":"/os_review/#desired-properties-of-the-scheduling-policy"},{"categories":["Note"],"content":"Goals of the Scheduling Policy Metrics on which the algorithm tries to optimize Turnaround time Average interval length from task arrival till completion Response time (fairness) Average interval length from task arrival till “response” For simplicity, we interpret “response” as the first time a task is scheduled The two metrics are trade-offs Optimizing on one will jeopardize the other ","date":"2021-12-25","objectID":"/os_review/:1:3","series":[],"tags":["OS"],"title":"OS Review","uri":"/os_review/#goals-of-the-scheduling-policy"},{"categories":["Note"],"content":"The FIFO policy ","date":"2021-12-25","objectID":"/os_review/:1:4","series":[],"tags":["OS"],"title":"OS Review","uri":"/os_review/#the-fifo-policy"},{"categories":["Note"],"content":"Shortest Time-to-Completion First (STCF) ","date":"2021-12-25","objectID":"/os_review/:1:5","series":[],"tags":["OS"],"title":"OS Review","uri":"/os_review/#shortest-time-to-completion-first-stcf"},{"categories":["Note"],"content":"Shortest Job First (SJF) –Historical Coverage ","date":"2021-12-25","objectID":"/os_review/:1:6","series":[],"tags":["OS"],"title":"OS Review","uri":"/os_review/#shortest-job-first-sjf-historical-coverage"},{"categories":["Note"],"content":"Round Robin ","date":"2021-12-25","objectID":"/os_review/:1:7","series":[],"tags":["OS"],"title":"OS Review","uri":"/os_review/#round-robin"},{"categories":["Note"],"content":"When a Process is Blocked by I/O It cannot be scheduled until it is woken up What shall the scheduling policy be? If a process is more interactive with users, it will more often be blocked by I/O. ","date":"2021-12-25","objectID":"/os_review/:1:8","series":[],"tags":["OS"],"title":"OS Review","uri":"/os_review/#when-a-process-is-blocked-by-io"},{"categories":["Note"],"content":"Two Well Known Scheduling Algorithms ","date":"2021-12-25","objectID":"/os_review/:2:0","series":[],"tags":["OS"],"title":"OS Review","uri":"/os_review/#two-well-known-scheduling-algorithms"},{"categories":["Note"],"content":"关于C的函数套娃！以下为错误案例！ void LevelOne(Obj* ptr) {LevelTwo(ptr)} void LevelTwo(Obj* ptr){...} {LevelThree(\u0026ptr)} void LevelThree(Obj** ptr){...} {......} int main(void) { Object* ptr = BuildObjArr(); LevelOne(ptr); } 上述code中，我们试图在第三层函数中对main中ptr指针本身进行修改。 然而在第二层函数向第三层函数传参数时，传入的是第二层函数中（ptr的拷贝）的地址，并非main中ptr的地址，所以在第三层函数，我们操作的指针实际上是levelTwo中的ptr的内容！ 修改code应为 void LevelOne(Obj** ptrptr) {LevelTwo(ptrptr)} void LevelTwo(Obj** ptrptr){...} {LevelThree(ptrptr)} void LevelThree(Obj** ptrptr){...} {......} int main(void) { Object* ptr = BuildObjArr(); LevelOne(\u0026ptr); } 当然，实际的code不需要这样实现，只要层层传入的参数是main中ptr的地址即可。 void GetMemory( char *p ) { p = (char *) malloc( 100 ); } void Test( void ) { char *str = NULL; GetMemory( str ); strcpy( str, \"hello world\" ); printf( str ); } 程序崩溃: 更改的是函数内的str的copy的指向，形参的改变未影响实参 char *GetMemory( void ) { char p[] = \"hello world\"; return p; } void Test( void ) { char *str = NULL; str = GetMemory(); printf( str ); } 可能返回乱码： 因为 GetMemory 返回的是指向“栈内存”的指针，该指针的地址不是 NULL，但其原现的内容已经被清除，新内容不可知。 p[]数组为函数内的局部自动变量,在函数返回后,内存已经被释放。这是许多程序员常犯的错误,其根源在于不理解变量的生存期 p[0] []和的优先度一定要注意 否则access的逻辑完全不同 编译器也不一定会报错 因为语法上没问题！！ //assign NULL to the pointer after free() to avoid wild pointer! free(ptr); ptr = NULL; 各种语言下的不同默认初始化值 同种语言下 class struct global local的初始化默认值 在struct里 不能初始化成员 当对pointer所指向的对象进行操作时，边界条件一定要考虑空指针的情况，否则会出现错误！ free时，也要考虑是否会free空指针！ a可以被看做指向数组首地址的指针。但是！这种说法在以下两种情况下不成立： sizeof(a); \u0026a; c语言中不允许在函数外部给全局变量赋值 全局中无法用变量作为数组长度，除非用macro （一部分编译器即使变量已经在生命时初始化了也不行） 注意各种遍历方式的区别和坑 掌握递归与非递归的遍历 怎么用 C 语言画出二叉树的图形：绘制2dbuffer？ 按层打印？ 怎么加线 波兰表示法与表达式树 归并排序 空间复杂度O(1)的实现方法 有没有退化 怎么实现的？（手摇算法 or 其他） 路由算法 双递归的进出栈 解释一下双递归：（遇到双递归问题时，当第一个递归执行的时候，第二个递归并不是不执行，而是先进栈，根据顺序来，简单明了的解释就是，第一个递归你该怎么走就怎么走，完全没什么可以阻挡你，第二个递归就不同了，他是在第一个递归的基础上执行的，但不是立刻执行，而是执行递归进栈，当第一个递归完全执行技术的时候，第二个递归出栈，开始慢慢执行！） 把arr为结构体数组，把arr赋值给结构体指针p，free(p)之后，arr指向的之前malloc的内存块都free了，但是p仍指向原地址，成为了野指针！记得要assign NULL! 允许可独立编译单元内存在未定义的函数 不允许可独立编译单元内存在未定义存储（数据类型）！ 可独立编译单元就是指.c文件 也就是说，在.h里声明一个struct 但是没有写具体定义，如果对应的.c文件没有具体定义，则编译失败，因为不清楚结构体的大小。 switch(foo) { case 1: int i = 42; // i exists all the way to the end of the switch dostuff(i); break; case 2: dostuff(i*2); // i is *also* in scope here, but is not initialized! } 报错的原因在于，switch语句中，在一个case里声明的变量，如果没有被{}包含，则在后续的cases中是可见的，但是 they will not be initialized because the initialization code belongs to another case. In the code above, if foo equals 1, everything is ok, but if it equals 2, we’ll accidentally use the i variable which does exist but probably contains garbage. ","date":"2021-12-25","objectID":"/pitfalls/:0:0","series":[],"tags":["C"],"title":"Pitfalls in C","uri":"/pitfalls/#"},{"categories":["Note"],"content":"Single-Source Shortest Paths Problem Motivation G(V,E,W) where V is the vertices, E is the edges, W is the weights Dijkstra (for non-negative weight edges) O(VlgV + E) where E = O(V2) Bellmen-Ford O(VE) Weighted graphs path p = \u003c v0, v1,…, vk\u003e ( vi, vi+1 ) ∈ E for 0 ≤ i \u003c k w(p) = ∑w( vi, vi+1 ) from 0 to k-1 find p with minimum weight v0 –p–\u003e vk is a path from v0 to vk shortest path weight from u to v as ẟ(u,v) = {min{w(p) : u –p–\u003e v} exsits, otherwise ∞} why BFS and DFS don’t work in this case? see recitation… notice that shorstest path ≠ path with min weight To get the sequence of vertices, we define the predecessor relationship d(v): value indside circle(current weight) π[v]: predecessor on current best path to v, π[s] = NIL when d(v) == 𝜹 Done More specific explanation, see the lecture note Negative weights Negative cycles what’s the termination condition? how to detect the negative cycle? General structure of shortest path algorithms (no negative cycles) Initialize for v ∈ V d[v] \u003c– ∞ π[v] \u003c– NIL d[S] \u003c– 0 repeat select edge (u,v) if d[v] \u003e d[u] + w[u,v] d[v] \u003c– d[u] + w[u,v] π[v] \u003c– u until all edges have d[v] ≤ d[u] + w(u,v) BUT! it’s brutal force and slow O(2n/2) T(0) = 0 T(n+2) = 2T(n) + 3 update d(n+2) 2 times and d(n+1) 1 time T(n) = 3 + 2x3 + 4x3 + … + 2n/2x3 = O(2n/2) Optimal Substructure Subpath of shortest paths are shortest paths ","date":"2021-12-25","objectID":"/single-source-shortest-paths-problem/:0:1","series":[],"tags":["Algorithm"],"title":"Single-Source Shortest Paths Problem","uri":"/single-source-shortest-paths-problem/#single-source-shortest-paths-problem"},{"categories":["Note"],"content":"Single-Source Shortest Paths Problem Motivation G(V,E,W) where V is the vertices, E is the edges, W is the weights Dijkstra (for non-negative weight edges) O(VlgV + E) where E = O(V2) Bellmen-Ford O(VE) Weighted graphs path p = ( vi, vi+1 ) ∈ E for 0 ≤ i vk is a path from v0 to vk shortest path weight from u to v as ẟ(u,v) = {min{w(p) : u –p– v} exsits, otherwise ∞} why BFS and DFS don’t work in this case? see recitation… notice that shorstest path ≠ path with min weight To get the sequence of vertices, we define the predecessor relationship d(v): value indside circle(current weight) π[v]: predecessor on current best path to v, π[s] = NIL when d(v) == 𝜹 Done More specific explanation, see the lecture note Negative weights Negative cycles what’s the termination condition? how to detect the negative cycle? General structure of shortest path algorithms (no negative cycles) Initialize for v ∈ V d[v] d[u] + w[u,v] d[v] ","date":"2021-12-25","objectID":"/single-source-shortest-paths-problem/:0:1","series":[],"tags":["Algorithm"],"title":"Single-Source Shortest Paths Problem","uri":"/single-source-shortest-paths-problem/#motivation"},{"categories":["Note"],"content":"Single-Source Shortest Paths Problem Motivation G(V,E,W) where V is the vertices, E is the edges, W is the weights Dijkstra (for non-negative weight edges) O(VlgV + E) where E = O(V2) Bellmen-Ford O(VE) Weighted graphs path p = ( vi, vi+1 ) ∈ E for 0 ≤ i vk is a path from v0 to vk shortest path weight from u to v as ẟ(u,v) = {min{w(p) : u –p– v} exsits, otherwise ∞} why BFS and DFS don’t work in this case? see recitation… notice that shorstest path ≠ path with min weight To get the sequence of vertices, we define the predecessor relationship d(v): value indside circle(current weight) π[v]: predecessor on current best path to v, π[s] = NIL when d(v) == 𝜹 Done More specific explanation, see the lecture note Negative weights Negative cycles what’s the termination condition? how to detect the negative cycle? General structure of shortest path algorithms (no negative cycles) Initialize for v ∈ V d[v] d[u] + w[u,v] d[v] ","date":"2021-12-25","objectID":"/single-source-shortest-paths-problem/:0:1","series":[],"tags":["Algorithm"],"title":"Single-Source Shortest Paths Problem","uri":"/single-source-shortest-paths-problem/#dijkstra-for-non-negative-weight-edges"},{"categories":["Note"],"content":"Single-Source Shortest Paths Problem Motivation G(V,E,W) where V is the vertices, E is the edges, W is the weights Dijkstra (for non-negative weight edges) O(VlgV + E) where E = O(V2) Bellmen-Ford O(VE) Weighted graphs path p = ( vi, vi+1 ) ∈ E for 0 ≤ i vk is a path from v0 to vk shortest path weight from u to v as ẟ(u,v) = {min{w(p) : u –p– v} exsits, otherwise ∞} why BFS and DFS don’t work in this case? see recitation… notice that shorstest path ≠ path with min weight To get the sequence of vertices, we define the predecessor relationship d(v): value indside circle(current weight) π[v]: predecessor on current best path to v, π[s] = NIL when d(v) == 𝜹 Done More specific explanation, see the lecture note Negative weights Negative cycles what’s the termination condition? how to detect the negative cycle? General structure of shortest path algorithms (no negative cycles) Initialize for v ∈ V d[v] d[u] + w[u,v] d[v] ","date":"2021-12-25","objectID":"/single-source-shortest-paths-problem/:0:1","series":[],"tags":["Algorithm"],"title":"Single-Source Shortest Paths Problem","uri":"/single-source-shortest-paths-problem/#bellmen-ford"},{"categories":["Note"],"content":"Single-Source Shortest Paths Problem Motivation G(V,E,W) where V is the vertices, E is the edges, W is the weights Dijkstra (for non-negative weight edges) O(VlgV + E) where E = O(V2) Bellmen-Ford O(VE) Weighted graphs path p = ( vi, vi+1 ) ∈ E for 0 ≤ i vk is a path from v0 to vk shortest path weight from u to v as ẟ(u,v) = {min{w(p) : u –p– v} exsits, otherwise ∞} why BFS and DFS don’t work in this case? see recitation… notice that shorstest path ≠ path with min weight To get the sequence of vertices, we define the predecessor relationship d(v): value indside circle(current weight) π[v]: predecessor on current best path to v, π[s] = NIL when d(v) == 𝜹 Done More specific explanation, see the lecture note Negative weights Negative cycles what’s the termination condition? how to detect the negative cycle? General structure of shortest path algorithms (no negative cycles) Initialize for v ∈ V d[v] d[u] + w[u,v] d[v] ","date":"2021-12-25","objectID":"/single-source-shortest-paths-problem/:0:1","series":[],"tags":["Algorithm"],"title":"Single-Source Shortest Paths Problem","uri":"/single-source-shortest-paths-problem/#weighted-graphs"},{"categories":["Note"],"content":"Single-Source Shortest Paths Problem Motivation G(V,E,W) where V is the vertices, E is the edges, W is the weights Dijkstra (for non-negative weight edges) O(VlgV + E) where E = O(V2) Bellmen-Ford O(VE) Weighted graphs path p = ( vi, vi+1 ) ∈ E for 0 ≤ i vk is a path from v0 to vk shortest path weight from u to v as ẟ(u,v) = {min{w(p) : u –p– v} exsits, otherwise ∞} why BFS and DFS don’t work in this case? see recitation… notice that shorstest path ≠ path with min weight To get the sequence of vertices, we define the predecessor relationship d(v): value indside circle(current weight) π[v]: predecessor on current best path to v, π[s] = NIL when d(v) == 𝜹 Done More specific explanation, see the lecture note Negative weights Negative cycles what’s the termination condition? how to detect the negative cycle? General structure of shortest path algorithms (no negative cycles) Initialize for v ∈ V d[v] d[u] + w[u,v] d[v] ","date":"2021-12-25","objectID":"/single-source-shortest-paths-problem/:0:1","series":[],"tags":["Algorithm"],"title":"Single-Source Shortest Paths Problem","uri":"/single-source-shortest-paths-problem/#negative-weights"},{"categories":["Note"],"content":"Single-Source Shortest Paths Problem Motivation G(V,E,W) where V is the vertices, E is the edges, W is the weights Dijkstra (for non-negative weight edges) O(VlgV + E) where E = O(V2) Bellmen-Ford O(VE) Weighted graphs path p = ( vi, vi+1 ) ∈ E for 0 ≤ i vk is a path from v0 to vk shortest path weight from u to v as ẟ(u,v) = {min{w(p) : u –p– v} exsits, otherwise ∞} why BFS and DFS don’t work in this case? see recitation… notice that shorstest path ≠ path with min weight To get the sequence of vertices, we define the predecessor relationship d(v): value indside circle(current weight) π[v]: predecessor on current best path to v, π[s] = NIL when d(v) == 𝜹 Done More specific explanation, see the lecture note Negative weights Negative cycles what’s the termination condition? how to detect the negative cycle? General structure of shortest path algorithms (no negative cycles) Initialize for v ∈ V d[v] d[u] + w[u,v] d[v] ","date":"2021-12-25","objectID":"/single-source-shortest-paths-problem/:0:1","series":[],"tags":["Algorithm"],"title":"Single-Source Shortest Paths Problem","uri":"/single-source-shortest-paths-problem/#general-structure-of-shortest-path-algorithms-no-negative-cycles"},{"categories":["Note"],"content":"Single-Source Shortest Paths Problem Motivation G(V,E,W) where V is the vertices, E is the edges, W is the weights Dijkstra (for non-negative weight edges) O(VlgV + E) where E = O(V2) Bellmen-Ford O(VE) Weighted graphs path p = ( vi, vi+1 ) ∈ E for 0 ≤ i vk is a path from v0 to vk shortest path weight from u to v as ẟ(u,v) = {min{w(p) : u –p– v} exsits, otherwise ∞} why BFS and DFS don’t work in this case? see recitation… notice that shorstest path ≠ path with min weight To get the sequence of vertices, we define the predecessor relationship d(v): value indside circle(current weight) π[v]: predecessor on current best path to v, π[s] = NIL when d(v) == 𝜹 Done More specific explanation, see the lecture note Negative weights Negative cycles what’s the termination condition? how to detect the negative cycle? General structure of shortest path algorithms (no negative cycles) Initialize for v ∈ V d[v] d[u] + w[u,v] d[v] ","date":"2021-12-25","objectID":"/single-source-shortest-paths-problem/:0:1","series":[],"tags":["Algorithm"],"title":"Single-Source Shortest Paths Problem","uri":"/single-source-shortest-paths-problem/#optimal-substructure"},{"categories":["Note"],"content":"Software Architectural Patterns ","date":"2021-12-25","objectID":"/software-architectural-patterns/:0:0","series":[],"tags":["Architectural Pattern"],"title":"Software Arch Patterns","uri":"/software-architectural-patterns/#software-architectural-patterns"},{"categories":["Note"],"content":"Layered pattern ","date":"2021-12-25","objectID":"/software-architectural-patterns/:1:0","series":[],"tags":["Architectural Pattern"],"title":"Software Arch Patterns","uri":"/software-architectural-patterns/#layered-pattern"},{"categories":["Note"],"content":"Client-server pattern ","date":"2021-12-25","objectID":"/software-architectural-patterns/:2:0","series":[],"tags":["Architectural Pattern"],"title":"Software Arch Patterns","uri":"/software-architectural-patterns/#client-server-pattern"},{"categories":["Note"],"content":"Master-slave pattern ","date":"2021-12-25","objectID":"/software-architectural-patterns/:3:0","series":[],"tags":["Architectural Pattern"],"title":"Software Arch Patterns","uri":"/software-architectural-patterns/#master-slave-pattern"},{"categories":["Note"],"content":"Pipe-filter pattern ","date":"2021-12-25","objectID":"/software-architectural-patterns/:4:0","series":[],"tags":["Architectural Pattern"],"title":"Software Arch Patterns","uri":"/software-architectural-patterns/#pipe-filter-pattern"},{"categories":["Note"],"content":"Broker pattern ","date":"2021-12-25","objectID":"/software-architectural-patterns/:5:0","series":[],"tags":["Architectural Pattern"],"title":"Software Arch Patterns","uri":"/software-architectural-patterns/#broker-pattern"},{"categories":["Note"],"content":"Peer-to-peer pattern ","date":"2021-12-25","objectID":"/software-architectural-patterns/:6:0","series":[],"tags":["Architectural Pattern"],"title":"Software Arch Patterns","uri":"/software-architectural-patterns/#peer-to-peer-pattern"},{"categories":["Note"],"content":"Event-bus pattern ","date":"2021-12-25","objectID":"/software-architectural-patterns/:7:0","series":[],"tags":["Architectural Pattern"],"title":"Software Arch Patterns","uri":"/software-architectural-patterns/#event-bus-pattern"},{"categories":["Note"],"content":"Model-view-controller pattern ","date":"2021-12-25","objectID":"/software-architectural-patterns/:8:0","series":[],"tags":["Architectural Pattern"],"title":"Software Arch Patterns","uri":"/software-architectural-patterns/#model-view-controller-pattern"},{"categories":["Note"],"content":"Blackboard pattern ","date":"2021-12-25","objectID":"/software-architectural-patterns/:9:0","series":[],"tags":["Architectural Pattern"],"title":"Software Arch Patterns","uri":"/software-architectural-patterns/#blackboard-pattern"},{"categories":["Note"],"content":"Interpreter pattern ","date":"2021-12-25","objectID":"/software-architectural-patterns/:10:0","series":[],"tags":["Architectural Pattern"],"title":"Software Arch Patterns","uri":"/software-architectural-patterns/#interpreter-pattern"},{"categories":["Note"],"content":"SQL ","date":"2021-12-25","objectID":"/sql/:0:0","series":[],"tags":["SQL"],"title":"SQL","uri":"/sql/#sql"},{"categories":["Note"],"content":"Intro DB is any collection of related info Computer is great for storing databases DBMS is the software to create, maintain, and secure a database. SQL is a language DBMS allow you to perform the CRUD operations and other administrative tasks Two types of DB, Relational and Non-Relational Relational DB use SQL and store data in tables with rows and columes Non-Relational data store data using other data structures ","date":"2021-12-25","objectID":"/sql/:0:1","series":[],"tags":["SQL"],"title":"SQL","uri":"/sql/#intro"},{"categories":["Note"],"content":"Table and Keys emp ID Name date Supervisors ID Branch ID 100 Null 1 101 100 3 102 101 2 Here emp ID is the primary key of the table brach ID is the foreign key that is the primary key of another table(or itselt) Foreign key helps to define the relationship of tables Sometimes we need composite keys which contains multiple atributes(more than one keys) since any one of keys is not able to uniquely identify a row emp id client id sales 107 500 55456 107 403 8765 102 403 9963 emp id and client id can be foreign keys linking to other tables, and these 2 keys construct the composite key. ","date":"2021-12-25","objectID":"/sql/:0:2","series":[],"tags":["SQL"],"title":"SQL","uri":"/sql/#table-and-keys"},{"categories":["Note"],"content":"SQL Basics SQL varies depending on systems but the concepts are the same SQL is a hybrid lang, a 4-in-1 lang Data Query Language(DQL) query the database for info get info already stored there Data Definition Lang(DDL) define database schemas Data Control Lang(DCL) control access to the data permission management Data Manipulation Lang(DML) insert, update, delete data Queries SELECT employee.name, employee.age FROM employee WHERE employee.salary \u003e 30000 ","date":"2021-12-25","objectID":"/sql/:0:3","series":[],"tags":["SQL"],"title":"SQL","uri":"/sql/#sql-basics"},{"categories":["Note"],"content":"SQL Basics SQL varies depending on systems but the concepts are the same SQL is a hybrid lang, a 4-in-1 lang Data Query Language(DQL) query the database for info get info already stored there Data Definition Lang(DDL) define database schemas Data Control Lang(DCL) control access to the data permission management Data Manipulation Lang(DML) insert, update, delete data Queries SELECT employee.name, employee.age FROM employee WHERE employee.salary 30000 ","date":"2021-12-25","objectID":"/sql/:0:3","series":[],"tags":["SQL"],"title":"SQL","uri":"/sql/#queries"},{"categories":["Note"],"content":"Installment mySQL download mySQL database server echo 'export PATH=/usr/local/mysql/bin:$PATH' \u003e\u003e ~/.bash_profile Notice it varies, just add the path to the configuration PopSQL popSQL which is kinda textediter ","date":"2021-12-25","objectID":"/sql/:0:4","series":[],"tags":["SQL"],"title":"SQL","uri":"/sql/#installment"},{"categories":["Note"],"content":"Installment mySQL download mySQL database server echo 'export PATH=/usr/local/mysql/bin:$PATH' ~/.bash_profile Notice it varies, just add the path to the configuration PopSQL popSQL which is kinda textediter ","date":"2021-12-25","objectID":"/sql/:0:4","series":[],"tags":["SQL"],"title":"SQL","uri":"/sql/#mysql"},{"categories":["Note"],"content":"Installment mySQL download mySQL database server echo 'export PATH=/usr/local/mysql/bin:$PATH' ~/.bash_profile Notice it varies, just add the path to the configuration PopSQL popSQL which is kinda textediter ","date":"2021-12-25","objectID":"/sql/:0:4","series":[],"tags":["SQL"],"title":"SQL","uri":"/sql/#popsql"},{"categories":["Note"],"content":"SQL Create a table INTDECIMAL(10,4)--total length of 10 and 4 after decimal point VARCHAR(1)BLOB--binary large object, stores large data DATE--YYYY-MM-DD TIMESTAMP--YYYY-MM-DD HH:MM:SS CREATETABLEstudent(student_idINTPRIMARYKEY,nameVARCHAR(20),majorVARCHAR(20)-- PRIMARY KEY(student_id) );--or you can define the primary key afterwards like above DESCRIBEstudent;DROPTABLEstudent;ALTERTABLEstudentADDgpaDECIMAL(3,2);--add column ALTERTABLEstudentDROPCOLUMNgpa;--drop column Insert data INSERTINTOstudentVALUES(1,'Jack','Biology');INSERTINTOstudentVALUES(2,'Kate','Sociology');SELECT*FROMstudent;--grab all the info from the table INSERTINTOstudent(student_id,name)VALUES(3,'Claire');INSERTINTOstudentVALUES(4,'Jack','Biology');INSERTINTOstudentVALUES(5,'Mike','Computer Science'); C CREATETABLEstudent(student_idINTUNIQUE,--student_id INT AUTO_INCREMENT, nameVARCHAR(20)NOTNULL,majorVARCHAR(20)DEFAULT'undecided');--then insert all data --primary key is both not null and unique Update and Delete UPDATEstudentSETmajor='Bio'WHEREmajor='Biology';UPDATEstudentSETmajor='Comp Sci'WHEREstudent_id=1ORmajor='Chemistry'UPDATEstudentSETname='Tom',Major='Undecided'WHEREstudent_id=1;UPDATEstudentSETmajor='undecided';DELETEFROMstudent;--delete all columns and rows DELETEFROMstudentWHEREstudent_id=5ANDmajor='undecided'; Basic Queries SELECT*FROMstudent;SELECTstudent.name,student.majorFROMstudentORDERBYstudent_idDESC;SELECTname,majorFROMstudentORDERBYmajor,student_idLIMIT3WHEREmajor='Biology'ORname\u003c\u003e'Kate';-- \u003c, \u003e, \u003c=, \u003e=, =, \u003c\u003e, AND, OR SELECT*FROMstudentWHEREnameIN('Claire','Kate','Mike'); Company Database Into CREATETABLEemployee(emp_idINTPRIMARYKEY,first_nameVARCHAR(40),last_nameVARCHAR(40),birth_dayDATE,sexVARCHAR(1),salaryINT,super_idINT,branch_idINT);CREATETABLEbranch(branch_idINTPRIMARYKEY,branch_nameVARCHAR(40),mgr_idINT,mgr_start_dateDATE,FOREIGNKEY(mgr_id)REFERENCESemployee(emp_id)ONDELETESETNULL);ALTERTABLEemployeeADDFOREIGNKEY(branch_id)REFERENCESbranch(branch_id)ONDELETESETNULL;ALTERTABLEemployeeADDFOREIGNKEY(super_id)REFERENCESemployee(emp_id)ONDELETESETNULL;CREATETABLEclient(client_idINTPRIMARYKEY,client_nameVARCHAR(40),branch_idINT,FOREIGNKEY(branch_id)REFERENCESbranch(branch_id)ONDELETESETNULL);CREATETABLEworks_with(emp_idINT,client_idINT,total_salesINT,PRIMARYKEY(emp_id,client_id),FOREIGNKEY(emp_id)REFERENCESemployee(emp_id)ONDELETECASCADE,FOREIGNKEY(client_id)REFERENCESclient(client_id)ONDELETECASCADE);CREATETABLEbranch_supplier(branch_idINT,supplier_nameVARCHAR(40),supply_typeVARCHAR(40),PRIMARYKEY(branch_id,supplier_name),FOREIGNKEY(branch_id)REFERENCESbranch(branch_id)ONDELETECASCADE);-- ----------------------------------------------------------------------------- -- Corporate INSERTINTOemployeeVALUES(100,'David','Wallace','1967-11-17','M',250000,NULL,NULL);INSERTINTObranchVALUES(1,'Corporate',100,'2006-02-09');UPDATEemployeeSETbranch_id=1WHEREemp_id=100;INSERTINTOemployeeVALUES(101,'Jan','Levinson','1961-05-11','F',110000,100,1);-- Scranton INSERTINTOemployeeVALUES(102,'Michael','Scott','1964-03-15','M',75000,100,NULL);INSERTINTObranchVALUES(2,'Scranton',102,'1992-04-06');UPDATEemployeeSETbranch_id=2WHEREemp_id=102;INSERTINTOemployeeVALUES(103,'Angela','Martin','1971-06-25','F',63000,102,2);INSERTINTOemployeeVALUES(104,'Kelly','Kapoor','1980-02-05','F',55000,102,2);INSERTINTOemployeeVALUES(105,'Stanley','Hudson','1958-02-19','M',69000,102,2);-- Stamford INSERTINTOemployeeVALUES(106,'Josh','Porter','1969-09-05','M',78000,100,NULL);INSERTINTObranchVALUES(3,'Stamford',106,'1998-02-13');UPDATEemployeeSETbranch_id=3WHEREemp_id=106;INSERTINTOemployeeVALUES(107,'Andy','Bernard','1973-07-22','M',65000,106,3);INSERTINTOemployeeVALUES(108,'Jim','Halpert','1978-10-01','M',71000,106,3);-- BRANCH SUPPLIER INSERTINTObranch_supplierVALUES(2,'Hammer Mill','Paper');INSERTINTObranch_supplierVALUES(2,'Uni-ball','Writing Utensils');INSERTINTObranch_supplierVALUES(3,'Patriot Paper','Paper');INSERTINTObranch_supplierVALUES(2,'J.T. Forms \u0026 Labels','Custom","date":"2021-12-25","objectID":"/sql/:0:5","series":[],"tags":["SQL"],"title":"SQL","uri":"/sql/#sql-1"},{"categories":["Note"],"content":"SQL Create a table INTDECIMAL(10,4)--total length of 10 and 4 after decimal point VARCHAR(1)BLOB--binary large object, stores large data DATE--YYYY-MM-DD TIMESTAMP--YYYY-MM-DD HH:MM:SS CREATETABLEstudent(student_idINTPRIMARYKEY,nameVARCHAR(20),majorVARCHAR(20)-- PRIMARY KEY(student_id) );--or you can define the primary key afterwards like above DESCRIBEstudent;DROPTABLEstudent;ALTERTABLEstudentADDgpaDECIMAL(3,2);--add column ALTERTABLEstudentDROPCOLUMNgpa;--drop column Insert data INSERTINTOstudentVALUES(1,'Jack','Biology');INSERTINTOstudentVALUES(2,'Kate','Sociology');SELECT*FROMstudent;--grab all the info from the table INSERTINTOstudent(student_id,name)VALUES(3,'Claire');INSERTINTOstudentVALUES(4,'Jack','Biology');INSERTINTOstudentVALUES(5,'Mike','Computer Science'); C CREATETABLEstudent(student_idINTUNIQUE,--student_id INT AUTO_INCREMENT, nameVARCHAR(20)NOTNULL,majorVARCHAR(20)DEFAULT'undecided');--then insert all data --primary key is both not null and unique Update and Delete UPDATEstudentSETmajor='Bio'WHEREmajor='Biology';UPDATEstudentSETmajor='Comp Sci'WHEREstudent_id=1ORmajor='Chemistry'UPDATEstudentSETname='Tom',Major='Undecided'WHEREstudent_id=1;UPDATEstudentSETmajor='undecided';DELETEFROMstudent;--delete all columns and rows DELETEFROMstudentWHEREstudent_id=5ANDmajor='undecided'; Basic Queries SELECT*FROMstudent;SELECTstudent.name,student.majorFROMstudentORDERBYstudent_idDESC;SELECTname,majorFROMstudentORDERBYmajor,student_idLIMIT3WHEREmajor='Biology'ORname'Kate';-- , =, =, , AND, OR SELECT*FROMstudentWHEREnameIN('Claire','Kate','Mike'); Company Database Into CREATETABLEemployee(emp_idINTPRIMARYKEY,first_nameVARCHAR(40),last_nameVARCHAR(40),birth_dayDATE,sexVARCHAR(1),salaryINT,super_idINT,branch_idINT);CREATETABLEbranch(branch_idINTPRIMARYKEY,branch_nameVARCHAR(40),mgr_idINT,mgr_start_dateDATE,FOREIGNKEY(mgr_id)REFERENCESemployee(emp_id)ONDELETESETNULL);ALTERTABLEemployeeADDFOREIGNKEY(branch_id)REFERENCESbranch(branch_id)ONDELETESETNULL;ALTERTABLEemployeeADDFOREIGNKEY(super_id)REFERENCESemployee(emp_id)ONDELETESETNULL;CREATETABLEclient(client_idINTPRIMARYKEY,client_nameVARCHAR(40),branch_idINT,FOREIGNKEY(branch_id)REFERENCESbranch(branch_id)ONDELETESETNULL);CREATETABLEworks_with(emp_idINT,client_idINT,total_salesINT,PRIMARYKEY(emp_id,client_id),FOREIGNKEY(emp_id)REFERENCESemployee(emp_id)ONDELETECASCADE,FOREIGNKEY(client_id)REFERENCESclient(client_id)ONDELETECASCADE);CREATETABLEbranch_supplier(branch_idINT,supplier_nameVARCHAR(40),supply_typeVARCHAR(40),PRIMARYKEY(branch_id,supplier_name),FOREIGNKEY(branch_id)REFERENCESbranch(branch_id)ONDELETECASCADE);-- ----------------------------------------------------------------------------- -- Corporate INSERTINTOemployeeVALUES(100,'David','Wallace','1967-11-17','M',250000,NULL,NULL);INSERTINTObranchVALUES(1,'Corporate',100,'2006-02-09');UPDATEemployeeSETbranch_id=1WHEREemp_id=100;INSERTINTOemployeeVALUES(101,'Jan','Levinson','1961-05-11','F',110000,100,1);-- Scranton INSERTINTOemployeeVALUES(102,'Michael','Scott','1964-03-15','M',75000,100,NULL);INSERTINTObranchVALUES(2,'Scranton',102,'1992-04-06');UPDATEemployeeSETbranch_id=2WHEREemp_id=102;INSERTINTOemployeeVALUES(103,'Angela','Martin','1971-06-25','F',63000,102,2);INSERTINTOemployeeVALUES(104,'Kelly','Kapoor','1980-02-05','F',55000,102,2);INSERTINTOemployeeVALUES(105,'Stanley','Hudson','1958-02-19','M',69000,102,2);-- Stamford INSERTINTOemployeeVALUES(106,'Josh','Porter','1969-09-05','M',78000,100,NULL);INSERTINTObranchVALUES(3,'Stamford',106,'1998-02-13');UPDATEemployeeSETbranch_id=3WHEREemp_id=106;INSERTINTOemployeeVALUES(107,'Andy','Bernard','1973-07-22','M',65000,106,3);INSERTINTOemployeeVALUES(108,'Jim','Halpert','1978-10-01','M',71000,106,3);-- BRANCH SUPPLIER INSERTINTObranch_supplierVALUES(2,'Hammer Mill','Paper');INSERTINTObranch_supplierVALUES(2,'Uni-ball','Writing Utensils');INSERTINTObranch_supplierVALUES(3,'Patriot Paper','Paper');INSERTINTObranch_supplierVALUES(2,'J.T. Forms \u0026 Labels','Custom","date":"2021-12-25","objectID":"/sql/:0:5","series":[],"tags":["SQL"],"title":"SQL","uri":"/sql/#create-a-table"},{"categories":["Note"],"content":"SQL Create a table INTDECIMAL(10,4)--total length of 10 and 4 after decimal point VARCHAR(1)BLOB--binary large object, stores large data DATE--YYYY-MM-DD TIMESTAMP--YYYY-MM-DD HH:MM:SS CREATETABLEstudent(student_idINTPRIMARYKEY,nameVARCHAR(20),majorVARCHAR(20)-- PRIMARY KEY(student_id) );--or you can define the primary key afterwards like above DESCRIBEstudent;DROPTABLEstudent;ALTERTABLEstudentADDgpaDECIMAL(3,2);--add column ALTERTABLEstudentDROPCOLUMNgpa;--drop column Insert data INSERTINTOstudentVALUES(1,'Jack','Biology');INSERTINTOstudentVALUES(2,'Kate','Sociology');SELECT*FROMstudent;--grab all the info from the table INSERTINTOstudent(student_id,name)VALUES(3,'Claire');INSERTINTOstudentVALUES(4,'Jack','Biology');INSERTINTOstudentVALUES(5,'Mike','Computer Science'); C CREATETABLEstudent(student_idINTUNIQUE,--student_id INT AUTO_INCREMENT, nameVARCHAR(20)NOTNULL,majorVARCHAR(20)DEFAULT'undecided');--then insert all data --primary key is both not null and unique Update and Delete UPDATEstudentSETmajor='Bio'WHEREmajor='Biology';UPDATEstudentSETmajor='Comp Sci'WHEREstudent_id=1ORmajor='Chemistry'UPDATEstudentSETname='Tom',Major='Undecided'WHEREstudent_id=1;UPDATEstudentSETmajor='undecided';DELETEFROMstudent;--delete all columns and rows DELETEFROMstudentWHEREstudent_id=5ANDmajor='undecided'; Basic Queries SELECT*FROMstudent;SELECTstudent.name,student.majorFROMstudentORDERBYstudent_idDESC;SELECTname,majorFROMstudentORDERBYmajor,student_idLIMIT3WHEREmajor='Biology'ORname'Kate';-- , =, =, , AND, OR SELECT*FROMstudentWHEREnameIN('Claire','Kate','Mike'); Company Database Into CREATETABLEemployee(emp_idINTPRIMARYKEY,first_nameVARCHAR(40),last_nameVARCHAR(40),birth_dayDATE,sexVARCHAR(1),salaryINT,super_idINT,branch_idINT);CREATETABLEbranch(branch_idINTPRIMARYKEY,branch_nameVARCHAR(40),mgr_idINT,mgr_start_dateDATE,FOREIGNKEY(mgr_id)REFERENCESemployee(emp_id)ONDELETESETNULL);ALTERTABLEemployeeADDFOREIGNKEY(branch_id)REFERENCESbranch(branch_id)ONDELETESETNULL;ALTERTABLEemployeeADDFOREIGNKEY(super_id)REFERENCESemployee(emp_id)ONDELETESETNULL;CREATETABLEclient(client_idINTPRIMARYKEY,client_nameVARCHAR(40),branch_idINT,FOREIGNKEY(branch_id)REFERENCESbranch(branch_id)ONDELETESETNULL);CREATETABLEworks_with(emp_idINT,client_idINT,total_salesINT,PRIMARYKEY(emp_id,client_id),FOREIGNKEY(emp_id)REFERENCESemployee(emp_id)ONDELETECASCADE,FOREIGNKEY(client_id)REFERENCESclient(client_id)ONDELETECASCADE);CREATETABLEbranch_supplier(branch_idINT,supplier_nameVARCHAR(40),supply_typeVARCHAR(40),PRIMARYKEY(branch_id,supplier_name),FOREIGNKEY(branch_id)REFERENCESbranch(branch_id)ONDELETECASCADE);-- ----------------------------------------------------------------------------- -- Corporate INSERTINTOemployeeVALUES(100,'David','Wallace','1967-11-17','M',250000,NULL,NULL);INSERTINTObranchVALUES(1,'Corporate',100,'2006-02-09');UPDATEemployeeSETbranch_id=1WHEREemp_id=100;INSERTINTOemployeeVALUES(101,'Jan','Levinson','1961-05-11','F',110000,100,1);-- Scranton INSERTINTOemployeeVALUES(102,'Michael','Scott','1964-03-15','M',75000,100,NULL);INSERTINTObranchVALUES(2,'Scranton',102,'1992-04-06');UPDATEemployeeSETbranch_id=2WHEREemp_id=102;INSERTINTOemployeeVALUES(103,'Angela','Martin','1971-06-25','F',63000,102,2);INSERTINTOemployeeVALUES(104,'Kelly','Kapoor','1980-02-05','F',55000,102,2);INSERTINTOemployeeVALUES(105,'Stanley','Hudson','1958-02-19','M',69000,102,2);-- Stamford INSERTINTOemployeeVALUES(106,'Josh','Porter','1969-09-05','M',78000,100,NULL);INSERTINTObranchVALUES(3,'Stamford',106,'1998-02-13');UPDATEemployeeSETbranch_id=3WHEREemp_id=106;INSERTINTOemployeeVALUES(107,'Andy','Bernard','1973-07-22','M',65000,106,3);INSERTINTOemployeeVALUES(108,'Jim','Halpert','1978-10-01','M',71000,106,3);-- BRANCH SUPPLIER INSERTINTObranch_supplierVALUES(2,'Hammer Mill','Paper');INSERTINTObranch_supplierVALUES(2,'Uni-ball','Writing Utensils');INSERTINTObranch_supplierVALUES(3,'Patriot Paper','Paper');INSERTINTObranch_supplierVALUES(2,'J.T. Forms \u0026 Labels','Custom","date":"2021-12-25","objectID":"/sql/:0:5","series":[],"tags":["SQL"],"title":"SQL","uri":"/sql/#insert-data"},{"categories":["Note"],"content":"SQL Create a table INTDECIMAL(10,4)--total length of 10 and 4 after decimal point VARCHAR(1)BLOB--binary large object, stores large data DATE--YYYY-MM-DD TIMESTAMP--YYYY-MM-DD HH:MM:SS CREATETABLEstudent(student_idINTPRIMARYKEY,nameVARCHAR(20),majorVARCHAR(20)-- PRIMARY KEY(student_id) );--or you can define the primary key afterwards like above DESCRIBEstudent;DROPTABLEstudent;ALTERTABLEstudentADDgpaDECIMAL(3,2);--add column ALTERTABLEstudentDROPCOLUMNgpa;--drop column Insert data INSERTINTOstudentVALUES(1,'Jack','Biology');INSERTINTOstudentVALUES(2,'Kate','Sociology');SELECT*FROMstudent;--grab all the info from the table INSERTINTOstudent(student_id,name)VALUES(3,'Claire');INSERTINTOstudentVALUES(4,'Jack','Biology');INSERTINTOstudentVALUES(5,'Mike','Computer Science'); C CREATETABLEstudent(student_idINTUNIQUE,--student_id INT AUTO_INCREMENT, nameVARCHAR(20)NOTNULL,majorVARCHAR(20)DEFAULT'undecided');--then insert all data --primary key is both not null and unique Update and Delete UPDATEstudentSETmajor='Bio'WHEREmajor='Biology';UPDATEstudentSETmajor='Comp Sci'WHEREstudent_id=1ORmajor='Chemistry'UPDATEstudentSETname='Tom',Major='Undecided'WHEREstudent_id=1;UPDATEstudentSETmajor='undecided';DELETEFROMstudent;--delete all columns and rows DELETEFROMstudentWHEREstudent_id=5ANDmajor='undecided'; Basic Queries SELECT*FROMstudent;SELECTstudent.name,student.majorFROMstudentORDERBYstudent_idDESC;SELECTname,majorFROMstudentORDERBYmajor,student_idLIMIT3WHEREmajor='Biology'ORname'Kate';-- , =, =, , AND, OR SELECT*FROMstudentWHEREnameIN('Claire','Kate','Mike'); Company Database Into CREATETABLEemployee(emp_idINTPRIMARYKEY,first_nameVARCHAR(40),last_nameVARCHAR(40),birth_dayDATE,sexVARCHAR(1),salaryINT,super_idINT,branch_idINT);CREATETABLEbranch(branch_idINTPRIMARYKEY,branch_nameVARCHAR(40),mgr_idINT,mgr_start_dateDATE,FOREIGNKEY(mgr_id)REFERENCESemployee(emp_id)ONDELETESETNULL);ALTERTABLEemployeeADDFOREIGNKEY(branch_id)REFERENCESbranch(branch_id)ONDELETESETNULL;ALTERTABLEemployeeADDFOREIGNKEY(super_id)REFERENCESemployee(emp_id)ONDELETESETNULL;CREATETABLEclient(client_idINTPRIMARYKEY,client_nameVARCHAR(40),branch_idINT,FOREIGNKEY(branch_id)REFERENCESbranch(branch_id)ONDELETESETNULL);CREATETABLEworks_with(emp_idINT,client_idINT,total_salesINT,PRIMARYKEY(emp_id,client_id),FOREIGNKEY(emp_id)REFERENCESemployee(emp_id)ONDELETECASCADE,FOREIGNKEY(client_id)REFERENCESclient(client_id)ONDELETECASCADE);CREATETABLEbranch_supplier(branch_idINT,supplier_nameVARCHAR(40),supply_typeVARCHAR(40),PRIMARYKEY(branch_id,supplier_name),FOREIGNKEY(branch_id)REFERENCESbranch(branch_id)ONDELETECASCADE);-- ----------------------------------------------------------------------------- -- Corporate INSERTINTOemployeeVALUES(100,'David','Wallace','1967-11-17','M',250000,NULL,NULL);INSERTINTObranchVALUES(1,'Corporate',100,'2006-02-09');UPDATEemployeeSETbranch_id=1WHEREemp_id=100;INSERTINTOemployeeVALUES(101,'Jan','Levinson','1961-05-11','F',110000,100,1);-- Scranton INSERTINTOemployeeVALUES(102,'Michael','Scott','1964-03-15','M',75000,100,NULL);INSERTINTObranchVALUES(2,'Scranton',102,'1992-04-06');UPDATEemployeeSETbranch_id=2WHEREemp_id=102;INSERTINTOemployeeVALUES(103,'Angela','Martin','1971-06-25','F',63000,102,2);INSERTINTOemployeeVALUES(104,'Kelly','Kapoor','1980-02-05','F',55000,102,2);INSERTINTOemployeeVALUES(105,'Stanley','Hudson','1958-02-19','M',69000,102,2);-- Stamford INSERTINTOemployeeVALUES(106,'Josh','Porter','1969-09-05','M',78000,100,NULL);INSERTINTObranchVALUES(3,'Stamford',106,'1998-02-13');UPDATEemployeeSETbranch_id=3WHEREemp_id=106;INSERTINTOemployeeVALUES(107,'Andy','Bernard','1973-07-22','M',65000,106,3);INSERTINTOemployeeVALUES(108,'Jim','Halpert','1978-10-01','M',71000,106,3);-- BRANCH SUPPLIER INSERTINTObranch_supplierVALUES(2,'Hammer Mill','Paper');INSERTINTObranch_supplierVALUES(2,'Uni-ball','Writing Utensils');INSERTINTObranch_supplierVALUES(3,'Patriot Paper','Paper');INSERTINTObranch_supplierVALUES(2,'J.T. Forms \u0026 Labels','Custom","date":"2021-12-25","objectID":"/sql/:0:5","series":[],"tags":["SQL"],"title":"SQL","uri":"/sql/#c"},{"categories":["Note"],"content":"SQL Create a table INTDECIMAL(10,4)--total length of 10 and 4 after decimal point VARCHAR(1)BLOB--binary large object, stores large data DATE--YYYY-MM-DD TIMESTAMP--YYYY-MM-DD HH:MM:SS CREATETABLEstudent(student_idINTPRIMARYKEY,nameVARCHAR(20),majorVARCHAR(20)-- PRIMARY KEY(student_id) );--or you can define the primary key afterwards like above DESCRIBEstudent;DROPTABLEstudent;ALTERTABLEstudentADDgpaDECIMAL(3,2);--add column ALTERTABLEstudentDROPCOLUMNgpa;--drop column Insert data INSERTINTOstudentVALUES(1,'Jack','Biology');INSERTINTOstudentVALUES(2,'Kate','Sociology');SELECT*FROMstudent;--grab all the info from the table INSERTINTOstudent(student_id,name)VALUES(3,'Claire');INSERTINTOstudentVALUES(4,'Jack','Biology');INSERTINTOstudentVALUES(5,'Mike','Computer Science'); C CREATETABLEstudent(student_idINTUNIQUE,--student_id INT AUTO_INCREMENT, nameVARCHAR(20)NOTNULL,majorVARCHAR(20)DEFAULT'undecided');--then insert all data --primary key is both not null and unique Update and Delete UPDATEstudentSETmajor='Bio'WHEREmajor='Biology';UPDATEstudentSETmajor='Comp Sci'WHEREstudent_id=1ORmajor='Chemistry'UPDATEstudentSETname='Tom',Major='Undecided'WHEREstudent_id=1;UPDATEstudentSETmajor='undecided';DELETEFROMstudent;--delete all columns and rows DELETEFROMstudentWHEREstudent_id=5ANDmajor='undecided'; Basic Queries SELECT*FROMstudent;SELECTstudent.name,student.majorFROMstudentORDERBYstudent_idDESC;SELECTname,majorFROMstudentORDERBYmajor,student_idLIMIT3WHEREmajor='Biology'ORname'Kate';-- , =, =, , AND, OR SELECT*FROMstudentWHEREnameIN('Claire','Kate','Mike'); Company Database Into CREATETABLEemployee(emp_idINTPRIMARYKEY,first_nameVARCHAR(40),last_nameVARCHAR(40),birth_dayDATE,sexVARCHAR(1),salaryINT,super_idINT,branch_idINT);CREATETABLEbranch(branch_idINTPRIMARYKEY,branch_nameVARCHAR(40),mgr_idINT,mgr_start_dateDATE,FOREIGNKEY(mgr_id)REFERENCESemployee(emp_id)ONDELETESETNULL);ALTERTABLEemployeeADDFOREIGNKEY(branch_id)REFERENCESbranch(branch_id)ONDELETESETNULL;ALTERTABLEemployeeADDFOREIGNKEY(super_id)REFERENCESemployee(emp_id)ONDELETESETNULL;CREATETABLEclient(client_idINTPRIMARYKEY,client_nameVARCHAR(40),branch_idINT,FOREIGNKEY(branch_id)REFERENCESbranch(branch_id)ONDELETESETNULL);CREATETABLEworks_with(emp_idINT,client_idINT,total_salesINT,PRIMARYKEY(emp_id,client_id),FOREIGNKEY(emp_id)REFERENCESemployee(emp_id)ONDELETECASCADE,FOREIGNKEY(client_id)REFERENCESclient(client_id)ONDELETECASCADE);CREATETABLEbranch_supplier(branch_idINT,supplier_nameVARCHAR(40),supply_typeVARCHAR(40),PRIMARYKEY(branch_id,supplier_name),FOREIGNKEY(branch_id)REFERENCESbranch(branch_id)ONDELETECASCADE);-- ----------------------------------------------------------------------------- -- Corporate INSERTINTOemployeeVALUES(100,'David','Wallace','1967-11-17','M',250000,NULL,NULL);INSERTINTObranchVALUES(1,'Corporate',100,'2006-02-09');UPDATEemployeeSETbranch_id=1WHEREemp_id=100;INSERTINTOemployeeVALUES(101,'Jan','Levinson','1961-05-11','F',110000,100,1);-- Scranton INSERTINTOemployeeVALUES(102,'Michael','Scott','1964-03-15','M',75000,100,NULL);INSERTINTObranchVALUES(2,'Scranton',102,'1992-04-06');UPDATEemployeeSETbranch_id=2WHEREemp_id=102;INSERTINTOemployeeVALUES(103,'Angela','Martin','1971-06-25','F',63000,102,2);INSERTINTOemployeeVALUES(104,'Kelly','Kapoor','1980-02-05','F',55000,102,2);INSERTINTOemployeeVALUES(105,'Stanley','Hudson','1958-02-19','M',69000,102,2);-- Stamford INSERTINTOemployeeVALUES(106,'Josh','Porter','1969-09-05','M',78000,100,NULL);INSERTINTObranchVALUES(3,'Stamford',106,'1998-02-13');UPDATEemployeeSETbranch_id=3WHEREemp_id=106;INSERTINTOemployeeVALUES(107,'Andy','Bernard','1973-07-22','M',65000,106,3);INSERTINTOemployeeVALUES(108,'Jim','Halpert','1978-10-01','M',71000,106,3);-- BRANCH SUPPLIER INSERTINTObranch_supplierVALUES(2,'Hammer Mill','Paper');INSERTINTObranch_supplierVALUES(2,'Uni-ball','Writing Utensils');INSERTINTObranch_supplierVALUES(3,'Patriot Paper','Paper');INSERTINTObranch_supplierVALUES(2,'J.T. Forms \u0026 Labels','Custom","date":"2021-12-25","objectID":"/sql/:0:5","series":[],"tags":["SQL"],"title":"SQL","uri":"/sql/#update-and-delete"},{"categories":["Note"],"content":"SQL Create a table INTDECIMAL(10,4)--total length of 10 and 4 after decimal point VARCHAR(1)BLOB--binary large object, stores large data DATE--YYYY-MM-DD TIMESTAMP--YYYY-MM-DD HH:MM:SS CREATETABLEstudent(student_idINTPRIMARYKEY,nameVARCHAR(20),majorVARCHAR(20)-- PRIMARY KEY(student_id) );--or you can define the primary key afterwards like above DESCRIBEstudent;DROPTABLEstudent;ALTERTABLEstudentADDgpaDECIMAL(3,2);--add column ALTERTABLEstudentDROPCOLUMNgpa;--drop column Insert data INSERTINTOstudentVALUES(1,'Jack','Biology');INSERTINTOstudentVALUES(2,'Kate','Sociology');SELECT*FROMstudent;--grab all the info from the table INSERTINTOstudent(student_id,name)VALUES(3,'Claire');INSERTINTOstudentVALUES(4,'Jack','Biology');INSERTINTOstudentVALUES(5,'Mike','Computer Science'); C CREATETABLEstudent(student_idINTUNIQUE,--student_id INT AUTO_INCREMENT, nameVARCHAR(20)NOTNULL,majorVARCHAR(20)DEFAULT'undecided');--then insert all data --primary key is both not null and unique Update and Delete UPDATEstudentSETmajor='Bio'WHEREmajor='Biology';UPDATEstudentSETmajor='Comp Sci'WHEREstudent_id=1ORmajor='Chemistry'UPDATEstudentSETname='Tom',Major='Undecided'WHEREstudent_id=1;UPDATEstudentSETmajor='undecided';DELETEFROMstudent;--delete all columns and rows DELETEFROMstudentWHEREstudent_id=5ANDmajor='undecided'; Basic Queries SELECT*FROMstudent;SELECTstudent.name,student.majorFROMstudentORDERBYstudent_idDESC;SELECTname,majorFROMstudentORDERBYmajor,student_idLIMIT3WHEREmajor='Biology'ORname'Kate';-- , =, =, , AND, OR SELECT*FROMstudentWHEREnameIN('Claire','Kate','Mike'); Company Database Into CREATETABLEemployee(emp_idINTPRIMARYKEY,first_nameVARCHAR(40),last_nameVARCHAR(40),birth_dayDATE,sexVARCHAR(1),salaryINT,super_idINT,branch_idINT);CREATETABLEbranch(branch_idINTPRIMARYKEY,branch_nameVARCHAR(40),mgr_idINT,mgr_start_dateDATE,FOREIGNKEY(mgr_id)REFERENCESemployee(emp_id)ONDELETESETNULL);ALTERTABLEemployeeADDFOREIGNKEY(branch_id)REFERENCESbranch(branch_id)ONDELETESETNULL;ALTERTABLEemployeeADDFOREIGNKEY(super_id)REFERENCESemployee(emp_id)ONDELETESETNULL;CREATETABLEclient(client_idINTPRIMARYKEY,client_nameVARCHAR(40),branch_idINT,FOREIGNKEY(branch_id)REFERENCESbranch(branch_id)ONDELETESETNULL);CREATETABLEworks_with(emp_idINT,client_idINT,total_salesINT,PRIMARYKEY(emp_id,client_id),FOREIGNKEY(emp_id)REFERENCESemployee(emp_id)ONDELETECASCADE,FOREIGNKEY(client_id)REFERENCESclient(client_id)ONDELETECASCADE);CREATETABLEbranch_supplier(branch_idINT,supplier_nameVARCHAR(40),supply_typeVARCHAR(40),PRIMARYKEY(branch_id,supplier_name),FOREIGNKEY(branch_id)REFERENCESbranch(branch_id)ONDELETECASCADE);-- ----------------------------------------------------------------------------- -- Corporate INSERTINTOemployeeVALUES(100,'David','Wallace','1967-11-17','M',250000,NULL,NULL);INSERTINTObranchVALUES(1,'Corporate',100,'2006-02-09');UPDATEemployeeSETbranch_id=1WHEREemp_id=100;INSERTINTOemployeeVALUES(101,'Jan','Levinson','1961-05-11','F',110000,100,1);-- Scranton INSERTINTOemployeeVALUES(102,'Michael','Scott','1964-03-15','M',75000,100,NULL);INSERTINTObranchVALUES(2,'Scranton',102,'1992-04-06');UPDATEemployeeSETbranch_id=2WHEREemp_id=102;INSERTINTOemployeeVALUES(103,'Angela','Martin','1971-06-25','F',63000,102,2);INSERTINTOemployeeVALUES(104,'Kelly','Kapoor','1980-02-05','F',55000,102,2);INSERTINTOemployeeVALUES(105,'Stanley','Hudson','1958-02-19','M',69000,102,2);-- Stamford INSERTINTOemployeeVALUES(106,'Josh','Porter','1969-09-05','M',78000,100,NULL);INSERTINTObranchVALUES(3,'Stamford',106,'1998-02-13');UPDATEemployeeSETbranch_id=3WHEREemp_id=106;INSERTINTOemployeeVALUES(107,'Andy','Bernard','1973-07-22','M',65000,106,3);INSERTINTOemployeeVALUES(108,'Jim','Halpert','1978-10-01','M',71000,106,3);-- BRANCH SUPPLIER INSERTINTObranch_supplierVALUES(2,'Hammer Mill','Paper');INSERTINTObranch_supplierVALUES(2,'Uni-ball','Writing Utensils');INSERTINTObranch_supplierVALUES(3,'Patriot Paper','Paper');INSERTINTObranch_supplierVALUES(2,'J.T. Forms \u0026 Labels','Custom","date":"2021-12-25","objectID":"/sql/:0:5","series":[],"tags":["SQL"],"title":"SQL","uri":"/sql/#basic-queries"},{"categories":["Note"],"content":"SQL Create a table INTDECIMAL(10,4)--total length of 10 and 4 after decimal point VARCHAR(1)BLOB--binary large object, stores large data DATE--YYYY-MM-DD TIMESTAMP--YYYY-MM-DD HH:MM:SS CREATETABLEstudent(student_idINTPRIMARYKEY,nameVARCHAR(20),majorVARCHAR(20)-- PRIMARY KEY(student_id) );--or you can define the primary key afterwards like above DESCRIBEstudent;DROPTABLEstudent;ALTERTABLEstudentADDgpaDECIMAL(3,2);--add column ALTERTABLEstudentDROPCOLUMNgpa;--drop column Insert data INSERTINTOstudentVALUES(1,'Jack','Biology');INSERTINTOstudentVALUES(2,'Kate','Sociology');SELECT*FROMstudent;--grab all the info from the table INSERTINTOstudent(student_id,name)VALUES(3,'Claire');INSERTINTOstudentVALUES(4,'Jack','Biology');INSERTINTOstudentVALUES(5,'Mike','Computer Science'); C CREATETABLEstudent(student_idINTUNIQUE,--student_id INT AUTO_INCREMENT, nameVARCHAR(20)NOTNULL,majorVARCHAR(20)DEFAULT'undecided');--then insert all data --primary key is both not null and unique Update and Delete UPDATEstudentSETmajor='Bio'WHEREmajor='Biology';UPDATEstudentSETmajor='Comp Sci'WHEREstudent_id=1ORmajor='Chemistry'UPDATEstudentSETname='Tom',Major='Undecided'WHEREstudent_id=1;UPDATEstudentSETmajor='undecided';DELETEFROMstudent;--delete all columns and rows DELETEFROMstudentWHEREstudent_id=5ANDmajor='undecided'; Basic Queries SELECT*FROMstudent;SELECTstudent.name,student.majorFROMstudentORDERBYstudent_idDESC;SELECTname,majorFROMstudentORDERBYmajor,student_idLIMIT3WHEREmajor='Biology'ORname'Kate';-- , =, =, , AND, OR SELECT*FROMstudentWHEREnameIN('Claire','Kate','Mike'); Company Database Into CREATETABLEemployee(emp_idINTPRIMARYKEY,first_nameVARCHAR(40),last_nameVARCHAR(40),birth_dayDATE,sexVARCHAR(1),salaryINT,super_idINT,branch_idINT);CREATETABLEbranch(branch_idINTPRIMARYKEY,branch_nameVARCHAR(40),mgr_idINT,mgr_start_dateDATE,FOREIGNKEY(mgr_id)REFERENCESemployee(emp_id)ONDELETESETNULL);ALTERTABLEemployeeADDFOREIGNKEY(branch_id)REFERENCESbranch(branch_id)ONDELETESETNULL;ALTERTABLEemployeeADDFOREIGNKEY(super_id)REFERENCESemployee(emp_id)ONDELETESETNULL;CREATETABLEclient(client_idINTPRIMARYKEY,client_nameVARCHAR(40),branch_idINT,FOREIGNKEY(branch_id)REFERENCESbranch(branch_id)ONDELETESETNULL);CREATETABLEworks_with(emp_idINT,client_idINT,total_salesINT,PRIMARYKEY(emp_id,client_id),FOREIGNKEY(emp_id)REFERENCESemployee(emp_id)ONDELETECASCADE,FOREIGNKEY(client_id)REFERENCESclient(client_id)ONDELETECASCADE);CREATETABLEbranch_supplier(branch_idINT,supplier_nameVARCHAR(40),supply_typeVARCHAR(40),PRIMARYKEY(branch_id,supplier_name),FOREIGNKEY(branch_id)REFERENCESbranch(branch_id)ONDELETECASCADE);-- ----------------------------------------------------------------------------- -- Corporate INSERTINTOemployeeVALUES(100,'David','Wallace','1967-11-17','M',250000,NULL,NULL);INSERTINTObranchVALUES(1,'Corporate',100,'2006-02-09');UPDATEemployeeSETbranch_id=1WHEREemp_id=100;INSERTINTOemployeeVALUES(101,'Jan','Levinson','1961-05-11','F',110000,100,1);-- Scranton INSERTINTOemployeeVALUES(102,'Michael','Scott','1964-03-15','M',75000,100,NULL);INSERTINTObranchVALUES(2,'Scranton',102,'1992-04-06');UPDATEemployeeSETbranch_id=2WHEREemp_id=102;INSERTINTOemployeeVALUES(103,'Angela','Martin','1971-06-25','F',63000,102,2);INSERTINTOemployeeVALUES(104,'Kelly','Kapoor','1980-02-05','F',55000,102,2);INSERTINTOemployeeVALUES(105,'Stanley','Hudson','1958-02-19','M',69000,102,2);-- Stamford INSERTINTOemployeeVALUES(106,'Josh','Porter','1969-09-05','M',78000,100,NULL);INSERTINTObranchVALUES(3,'Stamford',106,'1998-02-13');UPDATEemployeeSETbranch_id=3WHEREemp_id=106;INSERTINTOemployeeVALUES(107,'Andy','Bernard','1973-07-22','M',65000,106,3);INSERTINTOemployeeVALUES(108,'Jim','Halpert','1978-10-01','M',71000,106,3);-- BRANCH SUPPLIER INSERTINTObranch_supplierVALUES(2,'Hammer Mill','Paper');INSERTINTObranch_supplierVALUES(2,'Uni-ball','Writing Utensils');INSERTINTObranch_supplierVALUES(3,'Patriot Paper','Paper');INSERTINTObranch_supplierVALUES(2,'J.T. Forms \u0026 Labels','Custom","date":"2021-12-25","objectID":"/sql/:0:5","series":[],"tags":["SQL"],"title":"SQL","uri":"/sql/#company-database-into"},{"categories":["Note"],"content":"SQL Create a table INTDECIMAL(10,4)--total length of 10 and 4 after decimal point VARCHAR(1)BLOB--binary large object, stores large data DATE--YYYY-MM-DD TIMESTAMP--YYYY-MM-DD HH:MM:SS CREATETABLEstudent(student_idINTPRIMARYKEY,nameVARCHAR(20),majorVARCHAR(20)-- PRIMARY KEY(student_id) );--or you can define the primary key afterwards like above DESCRIBEstudent;DROPTABLEstudent;ALTERTABLEstudentADDgpaDECIMAL(3,2);--add column ALTERTABLEstudentDROPCOLUMNgpa;--drop column Insert data INSERTINTOstudentVALUES(1,'Jack','Biology');INSERTINTOstudentVALUES(2,'Kate','Sociology');SELECT*FROMstudent;--grab all the info from the table INSERTINTOstudent(student_id,name)VALUES(3,'Claire');INSERTINTOstudentVALUES(4,'Jack','Biology');INSERTINTOstudentVALUES(5,'Mike','Computer Science'); C CREATETABLEstudent(student_idINTUNIQUE,--student_id INT AUTO_INCREMENT, nameVARCHAR(20)NOTNULL,majorVARCHAR(20)DEFAULT'undecided');--then insert all data --primary key is both not null and unique Update and Delete UPDATEstudentSETmajor='Bio'WHEREmajor='Biology';UPDATEstudentSETmajor='Comp Sci'WHEREstudent_id=1ORmajor='Chemistry'UPDATEstudentSETname='Tom',Major='Undecided'WHEREstudent_id=1;UPDATEstudentSETmajor='undecided';DELETEFROMstudent;--delete all columns and rows DELETEFROMstudentWHEREstudent_id=5ANDmajor='undecided'; Basic Queries SELECT*FROMstudent;SELECTstudent.name,student.majorFROMstudentORDERBYstudent_idDESC;SELECTname,majorFROMstudentORDERBYmajor,student_idLIMIT3WHEREmajor='Biology'ORname'Kate';-- , =, =, , AND, OR SELECT*FROMstudentWHEREnameIN('Claire','Kate','Mike'); Company Database Into CREATETABLEemployee(emp_idINTPRIMARYKEY,first_nameVARCHAR(40),last_nameVARCHAR(40),birth_dayDATE,sexVARCHAR(1),salaryINT,super_idINT,branch_idINT);CREATETABLEbranch(branch_idINTPRIMARYKEY,branch_nameVARCHAR(40),mgr_idINT,mgr_start_dateDATE,FOREIGNKEY(mgr_id)REFERENCESemployee(emp_id)ONDELETESETNULL);ALTERTABLEemployeeADDFOREIGNKEY(branch_id)REFERENCESbranch(branch_id)ONDELETESETNULL;ALTERTABLEemployeeADDFOREIGNKEY(super_id)REFERENCESemployee(emp_id)ONDELETESETNULL;CREATETABLEclient(client_idINTPRIMARYKEY,client_nameVARCHAR(40),branch_idINT,FOREIGNKEY(branch_id)REFERENCESbranch(branch_id)ONDELETESETNULL);CREATETABLEworks_with(emp_idINT,client_idINT,total_salesINT,PRIMARYKEY(emp_id,client_id),FOREIGNKEY(emp_id)REFERENCESemployee(emp_id)ONDELETECASCADE,FOREIGNKEY(client_id)REFERENCESclient(client_id)ONDELETECASCADE);CREATETABLEbranch_supplier(branch_idINT,supplier_nameVARCHAR(40),supply_typeVARCHAR(40),PRIMARYKEY(branch_id,supplier_name),FOREIGNKEY(branch_id)REFERENCESbranch(branch_id)ONDELETECASCADE);-- ----------------------------------------------------------------------------- -- Corporate INSERTINTOemployeeVALUES(100,'David','Wallace','1967-11-17','M',250000,NULL,NULL);INSERTINTObranchVALUES(1,'Corporate',100,'2006-02-09');UPDATEemployeeSETbranch_id=1WHEREemp_id=100;INSERTINTOemployeeVALUES(101,'Jan','Levinson','1961-05-11','F',110000,100,1);-- Scranton INSERTINTOemployeeVALUES(102,'Michael','Scott','1964-03-15','M',75000,100,NULL);INSERTINTObranchVALUES(2,'Scranton',102,'1992-04-06');UPDATEemployeeSETbranch_id=2WHEREemp_id=102;INSERTINTOemployeeVALUES(103,'Angela','Martin','1971-06-25','F',63000,102,2);INSERTINTOemployeeVALUES(104,'Kelly','Kapoor','1980-02-05','F',55000,102,2);INSERTINTOemployeeVALUES(105,'Stanley','Hudson','1958-02-19','M',69000,102,2);-- Stamford INSERTINTOemployeeVALUES(106,'Josh','Porter','1969-09-05','M',78000,100,NULL);INSERTINTObranchVALUES(3,'Stamford',106,'1998-02-13');UPDATEemployeeSETbranch_id=3WHEREemp_id=106;INSERTINTOemployeeVALUES(107,'Andy','Bernard','1973-07-22','M',65000,106,3);INSERTINTOemployeeVALUES(108,'Jim','Halpert','1978-10-01','M',71000,106,3);-- BRANCH SUPPLIER INSERTINTObranch_supplierVALUES(2,'Hammer Mill','Paper');INSERTINTObranch_supplierVALUES(2,'Uni-ball','Writing Utensils');INSERTINTObranch_supplierVALUES(3,'Patriot Paper','Paper');INSERTINTObranch_supplierVALUES(2,'J.T. Forms \u0026 Labels','Custom","date":"2021-12-25","objectID":"/sql/:0:5","series":[],"tags":["SQL"],"title":"SQL","uri":"/sql/#more-basic-queries"},{"categories":["Note"],"content":"SQL Create a table INTDECIMAL(10,4)--total length of 10 and 4 after decimal point VARCHAR(1)BLOB--binary large object, stores large data DATE--YYYY-MM-DD TIMESTAMP--YYYY-MM-DD HH:MM:SS CREATETABLEstudent(student_idINTPRIMARYKEY,nameVARCHAR(20),majorVARCHAR(20)-- PRIMARY KEY(student_id) );--or you can define the primary key afterwards like above DESCRIBEstudent;DROPTABLEstudent;ALTERTABLEstudentADDgpaDECIMAL(3,2);--add column ALTERTABLEstudentDROPCOLUMNgpa;--drop column Insert data INSERTINTOstudentVALUES(1,'Jack','Biology');INSERTINTOstudentVALUES(2,'Kate','Sociology');SELECT*FROMstudent;--grab all the info from the table INSERTINTOstudent(student_id,name)VALUES(3,'Claire');INSERTINTOstudentVALUES(4,'Jack','Biology');INSERTINTOstudentVALUES(5,'Mike','Computer Science'); C CREATETABLEstudent(student_idINTUNIQUE,--student_id INT AUTO_INCREMENT, nameVARCHAR(20)NOTNULL,majorVARCHAR(20)DEFAULT'undecided');--then insert all data --primary key is both not null and unique Update and Delete UPDATEstudentSETmajor='Bio'WHEREmajor='Biology';UPDATEstudentSETmajor='Comp Sci'WHEREstudent_id=1ORmajor='Chemistry'UPDATEstudentSETname='Tom',Major='Undecided'WHEREstudent_id=1;UPDATEstudentSETmajor='undecided';DELETEFROMstudent;--delete all columns and rows DELETEFROMstudentWHEREstudent_id=5ANDmajor='undecided'; Basic Queries SELECT*FROMstudent;SELECTstudent.name,student.majorFROMstudentORDERBYstudent_idDESC;SELECTname,majorFROMstudentORDERBYmajor,student_idLIMIT3WHEREmajor='Biology'ORname'Kate';-- , =, =, , AND, OR SELECT*FROMstudentWHEREnameIN('Claire','Kate','Mike'); Company Database Into CREATETABLEemployee(emp_idINTPRIMARYKEY,first_nameVARCHAR(40),last_nameVARCHAR(40),birth_dayDATE,sexVARCHAR(1),salaryINT,super_idINT,branch_idINT);CREATETABLEbranch(branch_idINTPRIMARYKEY,branch_nameVARCHAR(40),mgr_idINT,mgr_start_dateDATE,FOREIGNKEY(mgr_id)REFERENCESemployee(emp_id)ONDELETESETNULL);ALTERTABLEemployeeADDFOREIGNKEY(branch_id)REFERENCESbranch(branch_id)ONDELETESETNULL;ALTERTABLEemployeeADDFOREIGNKEY(super_id)REFERENCESemployee(emp_id)ONDELETESETNULL;CREATETABLEclient(client_idINTPRIMARYKEY,client_nameVARCHAR(40),branch_idINT,FOREIGNKEY(branch_id)REFERENCESbranch(branch_id)ONDELETESETNULL);CREATETABLEworks_with(emp_idINT,client_idINT,total_salesINT,PRIMARYKEY(emp_id,client_id),FOREIGNKEY(emp_id)REFERENCESemployee(emp_id)ONDELETECASCADE,FOREIGNKEY(client_id)REFERENCESclient(client_id)ONDELETECASCADE);CREATETABLEbranch_supplier(branch_idINT,supplier_nameVARCHAR(40),supply_typeVARCHAR(40),PRIMARYKEY(branch_id,supplier_name),FOREIGNKEY(branch_id)REFERENCESbranch(branch_id)ONDELETECASCADE);-- ----------------------------------------------------------------------------- -- Corporate INSERTINTOemployeeVALUES(100,'David','Wallace','1967-11-17','M',250000,NULL,NULL);INSERTINTObranchVALUES(1,'Corporate',100,'2006-02-09');UPDATEemployeeSETbranch_id=1WHEREemp_id=100;INSERTINTOemployeeVALUES(101,'Jan','Levinson','1961-05-11','F',110000,100,1);-- Scranton INSERTINTOemployeeVALUES(102,'Michael','Scott','1964-03-15','M',75000,100,NULL);INSERTINTObranchVALUES(2,'Scranton',102,'1992-04-06');UPDATEemployeeSETbranch_id=2WHEREemp_id=102;INSERTINTOemployeeVALUES(103,'Angela','Martin','1971-06-25','F',63000,102,2);INSERTINTOemployeeVALUES(104,'Kelly','Kapoor','1980-02-05','F',55000,102,2);INSERTINTOemployeeVALUES(105,'Stanley','Hudson','1958-02-19','M',69000,102,2);-- Stamford INSERTINTOemployeeVALUES(106,'Josh','Porter','1969-09-05','M',78000,100,NULL);INSERTINTObranchVALUES(3,'Stamford',106,'1998-02-13');UPDATEemployeeSETbranch_id=3WHEREemp_id=106;INSERTINTOemployeeVALUES(107,'Andy','Bernard','1973-07-22','M',65000,106,3);INSERTINTOemployeeVALUES(108,'Jim','Halpert','1978-10-01','M',71000,106,3);-- BRANCH SUPPLIER INSERTINTObranch_supplierVALUES(2,'Hammer Mill','Paper');INSERTINTObranch_supplierVALUES(2,'Uni-ball','Writing Utensils');INSERTINTObranch_supplierVALUES(3,'Patriot Paper','Paper');INSERTINTObranch_supplierVALUES(2,'J.T. Forms \u0026 Labels','Custom","date":"2021-12-25","objectID":"/sql/:0:5","series":[],"tags":["SQL"],"title":"SQL","uri":"/sql/#function"},{"categories":["Note"],"content":"SQL Create a table INTDECIMAL(10,4)--total length of 10 and 4 after decimal point VARCHAR(1)BLOB--binary large object, stores large data DATE--YYYY-MM-DD TIMESTAMP--YYYY-MM-DD HH:MM:SS CREATETABLEstudent(student_idINTPRIMARYKEY,nameVARCHAR(20),majorVARCHAR(20)-- PRIMARY KEY(student_id) );--or you can define the primary key afterwards like above DESCRIBEstudent;DROPTABLEstudent;ALTERTABLEstudentADDgpaDECIMAL(3,2);--add column ALTERTABLEstudentDROPCOLUMNgpa;--drop column Insert data INSERTINTOstudentVALUES(1,'Jack','Biology');INSERTINTOstudentVALUES(2,'Kate','Sociology');SELECT*FROMstudent;--grab all the info from the table INSERTINTOstudent(student_id,name)VALUES(3,'Claire');INSERTINTOstudentVALUES(4,'Jack','Biology');INSERTINTOstudentVALUES(5,'Mike','Computer Science'); C CREATETABLEstudent(student_idINTUNIQUE,--student_id INT AUTO_INCREMENT, nameVARCHAR(20)NOTNULL,majorVARCHAR(20)DEFAULT'undecided');--then insert all data --primary key is both not null and unique Update and Delete UPDATEstudentSETmajor='Bio'WHEREmajor='Biology';UPDATEstudentSETmajor='Comp Sci'WHEREstudent_id=1ORmajor='Chemistry'UPDATEstudentSETname='Tom',Major='Undecided'WHEREstudent_id=1;UPDATEstudentSETmajor='undecided';DELETEFROMstudent;--delete all columns and rows DELETEFROMstudentWHEREstudent_id=5ANDmajor='undecided'; Basic Queries SELECT*FROMstudent;SELECTstudent.name,student.majorFROMstudentORDERBYstudent_idDESC;SELECTname,majorFROMstudentORDERBYmajor,student_idLIMIT3WHEREmajor='Biology'ORname'Kate';-- , =, =, , AND, OR SELECT*FROMstudentWHEREnameIN('Claire','Kate','Mike'); Company Database Into CREATETABLEemployee(emp_idINTPRIMARYKEY,first_nameVARCHAR(40),last_nameVARCHAR(40),birth_dayDATE,sexVARCHAR(1),salaryINT,super_idINT,branch_idINT);CREATETABLEbranch(branch_idINTPRIMARYKEY,branch_nameVARCHAR(40),mgr_idINT,mgr_start_dateDATE,FOREIGNKEY(mgr_id)REFERENCESemployee(emp_id)ONDELETESETNULL);ALTERTABLEemployeeADDFOREIGNKEY(branch_id)REFERENCESbranch(branch_id)ONDELETESETNULL;ALTERTABLEemployeeADDFOREIGNKEY(super_id)REFERENCESemployee(emp_id)ONDELETESETNULL;CREATETABLEclient(client_idINTPRIMARYKEY,client_nameVARCHAR(40),branch_idINT,FOREIGNKEY(branch_id)REFERENCESbranch(branch_id)ONDELETESETNULL);CREATETABLEworks_with(emp_idINT,client_idINT,total_salesINT,PRIMARYKEY(emp_id,client_id),FOREIGNKEY(emp_id)REFERENCESemployee(emp_id)ONDELETECASCADE,FOREIGNKEY(client_id)REFERENCESclient(client_id)ONDELETECASCADE);CREATETABLEbranch_supplier(branch_idINT,supplier_nameVARCHAR(40),supply_typeVARCHAR(40),PRIMARYKEY(branch_id,supplier_name),FOREIGNKEY(branch_id)REFERENCESbranch(branch_id)ONDELETECASCADE);-- ----------------------------------------------------------------------------- -- Corporate INSERTINTOemployeeVALUES(100,'David','Wallace','1967-11-17','M',250000,NULL,NULL);INSERTINTObranchVALUES(1,'Corporate',100,'2006-02-09');UPDATEemployeeSETbranch_id=1WHEREemp_id=100;INSERTINTOemployeeVALUES(101,'Jan','Levinson','1961-05-11','F',110000,100,1);-- Scranton INSERTINTOemployeeVALUES(102,'Michael','Scott','1964-03-15','M',75000,100,NULL);INSERTINTObranchVALUES(2,'Scranton',102,'1992-04-06');UPDATEemployeeSETbranch_id=2WHEREemp_id=102;INSERTINTOemployeeVALUES(103,'Angela','Martin','1971-06-25','F',63000,102,2);INSERTINTOemployeeVALUES(104,'Kelly','Kapoor','1980-02-05','F',55000,102,2);INSERTINTOemployeeVALUES(105,'Stanley','Hudson','1958-02-19','M',69000,102,2);-- Stamford INSERTINTOemployeeVALUES(106,'Josh','Porter','1969-09-05','M',78000,100,NULL);INSERTINTObranchVALUES(3,'Stamford',106,'1998-02-13');UPDATEemployeeSETbranch_id=3WHEREemp_id=106;INSERTINTOemployeeVALUES(107,'Andy','Bernard','1973-07-22','M',65000,106,3);INSERTINTOemployeeVALUES(108,'Jim','Halpert','1978-10-01','M',71000,106,3);-- BRANCH SUPPLIER INSERTINTObranch_supplierVALUES(2,'Hammer Mill','Paper');INSERTINTObranch_supplierVALUES(2,'Uni-ball','Writing Utensils');INSERTINTObranch_supplierVALUES(3,'Patriot Paper','Paper');INSERTINTObranch_supplierVALUES(2,'J.T. Forms \u0026 Labels','Custom","date":"2021-12-25","objectID":"/sql/:0:5","series":[],"tags":["SQL"],"title":"SQL","uri":"/sql/#wildcards"},{"categories":["Note"],"content":"SQL Create a table INTDECIMAL(10,4)--total length of 10 and 4 after decimal point VARCHAR(1)BLOB--binary large object, stores large data DATE--YYYY-MM-DD TIMESTAMP--YYYY-MM-DD HH:MM:SS CREATETABLEstudent(student_idINTPRIMARYKEY,nameVARCHAR(20),majorVARCHAR(20)-- PRIMARY KEY(student_id) );--or you can define the primary key afterwards like above DESCRIBEstudent;DROPTABLEstudent;ALTERTABLEstudentADDgpaDECIMAL(3,2);--add column ALTERTABLEstudentDROPCOLUMNgpa;--drop column Insert data INSERTINTOstudentVALUES(1,'Jack','Biology');INSERTINTOstudentVALUES(2,'Kate','Sociology');SELECT*FROMstudent;--grab all the info from the table INSERTINTOstudent(student_id,name)VALUES(3,'Claire');INSERTINTOstudentVALUES(4,'Jack','Biology');INSERTINTOstudentVALUES(5,'Mike','Computer Science'); C CREATETABLEstudent(student_idINTUNIQUE,--student_id INT AUTO_INCREMENT, nameVARCHAR(20)NOTNULL,majorVARCHAR(20)DEFAULT'undecided');--then insert all data --primary key is both not null and unique Update and Delete UPDATEstudentSETmajor='Bio'WHEREmajor='Biology';UPDATEstudentSETmajor='Comp Sci'WHEREstudent_id=1ORmajor='Chemistry'UPDATEstudentSETname='Tom',Major='Undecided'WHEREstudent_id=1;UPDATEstudentSETmajor='undecided';DELETEFROMstudent;--delete all columns and rows DELETEFROMstudentWHEREstudent_id=5ANDmajor='undecided'; Basic Queries SELECT*FROMstudent;SELECTstudent.name,student.majorFROMstudentORDERBYstudent_idDESC;SELECTname,majorFROMstudentORDERBYmajor,student_idLIMIT3WHEREmajor='Biology'ORname'Kate';-- , =, =, , AND, OR SELECT*FROMstudentWHEREnameIN('Claire','Kate','Mike'); Company Database Into CREATETABLEemployee(emp_idINTPRIMARYKEY,first_nameVARCHAR(40),last_nameVARCHAR(40),birth_dayDATE,sexVARCHAR(1),salaryINT,super_idINT,branch_idINT);CREATETABLEbranch(branch_idINTPRIMARYKEY,branch_nameVARCHAR(40),mgr_idINT,mgr_start_dateDATE,FOREIGNKEY(mgr_id)REFERENCESemployee(emp_id)ONDELETESETNULL);ALTERTABLEemployeeADDFOREIGNKEY(branch_id)REFERENCESbranch(branch_id)ONDELETESETNULL;ALTERTABLEemployeeADDFOREIGNKEY(super_id)REFERENCESemployee(emp_id)ONDELETESETNULL;CREATETABLEclient(client_idINTPRIMARYKEY,client_nameVARCHAR(40),branch_idINT,FOREIGNKEY(branch_id)REFERENCESbranch(branch_id)ONDELETESETNULL);CREATETABLEworks_with(emp_idINT,client_idINT,total_salesINT,PRIMARYKEY(emp_id,client_id),FOREIGNKEY(emp_id)REFERENCESemployee(emp_id)ONDELETECASCADE,FOREIGNKEY(client_id)REFERENCESclient(client_id)ONDELETECASCADE);CREATETABLEbranch_supplier(branch_idINT,supplier_nameVARCHAR(40),supply_typeVARCHAR(40),PRIMARYKEY(branch_id,supplier_name),FOREIGNKEY(branch_id)REFERENCESbranch(branch_id)ONDELETECASCADE);-- ----------------------------------------------------------------------------- -- Corporate INSERTINTOemployeeVALUES(100,'David','Wallace','1967-11-17','M',250000,NULL,NULL);INSERTINTObranchVALUES(1,'Corporate',100,'2006-02-09');UPDATEemployeeSETbranch_id=1WHEREemp_id=100;INSERTINTOemployeeVALUES(101,'Jan','Levinson','1961-05-11','F',110000,100,1);-- Scranton INSERTINTOemployeeVALUES(102,'Michael','Scott','1964-03-15','M',75000,100,NULL);INSERTINTObranchVALUES(2,'Scranton',102,'1992-04-06');UPDATEemployeeSETbranch_id=2WHEREemp_id=102;INSERTINTOemployeeVALUES(103,'Angela','Martin','1971-06-25','F',63000,102,2);INSERTINTOemployeeVALUES(104,'Kelly','Kapoor','1980-02-05','F',55000,102,2);INSERTINTOemployeeVALUES(105,'Stanley','Hudson','1958-02-19','M',69000,102,2);-- Stamford INSERTINTOemployeeVALUES(106,'Josh','Porter','1969-09-05','M',78000,100,NULL);INSERTINTObranchVALUES(3,'Stamford',106,'1998-02-13');UPDATEemployeeSETbranch_id=3WHEREemp_id=106;INSERTINTOemployeeVALUES(107,'Andy','Bernard','1973-07-22','M',65000,106,3);INSERTINTOemployeeVALUES(108,'Jim','Halpert','1978-10-01','M',71000,106,3);-- BRANCH SUPPLIER INSERTINTObranch_supplierVALUES(2,'Hammer Mill','Paper');INSERTINTObranch_supplierVALUES(2,'Uni-ball','Writing Utensils');INSERTINTObranch_supplierVALUES(3,'Patriot Paper','Paper');INSERTINTObranch_supplierVALUES(2,'J.T. Forms \u0026 Labels','Custom","date":"2021-12-25","objectID":"/sql/:0:5","series":[],"tags":["SQL"],"title":"SQL","uri":"/sql/#union"},{"categories":["Note"],"content":"SQL Create a table INTDECIMAL(10,4)--total length of 10 and 4 after decimal point VARCHAR(1)BLOB--binary large object, stores large data DATE--YYYY-MM-DD TIMESTAMP--YYYY-MM-DD HH:MM:SS CREATETABLEstudent(student_idINTPRIMARYKEY,nameVARCHAR(20),majorVARCHAR(20)-- PRIMARY KEY(student_id) );--or you can define the primary key afterwards like above DESCRIBEstudent;DROPTABLEstudent;ALTERTABLEstudentADDgpaDECIMAL(3,2);--add column ALTERTABLEstudentDROPCOLUMNgpa;--drop column Insert data INSERTINTOstudentVALUES(1,'Jack','Biology');INSERTINTOstudentVALUES(2,'Kate','Sociology');SELECT*FROMstudent;--grab all the info from the table INSERTINTOstudent(student_id,name)VALUES(3,'Claire');INSERTINTOstudentVALUES(4,'Jack','Biology');INSERTINTOstudentVALUES(5,'Mike','Computer Science'); C CREATETABLEstudent(student_idINTUNIQUE,--student_id INT AUTO_INCREMENT, nameVARCHAR(20)NOTNULL,majorVARCHAR(20)DEFAULT'undecided');--then insert all data --primary key is both not null and unique Update and Delete UPDATEstudentSETmajor='Bio'WHEREmajor='Biology';UPDATEstudentSETmajor='Comp Sci'WHEREstudent_id=1ORmajor='Chemistry'UPDATEstudentSETname='Tom',Major='Undecided'WHEREstudent_id=1;UPDATEstudentSETmajor='undecided';DELETEFROMstudent;--delete all columns and rows DELETEFROMstudentWHEREstudent_id=5ANDmajor='undecided'; Basic Queries SELECT*FROMstudent;SELECTstudent.name,student.majorFROMstudentORDERBYstudent_idDESC;SELECTname,majorFROMstudentORDERBYmajor,student_idLIMIT3WHEREmajor='Biology'ORname'Kate';-- , =, =, , AND, OR SELECT*FROMstudentWHEREnameIN('Claire','Kate','Mike'); Company Database Into CREATETABLEemployee(emp_idINTPRIMARYKEY,first_nameVARCHAR(40),last_nameVARCHAR(40),birth_dayDATE,sexVARCHAR(1),salaryINT,super_idINT,branch_idINT);CREATETABLEbranch(branch_idINTPRIMARYKEY,branch_nameVARCHAR(40),mgr_idINT,mgr_start_dateDATE,FOREIGNKEY(mgr_id)REFERENCESemployee(emp_id)ONDELETESETNULL);ALTERTABLEemployeeADDFOREIGNKEY(branch_id)REFERENCESbranch(branch_id)ONDELETESETNULL;ALTERTABLEemployeeADDFOREIGNKEY(super_id)REFERENCESemployee(emp_id)ONDELETESETNULL;CREATETABLEclient(client_idINTPRIMARYKEY,client_nameVARCHAR(40),branch_idINT,FOREIGNKEY(branch_id)REFERENCESbranch(branch_id)ONDELETESETNULL);CREATETABLEworks_with(emp_idINT,client_idINT,total_salesINT,PRIMARYKEY(emp_id,client_id),FOREIGNKEY(emp_id)REFERENCESemployee(emp_id)ONDELETECASCADE,FOREIGNKEY(client_id)REFERENCESclient(client_id)ONDELETECASCADE);CREATETABLEbranch_supplier(branch_idINT,supplier_nameVARCHAR(40),supply_typeVARCHAR(40),PRIMARYKEY(branch_id,supplier_name),FOREIGNKEY(branch_id)REFERENCESbranch(branch_id)ONDELETECASCADE);-- ----------------------------------------------------------------------------- -- Corporate INSERTINTOemployeeVALUES(100,'David','Wallace','1967-11-17','M',250000,NULL,NULL);INSERTINTObranchVALUES(1,'Corporate',100,'2006-02-09');UPDATEemployeeSETbranch_id=1WHEREemp_id=100;INSERTINTOemployeeVALUES(101,'Jan','Levinson','1961-05-11','F',110000,100,1);-- Scranton INSERTINTOemployeeVALUES(102,'Michael','Scott','1964-03-15','M',75000,100,NULL);INSERTINTObranchVALUES(2,'Scranton',102,'1992-04-06');UPDATEemployeeSETbranch_id=2WHEREemp_id=102;INSERTINTOemployeeVALUES(103,'Angela','Martin','1971-06-25','F',63000,102,2);INSERTINTOemployeeVALUES(104,'Kelly','Kapoor','1980-02-05','F',55000,102,2);INSERTINTOemployeeVALUES(105,'Stanley','Hudson','1958-02-19','M',69000,102,2);-- Stamford INSERTINTOemployeeVALUES(106,'Josh','Porter','1969-09-05','M',78000,100,NULL);INSERTINTObranchVALUES(3,'Stamford',106,'1998-02-13');UPDATEemployeeSETbranch_id=3WHEREemp_id=106;INSERTINTOemployeeVALUES(107,'Andy','Bernard','1973-07-22','M',65000,106,3);INSERTINTOemployeeVALUES(108,'Jim','Halpert','1978-10-01','M',71000,106,3);-- BRANCH SUPPLIER INSERTINTObranch_supplierVALUES(2,'Hammer Mill','Paper');INSERTINTObranch_supplierVALUES(2,'Uni-ball','Writing Utensils');INSERTINTObranch_supplierVALUES(3,'Patriot Paper','Paper');INSERTINTObranch_supplierVALUES(2,'J.T. Forms \u0026 Labels','Custom","date":"2021-12-25","objectID":"/sql/:0:5","series":[],"tags":["SQL"],"title":"SQL","uri":"/sql/#joins"},{"categories":["Note"],"content":"SQL Create a table INTDECIMAL(10,4)--total length of 10 and 4 after decimal point VARCHAR(1)BLOB--binary large object, stores large data DATE--YYYY-MM-DD TIMESTAMP--YYYY-MM-DD HH:MM:SS CREATETABLEstudent(student_idINTPRIMARYKEY,nameVARCHAR(20),majorVARCHAR(20)-- PRIMARY KEY(student_id) );--or you can define the primary key afterwards like above DESCRIBEstudent;DROPTABLEstudent;ALTERTABLEstudentADDgpaDECIMAL(3,2);--add column ALTERTABLEstudentDROPCOLUMNgpa;--drop column Insert data INSERTINTOstudentVALUES(1,'Jack','Biology');INSERTINTOstudentVALUES(2,'Kate','Sociology');SELECT*FROMstudent;--grab all the info from the table INSERTINTOstudent(student_id,name)VALUES(3,'Claire');INSERTINTOstudentVALUES(4,'Jack','Biology');INSERTINTOstudentVALUES(5,'Mike','Computer Science'); C CREATETABLEstudent(student_idINTUNIQUE,--student_id INT AUTO_INCREMENT, nameVARCHAR(20)NOTNULL,majorVARCHAR(20)DEFAULT'undecided');--then insert all data --primary key is both not null and unique Update and Delete UPDATEstudentSETmajor='Bio'WHEREmajor='Biology';UPDATEstudentSETmajor='Comp Sci'WHEREstudent_id=1ORmajor='Chemistry'UPDATEstudentSETname='Tom',Major='Undecided'WHEREstudent_id=1;UPDATEstudentSETmajor='undecided';DELETEFROMstudent;--delete all columns and rows DELETEFROMstudentWHEREstudent_id=5ANDmajor='undecided'; Basic Queries SELECT*FROMstudent;SELECTstudent.name,student.majorFROMstudentORDERBYstudent_idDESC;SELECTname,majorFROMstudentORDERBYmajor,student_idLIMIT3WHEREmajor='Biology'ORname'Kate';-- , =, =, , AND, OR SELECT*FROMstudentWHEREnameIN('Claire','Kate','Mike'); Company Database Into CREATETABLEemployee(emp_idINTPRIMARYKEY,first_nameVARCHAR(40),last_nameVARCHAR(40),birth_dayDATE,sexVARCHAR(1),salaryINT,super_idINT,branch_idINT);CREATETABLEbranch(branch_idINTPRIMARYKEY,branch_nameVARCHAR(40),mgr_idINT,mgr_start_dateDATE,FOREIGNKEY(mgr_id)REFERENCESemployee(emp_id)ONDELETESETNULL);ALTERTABLEemployeeADDFOREIGNKEY(branch_id)REFERENCESbranch(branch_id)ONDELETESETNULL;ALTERTABLEemployeeADDFOREIGNKEY(super_id)REFERENCESemployee(emp_id)ONDELETESETNULL;CREATETABLEclient(client_idINTPRIMARYKEY,client_nameVARCHAR(40),branch_idINT,FOREIGNKEY(branch_id)REFERENCESbranch(branch_id)ONDELETESETNULL);CREATETABLEworks_with(emp_idINT,client_idINT,total_salesINT,PRIMARYKEY(emp_id,client_id),FOREIGNKEY(emp_id)REFERENCESemployee(emp_id)ONDELETECASCADE,FOREIGNKEY(client_id)REFERENCESclient(client_id)ONDELETECASCADE);CREATETABLEbranch_supplier(branch_idINT,supplier_nameVARCHAR(40),supply_typeVARCHAR(40),PRIMARYKEY(branch_id,supplier_name),FOREIGNKEY(branch_id)REFERENCESbranch(branch_id)ONDELETECASCADE);-- ----------------------------------------------------------------------------- -- Corporate INSERTINTOemployeeVALUES(100,'David','Wallace','1967-11-17','M',250000,NULL,NULL);INSERTINTObranchVALUES(1,'Corporate',100,'2006-02-09');UPDATEemployeeSETbranch_id=1WHEREemp_id=100;INSERTINTOemployeeVALUES(101,'Jan','Levinson','1961-05-11','F',110000,100,1);-- Scranton INSERTINTOemployeeVALUES(102,'Michael','Scott','1964-03-15','M',75000,100,NULL);INSERTINTObranchVALUES(2,'Scranton',102,'1992-04-06');UPDATEemployeeSETbranch_id=2WHEREemp_id=102;INSERTINTOemployeeVALUES(103,'Angela','Martin','1971-06-25','F',63000,102,2);INSERTINTOemployeeVALUES(104,'Kelly','Kapoor','1980-02-05','F',55000,102,2);INSERTINTOemployeeVALUES(105,'Stanley','Hudson','1958-02-19','M',69000,102,2);-- Stamford INSERTINTOemployeeVALUES(106,'Josh','Porter','1969-09-05','M',78000,100,NULL);INSERTINTObranchVALUES(3,'Stamford',106,'1998-02-13');UPDATEemployeeSETbranch_id=3WHEREemp_id=106;INSERTINTOemployeeVALUES(107,'Andy','Bernard','1973-07-22','M',65000,106,3);INSERTINTOemployeeVALUES(108,'Jim','Halpert','1978-10-01','M',71000,106,3);-- BRANCH SUPPLIER INSERTINTObranch_supplierVALUES(2,'Hammer Mill','Paper');INSERTINTObranch_supplierVALUES(2,'Uni-ball','Writing Utensils');INSERTINTObranch_supplierVALUES(3,'Patriot Paper','Paper');INSERTINTObranch_supplierVALUES(2,'J.T. Forms \u0026 Labels','Custom","date":"2021-12-25","objectID":"/sql/:0:5","series":[],"tags":["SQL"],"title":"SQL","uri":"/sql/#nested-queries"},{"categories":["Note"],"content":"SQL Create a table INTDECIMAL(10,4)--total length of 10 and 4 after decimal point VARCHAR(1)BLOB--binary large object, stores large data DATE--YYYY-MM-DD TIMESTAMP--YYYY-MM-DD HH:MM:SS CREATETABLEstudent(student_idINTPRIMARYKEY,nameVARCHAR(20),majorVARCHAR(20)-- PRIMARY KEY(student_id) );--or you can define the primary key afterwards like above DESCRIBEstudent;DROPTABLEstudent;ALTERTABLEstudentADDgpaDECIMAL(3,2);--add column ALTERTABLEstudentDROPCOLUMNgpa;--drop column Insert data INSERTINTOstudentVALUES(1,'Jack','Biology');INSERTINTOstudentVALUES(2,'Kate','Sociology');SELECT*FROMstudent;--grab all the info from the table INSERTINTOstudent(student_id,name)VALUES(3,'Claire');INSERTINTOstudentVALUES(4,'Jack','Biology');INSERTINTOstudentVALUES(5,'Mike','Computer Science'); C CREATETABLEstudent(student_idINTUNIQUE,--student_id INT AUTO_INCREMENT, nameVARCHAR(20)NOTNULL,majorVARCHAR(20)DEFAULT'undecided');--then insert all data --primary key is both not null and unique Update and Delete UPDATEstudentSETmajor='Bio'WHEREmajor='Biology';UPDATEstudentSETmajor='Comp Sci'WHEREstudent_id=1ORmajor='Chemistry'UPDATEstudentSETname='Tom',Major='Undecided'WHEREstudent_id=1;UPDATEstudentSETmajor='undecided';DELETEFROMstudent;--delete all columns and rows DELETEFROMstudentWHEREstudent_id=5ANDmajor='undecided'; Basic Queries SELECT*FROMstudent;SELECTstudent.name,student.majorFROMstudentORDERBYstudent_idDESC;SELECTname,majorFROMstudentORDERBYmajor,student_idLIMIT3WHEREmajor='Biology'ORname'Kate';-- , =, =, , AND, OR SELECT*FROMstudentWHEREnameIN('Claire','Kate','Mike'); Company Database Into CREATETABLEemployee(emp_idINTPRIMARYKEY,first_nameVARCHAR(40),last_nameVARCHAR(40),birth_dayDATE,sexVARCHAR(1),salaryINT,super_idINT,branch_idINT);CREATETABLEbranch(branch_idINTPRIMARYKEY,branch_nameVARCHAR(40),mgr_idINT,mgr_start_dateDATE,FOREIGNKEY(mgr_id)REFERENCESemployee(emp_id)ONDELETESETNULL);ALTERTABLEemployeeADDFOREIGNKEY(branch_id)REFERENCESbranch(branch_id)ONDELETESETNULL;ALTERTABLEemployeeADDFOREIGNKEY(super_id)REFERENCESemployee(emp_id)ONDELETESETNULL;CREATETABLEclient(client_idINTPRIMARYKEY,client_nameVARCHAR(40),branch_idINT,FOREIGNKEY(branch_id)REFERENCESbranch(branch_id)ONDELETESETNULL);CREATETABLEworks_with(emp_idINT,client_idINT,total_salesINT,PRIMARYKEY(emp_id,client_id),FOREIGNKEY(emp_id)REFERENCESemployee(emp_id)ONDELETECASCADE,FOREIGNKEY(client_id)REFERENCESclient(client_id)ONDELETECASCADE);CREATETABLEbranch_supplier(branch_idINT,supplier_nameVARCHAR(40),supply_typeVARCHAR(40),PRIMARYKEY(branch_id,supplier_name),FOREIGNKEY(branch_id)REFERENCESbranch(branch_id)ONDELETECASCADE);-- ----------------------------------------------------------------------------- -- Corporate INSERTINTOemployeeVALUES(100,'David','Wallace','1967-11-17','M',250000,NULL,NULL);INSERTINTObranchVALUES(1,'Corporate',100,'2006-02-09');UPDATEemployeeSETbranch_id=1WHEREemp_id=100;INSERTINTOemployeeVALUES(101,'Jan','Levinson','1961-05-11','F',110000,100,1);-- Scranton INSERTINTOemployeeVALUES(102,'Michael','Scott','1964-03-15','M',75000,100,NULL);INSERTINTObranchVALUES(2,'Scranton',102,'1992-04-06');UPDATEemployeeSETbranch_id=2WHEREemp_id=102;INSERTINTOemployeeVALUES(103,'Angela','Martin','1971-06-25','F',63000,102,2);INSERTINTOemployeeVALUES(104,'Kelly','Kapoor','1980-02-05','F',55000,102,2);INSERTINTOemployeeVALUES(105,'Stanley','Hudson','1958-02-19','M',69000,102,2);-- Stamford INSERTINTOemployeeVALUES(106,'Josh','Porter','1969-09-05','M',78000,100,NULL);INSERTINTObranchVALUES(3,'Stamford',106,'1998-02-13');UPDATEemployeeSETbranch_id=3WHEREemp_id=106;INSERTINTOemployeeVALUES(107,'Andy','Bernard','1973-07-22','M',65000,106,3);INSERTINTOemployeeVALUES(108,'Jim','Halpert','1978-10-01','M',71000,106,3);-- BRANCH SUPPLIER INSERTINTObranch_supplierVALUES(2,'Hammer Mill','Paper');INSERTINTObranch_supplierVALUES(2,'Uni-ball','Writing Utensils');INSERTINTObranch_supplierVALUES(3,'Patriot Paper','Paper');INSERTINTObranch_supplierVALUES(2,'J.T. Forms \u0026 Labels','Custom","date":"2021-12-25","objectID":"/sql/:0:5","series":[],"tags":["SQL"],"title":"SQL","uri":"/sql/#on-delete"},{"categories":["Note"],"content":"SQL Create a table INTDECIMAL(10,4)--total length of 10 and 4 after decimal point VARCHAR(1)BLOB--binary large object, stores large data DATE--YYYY-MM-DD TIMESTAMP--YYYY-MM-DD HH:MM:SS CREATETABLEstudent(student_idINTPRIMARYKEY,nameVARCHAR(20),majorVARCHAR(20)-- PRIMARY KEY(student_id) );--or you can define the primary key afterwards like above DESCRIBEstudent;DROPTABLEstudent;ALTERTABLEstudentADDgpaDECIMAL(3,2);--add column ALTERTABLEstudentDROPCOLUMNgpa;--drop column Insert data INSERTINTOstudentVALUES(1,'Jack','Biology');INSERTINTOstudentVALUES(2,'Kate','Sociology');SELECT*FROMstudent;--grab all the info from the table INSERTINTOstudent(student_id,name)VALUES(3,'Claire');INSERTINTOstudentVALUES(4,'Jack','Biology');INSERTINTOstudentVALUES(5,'Mike','Computer Science'); C CREATETABLEstudent(student_idINTUNIQUE,--student_id INT AUTO_INCREMENT, nameVARCHAR(20)NOTNULL,majorVARCHAR(20)DEFAULT'undecided');--then insert all data --primary key is both not null and unique Update and Delete UPDATEstudentSETmajor='Bio'WHEREmajor='Biology';UPDATEstudentSETmajor='Comp Sci'WHEREstudent_id=1ORmajor='Chemistry'UPDATEstudentSETname='Tom',Major='Undecided'WHEREstudent_id=1;UPDATEstudentSETmajor='undecided';DELETEFROMstudent;--delete all columns and rows DELETEFROMstudentWHEREstudent_id=5ANDmajor='undecided'; Basic Queries SELECT*FROMstudent;SELECTstudent.name,student.majorFROMstudentORDERBYstudent_idDESC;SELECTname,majorFROMstudentORDERBYmajor,student_idLIMIT3WHEREmajor='Biology'ORname'Kate';-- , =, =, , AND, OR SELECT*FROMstudentWHEREnameIN('Claire','Kate','Mike'); Company Database Into CREATETABLEemployee(emp_idINTPRIMARYKEY,first_nameVARCHAR(40),last_nameVARCHAR(40),birth_dayDATE,sexVARCHAR(1),salaryINT,super_idINT,branch_idINT);CREATETABLEbranch(branch_idINTPRIMARYKEY,branch_nameVARCHAR(40),mgr_idINT,mgr_start_dateDATE,FOREIGNKEY(mgr_id)REFERENCESemployee(emp_id)ONDELETESETNULL);ALTERTABLEemployeeADDFOREIGNKEY(branch_id)REFERENCESbranch(branch_id)ONDELETESETNULL;ALTERTABLEemployeeADDFOREIGNKEY(super_id)REFERENCESemployee(emp_id)ONDELETESETNULL;CREATETABLEclient(client_idINTPRIMARYKEY,client_nameVARCHAR(40),branch_idINT,FOREIGNKEY(branch_id)REFERENCESbranch(branch_id)ONDELETESETNULL);CREATETABLEworks_with(emp_idINT,client_idINT,total_salesINT,PRIMARYKEY(emp_id,client_id),FOREIGNKEY(emp_id)REFERENCESemployee(emp_id)ONDELETECASCADE,FOREIGNKEY(client_id)REFERENCESclient(client_id)ONDELETECASCADE);CREATETABLEbranch_supplier(branch_idINT,supplier_nameVARCHAR(40),supply_typeVARCHAR(40),PRIMARYKEY(branch_id,supplier_name),FOREIGNKEY(branch_id)REFERENCESbranch(branch_id)ONDELETECASCADE);-- ----------------------------------------------------------------------------- -- Corporate INSERTINTOemployeeVALUES(100,'David','Wallace','1967-11-17','M',250000,NULL,NULL);INSERTINTObranchVALUES(1,'Corporate',100,'2006-02-09');UPDATEemployeeSETbranch_id=1WHEREemp_id=100;INSERTINTOemployeeVALUES(101,'Jan','Levinson','1961-05-11','F',110000,100,1);-- Scranton INSERTINTOemployeeVALUES(102,'Michael','Scott','1964-03-15','M',75000,100,NULL);INSERTINTObranchVALUES(2,'Scranton',102,'1992-04-06');UPDATEemployeeSETbranch_id=2WHEREemp_id=102;INSERTINTOemployeeVALUES(103,'Angela','Martin','1971-06-25','F',63000,102,2);INSERTINTOemployeeVALUES(104,'Kelly','Kapoor','1980-02-05','F',55000,102,2);INSERTINTOemployeeVALUES(105,'Stanley','Hudson','1958-02-19','M',69000,102,2);-- Stamford INSERTINTOemployeeVALUES(106,'Josh','Porter','1969-09-05','M',78000,100,NULL);INSERTINTObranchVALUES(3,'Stamford',106,'1998-02-13');UPDATEemployeeSETbranch_id=3WHEREemp_id=106;INSERTINTOemployeeVALUES(107,'Andy','Bernard','1973-07-22','M',65000,106,3);INSERTINTOemployeeVALUES(108,'Jim','Halpert','1978-10-01','M',71000,106,3);-- BRANCH SUPPLIER INSERTINTObranch_supplierVALUES(2,'Hammer Mill','Paper');INSERTINTObranch_supplierVALUES(2,'Uni-ball','Writing Utensils');INSERTINTObranch_supplierVALUES(3,'Patriot Paper','Paper');INSERTINTObranch_supplierVALUES(2,'J.T. Forms \u0026 Labels','Custom","date":"2021-12-25","objectID":"/sql/:0:5","series":[],"tags":["SQL"],"title":"SQL","uri":"/sql/#triggers"},{"categories":["Note"],"content":"SQL Create a table INTDECIMAL(10,4)--total length of 10 and 4 after decimal point VARCHAR(1)BLOB--binary large object, stores large data DATE--YYYY-MM-DD TIMESTAMP--YYYY-MM-DD HH:MM:SS CREATETABLEstudent(student_idINTPRIMARYKEY,nameVARCHAR(20),majorVARCHAR(20)-- PRIMARY KEY(student_id) );--or you can define the primary key afterwards like above DESCRIBEstudent;DROPTABLEstudent;ALTERTABLEstudentADDgpaDECIMAL(3,2);--add column ALTERTABLEstudentDROPCOLUMNgpa;--drop column Insert data INSERTINTOstudentVALUES(1,'Jack','Biology');INSERTINTOstudentVALUES(2,'Kate','Sociology');SELECT*FROMstudent;--grab all the info from the table INSERTINTOstudent(student_id,name)VALUES(3,'Claire');INSERTINTOstudentVALUES(4,'Jack','Biology');INSERTINTOstudentVALUES(5,'Mike','Computer Science'); C CREATETABLEstudent(student_idINTUNIQUE,--student_id INT AUTO_INCREMENT, nameVARCHAR(20)NOTNULL,majorVARCHAR(20)DEFAULT'undecided');--then insert all data --primary key is both not null and unique Update and Delete UPDATEstudentSETmajor='Bio'WHEREmajor='Biology';UPDATEstudentSETmajor='Comp Sci'WHEREstudent_id=1ORmajor='Chemistry'UPDATEstudentSETname='Tom',Major='Undecided'WHEREstudent_id=1;UPDATEstudentSETmajor='undecided';DELETEFROMstudent;--delete all columns and rows DELETEFROMstudentWHEREstudent_id=5ANDmajor='undecided'; Basic Queries SELECT*FROMstudent;SELECTstudent.name,student.majorFROMstudentORDERBYstudent_idDESC;SELECTname,majorFROMstudentORDERBYmajor,student_idLIMIT3WHEREmajor='Biology'ORname'Kate';-- , =, =, , AND, OR SELECT*FROMstudentWHEREnameIN('Claire','Kate','Mike'); Company Database Into CREATETABLEemployee(emp_idINTPRIMARYKEY,first_nameVARCHAR(40),last_nameVARCHAR(40),birth_dayDATE,sexVARCHAR(1),salaryINT,super_idINT,branch_idINT);CREATETABLEbranch(branch_idINTPRIMARYKEY,branch_nameVARCHAR(40),mgr_idINT,mgr_start_dateDATE,FOREIGNKEY(mgr_id)REFERENCESemployee(emp_id)ONDELETESETNULL);ALTERTABLEemployeeADDFOREIGNKEY(branch_id)REFERENCESbranch(branch_id)ONDELETESETNULL;ALTERTABLEemployeeADDFOREIGNKEY(super_id)REFERENCESemployee(emp_id)ONDELETESETNULL;CREATETABLEclient(client_idINTPRIMARYKEY,client_nameVARCHAR(40),branch_idINT,FOREIGNKEY(branch_id)REFERENCESbranch(branch_id)ONDELETESETNULL);CREATETABLEworks_with(emp_idINT,client_idINT,total_salesINT,PRIMARYKEY(emp_id,client_id),FOREIGNKEY(emp_id)REFERENCESemployee(emp_id)ONDELETECASCADE,FOREIGNKEY(client_id)REFERENCESclient(client_id)ONDELETECASCADE);CREATETABLEbranch_supplier(branch_idINT,supplier_nameVARCHAR(40),supply_typeVARCHAR(40),PRIMARYKEY(branch_id,supplier_name),FOREIGNKEY(branch_id)REFERENCESbranch(branch_id)ONDELETECASCADE);-- ----------------------------------------------------------------------------- -- Corporate INSERTINTOemployeeVALUES(100,'David','Wallace','1967-11-17','M',250000,NULL,NULL);INSERTINTObranchVALUES(1,'Corporate',100,'2006-02-09');UPDATEemployeeSETbranch_id=1WHEREemp_id=100;INSERTINTOemployeeVALUES(101,'Jan','Levinson','1961-05-11','F',110000,100,1);-- Scranton INSERTINTOemployeeVALUES(102,'Michael','Scott','1964-03-15','M',75000,100,NULL);INSERTINTObranchVALUES(2,'Scranton',102,'1992-04-06');UPDATEemployeeSETbranch_id=2WHEREemp_id=102;INSERTINTOemployeeVALUES(103,'Angela','Martin','1971-06-25','F',63000,102,2);INSERTINTOemployeeVALUES(104,'Kelly','Kapoor','1980-02-05','F',55000,102,2);INSERTINTOemployeeVALUES(105,'Stanley','Hudson','1958-02-19','M',69000,102,2);-- Stamford INSERTINTOemployeeVALUES(106,'Josh','Porter','1969-09-05','M',78000,100,NULL);INSERTINTObranchVALUES(3,'Stamford',106,'1998-02-13');UPDATEemployeeSETbranch_id=3WHEREemp_id=106;INSERTINTOemployeeVALUES(107,'Andy','Bernard','1973-07-22','M',65000,106,3);INSERTINTOemployeeVALUES(108,'Jim','Halpert','1978-10-01','M',71000,106,3);-- BRANCH SUPPLIER INSERTINTObranch_supplierVALUES(2,'Hammer Mill','Paper');INSERTINTObranch_supplierVALUES(2,'Uni-ball','Writing Utensils');INSERTINTObranch_supplierVALUES(3,'Patriot Paper','Paper');INSERTINTObranch_supplierVALUES(2,'J.T. Forms \u0026 Labels','Custom","date":"2021-12-25","objectID":"/sql/:0:5","series":[],"tags":["SQL"],"title":"SQL","uri":"/sql/#er-diagrams-intro"},{"categories":["Note"],"content":"SQL Create a table INTDECIMAL(10,4)--total length of 10 and 4 after decimal point VARCHAR(1)BLOB--binary large object, stores large data DATE--YYYY-MM-DD TIMESTAMP--YYYY-MM-DD HH:MM:SS CREATETABLEstudent(student_idINTPRIMARYKEY,nameVARCHAR(20),majorVARCHAR(20)-- PRIMARY KEY(student_id) );--or you can define the primary key afterwards like above DESCRIBEstudent;DROPTABLEstudent;ALTERTABLEstudentADDgpaDECIMAL(3,2);--add column ALTERTABLEstudentDROPCOLUMNgpa;--drop column Insert data INSERTINTOstudentVALUES(1,'Jack','Biology');INSERTINTOstudentVALUES(2,'Kate','Sociology');SELECT*FROMstudent;--grab all the info from the table INSERTINTOstudent(student_id,name)VALUES(3,'Claire');INSERTINTOstudentVALUES(4,'Jack','Biology');INSERTINTOstudentVALUES(5,'Mike','Computer Science'); C CREATETABLEstudent(student_idINTUNIQUE,--student_id INT AUTO_INCREMENT, nameVARCHAR(20)NOTNULL,majorVARCHAR(20)DEFAULT'undecided');--then insert all data --primary key is both not null and unique Update and Delete UPDATEstudentSETmajor='Bio'WHEREmajor='Biology';UPDATEstudentSETmajor='Comp Sci'WHEREstudent_id=1ORmajor='Chemistry'UPDATEstudentSETname='Tom',Major='Undecided'WHEREstudent_id=1;UPDATEstudentSETmajor='undecided';DELETEFROMstudent;--delete all columns and rows DELETEFROMstudentWHEREstudent_id=5ANDmajor='undecided'; Basic Queries SELECT*FROMstudent;SELECTstudent.name,student.majorFROMstudentORDERBYstudent_idDESC;SELECTname,majorFROMstudentORDERBYmajor,student_idLIMIT3WHEREmajor='Biology'ORname'Kate';-- , =, =, , AND, OR SELECT*FROMstudentWHEREnameIN('Claire','Kate','Mike'); Company Database Into CREATETABLEemployee(emp_idINTPRIMARYKEY,first_nameVARCHAR(40),last_nameVARCHAR(40),birth_dayDATE,sexVARCHAR(1),salaryINT,super_idINT,branch_idINT);CREATETABLEbranch(branch_idINTPRIMARYKEY,branch_nameVARCHAR(40),mgr_idINT,mgr_start_dateDATE,FOREIGNKEY(mgr_id)REFERENCESemployee(emp_id)ONDELETESETNULL);ALTERTABLEemployeeADDFOREIGNKEY(branch_id)REFERENCESbranch(branch_id)ONDELETESETNULL;ALTERTABLEemployeeADDFOREIGNKEY(super_id)REFERENCESemployee(emp_id)ONDELETESETNULL;CREATETABLEclient(client_idINTPRIMARYKEY,client_nameVARCHAR(40),branch_idINT,FOREIGNKEY(branch_id)REFERENCESbranch(branch_id)ONDELETESETNULL);CREATETABLEworks_with(emp_idINT,client_idINT,total_salesINT,PRIMARYKEY(emp_id,client_id),FOREIGNKEY(emp_id)REFERENCESemployee(emp_id)ONDELETECASCADE,FOREIGNKEY(client_id)REFERENCESclient(client_id)ONDELETECASCADE);CREATETABLEbranch_supplier(branch_idINT,supplier_nameVARCHAR(40),supply_typeVARCHAR(40),PRIMARYKEY(branch_id,supplier_name),FOREIGNKEY(branch_id)REFERENCESbranch(branch_id)ONDELETECASCADE);-- ----------------------------------------------------------------------------- -- Corporate INSERTINTOemployeeVALUES(100,'David','Wallace','1967-11-17','M',250000,NULL,NULL);INSERTINTObranchVALUES(1,'Corporate',100,'2006-02-09');UPDATEemployeeSETbranch_id=1WHEREemp_id=100;INSERTINTOemployeeVALUES(101,'Jan','Levinson','1961-05-11','F',110000,100,1);-- Scranton INSERTINTOemployeeVALUES(102,'Michael','Scott','1964-03-15','M',75000,100,NULL);INSERTINTObranchVALUES(2,'Scranton',102,'1992-04-06');UPDATEemployeeSETbranch_id=2WHEREemp_id=102;INSERTINTOemployeeVALUES(103,'Angela','Martin','1971-06-25','F',63000,102,2);INSERTINTOemployeeVALUES(104,'Kelly','Kapoor','1980-02-05','F',55000,102,2);INSERTINTOemployeeVALUES(105,'Stanley','Hudson','1958-02-19','M',69000,102,2);-- Stamford INSERTINTOemployeeVALUES(106,'Josh','Porter','1969-09-05','M',78000,100,NULL);INSERTINTObranchVALUES(3,'Stamford',106,'1998-02-13');UPDATEemployeeSETbranch_id=3WHEREemp_id=106;INSERTINTOemployeeVALUES(107,'Andy','Bernard','1973-07-22','M',65000,106,3);INSERTINTOemployeeVALUES(108,'Jim','Halpert','1978-10-01','M',71000,106,3);-- BRANCH SUPPLIER INSERTINTObranch_supplierVALUES(2,'Hammer Mill','Paper');INSERTINTObranch_supplierVALUES(2,'Uni-ball','Writing Utensils');INSERTINTObranch_supplierVALUES(3,'Patriot Paper','Paper');INSERTINTObranch_supplierVALUES(2,'J.T. Forms \u0026 Labels','Custom","date":"2021-12-25","objectID":"/sql/:0:5","series":[],"tags":["SQL"],"title":"SQL","uri":"/sql/#designing-an-erd"},{"categories":["Note"],"content":"SQL Create a table INTDECIMAL(10,4)--total length of 10 and 4 after decimal point VARCHAR(1)BLOB--binary large object, stores large data DATE--YYYY-MM-DD TIMESTAMP--YYYY-MM-DD HH:MM:SS CREATETABLEstudent(student_idINTPRIMARYKEY,nameVARCHAR(20),majorVARCHAR(20)-- PRIMARY KEY(student_id) );--or you can define the primary key afterwards like above DESCRIBEstudent;DROPTABLEstudent;ALTERTABLEstudentADDgpaDECIMAL(3,2);--add column ALTERTABLEstudentDROPCOLUMNgpa;--drop column Insert data INSERTINTOstudentVALUES(1,'Jack','Biology');INSERTINTOstudentVALUES(2,'Kate','Sociology');SELECT*FROMstudent;--grab all the info from the table INSERTINTOstudent(student_id,name)VALUES(3,'Claire');INSERTINTOstudentVALUES(4,'Jack','Biology');INSERTINTOstudentVALUES(5,'Mike','Computer Science'); C CREATETABLEstudent(student_idINTUNIQUE,--student_id INT AUTO_INCREMENT, nameVARCHAR(20)NOTNULL,majorVARCHAR(20)DEFAULT'undecided');--then insert all data --primary key is both not null and unique Update and Delete UPDATEstudentSETmajor='Bio'WHEREmajor='Biology';UPDATEstudentSETmajor='Comp Sci'WHEREstudent_id=1ORmajor='Chemistry'UPDATEstudentSETname='Tom',Major='Undecided'WHEREstudent_id=1;UPDATEstudentSETmajor='undecided';DELETEFROMstudent;--delete all columns and rows DELETEFROMstudentWHEREstudent_id=5ANDmajor='undecided'; Basic Queries SELECT*FROMstudent;SELECTstudent.name,student.majorFROMstudentORDERBYstudent_idDESC;SELECTname,majorFROMstudentORDERBYmajor,student_idLIMIT3WHEREmajor='Biology'ORname'Kate';-- , =, =, , AND, OR SELECT*FROMstudentWHEREnameIN('Claire','Kate','Mike'); Company Database Into CREATETABLEemployee(emp_idINTPRIMARYKEY,first_nameVARCHAR(40),last_nameVARCHAR(40),birth_dayDATE,sexVARCHAR(1),salaryINT,super_idINT,branch_idINT);CREATETABLEbranch(branch_idINTPRIMARYKEY,branch_nameVARCHAR(40),mgr_idINT,mgr_start_dateDATE,FOREIGNKEY(mgr_id)REFERENCESemployee(emp_id)ONDELETESETNULL);ALTERTABLEemployeeADDFOREIGNKEY(branch_id)REFERENCESbranch(branch_id)ONDELETESETNULL;ALTERTABLEemployeeADDFOREIGNKEY(super_id)REFERENCESemployee(emp_id)ONDELETESETNULL;CREATETABLEclient(client_idINTPRIMARYKEY,client_nameVARCHAR(40),branch_idINT,FOREIGNKEY(branch_id)REFERENCESbranch(branch_id)ONDELETESETNULL);CREATETABLEworks_with(emp_idINT,client_idINT,total_salesINT,PRIMARYKEY(emp_id,client_id),FOREIGNKEY(emp_id)REFERENCESemployee(emp_id)ONDELETECASCADE,FOREIGNKEY(client_id)REFERENCESclient(client_id)ONDELETECASCADE);CREATETABLEbranch_supplier(branch_idINT,supplier_nameVARCHAR(40),supply_typeVARCHAR(40),PRIMARYKEY(branch_id,supplier_name),FOREIGNKEY(branch_id)REFERENCESbranch(branch_id)ONDELETECASCADE);-- ----------------------------------------------------------------------------- -- Corporate INSERTINTOemployeeVALUES(100,'David','Wallace','1967-11-17','M',250000,NULL,NULL);INSERTINTObranchVALUES(1,'Corporate',100,'2006-02-09');UPDATEemployeeSETbranch_id=1WHEREemp_id=100;INSERTINTOemployeeVALUES(101,'Jan','Levinson','1961-05-11','F',110000,100,1);-- Scranton INSERTINTOemployeeVALUES(102,'Michael','Scott','1964-03-15','M',75000,100,NULL);INSERTINTObranchVALUES(2,'Scranton',102,'1992-04-06');UPDATEemployeeSETbranch_id=2WHEREemp_id=102;INSERTINTOemployeeVALUES(103,'Angela','Martin','1971-06-25','F',63000,102,2);INSERTINTOemployeeVALUES(104,'Kelly','Kapoor','1980-02-05','F',55000,102,2);INSERTINTOemployeeVALUES(105,'Stanley','Hudson','1958-02-19','M',69000,102,2);-- Stamford INSERTINTOemployeeVALUES(106,'Josh','Porter','1969-09-05','M',78000,100,NULL);INSERTINTObranchVALUES(3,'Stamford',106,'1998-02-13');UPDATEemployeeSETbranch_id=3WHEREemp_id=106;INSERTINTOemployeeVALUES(107,'Andy','Bernard','1973-07-22','M',65000,106,3);INSERTINTOemployeeVALUES(108,'Jim','Halpert','1978-10-01','M',71000,106,3);-- BRANCH SUPPLIER INSERTINTObranch_supplierVALUES(2,'Hammer Mill','Paper');INSERTINTObranch_supplierVALUES(2,'Uni-ball','Writing Utensils');INSERTINTObranch_supplierVALUES(3,'Patriot Paper','Paper');INSERTINTObranch_supplierVALUES(2,'J.T. Forms \u0026 Labels','Custom","date":"2021-12-25","objectID":"/sql/:0:5","series":[],"tags":["SQL"],"title":"SQL","uri":"/sql/#converting-erd-to-schema"},{"categories":["Note"],"content":"SSHD Setup Install openssh-server sudo apt-get install openssh-server Check if the sshd service is running ps -e | grep sshd If not, sudo /etc/init.d/ssh start If it’s for your LAN, then you may want to setup the static IP for your server Check your current ip ifconfig en0 Check current gateway For macOS user: netstat -nr | grep default For Linux user: ip route | grep default Notice that the sshd will start automatically on boot. If this is not what you want, you can remove this feature and start it manually. sudo systemctl diable ssh For security, you may want to change the default port # 22 to some other #. sudo vim /etc/ssh/sshd_config Now we can establish connection from the client ssh -p port# username@ip-addr If you use the default port #, then just use ssh username@ip-addr You can generate ssh key pair to avoid typing password on connection. ssh-keygen -t rsa then give the path to store it ssh-copy-id -u client-username -i name.pub -p port# username@ip copy the public key to the server, -u let the client user login without password. ssh -i private-key -p port# username@ip You can add the keys to ssh agent. ssh-add ssh-add -L to check the keys added. After logged in, go to .ssh/authorized_keys and make sure we haven’t added extra keys we don’t want to add. Now we can just use ssh -p port# ip to log in You can also add alias for the server in ~/.ssh/config vim ~/.ssh/config Host Alias HostName IP-addr User the username you want to log in as Port the port# you want to use then you can just use ssh alias for login You can use scp to upload or download files. scp local-file username@ip:path-on-server scp -r local-dir username@ip:path-on-server scp username@ip:path-on-server local-path scp -r username@ip:path-on-server local-path ","date":"2021-12-25","objectID":"/sshd-setup/:0:0","series":[],"tags":["Network"],"title":"SSHD Setup","uri":"/sshd-setup/#sshd-setup"},{"categories":["Note"],"content":"Notice If you want to log in as root, the you may want to edit `/etc/ssh/sshd_config` and change `#PermitRootLogin no` to `PermitRootLogin yes` Then `service ssh restart` You may need to use `ssh -T username@ip` for the purpose of verification ","date":"2021-12-25","objectID":"/sshd-setup/:0:1","series":[],"tags":["Network"],"title":"SSHD Setup","uri":"/sshd-setup/#notice"},{"categories":["Note"],"content":"#Solve the Prob: No Internet After Static IP Setup The reason is that we didn’t manually set up the DNS. So you may Ping 8.8.8.8 successfully, but not a regular website. sudo nano /etc/resolvconf/resolv.conf.d/head Write nameserver x.x.x.x y.y.y.y z.z.z.z Then reboot. This should solve your problem. ","date":"2021-12-25","objectID":"/set-up-static-ip/:0:0","series":[],"tags":["Network"],"title":"Static IP Setup","uri":"/set-up-static-ip/#"},{"categories":["Note"],"content":"Swift ","date":"2021-12-25","objectID":"/swift_note/:0:0","series":[],"tags":["Swift"],"title":"Swift","uri":"/swift_note/#swift"},{"categories":["Note"],"content":"Optional ","date":"2021-12-25","objectID":"/swift_note/:1:0","series":[],"tags":["Swift"],"title":"Swift","uri":"/swift_note/#optional"},{"categories":["Note"],"content":"Pointer ","date":"2021-12-25","objectID":"/swift_note/:2:0","series":[],"tags":["Swift"],"title":"Swift","uri":"/swift_note/#pointer"},{"categories":["Note"],"content":"~\u003e ","date":"2021-12-25","objectID":"/swift_note/:3:0","series":[],"tags":["Swift"],"title":"Swift","uri":"/swift_note/#heading"},{"categories":["Note"],"content":"is as ","date":"2021-12-25","objectID":"/swift_note/:4:0","series":[],"tags":["Swift"],"title":"Swift","uri":"/swift_note/#is-as"},{"categories":["Note"],"content":"closure let coffee: [String] = [\"Cappuccino\", \"Espresso\", \"Latte\", \"Ristretto\"] // normal func backward(_ n1: String, _ n2: String) -\u003e Bool { return n1 \u003e n2 } var reverseOrder = coffee.sorted(by: backward) /* RESULT: [\"Ristretto\", \"Latte\", \"Espresso\", \"Cappuccino\"] */ // inline reverseOrder = coffee.sorted(by: { (n1: String, n2: String) -\u003e Bool in return n1 \u003e n2 } ) // inferring type from context reverseOrder = coffee.sorted(by: { n1, n2 in return n1 \u003e n2 } ) // implicit returns from single-expression closure reverseOrder = coffee.sorted(by: { n1, n2 in n1 \u003e n2 } ) // shorthand arg names reverseOrder = coffee.sorted(by: { $0 \u003e $1 } ) /* $0 and $1 are closure’s first and second String arguments. */ // operator method reverseOrder = coffee.sorted(by: \u003e) /* RESULT: [\"Ristretto\", \"Latte\", \"Espresso\", \"Cappuccino\"] */ ","date":"2021-12-25","objectID":"/swift_note/:5:0","series":[],"tags":["Swift"],"title":"Swift","uri":"/swift_note/#closure"},{"categories":["Note"],"content":"Worth to know for loop is obsoleted in Swift 3. repeat…while in Swift works as do…while of other langs fallthrough keyword _ in func paras func myFunc(param1:String, _param2:String, _param3:String) {} // when we call the function, we don't need to specify the names. // note that the first param is always not externalized by default. $0 means the first param passed into the closure. let sorted_nums = numbers.sort {$0 \u003e $1} print(sorted_nums) let sorted_nums = numbers.sort { (first_obj, second_obj) in return first_obj \u003e second_obj} typealias works like typedef in C. ","date":"2021-12-25","objectID":"/swift_note/:6:0","series":[],"tags":["Swift"],"title":"Swift","uri":"/swift_note/#worth-to-know"},{"categories":["Note"],"content":"Topics in Algorithms Research Heometric folding algorithm folding a crease pattern -\u003e NP-complete design a crease pattern from a folded shape -\u003e P ","date":"2021-12-25","objectID":"/topics-in-algorithms-research/:0:1","series":[],"tags":["Algorithm"],"title":"Topics in Algorithm Research","uri":"/topics-in-algorithms-research/#topics-in-algorithms-research"},{"categories":["Note"],"content":"Topics in Algorithms Research Heometric folding algorithm folding a crease pattern - NP-complete design a crease pattern from a folded shape - P ","date":"2021-12-25","objectID":"/topics-in-algorithms-research/:0:1","series":[],"tags":["Algorithm"],"title":"Topics in Algorithm Research","uri":"/topics-in-algorithms-research/#heometric-folding-algorithm"},{"categories":["Note"],"content":"UML Class Diagrams ","date":"2021-12-25","objectID":"/uml-class-diagrams/:0:0","series":[],"tags":["UML"],"title":"UML","uri":"/uml-class-diagrams/#uml-class-diagrams"},{"categories":["Note"],"content":"Introduction In object-oriented programming, it’s not uncommon to visualize classes and their relationships using the Unified Modeling Language (UML). While UML has many different types of diagrams, this reading focusses only on UML class diagrams. ","date":"2021-12-25","objectID":"/uml-class-diagrams/:1:0","series":[],"tags":["UML"],"title":"UML","uri":"/uml-class-diagrams/#introduction"},{"categories":["Note"],"content":"Basic Class Diagram Consider the following UML class diagram: The diagram consists of a rectangle broken up vertically into three sections: Class name. In this case, the fully qualified name of the class is given. Sometimes, if multiple classes are given and assumed to be in the same package, then the simple name is used here instead. Variables. In UML, the variables of a class are called attributes. In this example, there are two private instance variables (indicated with a -) and one private static variable. In UML, attributes and methods are shown to be public with a + symbol to the left of the name. Static variables are underlined. Methods. In UML, the methods of a class are called operations. In this example, there is one public constructor, two public (indicated by +) instance methods, and one public static method. In UML, attributes and methods are shown to be public with a + symbol to the left of the name. Static methods are underlined. The diagram above gives enough information for a programmer (or a program) to generate the following Person.java file: package cs1302.example; public class Person { private String name; private int age; private static int personCounter; public Person(String name, int age) { ... } // Person public String getName() { ... } // getName public int getAge() { ... } // getAge public static int getPersonCounter() { ... } // getPersonCounter } // Person ","date":"2021-12-25","objectID":"/uml-class-diagrams/:1:1","series":[],"tags":["UML"],"title":"UML","uri":"/uml-class-diagrams/#basic-class-diagram"},{"categories":["Note"],"content":"Visibilities UML supports the standard four visibilities: Visibility Name Modifier Keyword UML Symbol private private - package private ~ protected protected # public public + For an in-depth discussion on visibilities, see the Visibility Reading. ","date":"2021-12-25","objectID":"/uml-class-diagrams/:1:2","series":[],"tags":["UML"],"title":"UML","uri":"/uml-class-diagrams/#visibilities"},{"categories":["Note"],"content":"Atributes and Parameters (Variables) In UML, attributes and parameters are written in the following format: visibility name : type ","date":"2021-12-25","objectID":"/uml-class-diagrams/:1:3","series":[],"tags":["UML"],"title":"UML","uri":"/uml-class-diagrams/#atributes-and-parameters-variables"},{"categories":["Note"],"content":"Operations (Methods) In UML, operations are written in the following format: visibility [\u003c\u003cstereotype\u003e\u003e] methodName(param1: type, param2: type): returnType ","date":"2021-12-25","objectID":"/uml-class-diagrams/:1:4","series":[],"tags":["UML"],"title":"UML","uri":"/uml-class-diagrams/#operations-methods"},{"categories":["Note"],"content":"Stereotypes A stereotype is optional and is used to convey additional information. For example, you might use the following stereotypes in different situations: Stereotype Description \u003c\u003cnew\u003e\u003e Denotes constructor. \u003c\u003cabstract\u003e\u003e Denotes abstract. \u003c\u003coverride\u003e\u003e Denotes override. \u003c\u003cinterface\u003e\u003e Denotes interface. \u003c\u003cfinal\u003e\u003e Denotes final. ","date":"2021-12-25","objectID":"/uml-class-diagrams/:1:5","series":[],"tags":["UML"],"title":"UML","uri":"/uml-class-diagrams/#stereotypes"},{"categories":["Note"],"content":"Abstract Classes and Operations The usual way to denote that a class or operation is abstract is to italicize the name of class or operation. Sometimes this is impractical in situations where it’s difficult to discern the difference between the normal lettering of a font and its italicized version. In such casses, the names might also be prefixed with an \u003c\u003cabstract\u003e\u003e stereotype in order to better communicate the intention to the viewer of the diagram. To illustrate the differences, consider the following three Shape classes: In the diagram, the first class on the left is not abstract and the other two are. While the italics in the middle class indicate that its abstract, it can be easily confused as a non-abstract class if viewed quickly. For this reason, we suggest you italicize and use a stereotype to indicate that a class is abstract just as is done with the third class in the diagram. ","date":"2021-12-25","objectID":"/uml-class-diagrams/:1:6","series":[],"tags":["UML"],"title":"UML","uri":"/uml-class-diagrams/#abstract-classes-and-operations"},{"categories":["Note"],"content":"Associations When you have more than one class in a diagram, you often want to express how they are associated. In UML, this is done with association arrows. While UML supports many different kinds of association arrows, the following are arguably the most common: Association Description Usage Solid line; open arrowhead. ClassA uses ClassB Solid line; unfilled triangle arrowhead. Child extends Parent Dashed line; unfilled triangle arrowhead. SomeClass implements SomeInterface It may seem nit picky, but each of these arrows is visually different with respect to its line and its arrowhead! ","date":"2021-12-25","objectID":"/uml-class-diagrams/:1:7","series":[],"tags":["UML"],"title":"UML","uri":"/uml-class-diagrams/#associations"},{"categories":["Note"],"content":"UML Software and Tools Before you continue reading, it’s important to note that you do not need a special program to work with UML. It’s quite possible (and encouraged) that you practice drawing UML digrams by hand either on paper or in your note-taking software. The purpose of a UML class diagram is to help visualize multiple classes and their relationships. Over the years, we’ve seen many students skip directly to using UML software and get frustrated. Since these programs have a learning curve, students spend too much time trying to figure out, for example, how to mark something as protected in the program when they could have simply written # had they done it by hand. Don’t get us wrong, these tools are great, and if you want to learn them, then you should. Just try to make sure it doesn’t impact your productivity, especially near a deadline. Below is a list of popular UML software programs. You are not required to have access to one for this course. While many of these programs do require a paid license, you are encouraged to seek out a free community edition or a free/reduced-price student license before making any purchases. If you find a tool that’s not in the list, then please share it on Piazza! Astah UML Diagrams.net StarUML Umbrello UML Designer Visual Paradigm You may be surprised by how much a regular license costs for some of the programs above. In practice, if you need a program like this for your job, then it’s not uncommon for your company to pay for the license just as many companies do for programs like Microsoft Word, Adobe Photoshop, etc. Copyright © Michael E. Cotterell, Bradley J. Barnes, and the University of Georgia. This work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License to students and the public. The content and opinions expressed on this Web page do not necessarily reflect the views of nor are they endorsed by the University of Georgia or the University System of Georgia. ","date":"2021-12-25","objectID":"/uml-class-diagrams/:2:0","series":[],"tags":["UML"],"title":"UML","uri":"/uml-class-diagrams/#uml-software-and-tools"},{"categories":["Note"],"content":"Termial Oriented Programming ","date":"2021-12-25","objectID":"/vim/:0:0","series":[],"tags":["Vim"],"title":"Vim","uri":"/vim/#termial-oriented-programming"},{"categories":["Note"],"content":"Some Useful Info https://vim-adventures.com/ This is a game for vim beginner. https://www.destroyallsoftware.com/screencasts This is an amazing guy introducing the power of the terminal. Doing everything in one terminal window is powerful. ","date":"2021-12-25","objectID":"/vim/:0:1","series":[],"tags":["Vim"],"title":"Vim","uri":"/vim/#some-useful-info"},{"categories":["Note"],"content":"Jobs Control jobs ps fg bg fg %1 kill %2 kill -9 24153 ./some_codes.sh \u0026 ctrl + z to suspend the current job including when you are in the Vim ctrl + c to kill the current job ","date":"2021-12-25","objectID":"/vim/:0:2","series":[],"tags":["Vim"],"title":"Vim","uri":"/vim/#jobs-control"},{"categories":["Note"],"content":"Map :map ,l :!g++ std=c++11 % -Wall -o name :map :map ,l :! ls -a :! command1 \u0026\u0026 command2 means that command 1 has to be suceeded before the command 2 runs :! c1 || c2 means that no matter c1 runs successfully or not the c2 will run :map ,l :w \u0026\u0026 :!g++ std=c++11 % -Wall -o name \u0026\u0026 name This is actually not a good practice since you may want to manually control when you save the file :vs :map move to the right vim session :! echo % prints out the current file name :!echo %:r prints out the current file name without extension, actually it just remove the very last extension, but you can use it multiple times. :!echo %:h header, it will give you just a . since the current folder is presented as . :!echo %:p:h this will give you the current folder’s full path :!echo %:p this is full path :!echo %:~ this is relative path to home, will stay unmodified if it’s not under home dir :!echo %:. reduced path e.g. test.txt :!mv currentPath newPath the way to rename a file or maybe add a plugin :map .. :e %:r_spec.rb it lets you jump to corresponding spec file And we also have many other map ways :nm[ap] :vm[ap] :xm[ap] and etc. which let you map the keys for diff modes :unmap .l :noremap lhs rhs means the map cannot be mapped recursively :remap works the oppsite :!! repeat the last one :ter Opens a terminal ","date":"2021-12-25","objectID":"/vim/:0:3","series":[],"tags":["Vim"],"title":"Vim","uri":"/vim/#map"},{"categories":["Note"],"content":"Commands verbs mm =\u003e mark here as m `m =\u003e go back to the mark m d =\u003e cut dw means delete a word c =\u003e change (delete and enter the insert mode) =\u003e indent v =\u003e visually select y =\u003e Yank (copy) u =\u003e undo ctrl+r =\u003e redo . =\u003e repeat the last operation motions w =\u003e word (forward by a “word”) b =\u003e back (back by a “word”) 2j =\u003e down 2 lines yy =\u003e copy the entire lines text object iw =\u003e “inner word” (works from anywhere in a word) it =\u003e “inner tag” (the contents of an HTML tag) i\" =\u003e “inner quotes” ip =\u003e “inner paragraph” as =\u003e “a sentence” Nouns –Parameterized Text Objects f =\u003e find the next character F reverse the direction t =\u003e find the next char but not include that char T reverse / search the next match ? reverse Combinations of Commands combination of these commands are already powerful and there are more to explore Relative Numbers :set relativenumber =\u003e this is so powerful!! Visual Mode is a Smell visual breaks repatability! be mindful of this, don;t use it unless you have to Custom Operators (https://www.youtube.com/watch?v=wlR5gYd6um0) Surround Commentary ReplaceWithRegister Titlecase Sort-motion System-copy Custom Text Objects Indent Entire Line Ruby block ","date":"2021-12-25","objectID":"/vim/:0:4","series":[],"tags":["Vim"],"title":"Vim","uri":"/vim/#commands"},{"categories":["Note"],"content":"Commands verbs mm = mark here as m `m = go back to the mark m d = cut dw means delete a word c = change (delete and enter the insert mode) = indent v = visually select y = Yank (copy) u = undo ctrl+r = redo . = repeat the last operation motions w = word (forward by a “word”) b = back (back by a “word”) 2j = down 2 lines yy = copy the entire lines text object iw = “inner word” (works from anywhere in a word) it = “inner tag” (the contents of an HTML tag) i\" = “inner quotes” ip = “inner paragraph” as = “a sentence” Nouns –Parameterized Text Objects f = find the next character F reverse the direction t = find the next char but not include that char T reverse / search the next match ? reverse Combinations of Commands combination of these commands are already powerful and there are more to explore Relative Numbers :set relativenumber = this is so powerful!! Visual Mode is a Smell visual breaks repatability! be mindful of this, don;t use it unless you have to Custom Operators (https://www.youtube.com/watch?v=wlR5gYd6um0) Surround Commentary ReplaceWithRegister Titlecase Sort-motion System-copy Custom Text Objects Indent Entire Line Ruby block ","date":"2021-12-25","objectID":"/vim/:0:4","series":[],"tags":["Vim"],"title":"Vim","uri":"/vim/#verbs"},{"categories":["Note"],"content":"Commands verbs mm = mark here as m `m = go back to the mark m d = cut dw means delete a word c = change (delete and enter the insert mode) = indent v = visually select y = Yank (copy) u = undo ctrl+r = redo . = repeat the last operation motions w = word (forward by a “word”) b = back (back by a “word”) 2j = down 2 lines yy = copy the entire lines text object iw = “inner word” (works from anywhere in a word) it = “inner tag” (the contents of an HTML tag) i\" = “inner quotes” ip = “inner paragraph” as = “a sentence” Nouns –Parameterized Text Objects f = find the next character F reverse the direction t = find the next char but not include that char T reverse / search the next match ? reverse Combinations of Commands combination of these commands are already powerful and there are more to explore Relative Numbers :set relativenumber = this is so powerful!! Visual Mode is a Smell visual breaks repatability! be mindful of this, don;t use it unless you have to Custom Operators (https://www.youtube.com/watch?v=wlR5gYd6um0) Surround Commentary ReplaceWithRegister Titlecase Sort-motion System-copy Custom Text Objects Indent Entire Line Ruby block ","date":"2021-12-25","objectID":"/vim/:0:4","series":[],"tags":["Vim"],"title":"Vim","uri":"/vim/#motions"},{"categories":["Note"],"content":"Commands verbs mm = mark here as m `m = go back to the mark m d = cut dw means delete a word c = change (delete and enter the insert mode) = indent v = visually select y = Yank (copy) u = undo ctrl+r = redo . = repeat the last operation motions w = word (forward by a “word”) b = back (back by a “word”) 2j = down 2 lines yy = copy the entire lines text object iw = “inner word” (works from anywhere in a word) it = “inner tag” (the contents of an HTML tag) i\" = “inner quotes” ip = “inner paragraph” as = “a sentence” Nouns –Parameterized Text Objects f = find the next character F reverse the direction t = find the next char but not include that char T reverse / search the next match ? reverse Combinations of Commands combination of these commands are already powerful and there are more to explore Relative Numbers :set relativenumber = this is so powerful!! Visual Mode is a Smell visual breaks repatability! be mindful of this, don;t use it unless you have to Custom Operators (https://www.youtube.com/watch?v=wlR5gYd6um0) Surround Commentary ReplaceWithRegister Titlecase Sort-motion System-copy Custom Text Objects Indent Entire Line Ruby block ","date":"2021-12-25","objectID":"/vim/:0:4","series":[],"tags":["Vim"],"title":"Vim","uri":"/vim/#text-object"},{"categories":["Note"],"content":"Commands verbs mm = mark here as m `m = go back to the mark m d = cut dw means delete a word c = change (delete and enter the insert mode) = indent v = visually select y = Yank (copy) u = undo ctrl+r = redo . = repeat the last operation motions w = word (forward by a “word”) b = back (back by a “word”) 2j = down 2 lines yy = copy the entire lines text object iw = “inner word” (works from anywhere in a word) it = “inner tag” (the contents of an HTML tag) i\" = “inner quotes” ip = “inner paragraph” as = “a sentence” Nouns –Parameterized Text Objects f = find the next character F reverse the direction t = find the next char but not include that char T reverse / search the next match ? reverse Combinations of Commands combination of these commands are already powerful and there are more to explore Relative Numbers :set relativenumber = this is so powerful!! Visual Mode is a Smell visual breaks repatability! be mindful of this, don;t use it unless you have to Custom Operators (https://www.youtube.com/watch?v=wlR5gYd6um0) Surround Commentary ReplaceWithRegister Titlecase Sort-motion System-copy Custom Text Objects Indent Entire Line Ruby block ","date":"2021-12-25","objectID":"/vim/:0:4","series":[],"tags":["Vim"],"title":"Vim","uri":"/vim/#nouns---parameterized-text-objects"},{"categories":["Note"],"content":"Commands verbs mm = mark here as m `m = go back to the mark m d = cut dw means delete a word c = change (delete and enter the insert mode) = indent v = visually select y = Yank (copy) u = undo ctrl+r = redo . = repeat the last operation motions w = word (forward by a “word”) b = back (back by a “word”) 2j = down 2 lines yy = copy the entire lines text object iw = “inner word” (works from anywhere in a word) it = “inner tag” (the contents of an HTML tag) i\" = “inner quotes” ip = “inner paragraph” as = “a sentence” Nouns –Parameterized Text Objects f = find the next character F reverse the direction t = find the next char but not include that char T reverse / search the next match ? reverse Combinations of Commands combination of these commands are already powerful and there are more to explore Relative Numbers :set relativenumber = this is so powerful!! Visual Mode is a Smell visual breaks repatability! be mindful of this, don;t use it unless you have to Custom Operators (https://www.youtube.com/watch?v=wlR5gYd6um0) Surround Commentary ReplaceWithRegister Titlecase Sort-motion System-copy Custom Text Objects Indent Entire Line Ruby block ","date":"2021-12-25","objectID":"/vim/:0:4","series":[],"tags":["Vim"],"title":"Vim","uri":"/vim/#combinations-of-commands"},{"categories":["Note"],"content":"Commands verbs mm = mark here as m `m = go back to the mark m d = cut dw means delete a word c = change (delete and enter the insert mode) = indent v = visually select y = Yank (copy) u = undo ctrl+r = redo . = repeat the last operation motions w = word (forward by a “word”) b = back (back by a “word”) 2j = down 2 lines yy = copy the entire lines text object iw = “inner word” (works from anywhere in a word) it = “inner tag” (the contents of an HTML tag) i\" = “inner quotes” ip = “inner paragraph” as = “a sentence” Nouns –Parameterized Text Objects f = find the next character F reverse the direction t = find the next char but not include that char T reverse / search the next match ? reverse Combinations of Commands combination of these commands are already powerful and there are more to explore Relative Numbers :set relativenumber = this is so powerful!! Visual Mode is a Smell visual breaks repatability! be mindful of this, don;t use it unless you have to Custom Operators (https://www.youtube.com/watch?v=wlR5gYd6um0) Surround Commentary ReplaceWithRegister Titlecase Sort-motion System-copy Custom Text Objects Indent Entire Line Ruby block ","date":"2021-12-25","objectID":"/vim/:0:4","series":[],"tags":["Vim"],"title":"Vim","uri":"/vim/#relative-numbers"},{"categories":["Note"],"content":"Commands verbs mm = mark here as m `m = go back to the mark m d = cut dw means delete a word c = change (delete and enter the insert mode) = indent v = visually select y = Yank (copy) u = undo ctrl+r = redo . = repeat the last operation motions w = word (forward by a “word”) b = back (back by a “word”) 2j = down 2 lines yy = copy the entire lines text object iw = “inner word” (works from anywhere in a word) it = “inner tag” (the contents of an HTML tag) i\" = “inner quotes” ip = “inner paragraph” as = “a sentence” Nouns –Parameterized Text Objects f = find the next character F reverse the direction t = find the next char but not include that char T reverse / search the next match ? reverse Combinations of Commands combination of these commands are already powerful and there are more to explore Relative Numbers :set relativenumber = this is so powerful!! Visual Mode is a Smell visual breaks repatability! be mindful of this, don;t use it unless you have to Custom Operators (https://www.youtube.com/watch?v=wlR5gYd6um0) Surround Commentary ReplaceWithRegister Titlecase Sort-motion System-copy Custom Text Objects Indent Entire Line Ruby block ","date":"2021-12-25","objectID":"/vim/:0:4","series":[],"tags":["Vim"],"title":"Vim","uri":"/vim/#visual-mode-is-a-smell"},{"categories":["Note"],"content":"Commands verbs mm = mark here as m `m = go back to the mark m d = cut dw means delete a word c = change (delete and enter the insert mode) = indent v = visually select y = Yank (copy) u = undo ctrl+r = redo . = repeat the last operation motions w = word (forward by a “word”) b = back (back by a “word”) 2j = down 2 lines yy = copy the entire lines text object iw = “inner word” (works from anywhere in a word) it = “inner tag” (the contents of an HTML tag) i\" = “inner quotes” ip = “inner paragraph” as = “a sentence” Nouns –Parameterized Text Objects f = find the next character F reverse the direction t = find the next char but not include that char T reverse / search the next match ? reverse Combinations of Commands combination of these commands are already powerful and there are more to explore Relative Numbers :set relativenumber = this is so powerful!! Visual Mode is a Smell visual breaks repatability! be mindful of this, don;t use it unless you have to Custom Operators (https://www.youtube.com/watch?v=wlR5gYd6um0) Surround Commentary ReplaceWithRegister Titlecase Sort-motion System-copy Custom Text Objects Indent Entire Line Ruby block ","date":"2021-12-25","objectID":"/vim/:0:4","series":[],"tags":["Vim"],"title":"Vim","uri":"/vim/#custom-operators-httpswwwyoutubecomwatchvwlr5gyd6um0"},{"categories":["Note"],"content":"Commands verbs mm = mark here as m `m = go back to the mark m d = cut dw means delete a word c = change (delete and enter the insert mode) = indent v = visually select y = Yank (copy) u = undo ctrl+r = redo . = repeat the last operation motions w = word (forward by a “word”) b = back (back by a “word”) 2j = down 2 lines yy = copy the entire lines text object iw = “inner word” (works from anywhere in a word) it = “inner tag” (the contents of an HTML tag) i\" = “inner quotes” ip = “inner paragraph” as = “a sentence” Nouns –Parameterized Text Objects f = find the next character F reverse the direction t = find the next char but not include that char T reverse / search the next match ? reverse Combinations of Commands combination of these commands are already powerful and there are more to explore Relative Numbers :set relativenumber = this is so powerful!! Visual Mode is a Smell visual breaks repatability! be mindful of this, don;t use it unless you have to Custom Operators (https://www.youtube.com/watch?v=wlR5gYd6um0) Surround Commentary ReplaceWithRegister Titlecase Sort-motion System-copy Custom Text Objects Indent Entire Line Ruby block ","date":"2021-12-25","objectID":"/vim/:0:4","series":[],"tags":["Vim"],"title":"Vim","uri":"/vim/#custom-text-objects"},{"categories":null,"content":"PceWlkr   Github: https://github.com/Peacewalker365   GPA(2019-now): \u003e3.9 ","date":"2021-12-12","objectID":"/about/:1:0","series":null,"tags":null,"title":"About ME","uri":"/about/#pcewlkr"},{"categories":null,"content":"Profile A quick learner and problem-solving-oriented senior student seeking opportunities to software developing, NLP, or image processing \u0026 recognition with AI. ","date":"2021-12-12","objectID":"/about/:1:1","series":null,"tags":null,"title":"About ME","uri":"/about/#profile"},{"categories":null,"content":"Projects InCollege CLI: A CLI based student platform developed with Python3 to communicate, learn skills, and post and find internships. Console2048: A console version 2048 game developed with C#. ATM: An event-driven GUI based software realized the basic functions of an ATM using Java. Data Structure \u0026 Algo Wheels: A collection of data structures and algorithms built from scratch using C/C++. Amazon Review Analysis Perform N-grams NLP using Python, Spark, and self-built Hadoop Cluster on Amazon official data set. Personal Blog Deploy personal tech blog using Hugo and github pages. CUDA Project Develop and optimize algorithms for Parallel Radix Partition and Spatial Distance Histogram Computation problems. ","date":"2021-12-12","objectID":"/about/:1:2","series":null,"tags":null,"title":"About ME","uri":"/about/#projects"},{"categories":null,"content":"Skills Programming Language: C/C++, Java, Python, Swift\u0026SwiftUI, CUDA, SQL Framework: Spring5, SpringBoot CS Basics: Design Patterns, Data Structure, Analysis of Algorithms, Operating Systems Dev Skills: Git, UML, Agile, bash/zsh, Jira, Hadoop Cluster ","date":"2021-12-12","objectID":"/about/:1:3","series":null,"tags":null,"title":"About ME","uri":"/about/#skills"},{"categories":null,"content":" first-post Share the knowledge and love. Read more... ","date":"2021-11-01","objectID":"/showcase/:0:0","series":null,"tags":null,"title":"Showcase","uri":"/showcase/#"},{"categories":null,"content":" You are not connected to the Internet, only cached pages will be available. ","date":"0001-01-01","objectID":"/offline/:0:0","series":null,"tags":null,"title":"Offline","uri":"/offline/#"}]